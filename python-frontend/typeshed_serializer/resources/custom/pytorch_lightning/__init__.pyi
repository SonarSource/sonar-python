from SonarPythonAnalyzerFakeStub import CustomStubBase
from typing import Any, Optional, Dict, List

class LightningModule(CustomStubBase):
    """PyTorch Lightning LightningModule base class"""

    def __init__(self) -> None: ...

    def training_step(self, batch: Any, batch_idx: int) -> Any: ...
    def validation_step(self, batch: Any, batch_idx: int) -> Any: ...
    def test_step(self, batch: Any, batch_idx: int) -> Any: ...
    def predict_step(self, batch: Any, batch_idx: int) -> Any: ...

    def training_epoch_end(self, outputs: Any) -> None: ...
    def validation_epoch_end(self, outputs: Any) -> None: ...
    def test_epoch_end(self, outputs: Any) -> None: ...

    def configure_optimizers(self) -> Any: ...

    def forward(self, *args: Any, **kwargs: Any) -> Any: ...

    # Properties commonly used in Lightning modules
    @property
    def current_epoch(self) -> int: ...

    @property
    def global_step(self) -> int: ...

    def state_dict(self) -> Dict[str, Any]: ...
    def load_state_dict(self, state_dict: Dict[str, Any]) -> None: ...


class Trainer(CustomStubBase):
    """PyTorch Lightning Trainer class"""

    def __init__(
        self,
        max_epochs: Optional[int] = None,
        callbacks: Optional[List[Any]] = None,
        **kwargs: Any
    ) -> None: ...

    def fit(self, model: LightningModule, **kwargs: Any) -> None: ...
    def test(self, model: LightningModule, **kwargs: Any) -> None: ...
    def predict(self, model: LightningModule, **kwargs: Any) -> None: ...

    def save_checkpoint(self, filepath: str) -> None: ...
    def load_from_checkpoint(self, checkpoint_path: str) -> LightningModule: ...
