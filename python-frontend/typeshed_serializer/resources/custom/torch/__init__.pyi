from SonarPythonAnalyzerFakeStub import CustomStubBase

import torch.nn as nn

from typing import Any, IO, Optional, Sequence, Union, Tuple, List

class Size(tuple):
    def __getitem__(self, index: int) -> int: ...
    def __len__(self) -> int: ...

class dtype(CustomStubBase): ...
class layout(CustomStubBase): ...
class device(CustomStubBase):
    def __init__(
        self,
        type: str,
        index: Optional[int] = ...,
    ) -> None: ...

class Tensor(CustomStubBase):
    # Properties
    @property
    def shape(self) -> Size: ...
    @property
    def size(self) -> Size: ...
    @property
    def dtype(self) -> dtype: ...
    @property
    def device(self) -> device: ...
    @property
    def ndim(self) -> int: ...
    @property
    def data(self) -> "Tensor": ...
    @property
    def grad(self) -> Optional["Tensor"]: ...
    @property
    def requires_grad(self) -> bool: ...
    @requires_grad.setter
    def requires_grad(self, value: bool) -> None: ...
    @property
    def is_leaf(self) -> bool: ...
    @property
    def grad_fn(self) -> Any: ...

    # Shape and size methods
    def size(self, dim: Optional[int] = ...) -> Union[Size, int]: ...
    def dim(self) -> int: ...
    def numel(self) -> int: ...
    def element_size(self) -> int: ...
    def nelement(self) -> int: ...

    # Data type and device methods
    def to(
        self,
        device: Optional[Union[device, str]] = ...,
        dtype: Optional[dtype] = ...,
        non_blocking: bool = ...,
        copy: bool = ...,
    ) -> "Tensor": ...
    def cuda(self, device: Optional[Union[int, str]] = ...) -> "Tensor": ...
    def cpu(self) -> "Tensor": ...
    def type(self, dtype: Optional[Union[dtype, str]] = ...) -> "Tensor": ...
    def float(self) -> "Tensor": ...
    def double(self) -> "Tensor": ...
    def int(self) -> "Tensor": ...
    def long(self) -> "Tensor": ...
    def bool(self) -> "Tensor": ...

    # Shape manipulation
    def view(self, *shape: int) -> "Tensor": ...
    def reshape(self, *shape: int) -> "Tensor": ...
    def resize_(self, *sizes: int) -> "Tensor": ...
    def squeeze(self, dim: Optional[int] = ...) -> "Tensor": ...
    def unsqueeze(self, dim: int) -> "Tensor": ...
    def transpose(self, dim0: int, dim1: int) -> "Tensor": ...
    def permute(self, *dims: int) -> "Tensor": ...
    def flatten(self, start_dim: int = ..., end_dim: int = ...) -> "Tensor": ...
    def expand(self, *sizes: Union[Size,int]) -> "Tensor": ...

    # Indexing and slicing
    def __getitem__(self, key: Any) -> "Tensor": ...
    def __setitem__(self, key: Any, value: Any) -> None: ...
    def select(self, dim: int, index: int) -> "Tensor": ...
    def index_select(self, dim: int, index: "Tensor") -> "Tensor": ...
    def masked_select(self, mask: "Tensor") -> "Tensor": ...

    # Mathematical operations
    def add(self, other: Union["Tensor", float, int], alpha: Union[float, int] = ...) -> "Tensor": ...
    def add_(self, other: Union["Tensor", float, int], alpha: Union[float, int] = ...) -> "Tensor": ...
    def sub(self, other: Union["Tensor", float, int], alpha: Union[float, int] = ...) -> "Tensor": ...
    def sub_(self, other: Union["Tensor", float, int], alpha: Union[float, int] = ...) -> "Tensor": ...
    def mul(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def mul_(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def div(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def div_(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def pow(self, exponent: Union["Tensor", float, int]) -> "Tensor": ...
    def pow_(self, exponent: Union["Tensor", float, int]) -> "Tensor": ...
    def sqrt(self) -> "Tensor": ...
    def sqrt_(self) -> "Tensor": ...
    def abs(self) -> "Tensor": ...
    def abs_(self) -> "Tensor": ...
    def neg(self) -> "Tensor": ...
    def neg_(self) -> "Tensor": ...

    # Additional mathematical functions with tensor method equivalents
    def exp(self) -> "Tensor": ...
    def exp_(self) -> "Tensor": ...
    def log(self) -> "Tensor": ...
    def log_(self) -> "Tensor": ...
    def sin(self) -> "Tensor": ...
    def sin_(self) -> "Tensor": ...
    def cos(self) -> "Tensor": ...
    def cos_(self) -> "Tensor": ...
    def tan(self) -> "Tensor": ...
    def tan_(self) -> "Tensor": ...
    def sinh(self) -> "Tensor": ...
    def sinh_(self) -> "Tensor": ...
    def cosh(self) -> "Tensor": ...
    def cosh_(self) -> "Tensor": ...
    def tanh(self) -> "Tensor": ...
    def tanh_(self) -> "Tensor": ...
    def floor(self) -> "Tensor": ...
    def floor_(self) -> "Tensor": ...
    def ceil(self) -> "Tensor": ...
    def ceil_(self) -> "Tensor": ...
    def round(self) -> "Tensor": ...
    def round_(self) -> "Tensor": ...
    def trunc(self) -> "Tensor": ...
    def trunc_(self) -> "Tensor": ...
    def frac(self) -> "Tensor": ...
    def frac_(self) -> "Tensor": ...
    def clamp(self, min: Optional[Union["Tensor", float]] = ..., max: Optional[Union["Tensor", float]] = ...) -> "Tensor": ...
    def clamp_(self, min: Optional[Union["Tensor", float]] = ..., max: Optional[Union["Tensor", float]] = ...) -> "Tensor": ...
    def sigmoid(self) -> "Tensor": ...
    def sigmoid_(self) -> "Tensor": ...
    def relu(self) -> "Tensor": ...
    def relu_(self) -> "Tensor": ...
    def leaky_relu(self, negative_slope: float = ...) -> "Tensor": ...
    def leaky_relu_(self, negative_slope: float = ...) -> "Tensor": ...
    def softmax(self, dim: int) -> "Tensor": ...
    def log_softmax(self, dim: int) -> "Tensor": ...
    def masked_fill(self, mask: "Tensor", value: Union[float, int]) -> "Tensor": ...
    def masked_fill_(self, mask: "Tensor", value: Union[float, int]) -> "Tensor": ...
    def index_fill(self, dim: int, index: "Tensor", value: Union[float, int]) -> "Tensor": ...
    def index_fill_(self, dim: int, index: "Tensor", value: Union[float, int]) -> "Tensor": ...
    def scatter(self, dim: int, index: "Tensor", src: Union["Tensor", float]) -> "Tensor": ...
    def scatter_(self, dim: int, index: "Tensor", src: Union["Tensor", float]) -> "Tensor": ...
    def copy(self, src: "Tensor", non_blocking: bool = ...) -> "Tensor": ...

    # Matrix operations
    def mm(self, mat2: "Tensor") -> "Tensor": ...
    def bmm(self, mat2: "Tensor") -> "Tensor": ...
    def matmul(self, other: "Tensor") -> "Tensor": ...
    def dot(self, other: "Tensor") -> "Tensor": ...
    
    # Reduction operations
    def sum(self, dim: Optional[Union[int, Tuple[int, ...]]] = ..., keepdim: bool = ...) -> "Tensor": ...
    def mean(self, dim: Optional[Union[int, Tuple[int, ...]]] = ..., keepdim: bool = ...) -> "Tensor": ...
    def max(self, dim: Optional[int] = ..., keepdim: bool = ...) -> Union["Tensor", Tuple["Tensor", "Tensor"]]: ...
    def min(self, dim: Optional[int] = ..., keepdim: bool = ...) -> Union["Tensor", Tuple["Tensor", "Tensor"]]: ...
    def std(self, dim: Optional[Union[int, Tuple[int, ...]]] = ..., keepdim: bool = ...) -> "Tensor": ...
    def var(self, dim: Optional[Union[int, Tuple[int, ...]]] = ..., keepdim: bool = ...) -> "Tensor": ...

    # Comparison operations
    def eq(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def ne(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def lt(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def le(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def gt(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def ge(self, other: Union["Tensor", float, int]) -> "Tensor": ...

    # Cloning and copying
    def clone(self) -> "Tensor": ...
    def detach(self) -> "Tensor": ...
    def detach_(self) -> "Tensor": ...
    def copy_(self, src: "Tensor", non_blocking: bool = ...) -> "Tensor": ...

    # Gradient methods
    def backward(
        self,
        gradient: Optional["Tensor"] = ...,
        retain_graph: Optional[bool] = ...,
        create_graph: bool = ...,
    ) -> None: ...
    def requires_grad_(self, requires_grad: bool = ...) -> "Tensor": ...
    def retain_grad(self) -> None: ...

    # Utility methods
    def item(self) -> Union[int, float, bool]: ...
    def tolist(self) -> List[Any]: ...
    def numpy(self) -> Any: ...  # numpy.ndarray would require numpy import

    # Magic methods
    def __add__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __sub__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __mul__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __truediv__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __pow__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __neg__(self) -> "Tensor": ...
    def __eq__(self, other: Any) -> "Tensor": ...  # type: ignore
    def __ne__(self, other: Any) -> "Tensor": ...  # type: ignore
    def __lt__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __le__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __gt__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __ge__(self, other: Union["Tensor", float, int]) -> "Tensor": ...
    def __len__(self) -> int: ...
    def __str__(self) -> str: ...
    def __repr__(self) -> str: ...

    def new_tensor(
        self,
        data: Any,
        dtype: Optional[dtype] = ...,
        device: Optional[Union[str, device]] = ...,
        requires_grad: Optional[bool] = ...,
        pin_memory: bool = ...,
    ) -> "Tensor": ...


# --- Common Tensor Creation Functions ---

def tensor(
    data: Any,
    dtype: Optional[dtype] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...


def empty(
    *size: int,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

def zeros(
    *size: int,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

def ones(
    *size: int,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

def rand(
    *size: int,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

def randn(
    *size: int,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

def arange(
    start: Union[int, float],
    end: Optional[Union[int, float]] = ...,
    step: Union[int, float] = ...,
    *,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

def full(
    size: Union[int, Sequence[int]],
    fill_value: Union[int, float],
    *,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

def eye(
    n: int,
    m: Optional[int] = ...,
    *,
    dtype: Optional[dtype] = ...,
    layout: Optional[layout] = ...,
    device: Optional[Union[str, device]] = ...,
    requires_grad: bool = ...,
    pin_memory: bool = ...,
) -> Tensor: ...

# --- Serialization Functions ---
def save(
        obj: object,
        f: Union[str, PathLike[str], IO[bytes]],
        pickle_module: Any = ...,
        pickle_protocol: int = ...,
        _use_new_zipfile_serialization: bool = ...
) -> None : ...

def load(
    f: Union[str, IO[bytes]],
    map_location: Optional[Union[str, device]] = ...,
    pickle_module: Any = ...,
    **pickle_load_args: Any
) -> Any: ...

# --- Mathematical Functions ---

def log(
    input: Tensor,
    *,
    out: Optional[Tensor] = ...,
) -> Tensor: ...

def exp(
    input: Tensor,
    *,
    out: Optional[Tensor] = ...,
) -> Tensor: ...

def log1p(
    input: Tensor,
    *,
    out: Optional[Tensor] = ...,
) -> Tensor: ...

def expm1(
    input: Tensor,
    *,
    out: Optional[Tensor] = ...,
) -> Tensor: ...

# --- Tensor manipulation ---

def cat(
    tensors: Sequence[Tensor],
    dim: int = 0,
    *,
    out: Optional[Tensor] = ...,
) -> Tensor: ...

def stack(
    tensors: Sequence[Tensor],
    dim: int = 0,
    *,
    out: Optional[Tensor] = ...,
) -> Tensor: ...

def flatten(intput:Tensor, start_dim: int = ..., end_dim: int = ...) -> Tensor: ...
