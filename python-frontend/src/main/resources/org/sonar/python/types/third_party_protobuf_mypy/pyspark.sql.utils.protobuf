
pyspark.sql.utilsÜ
ForeachBatchFunction&pyspark.sql.utils.ForeachBatchFunction"builtins.object*Ë
__init__/pyspark.sql.utils.ForeachBatchFunction.__init__"
None*Z
selfP
&pyspark.sql.utils.ForeachBatchFunction"&pyspark.sql.utils.ForeachBatchFunction*Q
sessionD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*×
call+pyspark.sql.utils.ForeachBatchFunction.call"
None*Z
selfP
&pyspark.sql.utils.ForeachBatchFunction"&pyspark.sql.utils.ForeachBatchFunction*
jdf
Any**
batch_id
builtins.int"builtins.intr€
func+pyspark.sql.utils.ForeachBatchFunction.funcK
CallableType[builtins.function]&
builtins.function"builtins.functionr
session.pyspark.sql.utils.ForeachBatchFunction.sessionD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionr_
error,pyspark.sql.utils.ForeachBatchFunction.error(
builtins.Exception"builtins.Exception”
toJArraypyspark.sql.utils.toJArray"
Any*
gateway
Any*
jtype
Any*9
arr0
typing.Sequence[Any]
Any"typing.SequenceJ
require_test_compiled'pyspark.sql.utils.require_test_compiled"
None|
to_strpyspark.sql.utils.to_str"D
Union[builtins.str,None]
builtins.str"builtins.str
None*
value
Anyj
is_timestamp_ntz_preferred,pyspark.sql.utils.is_timestamp_ntz_preferred"
builtins.bool"builtins.boolH
	is_remotepyspark.sql.utils.is_remote"
builtins.bool"builtins.bool™
try_remote_functions&pyspark.sql.utils.try_remote_functions"h
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function*o
fh
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function£
try_remote_avro_functions+pyspark.sql.utils.try_remote_avro_functions"h
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function*o
fh
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function«
try_remote_protobuf_functions/pyspark.sql.utils.try_remote_protobuf_functions"h
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function*o
fh
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function“
try_remote_window#pyspark.sql.utils.try_remote_window"h
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function*o
fh
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function›
try_remote_windowspec'pyspark.sql.utils.try_remote_windowspec"h
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function*o
fh
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function„
get_active_spark_context*pyspark.sql.utils.get_active_spark_context"<
pyspark.context.SparkContext"pyspark.context.SparkContext
try_remote_observation(pyspark.sql.utils.try_remote_observation"h
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function*o
fh
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function­
try_remote_session_classmethod0pyspark.sql.utils.try_remote_session_classmethod"h
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function*o
fh
pyspark.sql.utils.FuncTK
CallableType[builtins.function]&
builtins.function"builtins.function‰
pyspark_column_op#pyspark.sql.utils.pyspark_column_op"Ö
aUnion[TypeAlias[Union[pyspark.pandas.series.Series[Any],pyspark.pandas.indexes.base.Index]],None]ä
UTypeAlias[Union[pyspark.pandas.series.Series[Any],pyspark.pandas.indexes.base.Index]]â
JUnion[pyspark.pandas.series.Series[Any],pyspark.pandas.indexes.base.Index]J
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.SeriesF
!pyspark.pandas.indexes.base.Index"!pyspark.pandas.indexes.base.Index"$pyspark.pandas._typing.SeriesOrIndex
None*+
	func_name
builtins.str"builtins.str*
left’
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin*
right
Any*
fillna
Any ™
get_column_class"pyspark.sql.utils.get_column_class"a
Type[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"type±
get_dataframe_class%pyspark.sql.utils.get_dataframe_class"s
%Type[pyspark.sql.dataframe.DataFrame]B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame"type™
get_window_class"pyspark.sql.utils.get_window_class"a
Type[pyspark.sql.window.Window]6
pyspark.sql.window.Window"pyspark.sql.window.Window"type*
__annotations__!pyspark.sql.utils.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*1
	JavaArraypyspark.sql.utils.JavaArray
Any*1
	JavaClasspyspark.sql.utils.JavaClass
Any*5
JavaGatewaypyspark.sql.utils.JavaGateway
Any*3

JavaObjectpyspark.sql.utils.JavaObject
Any*H
	has_numpypyspark.sql.utils.has_numpy
builtins.bool"builtins.bool*
npnumpy 