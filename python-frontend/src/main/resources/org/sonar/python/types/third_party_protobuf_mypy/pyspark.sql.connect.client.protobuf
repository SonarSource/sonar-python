
pyspark.sql.connect.clientá%
ChannelBuilder.pyspark.sql.connect.client.core.ChannelBuilder"builtins.object*Ñ
default_port;pyspark.sql.connect.client.core.ChannelBuilder.default_port"
builtins.int"builtins.int0:builtins.staticmethodh*∑
__init__7pyspark.sql.connect.client.core.ChannelBuilder.__init__"
None*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder*%
url
builtins.str"builtins.str*‘
channelOptionsΩ
2Union[builtins.list[Tuple[builtins.str,Any]],None]{
&builtins.list[Tuple[builtins.str,Any]]B
Tuple[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.list
None *œ
_extract_attributesBpyspark.sql.connect.client.core.ChannelBuilder._extract_attributes"
None*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder*ÿ
metadata7pyspark.sql.connect.client.core.ChannelBuilder.metadata"¶
1typing.Iterable[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Iterable*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder*‚
secure5pyspark.sql.connect.client.core.ChannelBuilder.secure"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder0:builtins.property`*‰
endpoint7pyspark.sql.connect.client.core.ChannelBuilder.endpoint"
builtins.str"builtins.str*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder0:builtins.property`*à
_token5pyspark.sql.connect.client.core.ChannelBuilder._token"D
Union[builtins.str,None]
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder0:builtins.property`*à
userId5pyspark.sql.connect.client.core.ChannelBuilder.userId"D
Union[builtins.str,None]
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder0:builtins.property`*Ê
	userAgent8pyspark.sql.connect.client.core.ChannelBuilder.userAgent"
builtins.str"builtins.str*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder0:builtins.property`*’
get2pyspark.sql.connect.client.core.ChannelBuilder.get"
Any*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder*%
key
builtins.str"builtins.str*ê

session_id9pyspark.sql.connect.client.core.ChannelBuilder.session_id"D
Union[builtins.str,None]
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder0:builtins.property`*∫
	toChannel8pyspark.sql.connect.client.core.ChannelBuilder.toChannel"
Any*j
self`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilderrk
PARAM_USE_SSL<pyspark.sql.connect.client.core.ChannelBuilder.PARAM_USE_SSL
builtins.str"builtins.strrg
PARAM_TOKEN:pyspark.sql.connect.client.core.ChannelBuilder.PARAM_TOKEN
builtins.str"builtins.strrk
PARAM_USER_ID<pyspark.sql.connect.client.core.ChannelBuilder.PARAM_USER_ID
builtins.str"builtins.strrq
PARAM_USER_AGENT?pyspark.sql.connect.client.core.ChannelBuilder.PARAM_USER_AGENT
builtins.str"builtins.strrq
PARAM_SESSION_ID?pyspark.sql.connect.client.core.ChannelBuilder.PARAM_SESSION_ID
builtins.str"builtins.strru
MAX_MESSAGE_LENGTHApyspark.sql.connect.client.core.ChannelBuilder.MAX_MESSAGE_LENGTH
builtins.int"builtins.intr»
url2pyspark.sql.connect.client.core.ChannelBuilder.urlå
TTuple[builtins.str,builtins.str,builtins.str,builtins.str,builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str
builtins.str"builtins.str
builtins.str"builtins.str
builtins.str"builtins.str
builtins.str"builtins.strr∂
params5pyspark.sql.connect.client.core.ChannelBuilder.paramsu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dictr¯
_channel_options?pyspark.sql.connect.client.core.ChannelBuilder._channel_options¢
/builtins.list[Tuple[builtins.str,builtins.int]]`
 Tuple[builtins.str,builtins.int]
builtins.str"builtins.str
builtins.int"builtins.int"builtins.listrY
host3pyspark.sql.connect.client.core.ChannelBuilder.host
builtins.str"builtins.strrY
port3pyspark.sql.connect.client.core.ChannelBuilder.port
builtins.int"builtins.int¢®
SparkConnectClient2pyspark.sql.connect.client.core.SparkConnectClient"builtins.object*˘
retry_exceptionBpyspark.sql.connect.client.core.SparkConnectClient.retry_exception"
builtins.bool"builtins.bool*∂
cls¨
8Type[pyspark.sql.connect.client.core.SparkConnectClient]h
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient"type*/
e(
builtins.Exception"builtins.Exception0:builtins.classmethodp*∂
__init__;pyspark.sql.connect.client.core.SparkConnectClient.__init__"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*◊

connection∆
BUnion[builtins.str,pyspark.sql.connect.client.core.ChannelBuilder]
builtins.str"builtins.str`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilder*S
user_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *’
channel_optionsΩ
2Union[builtins.list[Tuple[builtins.str,Any]],None]{
&builtins.list[Tuple[builtins.str,Any]]B
Tuple[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.list
None *ß
retry_policyí
+Union[builtins.dict[builtins.str,Any],None]W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict
None *>
use_reattachable_execute
builtins.bool"builtins.bool *ì
	_retrying<pyspark.sql.connect.client.core.SparkConnectClient._retrying"T
(pyspark.sql.connect.client.core.Retrying"(pyspark.sql.connect.client.core.Retrying*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*Õ
disable_reattachable_executeOpyspark.sql.connect.client.core.SparkConnectClient.disable_reattachable_execute"h
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*À
enable_reattachable_executeNpyspark.sql.connect.client.core.SparkConnectClient.enable_reattachable_execute"h
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*ª
register_udf?pyspark.sql.connect.client.core.SparkConnectClient.register_udf"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*
function
Any*ä
return_type¯
9TypeAlias[Union[pyspark.sql.types.DataType,builtins.str]]ä
.Union[pyspark.sql.types.DataType,builtins.str]8
pyspark.sql.types.DataType"pyspark.sql.types.DataType
builtins.str"builtins.str",pyspark.sql.connect._typing.DataTypeOrString*P
nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *-
	eval_type
builtins.int"builtins.int *3
deterministic
builtins.bool"builtins.bool *ì
register_udtf@pyspark.sql.connect.client.core.SparkConnectClient.register_udtf"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*
function
Any*ä
return_type¯
9TypeAlias[Union[pyspark.sql.types.DataType,builtins.str]]ä
.Union[pyspark.sql.types.DataType,builtins.str]8
pyspark.sql.types.DataType"pyspark.sql.types.DataType
builtins.str"builtins.str",pyspark.sql.connect._typing.DataTypeOrString*&
name
builtins.str"builtins.str*-
	eval_type
builtins.int"builtins.int *3
deterministic
builtins.bool"builtins.bool *â
register_java@pyspark.sql.connect.client.core.SparkConnectClient.register_java"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*&
name
builtins.str"builtins.str*/
javaClassName
builtins.str"builtins.str*≠
return_typeô
3Union[pyspark.sql.types.DataType,builtins.str,None]8
pyspark.sql.types.DataType"pyspark.sql.types.DataType
builtins.str"builtins.str
None */
	aggregate
builtins.bool"builtins.bool *Ü
_build_metricsApyspark.sql.connect.client.core.SparkConnectClient._build_metrics"´
<typing.Iterator[pyspark.sql.connect.client.core.PlanMetrics]Z
+pyspark.sql.connect.client.core.PlanMetrics"+pyspark.sql.connect.client.core.PlanMetrics"typing.Iterator*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*é
metricsÄ
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*£

_resources=pyspark.sql.connect.client.core.SparkConnectClient._resources"·
Lbuiltins.dict[builtins.str,pyspark.resource.information.ResourceInformation]
builtins.str"builtins.strd
0pyspark.resource.information.ResourceInformation"0pyspark.resource.information.ResourceInformation"builtins.dict*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*≠
_build_observed_metricsJpyspark.sql.connect.client.core.SparkConnectClient._build_observed_metrics"√
Dtyping.Iterator[pyspark.sql.connect.client.core.PlanObservedMetrics]j
3pyspark.sql.connect.client.core.PlanObservedMetrics"3pyspark.sql.connect.client.core.PlanObservedMetrics"typing.Iterator*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*ã
metrics˝
Wtyping.Sequence[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics]ê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"typing.Sequence*Û
to_table_as_iteratorGpyspark.sql.connect.client.core.SparkConnectClient.to_table_as_iterator"ø
8typing.Iterator[Union[pyspark.sql.types.StructType,Any]]r
'Union[pyspark.sql.types.StructType,Any]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
Any"typing.Iterator*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*\
planR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*“
to_table;pyspark.sql.connect.client.core.SparkConnectClient.to_table"∂
3Tuple[Any,Union[pyspark.sql.types.StructType,None]]
Anyt
(Union[pyspark.sql.types.StructType,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*\
planR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*◊
	to_pandas<pyspark.sql.connect.client.core.SparkConnectClient.to_pandas":
pandas.core.frame.DataFrame"pandas.core.frame.DataFrame*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*\
planR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*˘
_proto_to_stringCpyspark.sql.connect.client.core.SparkConnectClient._proto_to_string"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*
p
Any*”
schema9pyspark.sql.connect.client.core.SparkConnectClient.schema"<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*\
planR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ı
explain_stringApyspark.sql.connect.client.core.SparkConnectClient.explain_string"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*\
planR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*0
explain_mode
builtins.str"builtins.str *Ÿ
execute_commandBpyspark.sql.connect.client.core.SparkConnectClient.execute_command"û
NTuple[Union[pandas.core.frame.DataFrame,None],builtins.dict[builtins.str,Any]]q
'Union[pandas.core.frame.DataFrame,None]:
pandas.core.frame.DataFrame"pandas.core.frame.DataFrame
NoneW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*m
command`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*§
same_semanticsApyspark.sql.connect.client.core.SparkConnectClient.same_semantics"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*\
planR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*]
otherR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*¡
semantic_hash@pyspark.sql.connect.client.core.SparkConnectClient.semantic_hash"
builtins.int"builtins.int*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*\
planR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ø
close8pyspark.sql.connect.client.core.SparkConnectClient.close"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*Ù
	is_closed<pyspark.sql.connect.client.core.SparkConnectClient.is_closed"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient0:builtins.property`*Ë
host7pyspark.sql.connect.client.core.SparkConnectClient.host"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient0:builtins.property`*í
token8pyspark.sql.connect.client.core.SparkConnectClient.token"D
Union[builtins.str,None]
builtins.str"builtins.str
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient0:builtins.property`*·
#_execute_plan_request_with_metadataVpyspark.sql.connect.client.core.SparkConnectClient._execute_plan_request_with_metadata"n
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*·
#_analyze_plan_request_with_metadataVpyspark.sql.connect.client.core.SparkConnectClient._analyze_plan_request_with_metadata"n
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*⁄
_analyze;pyspark.sql.connect.client.core.SparkConnectClient._analyze"^
-pyspark.sql.connect.client.core.AnalyzeResult"-pyspark.sql.connect.client.core.AnalyzeResult*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*(
method
builtins.str"builtins.str*
kwargs
Any*æ
_execute;pyspark.sql.connect.client.core.SparkConnectClient._execute"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*w
reqn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*∆
_execute_and_fetch_as_iteratorQpyspark.sql.connect.client.core.SparkConnectClient._execute_and_fetch_as_iterator"„
∏typing.Iterator[Union[Any,pyspark.sql.types.StructType,pyspark.sql.connect.client.core.PlanMetrics,pyspark.sql.connect.client.core.PlanObservedMetrics,builtins.dict[builtins.str,Any]]]î
ßUnion[Any,pyspark.sql.types.StructType,pyspark.sql.connect.client.core.PlanMetrics,pyspark.sql.connect.client.core.PlanObservedMetrics,builtins.dict[builtins.str,Any]]
Any<
pyspark.sql.types.StructType"pyspark.sql.types.StructTypeZ
+pyspark.sql.connect.client.core.PlanMetrics"+pyspark.sql.connect.client.core.PlanMetricsj
3pyspark.sql.connect.client.core.PlanObservedMetrics"3pyspark.sql.connect.client.core.PlanObservedMetricsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict"typing.Iterator*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*w
reqn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*≈	
_execute_and_fetchEpyspark.sql.connect.client.core.SparkConnectClient._execute_and_fetch"≈
›Tuple[Union[Any,None],Union[pyspark.sql.types.StructType,None],builtins.list[pyspark.sql.connect.client.core.PlanMetrics],builtins.list[pyspark.sql.connect.client.core.PlanObservedMetrics],builtins.dict[builtins.str,Any]]&
Union[Any,None]
Any
Nonet
(Union[pyspark.sql.types.StructType,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
Noneß
:builtins.list[pyspark.sql.connect.client.core.PlanMetrics]Z
+pyspark.sql.connect.client.core.PlanMetrics"+pyspark.sql.connect.client.core.PlanMetrics"builtins.listø
Bbuiltins.list[pyspark.sql.connect.client.core.PlanObservedMetrics]j
3pyspark.sql.connect.client.core.PlanObservedMetrics"3pyspark.sql.connect.client.core.PlanObservedMetrics"builtins.listW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*w
reqn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*3
self_destruct
builtins.bool"builtins.bool *À
_config_request_with_metadataPpyspark.sql.connect.client.core.SparkConnectClient._config_request_with_metadata"d
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*Ï
get_configs>pyspark.sql.connect.client.core.SparkConnectClient.get_configs"Ä
(builtins.tuple[Union[builtins.str,None]]D
Union[builtins.str,None]
builtins.str"builtins.str
None"builtins.tuple*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*&
keys
builtins.str"builtins.str*Å
get_config_with_defaultsKpyspark.sql.connect.client.core.SparkConnectClient.get_config_with_defaults"Ä
(builtins.tuple[Union[builtins.str,None]]D
Union[builtins.str,None]
builtins.str"builtins.str
None"builtins.tuple*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*†
pairsî
,Tuple[builtins.str,Union[builtins.str,None]]
builtins.str"builtins.strD
Union[builtins.str,None]
builtins.str"builtins.str
None*ü
config9pyspark.sql.connect.client.core.SparkConnectClient.config"\
,pyspark.sql.connect.client.core.ConfigResult",pyspark.sql.connect.client.core.ConfigResult*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*á
	operationx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*ƒ
_interrupt_requestEpyspark.sql.connect.client.core.SparkConnectClient._interrupt_request"j
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*0
interrupt_type
builtins.str"builtins.str*U
	id_or_tagD
Union[builtins.str,None]
builtins.str"builtins.str
None *…
interrupt_all@pyspark.sql.connect.client.core.SparkConnectClient.interrupt_all"Å
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*
interrupt_tag@pyspark.sql.connect.client.core.SparkConnectClient.interrupt_tag"Å
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*%
tag
builtins.str"builtins.str*˛
interrupt_operationFpyspark.sql.connect.client.core.SparkConnectClient.interrupt_operation"Å
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*'
op_id
builtins.str"builtins.str*Í
add_tag:pyspark.sql.connect.client.core.SparkConnectClient.add_tag"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*%
tag
builtins.str"builtins.str*

remove_tag=pyspark.sql.connect.client.core.SparkConnectClient.remove_tag"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*%
tag
builtins.str"builtins.str*Ö
get_tags;pyspark.sql.connect.client.core.SparkConnectClient.get_tags"H
builtins.set[builtins.str]
builtins.str"builtins.str"builtins.set*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*…

clear_tags=pyspark.sql.connect.client.core.SparkConnectClient.clear_tags"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*Ü
_throw_if_invalid_tagHpyspark.sql.connect.client.core.SparkConnectClient._throw_if_invalid_tag"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*%
tag
builtins.str"builtins.str*à
_handle_error@pyspark.sql.connect.client.core.SparkConnectClient._handle_error"
NoReturn
*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*3
error(
builtins.Exception"builtins.Exception*Û
_handle_rpc_errorDpyspark.sql.connect.client.core.SparkConnectClient._handle_rpc_error"
NoReturn
*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*
	rpc_error
Any*˙
add_artifacts@pyspark.sql.connect.client.core.SparkConnectClient.add_artifacts"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*&
path
builtins.str"builtins.str**
pyfile
builtins.bool"builtins.bool*+
archive
builtins.bool"builtins.bool*(
file
builtins.bool"builtins.bool*∫
copy_from_local_to_fsHpyspark.sql.connect.client.core.SparkConnectClient.copy_from_local_to_fs"
None*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient*,

local_path
builtins.str"builtins.str*+
	dest_path
builtins.str"builtins.str*ë
cache_artifactApyspark.sql.connect.client.core.SparkConnectClient.cache_artifact"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.client.core.SparkConnectClient"2pyspark.sql.connect.client.core.SparkConnectClient**
blob 
builtins.bytes"builtins.bytesrs
thread_local?pyspark.sql.connect.client.core.SparkConnectClient.thread_local"
threading.local"threading.localr©
_builder;pyspark.sql.connect.client.core.SparkConnectClient._builder`
.pyspark.sql.connect.client.core.ChannelBuilder".pyspark.sql.connect.client.core.ChannelBuilderrç
_user_id;pyspark.sql.connect.client.core.SparkConnectClient._user_idD
Union[builtins.str,None]
builtins.str"builtins.str
NonerŒ
_retry_policy@pyspark.sql.connect.client.core.SparkConnectClient._retry_policy{
*builtins.dict[builtins.str,builtins.float]
builtins.str"builtins.str 
builtins.float"builtins.float"builtins.dictrk
_session_id>pyspark.sql.connect.client.core.SparkConnectClient._session_id
builtins.str"builtins.strrP
_channel;pyspark.sql.connect.client.core.SparkConnectClient._channel
Anyre
_closed:pyspark.sql.connect.client.core.SparkConnectClient._closed
builtins.bool"builtins.boolr∆
_stub8pyspark.sql.connect.client.core.SparkConnectClient._stubÇ
?pyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub"?pyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStubr≈
_artifact_managerDpyspark.sql.connect.client.core.SparkConnectClient._artifact_managerj
3pyspark.sql.connect.client.artifact.ArtifactManager"3pyspark.sql.connect.client.artifact.ArtifactManagerrâ
_use_reattachable_executeLpyspark.sql.connect.client.core.SparkConnectClient._use_reattachable_execute
builtins.bool"builtins.boolÄ
getLogLevel+pyspark.sql.connect.client.core.getLogLevel"D
Union[builtins.int,None]
builtins.int"builtins.int
None*{
__path__#pyspark.sql.connect.client.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*ñ
__annotations__*pyspark.sql.connect.client.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict