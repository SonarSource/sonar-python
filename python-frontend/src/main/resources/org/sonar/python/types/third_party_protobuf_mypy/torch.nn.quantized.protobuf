
torch.nn.quantizedÁ
ReLU6.torch.ao.nn.quantized.modules.activation.ReLU6" torch.nn.modules.activation.ReLU*\
__init__7torch.ao.nn.quantized.modules.activation.ReLU6.__init__*
self*
inplace *V
forward6torch.ao.nn.quantized.modules.activation.ReLU6.forward*
self*	
input*O
	_get_name8torch.ao.nn.quantized.modules.activation.ReLU6._get_name*
self*Ñ

from_float9torch.ao.nn.quantized.modules.activation.ReLU6.from_float*
mod* 
use_precomputed_fake_quant 0:staticmethodh¿
	Hardswish2torch.ao.nn.quantized.modules.activation.Hardswish"%torch.nn.modules.activation.Hardswish*á
__init__;torch.ao.nn.quantized.modules.activation.Hardswish.__init__*
self*	
scale*

zero_point*
device *
dtype *Z
forward:torch.ao.nn.quantized.modules.activation.Hardswish.forward*
self*	
input*S
	_get_name<torch.ao.nn.quantized.modules.activation.Hardswish._get_name*
self*à

from_float=torch.ao.nn.quantized.modules.activation.Hardswish.from_float*
mod* 
use_precomputed_fake_quant 0:staticmethodh*ë
from_referenceAtorch.ao.nn.quantized.modules.activation.Hardswish.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodpó
ELU,torch.ao.nn.quantized.modules.activation.ELU"torch.nn.modules.activation.ELU*s
__init__5torch.ao.nn.quantized.modules.activation.ELU.__init__*
self*	
scale*

zero_point*
alpha *T
forward4torch.ao.nn.quantized.modules.activation.ELU.forward*
self*	
input*M
	_get_name6torch.ao.nn.quantized.modules.activation.ELU._get_name*
self*Ç

from_float7torch.ao.nn.quantized.modules.activation.ELU.from_float*
mod* 
use_precomputed_fake_quant 0:staticmethodh*ã
from_reference;torch.ao.nn.quantized.modules.activation.ELU.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodprD
scale2torch.ao.nn.quantized.modules.activation.ELU.scale
AnyrN

zero_point7torch.ao.nn.quantized.modules.activation.ELU.zero_point
Anyı
	LeakyReLU2torch.ao.nn.quantized.modules.activation.LeakyReLU"%torch.nn.modules.activation.LeakyReLU*¥
__init__;torch.ao.nn.quantized.modules.activation.LeakyReLU.__init__"
None*r
selfh
2torch.ao.nn.quantized.modules.activation.LeakyReLU"2torch.ao.nn.quantized.modules.activation.LeakyReLU*+
scale 
builtins.float"builtins.float*,

zero_point
builtins.int"builtins.int*6
negative_slope 
builtins.float"builtins.float *-
inplace
builtins.bool"builtins.bool *
device
Any *
dtype
Any *Z
forward:torch.ao.nn.quantized.modules.activation.LeakyReLU.forward*
self*	
input*S
	_get_name<torch.ao.nn.quantized.modules.activation.LeakyReLU._get_name*
self*ê

from_float=torch.ao.nn.quantized.modules.activation.LeakyReLU.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*ë
from_referenceAtorch.ao.nn.quantized.modules.activation.LeakyReLU.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodpﬁ
Sigmoid0torch.ao.nn.quantized.modules.activation.Sigmoid"#torch.nn.modules.activation.Sigmoid*®
__init__9torch.ao.nn.quantized.modules.activation.Sigmoid.__init__"
None*n
selfd
0torch.ao.nn.quantized.modules.activation.Sigmoid"0torch.ao.nn.quantized.modules.activation.Sigmoid*2
output_scale 
builtins.float"builtins.float*3
output_zero_point
builtins.int"builtins.int*X
forward8torch.ao.nn.quantized.modules.activation.Sigmoid.forward*
self*	
input*é

from_float;torch.ao.nn.quantized.modules.activation.Sigmoid.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodpro
output_scale=torch.ao.nn.quantized.modules.activation.Sigmoid.output_scale 
builtins.float"builtins.floatru
output_zero_pointBtorch.ao.nn.quantized.modules.activation.Sigmoid.output_zero_point
builtins.int"builtins.int¡
Softmax0torch.ao.nn.quantized.modules.activation.Softmax"#torch.nn.modules.activation.Softmax*y
__init__9torch.ao.nn.quantized.modules.activation.Softmax.__init__*
self*	
dim *
scale *

zero_point *X
forward8torch.ao.nn.quantized.modules.activation.Softmax.forward*
self*	
input*Q
	_get_name:torch.ao.nn.quantized.modules.activation.Softmax._get_name*
self*Ü

from_float;torch.ao.nn.quantized.modules.activation.Softmax.from_float*
mod* 
use_precomputed_fake_quant 0:staticmethodh*è
from_reference?torch.ao.nn.quantized.modules.activation.Softmax.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodprH
scale6torch.ao.nn.quantized.modules.activation.Softmax.scale
AnyrR

zero_point;torch.ao.nn.quantized.modules.activation.Softmax.zero_point
Anyà
MultiheadAttention;torch.ao.nn.quantized.modules.activation.MultiheadAttention"=torch.ao.nn.quantizable.modules.activation.MultiheadAttention*\
	_get_nameEtorch.ao.nn.quantized.modules.activation.MultiheadAttention._get_name*
self*y

from_floatFtorch.ao.nn.quantized.modules.activation.MultiheadAttention.from_float*
cls*	
other0:classmethodp*
from_observedItorch.ao.nn.quantized.modules.activation.MultiheadAttention.from_observed*
cls*	
other0:classmethodprõ
_FLOAT_MODULEItorch.ao.nn.quantized.modules.activation.MultiheadAttention._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.type“
PReLU.torch.ao.nn.quantized.modules.activation.PReLU"torch.nn.modules.module.Module*÷
__init__7torch.ao.nn.quantized.modules.activation.PReLU.__init__"
None*j
self`
.torch.ao.nn.quantized.modules.activation.PReLU".torch.ao.nn.quantized.modules.activation.PReLU*2
output_scale 
builtins.float"builtins.float*3
output_zero_point
builtins.int"builtins.int*2
num_parameters
builtins.int"builtins.int *Ú

set_weight9torch.ao.nn.quantized.modules.activation.PReLU.set_weight"
None*j
self`
.torch.ao.nn.quantized.modules.activation.PReLU".torch.ao.nn.quantized.modules.activation.PReLU*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*î
forward6torch.ao.nn.quantized.modules.activation.PReLU.forward",
torch._tensor.Tensor"torch._tensor.Tensor*j
self`
.torch.ao.nn.quantized.modules.activation.PReLU".torch.ao.nn.quantized.modules.activation.PReLU*7
input,
torch._tensor.Tensor"torch._tensor.Tensor*O
	_get_name8torch.ao.nn.quantized.modules.activation.PReLU._get_name*
self*å

from_float9torch.ao.nn.quantized.modules.activation.PReLU.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*ç
from_reference=torch.ao.nn.quantized.modules.activation.PReLU.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodprm
num_parameters=torch.ao.nn.quantized.modules.activation.PReLU.num_parameters
builtins.int"builtins.intr_
scale4torch.ao.nn.quantized.modules.activation.PReLU.scale 
builtins.float"builtins.floatre

zero_point9torch.ao.nn.quantized.modules.activation.PReLU.zero_point
builtins.int"builtins.intrm
weight5torch.ao.nn.quantized.modules.activation.PReLU.weight,
torch._tensor.Tensor"torch._tensor.Tensor◊	
BatchNorm2d3torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d"2torch.ao.nn.quantized.modules.batchnorm._BatchNorm*Ω
__init__<torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d.__init__"
None*t
selfj
3torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d"3torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d*
num_features
Any*
eps
Any *
momentum
Any *
device
Any *
dtype
Any *T
	_get_name=torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d._get_name*
self*m
_check_input_dimDtorch.ao.nn.quantized.modules.batchnorm.BatchNorm2d._check_input_dim*
self*	
input*£
forward;torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d.forward",
torch._tensor.Tensor"torch._tensor.Tensor*t
selfj
3torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d"3torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d*7
input,
torch._tensor.Tensor"torch._tensor.Tensor*ë

from_float>torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodprü
_NNI_BN_RELU_MODULEGtorch.ao.nn.quantized.modules.batchnorm.BatchNorm2d._NNI_BN_RELU_MODULE?
CallableType[builtins.type]
builtins.type"builtins.type¥
BatchNorm3d3torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d"2torch.ao.nn.quantized.modules.batchnorm._BatchNorm*ö
__init__<torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d.__init__*
self*
num_features*	
eps *
momentum *
device *
dtype *T
	_get_name=torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d._get_name*
self*m
_check_input_dimDtorch.ao.nn.quantized.modules.batchnorm.BatchNorm3d._check_input_dim*
self*	
input*£
forward;torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d.forward",
torch._tensor.Tensor"torch._tensor.Tensor*t
selfj
3torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d"3torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d*7
input,
torch._tensor.Tensor"torch._tensor.Tensor*ë

from_float>torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodprü
_NNI_BN_RELU_MODULEGtorch.ao.nn.quantized.modules.batchnorm.BatchNorm3d._NNI_BN_RELU_MODULE?
CallableType[builtins.type]
builtins.type"builtins.type≠!
Conv1d)torch.ao.nn.quantized.modules.conv.Conv1d"*torch.ao.nn.quantized.modules.conv._ConvNd*ä
__init__2torch.ao.nn.quantized.modules.conv.Conv1d.__init__"
None*`
selfV
)torch.ao.nn.quantized.modules.conv.Conv1d")torch.ao.nn.quantized.modules.conv.Conv1d*-
in_channels
builtins.int"builtins.int*.
out_channels
builtins.int"builtins.int*ë
kernel_sizeˇ
STypeAlias[TypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]]Ñ
HTypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]â
=Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.objectt
Tuple[torch.nn.common_types.T]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.object"*torch.nn.common_types._scalar_or_tuple_1_t"torch.nn.common_types._size_1_t*é
strideˇ
STypeAlias[TypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]]Ñ
HTypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]â
=Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.objectt
Tuple[torch.nn.common_types.T]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.object"*torch.nn.common_types._scalar_or_tuple_1_t"torch.nn.common_types._size_1_t *è
paddingˇ
STypeAlias[TypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]]Ñ
HTypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]â
=Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.objectt
Tuple[torch.nn.common_types.T]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.object"*torch.nn.common_types._scalar_or_tuple_1_t"torch.nn.common_types._size_1_t *ê
dilationˇ
STypeAlias[TypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]]Ñ
HTypeAlias[Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]]â
=Union[torch.nn.common_types.T,Tuple[torch.nn.common_types.T]]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.objectt
Tuple[torch.nn.common_types.T]P
torch.nn.common_types.T"
builtins.object"builtins.object"builtins.object"*torch.nn.common_types._scalar_or_tuple_1_t"torch.nn.common_types._size_1_t **
groups
builtins.int"builtins.int **
bias
builtins.bool"builtins.bool *0
padding_mode
builtins.str"builtins.str *
device
Any *
dtype
Any *J
	_get_name3torch.ao.nn.quantized.modules.conv.Conv1d._get_name*
self*“
set_weight_bias9torch.ao.nn.quantized.modules.conv.Conv1d.set_weight_bias"
None*`
selfV
)torch.ao.nn.quantized.modules.conv.Conv1d")torch.ao.nn.quantized.modules.conv.Conv1d*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*c
b\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*P
_weight_bias6torch.ao.nn.quantized.modules.conv.Conv1d._weight_bias*
self*D
weight0torch.ao.nn.quantized.modules.conv.Conv1d.weight*
self*@
bias.torch.ao.nn.quantized.modules.conv.Conv1d.bias*
self*Q
forward1torch.ao.nn.quantized.modules.conv.Conv1d.forward*
self*	
input*á

from_float4torch.ao.nn.quantized.modules.conv.Conv1d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodprâ
_FLOAT_MODULE7torch.ao.nn.quantized.modules.conv.Conv1d._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typerõ
_NNIQAT_CONV_BN_MODULE@torch.ao.nn.quantized.modules.conv.Conv1d._NNIQAT_CONV_BN_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typerô
_NNI_CONV_RELU_MODULE?torch.ao.nn.quantized.modules.conv.Conv1d._NNI_CONV_RELU_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typer`
_NNI_CONV_ADD_MODULE>torch.ao.nn.quantized.modules.conv.Conv1d._NNI_CONV_ADD_MODULE
Nonerj
_NNI_CONV_ADD_RELU_MODULECtorch.ao.nn.quantized.modules.conv.Conv1d._NNI_CONV_ADD_RELU_MODULE
NonerS
_packed_params8torch.ao.nn.quantized.modules.conv.Conv1d._packed_params
AnyÖ
Conv2d)torch.ao.nn.quantized.modules.conv.Conv2d"*torch.ao.nn.quantized.modules.conv._ConvNd*Ú
__init__2torch.ao.nn.quantized.modules.conv.Conv2d.__init__*
self*
in_channels*
out_channels*
kernel_size*
stride *
padding *
dilation *
groups *

bias *
padding_mode *
device *
dtype *J
	_get_name3torch.ao.nn.quantized.modules.conv.Conv2d._get_name*
self*“
set_weight_bias9torch.ao.nn.quantized.modules.conv.Conv2d.set_weight_bias"
None*`
selfV
)torch.ao.nn.quantized.modules.conv.Conv2d")torch.ao.nn.quantized.modules.conv.Conv2d*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*c
b\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*P
_weight_bias6torch.ao.nn.quantized.modules.conv.Conv2d._weight_bias*
self*D
weight0torch.ao.nn.quantized.modules.conv.Conv2d.weight*
self*@
bias.torch.ao.nn.quantized.modules.conv.Conv2d.bias*
self*Q
forward1torch.ao.nn.quantized.modules.conv.Conv2d.forward*
self*	
input*á

from_float4torch.ao.nn.quantized.modules.conv.Conv2d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodprâ
_FLOAT_MODULE7torch.ao.nn.quantized.modules.conv.Conv2d._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typerõ
_NNIQAT_CONV_BN_MODULE@torch.ao.nn.quantized.modules.conv.Conv2d._NNIQAT_CONV_BN_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typerô
_NNI_CONV_RELU_MODULE?torch.ao.nn.quantized.modules.conv.Conv2d._NNI_CONV_RELU_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typeró
_NNI_CONV_ADD_MODULE>torch.ao.nn.quantized.modules.conv.Conv2d._NNI_CONV_ADD_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typer°
_NNI_CONV_ADD_RELU_MODULECtorch.ao.nn.quantized.modules.conv.Conv2d._NNI_CONV_ADD_RELU_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typerS
_packed_params8torch.ao.nn.quantized.modules.conv.Conv2d._packed_params
Anyï
Conv3d)torch.ao.nn.quantized.modules.conv.Conv3d"*torch.ao.nn.quantized.modules.conv._ConvNd*Ú
__init__2torch.ao.nn.quantized.modules.conv.Conv3d.__init__*
self*
in_channels*
out_channels*
kernel_size*
stride *
padding *
dilation *
groups *

bias *
padding_mode *
device *
dtype *J
	_get_name3torch.ao.nn.quantized.modules.conv.Conv3d._get_name*
self*“
set_weight_bias9torch.ao.nn.quantized.modules.conv.Conv3d.set_weight_bias"
None*`
selfV
)torch.ao.nn.quantized.modules.conv.Conv3d")torch.ao.nn.quantized.modules.conv.Conv3d*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*c
b\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*P
_weight_bias6torch.ao.nn.quantized.modules.conv.Conv3d._weight_bias*
self*D
weight0torch.ao.nn.quantized.modules.conv.Conv3d.weight*
self*@
bias.torch.ao.nn.quantized.modules.conv.Conv3d.bias*
self*Q
forward1torch.ao.nn.quantized.modules.conv.Conv3d.forward*
self*	
input*á

from_float4torch.ao.nn.quantized.modules.conv.Conv3d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodprâ
_FLOAT_MODULE7torch.ao.nn.quantized.modules.conv.Conv3d._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typerõ
_NNIQAT_CONV_BN_MODULE@torch.ao.nn.quantized.modules.conv.Conv3d._NNIQAT_CONV_BN_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typerô
_NNI_CONV_RELU_MODULE?torch.ao.nn.quantized.modules.conv.Conv3d._NNI_CONV_RELU_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typer`
_NNI_CONV_ADD_MODULE>torch.ao.nn.quantized.modules.conv.Conv3d._NNI_CONV_ADD_MODULE
Nonerj
_NNI_CONV_ADD_RELU_MODULECtorch.ao.nn.quantized.modules.conv.Conv3d._NNI_CONV_ADD_RELU_MODULE
NonerS
_packed_params8torch.ao.nn.quantized.modules.conv.Conv3d._packed_params
Any¿
ConvTranspose1d2torch.ao.nn.quantized.modules.conv.ConvTranspose1d"3torch.ao.nn.quantized.modules.conv._ConvTransposeNd*ë
__init__;torch.ao.nn.quantized.modules.conv.ConvTranspose1d.__init__*
self*
in_channels*
out_channels*
kernel_size*
stride *
padding *
output_padding *
groups *

bias *
dilation *
padding_mode *
device *
dtype *S
	_get_name<torch.ao.nn.quantized.modules.conv.ConvTranspose1d._get_name*
self*Ì
set_weight_biasBtorch.ao.nn.quantized.modules.conv.ConvTranspose1d.set_weight_bias"
None*r
selfh
2torch.ao.nn.quantized.modules.conv.ConvTranspose1d"2torch.ao.nn.quantized.modules.conv.ConvTranspose1d*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*c
b\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*Y
_weight_bias?torch.ao.nn.quantized.modules.conv.ConvTranspose1d._weight_bias*
self*M
weight9torch.ao.nn.quantized.modules.conv.ConvTranspose1d.weight*
self*I
bias7torch.ao.nn.quantized.modules.conv.ConvTranspose1d.bias*
self*Z
forward:torch.ao.nn.quantized.modules.conv.ConvTranspose1d.forward*
self*	
input*¶
from_referenceAtorch.ao.nn.quantized.modules.conv.ConvTranspose1d.from_reference*
cls*

ref_qconvt*
output_scale*
output_zero_point0:classmethodprí
_FLOAT_MODULE@torch.ao.nn.quantized.modules.conv.ConvTranspose1d._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typer\
_packed_paramsAtorch.ao.nn.quantized.modules.conv.ConvTranspose1d._packed_params
Any¿
ConvTranspose2d2torch.ao.nn.quantized.modules.conv.ConvTranspose2d"3torch.ao.nn.quantized.modules.conv._ConvTransposeNd*ë
__init__;torch.ao.nn.quantized.modules.conv.ConvTranspose2d.__init__*
self*
in_channels*
out_channels*
kernel_size*
stride *
padding *
output_padding *
groups *

bias *
dilation *
padding_mode *
device *
dtype *S
	_get_name<torch.ao.nn.quantized.modules.conv.ConvTranspose2d._get_name*
self*Ì
set_weight_biasBtorch.ao.nn.quantized.modules.conv.ConvTranspose2d.set_weight_bias"
None*r
selfh
2torch.ao.nn.quantized.modules.conv.ConvTranspose2d"2torch.ao.nn.quantized.modules.conv.ConvTranspose2d*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*c
b\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*Y
_weight_bias?torch.ao.nn.quantized.modules.conv.ConvTranspose2d._weight_bias*
self*M
weight9torch.ao.nn.quantized.modules.conv.ConvTranspose2d.weight*
self*I
bias7torch.ao.nn.quantized.modules.conv.ConvTranspose2d.bias*
self*Z
forward:torch.ao.nn.quantized.modules.conv.ConvTranspose2d.forward*
self*	
input*¶
from_referenceAtorch.ao.nn.quantized.modules.conv.ConvTranspose2d.from_reference*
cls*

ref_qconvt*
output_scale*
output_zero_point0:classmethodprí
_FLOAT_MODULE@torch.ao.nn.quantized.modules.conv.ConvTranspose2d._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typer\
_packed_paramsAtorch.ao.nn.quantized.modules.conv.ConvTranspose2d._packed_params
Any¿
ConvTranspose3d2torch.ao.nn.quantized.modules.conv.ConvTranspose3d"3torch.ao.nn.quantized.modules.conv._ConvTransposeNd*ë
__init__;torch.ao.nn.quantized.modules.conv.ConvTranspose3d.__init__*
self*
in_channels*
out_channels*
kernel_size*
stride *
padding *
output_padding *
groups *

bias *
dilation *
padding_mode *
device *
dtype *S
	_get_name<torch.ao.nn.quantized.modules.conv.ConvTranspose3d._get_name*
self*Ì
set_weight_biasBtorch.ao.nn.quantized.modules.conv.ConvTranspose3d.set_weight_bias"
None*r
selfh
2torch.ao.nn.quantized.modules.conv.ConvTranspose3d"2torch.ao.nn.quantized.modules.conv.ConvTranspose3d*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*c
b\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*Y
_weight_bias?torch.ao.nn.quantized.modules.conv.ConvTranspose3d._weight_bias*
self*M
weight9torch.ao.nn.quantized.modules.conv.ConvTranspose3d.weight*
self*I
bias7torch.ao.nn.quantized.modules.conv.ConvTranspose3d.bias*
self*Z
forward:torch.ao.nn.quantized.modules.conv.ConvTranspose3d.forward*
self*	
input*¶
from_referenceAtorch.ao.nn.quantized.modules.conv.ConvTranspose3d.from_reference*
cls*

ref_qconvt*
output_scale*
output_zero_point0:classmethodprí
_FLOAT_MODULE@torch.ao.nn.quantized.modules.conv.ConvTranspose3d._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typer\
_packed_paramsAtorch.ao.nn.quantized.modules.conv.ConvTranspose3d._packed_params
Anyû
Dropout-torch.ao.nn.quantized.modules.dropout.Dropout" torch.nn.modules.dropout.Dropout*U
forward5torch.ao.nn.quantized.modules.dropout.Dropout.forward*
self*	
input*N
	_get_name7torch.ao.nn.quantized.modules.dropout.Dropout._get_name*
self*ã

from_float8torch.ao.nn.quantized.modules.dropout.Dropout.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*å
from_reference<torch.ao.nn.quantized.modules.dropout.Dropout.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodpî
	Embedding5torch.ao.nn.quantized.modules.embedding_ops.Embedding"torch.nn.modules.module.Module*Ñ
__init__>torch.ao.nn.quantized.modules.embedding_ops.Embedding.__init__"
None*x
selfn
5torch.ao.nn.quantized.modules.embedding_ops.Embedding"5torch.ao.nn.quantized.modules.embedding_ops.Embedding*0
num_embeddings
builtins.int"builtins.int*/
embedding_dim
builtins.int"builtins.int*W
padding_idxD
Union[builtins.int,None]
builtins.int"builtins.int
None *Z
max_normJ
Union[builtins.float,None] 
builtins.float"builtins.float
None *1
	norm_type 
builtins.float"builtins.float *8
scale_grad_by_freq
builtins.bool"builtins.bool *,
sparse
builtins.bool"builtins.bool *k
_weight\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None *
dtype
Any *´
forward=torch.ao.nn.quantized.modules.embedding_ops.Embedding.forward",
torch._tensor.Tensor"torch._tensor.Tensor*x
selfn
5torch.ao.nn.quantized.modules.embedding_ops.Embedding"5torch.ao.nn.quantized.modules.embedding_ops.Embedding*9
indices,
torch._tensor.Tensor"torch._tensor.Tensor*V
	_get_name?torch.ao.nn.quantized.modules.embedding_ops.Embedding._get_name*
self*L
__repr__>torch.ao.nn.quantized.modules.embedding_ops.Embedding.__repr__* *X

extra_repr@torch.ao.nn.quantized.modules.embedding_ops.Embedding.extra_repr*
self*á

set_weight@torch.ao.nn.quantized.modules.embedding_ops.Embedding.set_weight"
None*x
selfn
5torch.ao.nn.quantized.modules.embedding_ops.Embedding"5torch.ao.nn.quantized.modules.embedding_ops.Embedding*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*P
weight<torch.ao.nn.quantized.modules.embedding_ops.Embedding.weight*
self*ì

from_float@torch.ao.nn.quantized.modules.embedding_ops.Embedding.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*É
from_referenceDtorch.ao.nn.quantized.modules.embedding_ops.Embedding.from_reference*
cls*
ref_embedding0:classmethodprh
_version>torch.ao.nn.quantized.modules.embedding_ops.Embedding._version
builtins.int"builtins.intrt
num_embeddingsDtorch.ao.nn.quantized.modules.embedding_ops.Embedding.num_embeddings
builtins.int"builtins.intrr
embedding_dimCtorch.ao.nn.quantized.modules.embedding_ops.Embedding.embedding_dim
builtins.int"builtins.intrM
dtype;torch.ao.nn.quantized.modules.embedding_ops.Embedding.dtype
Anyrﬂ
_packed_paramsDtorch.ao.nn.quantized.modules.embedding_ops.Embedding._packed_paramsÜ
Atorch.ao.nn.quantized.modules.embedding_ops.EmbeddingPackedParams"Atorch.ao.nn.quantized.modules.embedding_ops.EmbeddingPackedParamsã
EmbeddingBag8torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag"5torch.ao.nn.quantized.modules.embedding_ops.Embedding*ô
__init__Atorch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag.__init__"
None*~
selft
8torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag"8torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag*0
num_embeddings
builtins.int"builtins.int*/
embedding_dim
builtins.int"builtins.int*Z
max_normJ
Union[builtins.float,None] 
builtins.float"builtins.float
None *1
	norm_type 
builtins.float"builtins.float *8
scale_grad_by_freq
builtins.bool"builtins.bool *(
mode
builtins.str"builtins.str *,
sparse
builtins.bool"builtins.bool *k
_weight\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None *9
include_last_offset
builtins.bool"builtins.bool *
dtype
Any *ô
forward@torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag.forward",
torch._tensor.Tensor"torch._tensor.Tensor*~
selft
8torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag"8torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag*9
indices,
torch._tensor.Tensor"torch._tensor.Tensor*k
offsets\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None *v
per_sample_weights\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None *~
compressed_indices_mapping\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None *Y
	_get_nameBtorch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag._get_name*
self*ñ

from_floatCtorch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*ä
from_referenceGtorch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag.from_reference*
cls*
ref_embedding_bag0:classmethodprk
_versionAtorch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag._version
builtins.int"builtins.intrc
mode=torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag.mode
builtins.str"builtins.strry
pruned_weightsGtorch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag.pruned_weights
builtins.bool"builtins.boolrÉ
include_last_offsetLtorch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag.include_last_offset
builtins.bool"builtins.boolæ
FloatFunctional@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"torch.nn.modules.module.Module*_
__init__Itorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.__init__*
self*d
forwardHtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.forward*
self*
x*ı
addDtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.add",
torch._tensor.Tensor"torch._tensor.Tensor*è
selfÑ
@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*˜

add_scalarKtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.add_scalar",
torch._tensor.Tensor"torch._tensor.Tensor*è
selfÑ
@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*'
y 
builtins.float"builtins.float*ı
mulDtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.mul",
torch._tensor.Tensor"torch._tensor.Tensor*è
selfÑ
@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*˜

mul_scalarKtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.mul_scalar",
torch._tensor.Tensor"torch._tensor.Tensor*è
selfÑ
@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*'
y 
builtins.float"builtins.float*ü
catDtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.cat",
torch._tensor.Tensor"torch._tensor.Tensor*è
selfÑ
@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional*i
xb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*'
dim
builtins.int"builtins.int *ˇ
add_reluItorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.add_relu",
torch._tensor.Tensor"torch._tensor.Tensor*è
selfÑ
@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*˚
matmulGtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.matmul",
torch._tensor.Tensor"torch._tensor.Tensor*è
selfÑ
@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional"@torch.ao.nn.quantized.modules.functional_modules.FloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensorr|
activation_post_processXtorch.ao.nn.quantized.modules.functional_modules.FloatFunctional.activation_post_process
Anyè
FXFloatFunctionalBtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"torch.nn.modules.module.Module*f
forwardJtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.forward*
self*
x*˚
addFtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.add",
torch._tensor.Tensor"torch._tensor.Tensor*ì
selfà
Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*˝

add_scalarMtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.add_scalar",
torch._tensor.Tensor"torch._tensor.Tensor*ì
selfà
Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*'
y 
builtins.float"builtins.float*˚
mulFtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.mul",
torch._tensor.Tensor"torch._tensor.Tensor*ì
selfà
Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*˝

mul_scalarMtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.mul_scalar",
torch._tensor.Tensor"torch._tensor.Tensor*ì
selfà
Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*'
y 
builtins.float"builtins.float*•
catFtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.cat",
torch._tensor.Tensor"torch._tensor.Tensor*ì
selfà
Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional*i
xb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*'
dim
builtins.int"builtins.int *Ö
add_reluKtorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.add_relu",
torch._tensor.Tensor"torch._tensor.Tensor*ì
selfà
Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*Å
matmulItorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional.matmul",
torch._tensor.Tensor"torch._tensor.Tensor*ì
selfà
Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional"Btorch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.TensorÌ
QFunctional<torch.ao.nn.quantized.modules.functional_modules.QFunctional"torch.nn.modules.module.Module*[
__init__Etorch.ao.nn.quantized.modules.functional_modules.QFunctional.__init__*
self*ù
_save_to_state_dictPtorch.ao.nn.quantized.modules.functional_modules.QFunctional._save_to_state_dict*
self*
destination*

prefix*
	keep_vars*Ë
_load_from_state_dictRtorch.ao.nn.quantized.modules.functional_modules.QFunctional._load_from_state_dict*
self*

state_dict*

prefix*
local_metadata*

strict*
missing_keys*
unexpected_keys*

error_msgs*]
	_get_nameFtorch.ao.nn.quantized.modules.functional_modules.QFunctional._get_name*
self*_

extra_reprGtorch.ao.nn.quantized.modules.functional_modules.QFunctional.extra_repr*
self*`
forwardDtorch.ao.nn.quantized.modules.functional_modules.QFunctional.forward*
self*
x*Ë
add@torch.ao.nn.quantized.modules.functional_modules.QFunctional.add",
torch._tensor.Tensor"torch._tensor.Tensor*Ü
self|
<torch.ao.nn.quantized.modules.functional_modules.QFunctional"<torch.ao.nn.quantized.modules.functional_modules.QFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*Í

add_scalarGtorch.ao.nn.quantized.modules.functional_modules.QFunctional.add_scalar",
torch._tensor.Tensor"torch._tensor.Tensor*Ü
self|
<torch.ao.nn.quantized.modules.functional_modules.QFunctional"<torch.ao.nn.quantized.modules.functional_modules.QFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*'
y 
builtins.float"builtins.float*Ë
mul@torch.ao.nn.quantized.modules.functional_modules.QFunctional.mul",
torch._tensor.Tensor"torch._tensor.Tensor*Ü
self|
<torch.ao.nn.quantized.modules.functional_modules.QFunctional"<torch.ao.nn.quantized.modules.functional_modules.QFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*Í

mul_scalarGtorch.ao.nn.quantized.modules.functional_modules.QFunctional.mul_scalar",
torch._tensor.Tensor"torch._tensor.Tensor*Ü
self|
<torch.ao.nn.quantized.modules.functional_modules.QFunctional"<torch.ao.nn.quantized.modules.functional_modules.QFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*'
y 
builtins.float"builtins.float*í
cat@torch.ao.nn.quantized.modules.functional_modules.QFunctional.cat",
torch._tensor.Tensor"torch._tensor.Tensor*Ü
self|
<torch.ao.nn.quantized.modules.functional_modules.QFunctional"<torch.ao.nn.quantized.modules.functional_modules.QFunctional*i
xb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*'
dim
builtins.int"builtins.int *Ú
add_reluEtorch.ao.nn.quantized.modules.functional_modules.QFunctional.add_relu",
torch._tensor.Tensor"torch._tensor.Tensor*Ü
self|
<torch.ao.nn.quantized.modules.functional_modules.QFunctional"<torch.ao.nn.quantized.modules.functional_modules.QFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*Ó
matmulCtorch.ao.nn.quantized.modules.functional_modules.QFunctional.matmul",
torch._tensor.Tensor"torch._tensor.Tensor*Ü
self|
<torch.ao.nn.quantized.modules.functional_modules.QFunctional"<torch.ao.nn.quantized.modules.functional_modules.QFunctional*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*3
y,
torch._tensor.Tensor"torch._tensor.Tensor*ö

from_floatGtorch.ao.nn.quantized.modules.functional_modules.QFunctional.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodprT
scaleBtorch.ao.nn.quantized.modules.functional_modules.QFunctional.scale
Anyr^

zero_pointGtorch.ao.nn.quantized.modules.functional_modules.QFunctional.zero_point
Anyrx
activation_post_processTtorch.ao.nn.quantized.modules.functional_modules.QFunctional.activation_post_process
Anyæ
Linear+torch.ao.nn.quantized.modules.linear.Linear";torch.ao.nn.quantized.modules.utils.WeightedQuantizedModule*á
__init__4torch.ao.nn.quantized.modules.linear.Linear.__init__*
self*
in_features*
out_features*
bias_ *
dtype *L
	_get_name5torch.ao.nn.quantized.modules.linear.Linear._get_name*
self*N

extra_repr6torch.ao.nn.quantized.modules.linear.Linear.extra_repr*
self*B
__repr__4torch.ao.nn.quantized.modules.linear.Linear.__repr__* *á
forward3torch.ao.nn.quantized.modules.linear.Linear.forward",
torch._tensor.Tensor"torch._tensor.Tensor*d
selfZ
+torch.ao.nn.quantized.modules.linear.Linear"+torch.ao.nn.quantized.modules.linear.Linear*3
x,
torch._tensor.Tensor"torch._tensor.Tensor*å
_save_to_state_dict?torch.ao.nn.quantized.modules.linear.Linear._save_to_state_dict*
self*
destination*

prefix*
	keep_vars*◊
_load_from_state_dictAtorch.ao.nn.quantized.modules.linear.Linear._load_from_state_dict*
self*

state_dict*

prefix*
local_metadata*

strict*
missing_keys*
unexpected_keys*

error_msgs*R
_weight_bias8torch.ao.nn.quantized.modules.linear.Linear._weight_bias*
self*F
weight2torch.ao.nn.quantized.modules.linear.Linear.weight*
self*B
bias0torch.ao.nn.quantized.modules.linear.Linear.bias*
self*ÿ
set_weight_bias;torch.ao.nn.quantized.modules.linear.Linear.set_weight_bias"
None*d
selfZ
+torch.ao.nn.quantized.modules.linear.Linear"+torch.ao.nn.quantized.modules.linear.Linear*3
w,
torch._tensor.Tensor"torch._tensor.Tensor*c
b\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None*â

from_float6torch.ao.nn.quantized.modules.linear.Linear.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*†
from_reference:torch.ao.nn.quantized.modules.linear.Linear.from_reference*
cls*
ref_qlinear*
output_scale*
output_zero_point0:classmethodpr^
_version4torch.ao.nn.quantized.modules.linear.Linear._version
builtins.int"builtins.intrë
_FLOAT_MODULE9torch.ao.nn.quantized.modules.linear.Linear._FLOAT_MODULEƒ
>Tuple[CallableType[builtins.type],CallableType[builtins.type]]?
CallableType[builtins.type]
builtins.type"builtins.type?
CallableType[builtins.type]
builtins.type"builtins.typerO
in_features7torch.ao.nn.quantized.modules.linear.Linear.in_features
AnyrQ
out_features8torch.ao.nn.quantized.modules.linear.Linear.out_features
AnyrU
_packed_params:torch.ao.nn.quantized.modules.linear.Linear._packed_params
AnyrC
scale1torch.ao.nn.quantized.modules.linear.Linear.scale
AnyrM

zero_point6torch.ao.nn.quantized.modules.linear.Linear.zero_point
Anyó	
	LayerNorm5torch.ao.nn.quantized.modules.normalization.LayerNorm"(torch.nn.modules.normalization.LayerNorm*¶
__init__>torch.ao.nn.quantized.modules.normalization.LayerNorm.__init__"
None*x
selfn
5torch.ao.nn.quantized.modules.normalization.LayerNorm"5torch.ao.nn.quantized.modules.normalization.LayerNorm*
normalized_shape
Any*
weight
Any*
bias
Any*
scale
Any*

zero_point
Any*
eps
Any *!
elementwise_affine
Any *
device
Any *
dtype
Any *]
forward=torch.ao.nn.quantized.modules.normalization.LayerNorm.forward*
self*	
input*V
	_get_name?torch.ao.nn.quantized.modules.normalization.LayerNorm._get_name*
self*ì

from_float@torch.ao.nn.quantized.modules.normalization.LayerNorm.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*î
from_referenceDtorch.ao.nn.quantized.modules.normalization.LayerNorm.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodprO
weight<torch.ao.nn.quantized.modules.normalization.LayerNorm.weight
AnyrK
bias:torch.ao.nn.quantized.modules.normalization.LayerNorm.bias
Any¨	
	GroupNorm5torch.ao.nn.quantized.modules.normalization.GroupNorm"(torch.nn.modules.normalization.GroupNorm*Ø
__init__>torch.ao.nn.quantized.modules.normalization.GroupNorm.__init__"
None*x
selfn
5torch.ao.nn.quantized.modules.normalization.GroupNorm"5torch.ao.nn.quantized.modules.normalization.GroupNorm*

num_groups
Any*
num_channels
Any*
weight
Any*
bias
Any*
scale
Any*

zero_point
Any*
eps
Any *
affine
Any *
device
Any *
dtype
Any *]
forward=torch.ao.nn.quantized.modules.normalization.GroupNorm.forward*
self*	
input*V
	_get_name?torch.ao.nn.quantized.modules.normalization.GroupNorm._get_name*
self*ì

from_float@torch.ao.nn.quantized.modules.normalization.GroupNorm.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodpr†
__constants__Ctorch.ao.nn.quantized.modules.normalization.GroupNorm.__constants__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.listrO
weight<torch.ao.nn.quantized.modules.normalization.GroupNorm.weight
AnyrK
bias:torch.ao.nn.quantized.modules.normalization.GroupNorm.bias
AnyÄ

InstanceNorm1d:torch.ao.nn.quantized.modules.normalization.InstanceNorm1d",torch.nn.modules.instancenorm.InstanceNorm1d*„
__init__Ctorch.ao.nn.quantized.modules.normalization.InstanceNorm1d.__init__"
None*Ç
selfx
:torch.ao.nn.quantized.modules.normalization.InstanceNorm1d":torch.ao.nn.quantized.modules.normalization.InstanceNorm1d*
num_features
Any*
weight
Any*
bias
Any*
scale
Any*

zero_point
Any*
eps
Any *
momentum
Any *
affine
Any *"
track_running_stats
Any *
device
Any *
dtype
Any *b
forwardBtorch.ao.nn.quantized.modules.normalization.InstanceNorm1d.forward*
self*	
input*[
	_get_nameDtorch.ao.nn.quantized.modules.normalization.InstanceNorm1d._get_name*
self*ò

from_floatEtorch.ao.nn.quantized.modules.normalization.InstanceNorm1d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*ô
from_referenceItorch.ao.nn.quantized.modules.normalization.InstanceNorm1d.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodprT
weightAtorch.ao.nn.quantized.modules.normalization.InstanceNorm1d.weight
AnyrP
bias?torch.ao.nn.quantized.modules.normalization.InstanceNorm1d.bias
AnyÄ

InstanceNorm2d:torch.ao.nn.quantized.modules.normalization.InstanceNorm2d",torch.nn.modules.instancenorm.InstanceNorm2d*„
__init__Ctorch.ao.nn.quantized.modules.normalization.InstanceNorm2d.__init__"
None*Ç
selfx
:torch.ao.nn.quantized.modules.normalization.InstanceNorm2d":torch.ao.nn.quantized.modules.normalization.InstanceNorm2d*
num_features
Any*
weight
Any*
bias
Any*
scale
Any*

zero_point
Any*
eps
Any *
momentum
Any *
affine
Any *"
track_running_stats
Any *
device
Any *
dtype
Any *b
forwardBtorch.ao.nn.quantized.modules.normalization.InstanceNorm2d.forward*
self*	
input*[
	_get_nameDtorch.ao.nn.quantized.modules.normalization.InstanceNorm2d._get_name*
self*ò

from_floatEtorch.ao.nn.quantized.modules.normalization.InstanceNorm2d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*ô
from_referenceItorch.ao.nn.quantized.modules.normalization.InstanceNorm2d.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodprT
weightAtorch.ao.nn.quantized.modules.normalization.InstanceNorm2d.weight
AnyrP
bias?torch.ao.nn.quantized.modules.normalization.InstanceNorm2d.bias
AnyÄ

InstanceNorm3d:torch.ao.nn.quantized.modules.normalization.InstanceNorm3d",torch.nn.modules.instancenorm.InstanceNorm3d*„
__init__Ctorch.ao.nn.quantized.modules.normalization.InstanceNorm3d.__init__"
None*Ç
selfx
:torch.ao.nn.quantized.modules.normalization.InstanceNorm3d":torch.ao.nn.quantized.modules.normalization.InstanceNorm3d*
num_features
Any*
weight
Any*
bias
Any*
scale
Any*

zero_point
Any*
eps
Any *
momentum
Any *
affine
Any *"
track_running_stats
Any *
device
Any *
dtype
Any *b
forwardBtorch.ao.nn.quantized.modules.normalization.InstanceNorm3d.forward*
self*	
input*[
	_get_nameDtorch.ao.nn.quantized.modules.normalization.InstanceNorm3d._get_name*
self*ò

from_floatEtorch.ao.nn.quantized.modules.normalization.InstanceNorm3d.from_float*
cls*
mod* 
use_precomputed_fake_quant 0:classmethodp*ô
from_referenceItorch.ao.nn.quantized.modules.normalization.InstanceNorm3d.from_reference*
cls*
mod*	
scale*

zero_point0:classmethodprT
weightAtorch.ao.nn.quantized.modules.normalization.InstanceNorm3d.weight
AnyrP
bias?torch.ao.nn.quantized.modules.normalization.InstanceNorm3d.bias
Anyá
LSTM&torch.ao.nn.quantized.modules.rnn.LSTM"(torch.ao.nn.quantizable.modules.rnn.LSTM*G
	_get_name0torch.ao.nn.quantized.modules.rnn.LSTM._get_name*
self*o

from_float1torch.ao.nn.quantized.modules.rnn.LSTM.from_float*
cls*
args*

kwargs0:classmethodp*j
from_observed4torch.ao.nn.quantized.modules.rnn.LSTM.from_observed*
cls*	
other0:classmethodprÜ
_FLOAT_MODULE4torch.ao.nn.quantized.modules.rnn.LSTM._FLOAT_MODULE?
CallableType[builtins.type]
builtins.type"builtins.typeˇ
Quantize&torch.ao.nn.quantized.modules.Quantize"torch.nn.modules.module.Module*Å
__init__/torch.ao.nn.quantized.modules.Quantize.__init__*
self*	
scale*

zero_point*	
dtype*
factory_kwargs *J
forward.torch.ao.nn.quantized.modules.Quantize.forward*
self*
X*|

from_float1torch.ao.nn.quantized.modules.Quantize.from_float*
mod* 
use_precomputed_fake_quant 0:staticmethodh*I

extra_repr1torch.ao.nn.quantized.modules.Quantize.extra_repr*
selfrc
scale,torch.ao.nn.quantized.modules.Quantize.scale,
torch._tensor.Tensor"torch._tensor.Tensorrm

zero_point1torch.ao.nn.quantized.modules.Quantize.zero_point,
torch._tensor.Tensor"torch._tensor.Tensorr>
dtype,torch.ao.nn.quantized.modules.Quantize.dtype
Any•

DeQuantize(torch.ao.nn.quantized.modules.DeQuantize"torch.nn.modules.module.Module*M
forward0torch.ao.nn.quantized.modules.DeQuantize.forward*
self*
Xq*~

from_float3torch.ao.nn.quantized.modules.DeQuantize.from_float*
mod* 
use_precomputed_fake_quant 0:staticmethodh*s
__path__torch.nn.quantized.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*é
__annotations__"torch.nn.quantized.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*'
dynamictorch.nn.quantized.dynamic *-

functionaltorch.nn.quantized.functional *'
modulestorch.nn.quantized.modules *q
__all__torch.nn.quantized.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list