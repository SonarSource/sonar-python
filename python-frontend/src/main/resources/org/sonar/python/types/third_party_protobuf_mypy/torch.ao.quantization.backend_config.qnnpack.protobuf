
,torch.ao.quantization.backend_config.qnnpackî
get_qnnpack_backend_configGtorch.ao.quantization.backend_config.qnnpack.get_qnnpack_backend_config"†
Atorch.ao.quantization.backend_config.backend_config.BackendConfig"Atorch.ao.quantization.backend_config.backend_config.BackendConfig*¨
__annotations__<torch.ao.quantization.backend_config.qnnpack.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*‹
__all__4torch.ao.quantization.backend_config.qnnpack.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*„
'qnnpack_weighted_op_quint8_dtype_configTtorch.ao.quantization.backend_config.qnnpack.qnnpack_weighted_op_quint8_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*‚
&qnnpack_default_op_quint8_dtype_configStorch.ao.quantization.backend_config.qnnpack.qnnpack_default_op_quint8_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*þ
$qnnpack_default_op_fp16_dtype_configQtorch.ao.quantization.backend_config.qnnpack.qnnpack_default_op_fp16_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*ˆ
)qnnpack_default_dynamic_int8_dtype_configVtorch.ao.quantization.backend_config.qnnpack.qnnpack_default_dynamic_int8_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*Ž
,qnnpack_default_dynamic_float16_dtype_configYtorch.ao.quantization.backend_config.qnnpack.qnnpack_default_dynamic_float16_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*„
'qnnpack_weight_only_quint8_dtype_configTtorch.ao.quantization.backend_config.qnnpack.qnnpack_weight_only_quint8_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*ˆ
)qnnpack_weight_only_quint4x2_dtype_configVtorch.ao.quantization.backend_config.qnnpack.qnnpack_weight_only_quint4x2_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*
$qnnpack_act_qint8_scale_min_2_neg_12Qtorch.ao.quantization.backend_config.qnnpack.qnnpack_act_qint8_scale_min_2_neg_12”
Htorch.ao.quantization.backend_config.backend_config.DTypeWithConstraints"Htorch.ao.quantization.backend_config.backend_config.DTypeWithConstraints*´
6qnnpack_weight_qint8_neg_127_to_127_scale_min_2_neg_12ctorch.ao.quantization.backend_config.qnnpack.qnnpack_weight_qint8_neg_127_to_127_scale_min_2_neg_12”
Htorch.ao.quantization.backend_config.backend_config.DTypeWithConstraints"Htorch.ao.quantization.backend_config.backend_config.DTypeWithConstraints*–
0qnnpack_weighted_op_qint8_symmetric_dtype_config]torch.ao.quantization.backend_config.qnnpack.qnnpack_weighted_op_qint8_symmetric_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig*”
/qnnpack_default_op_qint8_symmetric_dtype_config\torch.ao.quantization.backend_config.qnnpack.qnnpack_default_op_qint8_symmetric_dtype_config‚
?torch.ao.quantization.backend_config.backend_config.DTypeConfig"?torch.ao.quantization.backend_config.backend_config.DTypeConfig