
pyspark.conf≈
	SparkConfpyspark.conf.SparkConf"builtins.object*è
__init__pyspark.conf.SparkConf.__init__"
None*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*2
loadDefaults
builtins.bool"builtins.bool *2
_jvm&
Union[Any,None]
Any
None *4
_jconf&
Union[Any,None]
Any
None *ﬂ
setpyspark.conf.SparkConf.set"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*%
key
builtins.str"builtins.str*'
value
builtins.str"builtins.str*Ò
setIfMissing#pyspark.conf.SparkConf.setIfMissing"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*%
key
builtins.str"builtins.str*'
value
builtins.str"builtins.str*ƒ
	setMaster pyspark.conf.SparkConf.setMaster"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*'
value
builtins.str"builtins.str*∆

setAppName!pyspark.conf.SparkConf.setAppName"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*'
value
builtins.str"builtins.str* 
setSparkHome#pyspark.conf.SparkConf.setSparkHome"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*'
value
builtins.str"builtins.str*∆
setAllpyspark.conf.SparkConf.setAll"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*Æ
pairs¢
/builtins.list[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.list*à
getAllpyspark.conf.SparkConf.getAll"¢
/builtins.list[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.list*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*Æ
containspyspark.conf.SparkConf.contains"
builtins.bool"builtins.bool*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*%
key
builtins.str"builtins.str*è
toDebugString$pyspark.conf.SparkConf.toDebugString"
builtins.str"builtins.str*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf2§
setExecutorEnv%pyspark.conf.SparkConf.setExecutorEnvÉ
setExecutorEnv%pyspark.conf.SparkConf.setExecutorEnv"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*%
key
builtins.str"builtins.str*'
value
builtins.str"builtins.str0:overloadX‰
setExecutorEnv%pyspark.conf.SparkConf.setExecutorEnv"0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*Æ
pairs¢
/builtins.list[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.list0:overloadX2÷
getpyspark.conf.SparkConf.getÿ
getpyspark.conf.SparkConf.get"D
Union[builtins.str,None]
builtins.str"builtins.str
None*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*%
key
builtins.str"builtins.str0:overloadXÙ
getpyspark.conf.SparkConf.get"D
Union[builtins.str,None]
builtins.str"builtins.str
None*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*%
key
builtins.str"builtins.str*
defaultValue
None0:overloadX‡
getpyspark.conf.SparkConf.get"
builtins.str"builtins.str*:
self0
pyspark.conf.SparkConf"pyspark.conf.SparkConf*%
key
builtins.str"builtins.str*.
defaultValue
builtins.str"builtins.str0:overloadXrO
_jconfpyspark.conf.SparkConf._jconf&
Union[Any,None]
Any
Noner·
_confpyspark.conf.SparkConf._confπ
4Union[builtins.dict[builtins.str,builtins.str],None]u
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict
None%
_testpyspark.conf._test"
None*à
__annotations__pyspark.conf.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*k
__all__pyspark.conf.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*(
JVMViewpyspark.conf.JVMView
Any*.

JavaObjectpyspark.conf.JavaObject
Any