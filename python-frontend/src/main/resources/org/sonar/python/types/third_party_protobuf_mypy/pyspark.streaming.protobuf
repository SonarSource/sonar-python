
pyspark.streamingˆH
StreamingContext*pyspark.streaming.context.StreamingContext"builtins.object*Œ
__init__3pyspark.streaming.context.StreamingContext.__init__"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*N
sparkContext<
pyspark.context.SparkContext"pyspark.context.SparkContext*Y
batchDurationD
Union[builtins.int,None]
builtins.int"builtins.int
None *2
jssc&
Union[Any,None]
Any
None *Ü
_initialize_context>pyspark.streaming.context.StreamingContext._initialize_context"
Any*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*D
sc<
pyspark.context.SparkContext"pyspark.context.SparkContext*R
durationD
Union[builtins.int,None]
builtins.int"builtins.int
None*Û

_jduration5pyspark.streaming.context.StreamingContext._jduration"
Any*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*)
seconds
builtins.int"builtins.int*‘
_ensure_initialized>pyspark.streaming.context.StreamingContext._ensure_initialized"
None*ž
cls”
0Type[pyspark.streaming.context.StreamingContext]X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext"type0:classmethodp*ß
getOrCreate6pyspark.streaming.context.StreamingContext.getOrCreate"X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*ž
cls”
0Type[pyspark.streaming.context.StreamingContext]X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext"type*0
checkpointPath
builtins.str"builtins.str*Z
	setupFuncK
CallableType[builtins.function]&
builtins.function"builtins.function0:classmethodp*”
	getActive4pyspark.streaming.context.StreamingContext.getActive"ž
6Union[pyspark.streaming.context.StreamingContext,None]X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext
None*ž
cls”
0Type[pyspark.streaming.context.StreamingContext]X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext"type0:classmethodp*ë
getActiveOrCreate<pyspark.streaming.context.StreamingContext.getActiveOrCreate"X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*ž
cls”
0Type[pyspark.streaming.context.StreamingContext]X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext"type*0
checkpointPath
builtins.str"builtins.str*Z
	setupFuncK
CallableType[builtins.function]&
builtins.function"builtins.function0:classmethodp*÷
sparkContext7pyspark.streaming.context.StreamingContext.sparkContext"<
pyspark.context.SparkContext"pyspark.context.SparkContext*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext0:property`*§
start0pyspark.streaming.context.StreamingContext.start"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*’
awaitTermination;pyspark.streaming.context.StreamingContext.awaitTermination"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*S
timeoutD
Union[builtins.int,None]
builtins.int"builtins.int
None *ú
awaitTerminationOrTimeoutDpyspark.streaming.context.StreamingContext.awaitTerminationOrTimeout"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*)
timeout
builtins.int"builtins.int*“
stop/pyspark.streaming.context.StreamingContext.stop"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*6
stopSparkContext
builtins.bool"builtins.bool *4
stopGraceFully
builtins.bool"builtins.bool *Ù
remember3pyspark.streaming.context.StreamingContext.remember"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext**
duration
builtins.int"builtins.int*Þ

checkpoint5pyspark.streaming.context.StreamingContext.checkpoint"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*+
	directory
builtins.str"builtins.str*×
socketTextStream;pyspark.streaming.context.StreamingContext.socketTextStream"r
/pyspark.streaming.dstream.DStream[builtins.str]
builtins.str"builtins.str"!pyspark.streaming.dstream.DStream*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext**
hostname
builtins.str"builtins.str*&
port
builtins.int"builtins.int*Z
storageLevelF
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel *Ð
textFileStream9pyspark.streaming.context.StreamingContext.textFileStream"r
/pyspark.streaming.dstream.DStream[builtins.str]
builtins.str"builtins.str"!pyspark.streaming.dstream.DStream*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*+
	directory
builtins.str"builtins.str*
binaryRecordsStream>pyspark.streaming.context.StreamingContext.binaryRecordsStream"x
1pyspark.streaming.dstream.DStream[builtins.bytes] 
builtins.bytes"builtins.bytes"!pyspark.streaming.dstream.DStream*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*+
	directory
builtins.str"builtins.str*.
recordLength
builtins.int"builtins.int*³
_check_serializers=pyspark.streaming.context.StreamingContext._check_serializers"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*ï
rddsä
;builtins.list[pyspark.rdd.RDD[pyspark.streaming.context.T]]•
,pyspark.rdd.RDD[pyspark.streaming.context.T]T
pyspark.streaming.context.T"
builtins.object"builtins.object"builtins.object"pyspark.rdd.RDD"builtins.list*ú
queueStream6pyspark.streaming.context.StreamingContext.queueStream"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.context.T]T
pyspark.streaming.context.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*ï
rddsä
;builtins.list[pyspark.rdd.RDD[pyspark.streaming.context.T]]•
,pyspark.rdd.RDD[pyspark.streaming.context.T]T
pyspark.streaming.context.T"
builtins.object"builtins.object"builtins.object"pyspark.rdd.RDD"builtins.list*0

oneAtATime
builtins.bool"builtins.bool *î
defaultÞ
8Union[pyspark.rdd.RDD[pyspark.streaming.context.T],None]•
,pyspark.rdd.RDD[pyspark.streaming.context.T]T
pyspark.streaming.context.T"
builtins.object"builtins.object"builtins.object"pyspark.rdd.RDD
None *ï
	transform4pyspark.streaming.context.StreamingContext.transform"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.context.T]T
pyspark.streaming.context.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*«
dstreamsœ
5builtins.list[pyspark.streaming.dstream.DStream[Any]]T
&pyspark.streaming.dstream.DStream[Any]
Any"!pyspark.streaming.dstream.DStream"builtins.list*^
transformFuncK
CallableType[builtins.function]&
builtins.function"builtins.function*¤
union0pyspark.streaming.context.StreamingContext.union"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.context.T]T
pyspark.streaming.context.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*È
dstreams¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.context.T]T
pyspark.streaming.context.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*º
addStreamingListener?pyspark.streaming.context.StreamingContext.addStreamingListener"
None*b
selfX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*s
streamingListener\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListenerr”
_transformerSerializerApyspark.streaming.context.StreamingContext._transformerSerializer¶
>Union[pyspark.streaming.util.TransformFunctionSerializer,None]h
2pyspark.streaming.util.TransformFunctionSerializer"2pyspark.streaming.util.TransformFunctionSerializer
Nonerì
_activeContext9pyspark.streaming.context.StreamingContext._activeContextž
6Union[pyspark.streaming.context.StreamingContext,None]X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext
Noners
_sc.pyspark.streaming.context.StreamingContext._sc<
pyspark.context.SparkContext"pyspark.context.SparkContextr_
_jvm/pyspark.streaming.context.StreamingContext._jvm&
Union[Any,None]
Any
NonerB
_jssc0pyspark.streaming.context.StreamingContext._jssc
Anyä¢
DStream!pyspark.streaming.dstream.DStream"builtins.object*à
__init__*pyspark.streaming.dstream.DStream.__init__"
None*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*
jdstream
Any*a
sscX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*W
jrdd_deserializer@
pyspark.serializers.Serializer"pyspark.serializers.Serializer*Û
context)pyspark.streaming.dstream.DStream.context"X
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContext*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*ñ
count'pyspark.streaming.dstream.DStream.count"r
/pyspark.streaming.dstream.DStream[builtins.int]
builtins.int"builtins.int"!pyspark.streaming.dstream.DStream*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‰
filter(pyspark.streaming.dstream.DStream.filter"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*È
flatMap)pyspark.streaming.dstream.DStream.flatMap"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*;
preservesPartitioning
builtins.bool"builtins.bool *À
map%pyspark.streaming.dstream.DStream.map"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*;
preservesPartitioning
builtins.bool"builtins.bool *Ô
mapPartitions/pyspark.streaming.dstream.DStream.mapPartitions"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*;
preservesPartitioning
builtins.bool"builtins.bool *æ
mapPartitionsWithIndex8pyspark.streaming.dstream.DStream.mapPartitionsWithIndex"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*;
preservesPartitioning
builtins.bool"builtins.bool *Œ
reduce(pyspark.streaming.dstream.DStream.reduce"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*í
reduceByKey-pyspark.streaming.dstream.DStream.reduceByKey"÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *·	
combineByKey.pyspark.streaming.dstream.DStream.combineByKey"÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*_
createCombinerK
CallableType[builtins.function]&
builtins.function"builtins.function*[

mergeValueK
CallableType[builtins.function]&
builtins.function"builtins.function*_
mergeCombinersK
CallableType[builtins.function]&
builtins.function"builtins.function*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *Î
partitionBy-pyspark.streaming.dstream.DStream.partitionBy"÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*/
numPartitions
builtins.int"builtins.int*`
partitionFuncK
CallableType[builtins.function]&
builtins.function"builtins.function *²
pprint(pyspark.streaming.dstream.DStream.pprint"
None*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*'
num
builtins.int"builtins.int *‹
	mapValues+pyspark.streaming.dstream.DStream.mapValues"÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*“
flatMapValues/pyspark.streaming.dstream.DStream.flatMapValues"÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*þ
glom&pyspark.streaming.dstream.DStream.glom"†
Mpyspark.streaming.dstream.DStream[builtins.list[pyspark.streaming.dstream.T]]‘
*builtins.list[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"builtins.list"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*³
cache'pyspark.streaming.dstream.DStream.cache"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‘
persist)pyspark.streaming.dstream.DStream.persist"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*X
storageLevelF
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel*é

checkpoint,pyspark.streaming.dstream.DStream.checkpoint"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream**
interval
builtins.int"builtins.int*ø

groupByKey,pyspark.streaming.dstream.DStream.groupByKey"Û
rpyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,typing.Iterable[pyspark.streaming.dstream.V]]]Á
OTuple[pyspark.streaming.dstream.K,typing.Iterable[pyspark.streaming.dstream.V]]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashable•
,typing.Iterable[pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"typing.Iterable"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *©
countByValue.pyspark.streaming.dstream.DStream.countByValue"¡
Rpyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,builtins.int]]§
/Tuple[pyspark.streaming.dstream.K,builtins.int]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashable
builtins.int"builtins.int"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.K]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashable"!pyspark.streaming.dstream.DStream*™
saveAsTextFiles1pyspark.streaming.dstream.DStream.saveAsTextFiles"
None*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*(
prefix
builtins.str"builtins.str*R
suffixD
Union[builtins.str,None]
builtins.str"builtins.str
None *ð
repartition-pyspark.streaming.dstream.DStream.repartition"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*/
numPartitions
builtins.int"builtins.int*§
_slideDuration0pyspark.streaming.dstream.DStream._slideDuration"
None*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream0:property`*¹
union'pyspark.streaming.dstream.DStream.union"÷
apyspark.streaming.dstream.DStream[Union[pyspark.streaming.dstream.T,pyspark.streaming.dstream.U]]î
>Union[pyspark.streaming.dstream.T,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.objectT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Å
other¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*¾
cogroup)pyspark.streaming.dstream.DStream.cogroup"¡
Òpyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,Tuple[pyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.V],pyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.U]]]]¦
¯Tuple[pyspark.streaming.dstream.K,Tuple[pyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.V],pyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.U]]]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashable™
ŒTuple[pyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.V],pyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.U]]Á
Bpyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"%pyspark.resultiterable.ResultIterableÁ
Bpyspark.resultiterable.ResultIterable[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"%pyspark.resultiterable.ResultIterable"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*ƒ
other÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *ð
join&pyspark.streaming.dstream.DStream.join"Ù
„pyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,Tuple[pyspark.streaming.dstream.V,pyspark.streaming.dstream.U]]]¬
aTuple[pyspark.streaming.dstream.K,Tuple[pyspark.streaming.dstream.V,pyspark.streaming.dstream.U]]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashableî
>Tuple[pyspark.streaming.dstream.V,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.objectT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*ƒ
other÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *Þ
leftOuterJoin/pyspark.streaming.dstream.DStream.leftOuterJoin"µ
pyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,Tuple[pyspark.streaming.dstream.V,Union[pyspark.streaming.dstream.U,None]]]]ü
mTuple[pyspark.streaming.dstream.K,Tuple[pyspark.streaming.dstream.V,Union[pyspark.streaming.dstream.U,None]]]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashable²
JTuple[pyspark.streaming.dstream.V,Union[pyspark.streaming.dstream.U,None]]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object‹
'Union[pyspark.streaming.dstream.U,None]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object
None"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*ƒ
other÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *à
rightOuterJoin0pyspark.streaming.dstream.DStream.rightOuterJoin"µ
pyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,Tuple[Union[pyspark.streaming.dstream.V,None],pyspark.streaming.dstream.U]]]ü
mTuple[pyspark.streaming.dstream.K,Tuple[Union[pyspark.streaming.dstream.V,None],pyspark.streaming.dstream.U]]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashable²
JTuple[Union[pyspark.streaming.dstream.V,None],pyspark.streaming.dstream.U]‹
'Union[pyspark.streaming.dstream.V,None]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object
NoneT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*ƒ
other÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *º
fullOuterJoin/pyspark.streaming.dstream.DStream.fullOuterJoin"‘
œpyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,Tuple[Union[pyspark.streaming.dstream.V,None],Union[pyspark.streaming.dstream.U,None]]]]Ì
yTuple[pyspark.streaming.dstream.K,Tuple[Union[pyspark.streaming.dstream.V,None],Union[pyspark.streaming.dstream.U,None]]]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashableö
VTuple[Union[pyspark.streaming.dstream.V,None],Union[pyspark.streaming.dstream.U,None]]‹
'Union[pyspark.streaming.dstream.V,None]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object
None‹
'Union[pyspark.streaming.dstream.U,None]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object
None"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*ƒ
other÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *»
_jtime(pyspark.streaming.dstream.DStream._jtime"
Any*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*°
	timestamp 
4Union[datetime.datetime,builtins.int,builtins.float]&
datetime.datetime"datetime.datetime
builtins.int"builtins.int 
builtins.float"builtins.float*Ú
slice'pyspark.streaming.dstream.DStream.slice"ä
;builtins.list[pyspark.rdd.RDD[pyspark.streaming.dstream.T]]•
,pyspark.rdd.RDD[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"pyspark.rdd.RDD"builtins.list*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*z
begino
%Union[datetime.datetime,builtins.int]&
datetime.datetime"datetime.datetime
builtins.int"builtins.int*x
endo
%Union[datetime.datetime,builtins.int]&
datetime.datetime"datetime.datetime
builtins.int"builtins.int*¤
_validate_window_param8pyspark.streaming.dstream.DStream._validate_window_param"
None*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*(
window
builtins.int"builtins.int*O
slideD
Union[builtins.int,None]
builtins.int"builtins.int
None*È
window(pyspark.streaming.dstream.DStream.window"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ê
self¿
Apyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T_co]W
pyspark.streaming.dstream.T_co"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*0
windowDuration
builtins.int"builtins.int*Y
slideDurationD
Union[builtins.int,None]
builtins.int"builtins.int
None *¢
reduceByWindow0pyspark.streaming.dstream.DStream.reduceByWindow"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*[

reduceFuncK
CallableType[builtins.function]&
builtins.function"builtins.function*š
invReduceFunc†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*0
windowDuration
builtins.int"builtins.int*/
slideDuration
builtins.int"builtins.int*Þ
countByWindow/pyspark.streaming.dstream.DStream.countByWindow"r
/pyspark.streaming.dstream.DStream[builtins.int]
builtins.int"builtins.int"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*0
windowDuration
builtins.int"builtins.int*/
slideDuration
builtins.int"builtins.int*ù
countByValueAndWindow7pyspark.streaming.dstream.DStream.countByValueAndWindow"¡
Rpyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.T,builtins.int]]§
/Tuple[pyspark.streaming.dstream.T,builtins.int]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object
builtins.int"builtins.int"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*0
windowDuration
builtins.int"builtins.int*/
slideDuration
builtins.int"builtins.int*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *í
groupByKeyAndWindow5pyspark.streaming.dstream.DStream.groupByKeyAndWindow"Û
rpyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,typing.Iterable[pyspark.streaming.dstream.V]]]Á
OTuple[pyspark.streaming.dstream.K,typing.Iterable[pyspark.streaming.dstream.V]]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.Hashable•
,typing.Iterable[pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"typing.Iterable"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*0
windowDuration
builtins.int"builtins.int*/
slideDuration
builtins.int"builtins.int*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *¿
reduceByKeyAndWindow6pyspark.streaming.dstream.DStream.reduceByKeyAndWindow"÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*”
invFunc†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*0
windowDuration
builtins.int"builtins.int*Y
slideDurationD
Union[builtins.int,None]
builtins.int"builtins.int
None *Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *™

filterFunc†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None *ù
updateStateByKey2pyspark.streaming.dstream.DStream.updateStateByKey"÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.S"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*‚
self÷
apyspark.streaming.dstream.DStream[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*[

updateFuncK
CallableType[builtins.function]&
builtins.function"builtins.function*Y
numPartitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *ù

initialRDDæ
«Union[pyspark.rdd.RDD[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]],typing.Iterable[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]],None]Ó
Opyspark.rdd.RDD[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.S"
builtins.object"builtins.object"builtins.object"pyspark.rdd.RDDÓ
Otyping.Iterable[Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]]î
>Tuple[pyspark.streaming.dstream.K,pyspark.streaming.dstream.S]T
pyspark.streaming.dstream.K"
typing.Hashable"typing.Hashable"typing.HashableT
pyspark.streaming.dstream.S"
builtins.object"builtins.object"builtins.object"typing.Iterable
None 2 

foreachRDD,pyspark.streaming.dstream.DStream.foreachRDDð

foreachRDD,pyspark.streaming.dstream.DStream.foreachRDD"
None*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function0:overloadXð

foreachRDD,pyspark.streaming.dstream.DStream.foreachRDD"
None*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function0:overloadX2ª	
	transform+pyspark.streaming.dstream.DStream.transform¶
	transform+pyspark.streaming.dstream.DStream.transform"Ï
Ipyspark.streaming.dstream.TransformedDStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object",pyspark.streaming.dstream.TransformedDStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function0:overloadX¶
	transform+pyspark.streaming.dstream.DStream.transform"Ï
Ipyspark.streaming.dstream.TransformedDStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object",pyspark.streaming.dstream.TransformedDStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function0:overloadX2’
transformWith/pyspark.streaming.dstream.DStream.transformWith¦
transformWith/pyspark.streaming.dstream.DStream.transformWith"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*Å
other¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*4
keepSerializer
builtins.bool"builtins.bool 0:overloadX¦
transformWith/pyspark.streaming.dstream.DStream.transformWith"¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.V]T
pyspark.streaming.dstream.V"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*Ä
self¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.T]T
pyspark.streaming.dstream.T"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*Å
other¹
>pyspark.streaming.dstream.DStream[pyspark.streaming.dstream.U]T
pyspark.streaming.dstream.U"
builtins.object"builtins.object"builtins.object"!pyspark.streaming.dstream.DStream*4
keepSerializer
builtins.bool"builtins.bool 0:overloadXPrA
	_jdstream+pyspark.streaming.dstream.DStream._jdstream
Anyrˆ
_ssc&pyspark.streaming.dstream.DStream._sscX
*pyspark.streaming.context.StreamingContext"*pyspark.streaming.context.StreamingContextrj
_sc%pyspark.streaming.dstream.DStream._sc<
pyspark.context.SparkContext"pyspark.context.SparkContextrŒ
_jrdd_deserializer4pyspark.streaming.dstream.DStream._jrdd_deserializer@
pyspark.serializers.Serializer"pyspark.serializers.SerializerrX
	is_cached+pyspark.streaming.dstream.DStream.is_cached
builtins.bool"builtins.boolrd
is_checkpointed1pyspark.streaming.dstream.DStream.is_checkpointed
builtins.bool"builtins.bool¤
StreamingListener,pyspark.streaming.listener.StreamingListener"builtins.object*³
__init__5pyspark.streaming.listener.StreamingListener.__init__"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*æ
onStreamingStarted?pyspark.streaming.listener.StreamingListener.onStreamingStarted"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*
streamingStarted
Any*ã
onReceiverStarted>pyspark.streaming.listener.StreamingListener.onReceiverStarted"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*
receiverStarted
Any*Ý
onReceiverError<pyspark.streaming.listener.StreamingListener.onReceiverError"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*
receiverError
Any*ã
onReceiverStopped>pyspark.streaming.listener.StreamingListener.onReceiverStopped"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*
receiverStopped
Any*à
onBatchSubmitted=pyspark.streaming.listener.StreamingListener.onBatchSubmitted"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*
batchSubmitted
Any*Ü
onBatchStarted;pyspark.streaming.listener.StreamingListener.onBatchStarted"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*
batchSubmitted
Any*à
onBatchCompleted=pyspark.streaming.listener.StreamingListener.onBatchCompleted"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*
batchCompleted
Any*ø
onOutputOperationStartedEpyspark.streaming.listener.StreamingListener.onOutputOperationStarted"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*#
outputOperationStarted
Any*þ
onOutputOperationCompletedGpyspark.streaming.listener.StreamingListener.onOutputOperationCompleted"
None*f
self\
,pyspark.streaming.listener.StreamingListener",pyspark.streaming.listener.StreamingListener*%
outputOperationCompleted
Anyzã
Java1pyspark.streaming.listener.StreamingListener.Java"builtins.objectr–

implements<pyspark.streaming.listener.StreamingListener.Java.implementsJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*r
__path__pyspark.streaming.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*
__annotations__!pyspark.streaming.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*p
__all__pyspark.streaming.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list