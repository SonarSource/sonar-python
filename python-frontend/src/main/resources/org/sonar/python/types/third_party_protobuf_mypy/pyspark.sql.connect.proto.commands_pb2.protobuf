
&pyspark.sql.connect.proto.commands_pb2Žm
Command.pyspark.sql.connect.proto.commands_pb2.Command"builtins.object*è
register_function@pyspark.sql.connect.proto.commands_pb2.Command.register_function"–
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*»
write_operation>pyspark.sql.connect.proto.commands_pb2.Command.write_operation"n
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*à
create_dataframe_viewDpyspark.sql.connect.proto.commands_pb2.Command.create_dataframe_view"†
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*Å
write_operation_v2Apyspark.sql.connect.proto.commands_pb2.Command.write_operation_v2"r
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*«
sql_command:pyspark.sql.connect.proto.commands_pb2.Command.sql_command"f
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*ì
write_stream_operation_startKpyspark.sql.connect.proto.commands_pb2.Command.write_stream_operation_start"„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*Ù
streaming_query_commandFpyspark.sql.connect.proto.commands_pb2.Command.streaming_query_command"|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*Ñ
get_resources_commandDpyspark.sql.connect.proto.commands_pb2.Command.get_resources_command"x
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*ø
streaming_query_manager_commandNpyspark.sql.connect.proto.commands_pb2.Command.streaming_query_manager_command"Š
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*ú
register_table_functionFpyspark.sql.connect.proto.commands_pb2.Command.register_table_function"œ
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*È
	extension8pyspark.sql.connect.proto.commands_pb2.Command.extension"
Any*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*Ã
__init__7pyspark.sql.connect.proto.commands_pb2.Command.__init__"
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*–
register_functionü
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]–
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *×
write_operation¿
AUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation,None]n
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation
None *‚
create_dataframe_viewä
MUnion[pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand,None]†
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand
None *à
write_operation_v2Å
CUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperationV2,None]r
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2
None *Ç
sql_command³
=Union[pyspark.sql.connect.proto.commands_pb2.SqlCommand,None]f
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand
None *†
write_stream_operation_startá
LUnion[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart,None]„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart
None *ô
streaming_query_commandÔ
HUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand,None]|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand
None *ì
get_resources_commandÎ
FUnion[pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand,None]x
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand
None *’
streaming_query_manager_commandê
OUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand,None]Š
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand
None *¥
register_table_function…
XUnion[pyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction,None]œ
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction
None *7
	extension&
Union[Any,None]
Any
None *¶
HasField7pyspark.sql.connect.proto.commands_pb2.Command.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*ä

field_nameÓ
®Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¤

ClearField9pyspark.sql.connect.proto.commands_pb2.Command.ClearField"
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*ä

field_nameÓ
®Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ú	

WhichOneof9pyspark.sql.connect.proto.commands_pb2.Command.WhichOneof"ÿ
ýUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.commands_pb2.Command.DESCRIPTOR
Anyr
REGISTER_FUNCTION_FIELD_NUMBERMpyspark.sql.connect.proto.commands_pb2.Command.REGISTER_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr‰
WRITE_OPERATION_FIELD_NUMBERKpyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_FIELD_NUMBER
builtins.int"builtins.intr•
"CREATE_DATAFRAME_VIEW_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.Command.CREATE_DATAFRAME_VIEW_FIELD_NUMBER
builtins.int"builtins.intr
WRITE_OPERATION_V2_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_V2_FIELD_NUMBER
builtins.int"builtins.intr
SQL_COMMAND_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.Command.SQL_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr£
)WRITE_STREAM_OPERATION_START_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.Command.WRITE_STREAM_OPERATION_START_FIELD_NUMBER
builtins.int"builtins.intr™
$STREAMING_QUERY_COMMAND_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.Command.STREAMING_QUERY_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr•
"GET_RESOURCES_COMMAND_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.Command.GET_RESOURCES_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr©
,STREAMING_QUERY_MANAGER_COMMAND_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.Command.STREAMING_QUERY_MANAGER_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr™
$REGISTER_TABLE_FUNCTION_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.Command.REGISTER_TABLE_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr}
EXTENSION_FIELD_NUMBEREpyspark.sql.connect.proto.commands_pb2.Command.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intÄ(

SqlCommand1pyspark.sql.connect.proto.commands_pb2.SqlCommand"builtins.object*Ç
args6pyspark.sql.connect.proto.commands_pb2.SqlCommand.args"
Any*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand0:property`*Ï
pos_args:pyspark.sql.connect.proto.commands_pb2.SqlCommand.pos_args"
Any*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand0:property`*Ô
__init__:pyspark.sql.connect.proto.commands_pb2.SqlCommand.__init__"
None*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*'
sql
builtins.str"builtins.str *Š
argsý
eUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]‡
Ytyping.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]
builtins.str"builtins.str|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Mapping
None *Ù
pos_argsÈ
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]Þ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *×

ClearField<pyspark.sql.connect.proto.commands_pb2.SqlCommand.ClearField"
None*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*Ž

field_nameý
Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.commands_pb2.SqlCommand.DESCRIPTOR
Anyrt
SQL_FIELD_NUMBERBpyspark.sql.connect.proto.commands_pb2.SqlCommand.SQL_FIELD_NUMBER
builtins.int"builtins.intrv
ARGS_FIELD_NUMBERCpyspark.sql.connect.proto.commands_pb2.SqlCommand.ARGS_FIELD_NUMBER
builtins.int"builtins.intr~
POS_ARGS_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.SqlCommand.POS_ARGS_FIELD_NUMBER
builtins.int"builtins.intrZ
sql5pyspark.sql.connect.proto.commands_pb2.SqlCommand.sql
builtins.str"builtins.strz…
	ArgsEntry;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry"builtins.object*Ý
valueApyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.value"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*„
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry0:property`*ï
__init__Dpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.__init__"
None*„
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry*'
key
builtins.str"builtins.str *â
valueÔ
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *»
HasFieldDpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.HasField"
builtins.bool"builtins.bool*„
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ï

ClearFieldFpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.ClearField"
None*„
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.DESCRIPTOR
Anyr~
KEY_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr‚
VALUE_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrd
key?pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.key
builtins.str"builtins.str‰
CreateDataFrameViewCommandApyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"builtins.object*Ø
inputGpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*‘
self†
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand0:property`*¿
__init__Jpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.__init__"
None*‘
self†
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*¾
input°
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
name
builtins.str"builtins.str */
	is_global
builtins.bool"builtins.bool *-
replace
builtins.bool"builtins.bool *Î
HasFieldJpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.HasField"
builtins.bool"builtins.bool*‘
self†
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¯

ClearFieldLpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.ClearField"
None*‘
self†
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*´

field_name£
¾Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.DESCRIPTOR
Anyrˆ
INPUT_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.INPUT_FIELD_NUMBER
builtins.int"builtins.intr†
NAME_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.NAME_FIELD_NUMBER
builtins.int"builtins.intr
IS_GLOBAL_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.IS_GLOBAL_FIELD_NUMBER
builtins.int"builtins.intrŒ
REPLACE_FIELD_NUMBERVpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.REPLACE_FIELD_NUMBER
builtins.int"builtins.intrl
nameFpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.name
builtins.str"builtins.strrx
	is_globalKpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.is_global
builtins.bool"builtins.boolrt
replaceIpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.replace
builtins.bool"builtins.bool¨®
WriteOperation5pyspark.sql.connect.proto.commands_pb2.WriteOperation"builtins.object*²
input;pyspark.sql.connect.proto.commands_pb2.WriteOperation.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*Ñ
table;pyspark.sql.connect.proto.commands_pb2.WriteOperation.table"‚
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*í
sort_column_namesGpyspark.sql.connect.proto.commands_pb2.WriteOperation.sort_column_names"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*ó
partitioning_columnsJpyspark.sql.connect.proto.commands_pb2.WriteOperation.partitioning_columns"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*×
	bucket_by?pyspark.sql.connect.proto.commands_pb2.WriteOperation.bucket_by"€
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*Ù
options=pyspark.sql.connect.proto.commands_pb2.WriteOperation.options"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*¬
__init__>pyspark.sql.connect.proto.commands_pb2.WriteOperation.__init__"
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¾
input°
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *R
sourceD
Union[builtins.str,None]
builtins.str"builtins.str
None *(
path
builtins.str"builtins.str *ì
tableÞ
KUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable,None]‚
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable
None *£
mode–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType *¡
sort_column_names‡
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *¤
partitioning_columns‡
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *í
	bucket_byÛ
JUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy,None]€
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy
None *Ì
options¼
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *
HasField>pyspark.sql.connect.proto.commands_pb2.WriteOperation.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¦	

field_name•	
ÈUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*“

ClearField@pyspark.sql.connect.proto.commands_pb2.WriteOperation.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¾

field_name­
€Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¼	

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneofŒ

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÜ

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof"·
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.commands_pb2.WriteOperation.DESCRIPTOR
Anyrý
SAVE_MODE_UNSPECIFIEDKpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_UNSPECIFIED–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperó
SAVE_MODE_APPENDFpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_APPEND–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperù
SAVE_MODE_OVERWRITEIpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_OVERWRITE–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyper…
SAVE_MODE_ERROR_IF_EXISTSOpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_ERROR_IF_EXISTS–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperó
SAVE_MODE_IGNOREFpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_IGNORE–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyper|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.commands_pb2.WriteOperation.INPUT_FIELD_NUMBER
builtins.int"builtins.intr~
SOURCE_FIELD_NUMBERIpyspark.sql.connect.proto.commands_pb2.WriteOperation.SOURCE_FIELD_NUMBER
builtins.int"builtins.intrz
PATH_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.WriteOperation.PATH_FIELD_NUMBER
builtins.int"builtins.intr|
TABLE_FIELD_NUMBERHpyspark.sql.connect.proto.commands_pb2.WriteOperation.TABLE_FIELD_NUMBER
builtins.int"builtins.intrz
MODE_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.WriteOperation.MODE_FIELD_NUMBER
builtins.int"builtins.intr”
SORT_COLUMN_NAMES_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.WriteOperation.SORT_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intrš
!PARTITIONING_COLUMNS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperation.PARTITIONING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intr„
BUCKET_BY_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.WriteOperation.BUCKET_BY_FIELD_NUMBER
builtins.int"builtins.intr€
OPTIONS_FIELD_NUMBERJpyspark.sql.connect.proto.commands_pb2.WriteOperation.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrd
source<pyspark.sql.connect.proto.commands_pb2.WriteOperation.source
builtins.str"builtins.strr`
path:pyspark.sql.connect.proto.commands_pb2.WriteOperation.path
builtins.str"builtins.strrÛ
mode:pyspark.sql.connect.proto.commands_pb2.WriteOperation.mode–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTypezû
	_SaveMode?pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode"builtins.objectz›
	ValueTypeIpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"builtins.int*´
__init__Rpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType.__init__"
None*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType*&
item
builtins.int"builtins.intzØ
_SaveModeEnumTypeWrapperNpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper"builtins.typerp

DESCRIPTORYpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.DESCRIPTOR
Anyr–
SAVE_MODE_UNSPECIFIEDdpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_UNSPECIFIED–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperŒ
SAVE_MODE_APPEND_pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_APPEND–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyper’
SAVE_MODE_OVERWRITEbpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_OVERWRITE–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperž
SAVE_MODE_ERROR_IF_EXISTShpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_ERROR_IF_EXISTS–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperŒ
SAVE_MODE_IGNORE_pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_IGNORE–
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTypezÝ
SaveMode>pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveMode"?pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode@bNpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapperzñ
OptionsEntryBpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry"builtins.object*Ë
__init__Kpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.__init__"
None*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry"Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *å

ClearFieldMpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.ClearField"
None*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry"Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.DESCRIPTOR
Anyr…
KEY_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr‰
VALUE_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrk
keyFpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.key
builtins.str"builtins.strro
valueHpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.value
builtins.str"builtins.strz£(
	SaveTable?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"builtins.object*í
__init__Hpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.__init__"
None*
self‚
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable*.

table_name
builtins.str"builtins.str *Ì
save_method¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType *Ü

ClearFieldJpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.ClearField"
None*
self‚
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.DESCRIPTOR
Anyr¹
TABLE_SAVE_METHOD_UNSPECIFIED]pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_UNSPECIFIED¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyper½
TABLE_SAVE_METHOD_SAVE_AS_TABLE_pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_SAVE_AS_TABLE¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyper¹
TABLE_SAVE_METHOD_INSERT_INTO]pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_INSERT_INTO¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyper
TABLE_NAME_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr’
SAVE_METHOD_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.SAVE_METHOD_FIELD_NUMBER
builtins.int"builtins.intrv

table_nameJpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.table_name
builtins.str"builtins.strr•
save_methodKpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.save_method¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTypez×
_TableSaveMethodPpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod"builtins.objectzß
	ValueTypeZpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"builtins.int*ç
__init__cpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType.__init__"
None*Ã
self¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType*&
item
builtins.int"builtins.intz­

_TableSaveMethodEnumTypeWrapper_pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper"builtins.typer

DESCRIPTORjpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.DESCRIPTOR
AnyrÙ
TABLE_SAVE_METHOD_UNSPECIFIED}pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_UNSPECIFIED¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyperÝ
TABLE_SAVE_METHOD_SAVE_AS_TABLEpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_SAVE_AS_TABLE¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyperÙ
TABLE_SAVE_METHOD_INSERT_INTO}pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_INSERT_INTO¸
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTypez—
TableSaveMethodOpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TableSaveMethod"Ppyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod@b_pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapperz 
BucketBy>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy"builtins.object*Ž
bucket_column_namesRpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.bucket_column_names"
Any*‹
self€
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy0:property`*Â
__init__Gpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.__init__"
None*‹
self€
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy*£
bucket_column_names‡
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None */
num_buckets
builtins.int"builtins.int *Ù

ClearFieldIpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.ClearField"
None*‹
self€
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.DESCRIPTOR
Anyr¡
 BUCKET_COLUMN_NAMES_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.BUCKET_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intr‘
NUM_BUCKETS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.NUM_BUCKETS_FIELD_NUMBER
builtins.int"builtins.intrw
num_bucketsJpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.num_buckets
builtins.int"builtins.intÔ|
WriteOperationV27pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"builtins.object*¸
input=pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*ù
partitioning_columnsLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.partitioning_columns"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*ß
options?pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.options"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*ñ
table_propertiesHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_properties"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*Ü
overwrite_conditionKpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.overwrite_condition"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*‡
__init__@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.__init__"
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*¾
input°
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *.

table_name
builtins.str"builtins.str *T
providerD
Union[builtins.str,None]
builtins.str"builtins.str
None *Å
partitioning_columns¨
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]Æ
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Ì
options¼
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *Õ
table_properties¼
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *Ÿ
mode’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType *Ø
overwrite_condition¼
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *¡
HasField@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.HasField"
builtins.bool"builtins.bool*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*´

field_name£
¾Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Í

ClearFieldBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*ò

field_nameá
¤Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ý

WhichOneofBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.DESCRIPTOR
Anyrñ
MODE_UNSPECIFIEDHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_UNSPECIFIED’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperç
MODE_CREATECpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperí
MODE_OVERWRITEFpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperƒ
MODE_OVERWRITE_PARTITIONSQpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITE_PARTITIONS’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperç
MODE_APPENDCpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_APPEND’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperé
MODE_REPLACEDpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_REPLACE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperý
MODE_CREATE_OR_REPLACENpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATE_OR_REPLACE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper~
INPUT_FIELD_NUMBERJpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.INPUT_FIELD_NUMBER
builtins.int"builtins.intrˆ
TABLE_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr„
PROVIDER_FIELD_NUMBERMpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PROVIDER_FIELD_NUMBER
builtins.int"builtins.intrœ
!PARTITIONING_COLUMNS_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PARTITIONING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intr‚
OPTIONS_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intr”
TABLE_PROPERTIES_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_PROPERTIES_FIELD_NUMBER
builtins.int"builtins.intr|
MODE_FIELD_NUMBERIpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_FIELD_NUMBER
builtins.int"builtins.intrš
 OVERWRITE_CONDITION_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OVERWRITE_CONDITION_FIELD_NUMBER
builtins.int"builtins.intrn

table_nameBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_name
builtins.str"builtins.strrj
provider@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.provider
builtins.str"builtins.strrÙ
mode<pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.mode’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTypezí
_Mode=pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode"builtins.objectz“
	ValueTypeGpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"builtins.int*®
__init__Ppyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType.__init__"
None*
self’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType*&
item
builtins.int"builtins.intz 
_ModeEnumTypeWrapperLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper"builtins.typern

DESCRIPTORWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.DESCRIPTOR
Anyr†
MODE_UNSPECIFIED]pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_UNSPECIFIED’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperü
MODE_CREATEXpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_CREATE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper‚
MODE_OVERWRITE[pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_OVERWRITE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper˜
MODE_OVERWRITE_PARTITIONSfpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_OVERWRITE_PARTITIONS’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperü
MODE_APPENDXpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_APPEND’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperþ
MODE_REPLACEYpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_REPLACE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper’
MODE_CREATE_OR_REPLACEcpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_CREATE_OR_REPLACE’
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTypezÓ
Mode<pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.Mode"=pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode@bLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapperz‰
OptionsEntryDpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry"builtins.object*Ñ
__init__Mpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.__init__"
None*—
selfŒ
Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry"Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *ë

ClearFieldOpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.ClearField"
None*—
selfŒ
Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry"Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.DESCRIPTOR
Anyr‡
KEY_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr‹
VALUE_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrm
keyHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.key
builtins.str"builtins.strrq
valueJpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.value
builtins.str"builtins.strzñ
TablePropertiesEntryLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry"builtins.object*é
__init__Upyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.__init__"
None*§
selfœ
Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry"Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *ƒ

ClearFieldWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.ClearField"
None*§
selfœ
Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry"Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrn

DESCRIPTORWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.DESCRIPTOR
Anyr
KEY_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr“
VALUE_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intru
keyPpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.key
builtins.str"builtins.strry
valueRpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.value
builtins.str"builtins.strÐw
WriteStreamOperationStart@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"builtins.object*Õ
inputFpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*ü
optionsHpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.options"
Any*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`* 
partitioning_column_namesZpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.partitioning_column_names"
Any*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*†
foreach_writerOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.foreach_writer"‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*„
foreach_batchNpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.foreach_batch"‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*æ
__init__Ipyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.__init__"
None*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¾
input°
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None **
format
builtins.str"builtins.str *Ì
options¼
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *©
partitioning_column_names‡
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *<
processing_time_interval
builtins.str"builtins.str *3
available_now
builtins.bool"builtins.bool **
once
builtins.bool"builtins.bool *B
continuous_checkpoint_interval
builtins.str"builtins.str */
output_mode
builtins.str"builtins.str *.

query_name
builtins.str"builtins.str *(
path
builtins.str"builtins.str *.

table_name
builtins.str"builtins.str *õ
foreach_writerÞ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction,None]‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction
None *ô
foreach_batchÞ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction,None]‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction
None *È
HasFieldIpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.HasField"
builtins.bool"builtins.bool*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¾

field_name­
€Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ô

ClearFieldKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.ClearField"
None*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*ü

field_nameë
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2û

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneofÿ

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneof"·
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneof"Õ
cUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*
self„
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrb

DESCRIPTORKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.DESCRIPTOR
Anyr‡
INPUT_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.INPUT_FIELD_NUMBER
builtins.int"builtins.intr‰
FORMAT_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FORMAT_FIELD_NUMBER
builtins.int"builtins.intr‹
OPTIONS_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intr¯
&PARTITIONING_COLUMN_NAMES_FIELD_NUMBERgpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PARTITIONING_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intr­
%PROCESSING_TIME_INTERVAL_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PROCESSING_TIME_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intr—
AVAILABLE_NOW_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.AVAILABLE_NOW_FIELD_NUMBER
builtins.int"builtins.intr…
ONCE_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.ONCE_FIELD_NUMBER
builtins.int"builtins.intr¹
+CONTINUOUS_CHECKPOINT_INTERVAL_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.CONTINUOUS_CHECKPOINT_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intr“
OUTPUT_MODE_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OUTPUT_MODE_FIELD_NUMBER
builtins.int"builtins.intr‘
QUERY_NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.QUERY_NAME_FIELD_NUMBER
builtins.int"builtins.intr…
PATH_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PATH_FIELD_NUMBER
builtins.int"builtins.intr‘
TABLE_NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr™
FOREACH_WRITER_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FOREACH_WRITER_FIELD_NUMBER
builtins.int"builtins.intr—
FOREACH_BATCH_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FOREACH_BATCH_FIELD_NUMBER
builtins.int"builtins.intro
formatGpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.format
builtins.str"builtins.strr“
processing_time_intervalYpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.processing_time_interval
builtins.str"builtins.strr
available_nowNpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.available_now
builtins.bool"builtins.boolrm
onceEpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.once
builtins.bool"builtins.boolrŸ
continuous_checkpoint_interval_pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.continuous_checkpoint_interval
builtins.str"builtins.strry
output_modeLpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.output_mode
builtins.str"builtins.strrw

query_nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.query_name
builtins.str"builtins.strrk
pathEpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.path
builtins.str"builtins.strrw

table_nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.table_name
builtins.str"builtins.strzõ
OptionsEntryMpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry"builtins.object*ì
__init__Vpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.__init__"
None*©
selfž
Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry"Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *†

ClearFieldXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.ClearField"
None*©
selfž
Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry"Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesro

DESCRIPTORXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.DESCRIPTOR
Anyr
KEY_FIELD_NUMBER^pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr”
VALUE_FIELD_NUMBER`pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrv
keyQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.key
builtins.str"builtins.strrz
valueSpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.value
builtins.str"builtins.strœ 
StreamingForeachFunction?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"builtins.object*ì
python_functionOpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.python_function"j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction0:property`*ô
scala_functionNpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.scala_function"t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction0:property`*¤
__init__Hpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.__init__"
None*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*Ñ
python_function¹
?Union[pyspark.sql.connect.proto.expressions_pb2.PythonUDF,None]j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF
None *ß
scala_functionÈ
DUnion[pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF,None]t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF
None *•
HasFieldHpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.HasField"
builtins.bool"builtins.bool*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*Ž

field_nameý
Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ƒ

ClearFieldJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.ClearField"
None*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*Ž

field_nameý
Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ç

WhichOneofJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.WhichOneof"·
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.DESCRIPTOR
Anyrš
PYTHON_FUNCTION_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.PYTHON_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr˜
SCALA_FUNCTION_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.SCALA_FUNCTION_FIELD_NUMBER
builtins.int"builtins.int€
WriteStreamOperationStartResultFpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"builtins.object*Œ
query_idOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.query_id"‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*›
self
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult0:property`*Ÿ
__init__Opyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.__init__"
None*›
self
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*ï
query_idÞ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *(
name
builtins.str"builtins.str *Ý
HasFieldOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.HasField"
builtins.bool"builtins.bool*›
self
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ñ

ClearFieldQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.ClearField"
None*›
self
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.DESCRIPTOR
Anyr“
QUERY_ID_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intr‹
NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.NAME_FIELD_NUMBER
builtins.int"builtins.intrq
nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.name
builtins.str"builtins.strÙ
StreamingQueryInstanceId?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"builtins.object*Â
__init__Hpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.__init__"
None*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*&
id
builtins.str"builtins.str **
run_id
builtins.str"builtins.str *Ü

ClearFieldJpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.ClearField"
None*
self‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.DESCRIPTOR
Anyr€
ID_FIELD_NUMBEROpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.ID_FIELD_NUMBER
builtins.int"builtins.intrˆ
RUN_ID_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.RUN_ID_FIELD_NUMBER
builtins.int"builtins.intrf
idBpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.id
builtins.str"builtins.strrn
run_idFpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.run_id
builtins.str"builtins.strœm
StreamingQueryCommand<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"builtins.object*í
query_idEpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.query_id"‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*†
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:property`*ƒ
explainDpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.explain"š
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand*†
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:property`*©
await_terminationNpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.await_termination"¬
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*†
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:property`*Ù

__init__Epyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.__init__"
None*†
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*ï
query_idÞ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *,
status
builtins.bool"builtins.bool *3
last_progress
builtins.bool"builtins.bool *5
recent_progress
builtins.bool"builtins.bool **
stop
builtins.bool"builtins.bool *;
process_all_available
builtins.bool"builtins.bool *’
explain‚
WUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand,None]š
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand
None */
	exception
builtins.bool"builtins.bool *·
await_termination
`Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand,None]¬
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand
None *•
HasFieldEpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.HasField"
builtins.bool"builtins.bool*†
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*˜

field_name‡
ÒUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ƒ

ClearFieldGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ClearField"
None*†
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*˜

field_name‡
ÒUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¸

WhichOneofGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.WhichOneof"’
»Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*†
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.DESCRIPTOR
Anyr‰
QUERY_ID_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intr…
STATUS_FIELD_NUMBERPpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.STATUS_FIELD_NUMBER
builtins.int"builtins.intr“
LAST_PROGRESS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.LAST_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intr—
RECENT_PROGRESS_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.RECENT_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intr
STOP_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.STOP_FIELD_NUMBER
builtins.int"builtins.intr£
"PROCESS_ALL_AVAILABLE_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.PROCESS_ALL_AVAILABLE_FIELD_NUMBER
builtins.int"builtins.intr‡
EXPLAIN_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intr‹
EXCEPTION_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.EXCEPTION_FIELD_NUMBER
builtins.int"builtins.intr›
AWAIT_TERMINATION_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AWAIT_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intrm
statusCpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.status
builtins.bool"builtins.boolr{
last_progressJpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.last_progress
builtins.bool"builtins.boolr
recent_progressLpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.recent_progress
builtins.bool"builtins.boolri
stopApyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.stop
builtins.bool"builtins.boolr‹
process_all_availableRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.process_all_available
builtins.bool"builtins.boolrs
	exceptionFpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.exception
builtins.bool"builtins.boolz

ExplainCommandKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"builtins.object*Â
__init__Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.__init__"
None*¥
selfš
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand*.
extended
builtins.bool"builtins.bool *Ú

ClearFieldVpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.ClearField"
None*¥
selfš
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrm

DESCRIPTORVpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.DESCRIPTOR
Anyr˜
EXTENDED_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.EXTENDED_FIELD_NUMBER
builtins.int"builtins.intr€
extendedTpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.extended
builtins.bool"builtins.boolzÝ
AwaitTerminationCommandTpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"builtins.object*…
__init__]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.__init__"
None*·
self¬
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*V

timeout_msD
Union[builtins.int,None]
builtins.int"builtins.int
None *­
HasField]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.HasField"
builtins.bool"builtins.bool*·
self¬
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*›

ClearField_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.ClearField"
None*·
self¬
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ö

WhichOneof_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*·
self¬
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrv

DESCRIPTOR_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.DESCRIPTOR
Anyr¥
TIMEOUT_MS_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.TIMEOUT_MS_FIELD_NUMBER
builtins.int"builtins.intr‹

timeout_ms_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.timeout_ms
builtins.int"builtins.int®·
StreamingQueryCommandResultBpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"builtins.object*€
query_idKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.query_id"‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*œ
statusIpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.status"¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*¾
recent_progressRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.recent_progress"²
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`* 
explainJpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.explain"¤
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*¨
	exceptionLpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.exception"¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*Æ
await_terminationTpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.await_termination"¶
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*ã
__init__Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.__init__"
None*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*ï
query_idÞ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *
statusŽ
[Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult,None]¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult
None *¾
recent_progress¦
cUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult,None]²
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult
None *¡
explain‘
\Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult,None]¤
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult
None *©
	exception—
^Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult,None]¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult
None *Æ
await_termination¬
eUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult,None]¶
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult
None *¶
HasFieldKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.HasField"
builtins.bool"builtins.bool*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¦	

field_name•	
ÈUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¤

ClearFieldMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ClearField"
None*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¦	

field_name•	
ÈUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ý

WhichOneofMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.WhichOneof"¤
yUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*“
selfˆ
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.DESCRIPTOR
Anyr
QUERY_ID_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intr‹
STATUS_FIELD_NUMBERVpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.STATUS_FIELD_NUMBER
builtins.int"builtins.intr
RECENT_PROGRESS_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RECENT_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intr
EXPLAIN_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intr‘
EXCEPTION_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.EXCEPTION_FIELD_NUMBER
builtins.int"builtins.intr¡
AWAIT_TERMINATION_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AWAIT_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intz±
StatusResultOpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"builtins.object*õ
__init__Xpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.__init__"
None*­
self¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*2
status_message
builtins.str"builtins.str *7
is_data_available
builtins.bool"builtins.bool *7
is_trigger_active
builtins.bool"builtins.bool */
	is_active
builtins.bool"builtins.bool *Ù

ClearFieldZpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.ClearField"
None*­
self¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*´

field_name£
¾Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrq

DESCRIPTORZpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.DESCRIPTOR
Anyr¨
STATUS_MESSAGE_FIELD_NUMBERkpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.STATUS_MESSAGE_FIELD_NUMBER
builtins.int"builtins.intr®
IS_DATA_AVAILABLE_FIELD_NUMBERnpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.IS_DATA_AVAILABLE_FIELD_NUMBER
builtins.int"builtins.intr®
IS_TRIGGER_ACTIVE_FIELD_NUMBERnpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.IS_TRIGGER_ACTIVE_FIELD_NUMBER
builtins.int"builtins.intrž
IS_ACTIVE_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.IS_ACTIVE_FIELD_NUMBER
builtins.int"builtins.intrŽ
status_message^pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.status_message
builtins.str"builtins.strr–
is_data_availableapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.is_data_available
builtins.bool"builtins.boolr–
is_trigger_activeapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.is_trigger_active
builtins.bool"builtins.boolr†
	is_activeYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.is_active
builtins.bool"builtins.boolzù
RecentProgressResultWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"builtins.object*Û
recent_progress_jsonlpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.recent_progress_json"
Any*½
self²
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult0:property`*Ý
__init__`pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.__init__"
None*½
self²
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult*¤
recent_progress_json‡
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *þ

ClearFieldbpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.ClearField"
None*½
self²
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesry

DESCRIPTORbpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.DESCRIPTOR
Anyr¼
!RECENT_PROGRESS_JSON_FIELD_NUMBERypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.RECENT_PROGRESS_JSON_FIELD_NUMBER
builtins.int"builtins.intz¿

ExplainResultPpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"builtins.object*Í
__init__Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.__init__"
None*¯
self¤
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult**
result
builtins.str"builtins.str *é

ClearField[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.ClearField"
None*¯
self¤
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrr

DESCRIPTOR[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.DESCRIPTOR
Anyr™
RESULT_FIELD_NUMBERdpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.RESULT_FIELD_NUMBER
builtins.int"builtins.intr
resultWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.result
builtins.str"builtins.strzû1
ExceptionResultRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"builtins.object*¸
__init__[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.__init__"
None*³
self¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*]
exception_messageD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
error_classD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
stack_traceD
Union[builtins.str,None]
builtins.str"builtins.str
None *À

HasField[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.HasField"
builtins.bool"builtins.bool*³
self¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*€

field_nameï
šUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*®


ClearField]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.ClearField"
None*³
self¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*€

field_nameï
šUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2£

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneofå

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*³
self¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXå

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*³
self¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXå

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*³
self¨
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrt

DESCRIPTOR]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.DESCRIPTOR
Anyr±
EXCEPTION_MESSAGE_FIELD_NUMBERqpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.EXCEPTION_MESSAGE_FIELD_NUMBER
builtins.int"builtins.intr¥
ERROR_CLASS_FIELD_NUMBERkpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.ERROR_CLASS_FIELD_NUMBER
builtins.int"builtins.intr¥
STACK_TRACE_FIELD_NUMBERkpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.STACK_TRACE_FIELD_NUMBER
builtins.int"builtins.intr—
exception_messagedpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.exception_message
builtins.str"builtins.strr‹
error_class^pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.error_class
builtins.str"builtins.strr‹
stack_trace^pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.stack_trace
builtins.str"builtins.strz»
AwaitTerminationResultYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"builtins.object*î
__init__bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.__init__"
None*Á
self¶
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult*0

terminated
builtins.bool"builtins.bool *„

ClearFielddpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.ClearField"
None*Á
self¶
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr{

DESCRIPTORdpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.DESCRIPTOR
Anyrª
TERMINATED_FIELD_NUMBERqpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.TERMINATED_FIELD_NUMBER
builtins.int"builtins.intr’

terminateddpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.terminated
builtins.bool"builtins.bool¶ƒ
StreamingQueryManagerCommandCpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"builtins.object*Û
await_any_terminationYpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.await_any_termination"À
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*•
selfŠ
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:property`*Ï
add_listenerPpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.add_listener"Æ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*•
selfŠ
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:property`*Õ
remove_listenerSpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.remove_listener"Æ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*•
selfŠ
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:property`*Ü
__init__Lpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.__init__"
None*•
selfŠ
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*,
active
builtins.bool"builtins.bool *-
	get_query
builtins.str"builtins.str *Ù
await_any_termination»
jUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand,None]À
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand
None *6
reset_terminated
builtins.bool"builtins.bool *Ù
add_listenerÄ
mUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand,None]Æ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand
None *Ü
remove_listenerÄ
mUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand,None]Æ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand
None *4
list_listeners
builtins.bool"builtins.bool *ß
HasFieldLpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.HasField"
builtins.bool"builtins.bool*•
selfŠ
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*Ì


field_name»

öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Í

ClearFieldNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ClearField"
None*•
selfŠ
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*Ì


field_name»

öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ÿ

WhichOneofNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.WhichOneof"Ã
¥Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*•
selfŠ
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.DESCRIPTOR
AnyrŒ
ACTIVE_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ACTIVE_FIELD_NUMBER
builtins.int"builtins.intr’
GET_QUERY_FIELD_NUMBERZpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.GET_QUERY_FIELD_NUMBER
builtins.int"builtins.intrª
"AWAIT_ANY_TERMINATION_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AWAIT_ANY_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intr 
RESET_TERMINATED_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.RESET_TERMINATED_FIELD_NUMBER
builtins.int"builtins.intr˜
ADD_LISTENER_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ADD_LISTENER_FIELD_NUMBER
builtins.int"builtins.intrž
REMOVE_LISTENER_FIELD_NUMBER`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.REMOVE_LISTENER_FIELD_NUMBER
builtins.int"builtins.intrœ
LIST_LISTENERS_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.LIST_LISTENERS_FIELD_NUMBER
builtins.int"builtins.intrt
activeJpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.active
builtins.bool"builtins.boolrx
	get_queryMpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.get_query
builtins.str"builtins.strrˆ
reset_terminatedTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.reset_terminated
builtins.bool"builtins.boolr„
list_listenersRpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.list_listeners
builtins.bool"builtins.boolz
AwaitAnyTerminationCommand^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"builtins.object*£
__init__gpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.__init__"
None*Ë
selfÀ
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*V

timeout_msD
Union[builtins.int,None]
builtins.int"builtins.int
None *Ë
HasFieldgpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.HasField"
builtins.bool"builtins.bool*Ë
selfÀ
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¹

ClearFieldipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.ClearField"
None*Ë
selfÀ
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ô

WhichOneofipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ë
selfÀ
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr€

DESCRIPTORipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.DESCRIPTOR
Anyr¯
TIMEOUT_MS_FIELD_NUMBERvpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.TIMEOUT_MS_FIELD_NUMBER
builtins.int"builtins.intr•

timeout_msipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.timeout_ms
builtins.int"builtins.intzè$
StreamingQueryListenerCommandapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"builtins.object*â
python_listener_payloadypyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.python_listener_payload"j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*Ñ
selfÆ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand0:property`*’
__init__jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.__init__"
None*Ñ
selfÆ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*8
listener_payload 
builtins.bytes"builtins.bytes *Ù
python_listener_payload¹
?Union[pyspark.sql.connect.proto.expressions_pb2.PythonUDF,None]j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF
None *&
id
builtins.str"builtins.str *Ô
HasFieldjpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.HasField"
builtins.bool"builtins.bool*Ñ
selfÆ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*

ClearFieldlpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.ClearField"
None*Ñ
selfÆ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*´

field_name£
¾Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ý

WhichOneoflpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ñ
selfÆ
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrƒ

DESCRIPTORlpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.DESCRIPTOR
Anyr¾
LISTENER_PAYLOAD_FIELD_NUMBERpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.LISTENER_PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intrÍ
$PYTHON_LISTENER_PAYLOAD_FIELD_NUMBER†pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.PYTHON_LISTENER_PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intr¢
ID_FIELD_NUMBERqpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.ID_FIELD_NUMBER
builtins.int"builtins.intr¨
listener_payloadrpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.listener_payload 
builtins.bytes"builtins.bytesrˆ
iddpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.id
builtins.str"builtins.strÑ§
"StreamingQueryManagerCommandResultIpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"builtins.object*¿
activePpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.active"°
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*Ñ
queryOpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.query"Ä
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*÷
await_any_termination_pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.await_any_termination"Ê
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*÷
list_listenersXpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.list_listeners"Ø
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*š
__init__Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.__init__"
None*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*²
active£
bUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult,None]°
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult
None *Ï
queryÁ
lUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance,None]Ä
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance
None *è
await_any_terminationÊ
oUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult,None]Ê
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult
None *6
reset_terminated
builtins.bool"builtins.bool *2
add_listener
builtins.bool"builtins.bool *5
remove_listener
builtins.bool"builtins.bool *ö
list_listenersß
vUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult,None]Ø
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult
None *ñ
HasFieldRpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.HasField"
builtins.bool"builtins.bool*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Ì


field_name»

öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ß

ClearFieldTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ClearField"
None*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Ì


field_name»

öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‘

WhichOneofTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.WhichOneof"Ã
¥Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*¡
self–
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrk

DESCRIPTORTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.DESCRIPTOR
Anyr’
ACTIVE_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ACTIVE_FIELD_NUMBER
builtins.int"builtins.intr
QUERY_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.QUERY_FIELD_NUMBER
builtins.int"builtins.intr°
"AWAIT_ANY_TERMINATION_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AWAIT_ANY_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intr¦
RESET_TERMINATED_FIELD_NUMBERgpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.RESET_TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrž
ADD_LISTENER_FIELD_NUMBERcpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ADD_LISTENER_FIELD_NUMBER
builtins.int"builtins.intr¤
REMOVE_LISTENER_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.REMOVE_LISTENER_FIELD_NUMBER
builtins.int"builtins.intr¢
LIST_LISTENERS_FIELD_NUMBERepyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.LIST_LISTENERS_FIELD_NUMBER
builtins.int"builtins.intrŽ
reset_terminatedZpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.reset_terminated
builtins.bool"builtins.boolr†
add_listenerVpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.add_listener
builtins.bool"builtins.boolrŒ
remove_listenerYpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.remove_listener
builtins.bool"builtins.boolz™
ActiveResultVpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"builtins.object*Ì
active_queriesepyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.active_queries"
Any*»
self°
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult0:property`*¦
__init___pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.__init__"
None*»
self°
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult*ð
active_queriesÙ
}Union[typing.Iterable[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance],None]Ë
qtyping.Iterable[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance]Ä
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"typing.Iterable
None *û

ClearFieldapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.ClearField"
None*»
self°
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrx

DESCRIPTORapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.DESCRIPTOR
Anyr¯
ACTIVE_QUERIES_FIELD_NUMBERrpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.ACTIVE_QUERIES_FIELD_NUMBER
builtins.int"builtins.intz®!
StreamingQueryInstance`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"builtins.object*Î
idcpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.id"‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*Ï
selfÄ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance0:property`*
__init__ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.__init__"
None*Ï
selfÄ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*é
idÞ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]‚
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *P
nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *ø
HasFieldipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.HasField"
builtins.bool"builtins.bool*Ï
selfÄ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*Ž

field_nameý
Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*æ

ClearFieldkpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.ClearField"
None*Ï
selfÄ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*Ž

field_nameý
Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ú

WhichOneofkpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ï
selfÄ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*Â
oneof_group°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr‚

DESCRIPTORkpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.DESCRIPTOR
Anyr¡
ID_FIELD_NUMBERppyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.ID_FIELD_NUMBER
builtins.int"builtins.intr¥
NAME_FIELD_NUMBERrpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.NAME_FIELD_NUMBER
builtins.int"builtins.intr‹
nameepyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.name
builtins.str"builtins.strz£
AwaitAnyTerminationResultcpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"builtins.object*Œ
__init__lpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.__init__"
None*Õ
selfÊ
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult*0

terminated
builtins.bool"builtins.bool *¢

ClearFieldnpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.ClearField"
None*Õ
selfÊ
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr…

DESCRIPTORnpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.DESCRIPTOR
Anyr´
TERMINATED_FIELD_NUMBER{pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrœ

terminatednpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.terminated
builtins.bool"builtins.boolzý
StreamingQueryListenerInstancehpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance"builtins.object*£
__init__qpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.__init__"
None*ß
selfÔ
hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance"hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance*8
listener_payload 
builtins.bytes"builtins.bytes *±

ClearFieldspyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.ClearField"
None*ß
selfÔ
hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance"hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrŠ

DESCRIPTORspyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.DESCRIPTOR
AnyrÆ
LISTENER_PAYLOAD_FIELD_NUMBER†pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.LISTENER_PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intr¯
listener_payloadypyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.listener_payload 
builtins.bytes"builtins.byteszÃ
 ListStreamingQueryListenerResultjpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"builtins.object*„
listener_idswpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.listener_ids"
Any*ã
selfØ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult0:property`*Ž
__init__spyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.__init__"
None*ã
selfØ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult*œ
listener_ids‡
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *·

ClearFieldupyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.ClearField"
None*ã
selfØ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrŒ

DESCRIPTORupyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.DESCRIPTOR
AnyrÀ
LISTENER_IDS_FIELD_NUMBER„pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.LISTENER_IDS_FIELD_NUMBER
builtins.int"builtins.int¡
GetResourcesCommand:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand"builtins.object*Þ
__init__Cpyspark.sql.connect.proto.commands_pb2.GetResourcesCommand.__init__"
None*‚
selfx
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandr\

DESCRIPTOREpyspark.sql.connect.proto.commands_pb2.GetResourcesCommand.DESCRIPTOR
Anyë"
GetResourcesCommandResult@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"builtins.object*€
	resourcesJpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.resources"
Any*
self„
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult0:property`*ó
__init__Ipyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.__init__"
None*
self„
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*ÿ
	resourcesí
aUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.common_pb2.ResourceInformation],None]û
Utyping.Mapping[builtins.str,pyspark.sql.connect.proto.common_pb2.ResourceInformation]
builtins.str"builtins.strt
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation"typing.Mapping
None *¹

ClearFieldKpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ClearField"
None*
self„
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.DESCRIPTOR
Anyr
RESOURCES_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.RESOURCES_FIELD_NUMBER
builtins.int"builtins.intzÏ
ResourcesEntryOpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"builtins.object*’
valueUpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.value"t
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation*­
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry0:property`* 
__init__Xpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.__init__"
None*­
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry*'
key
builtins.str"builtins.str *Ö
valueÈ
DUnion[pyspark.sql.connect.proto.common_pb2.ResourceInformation,None]t
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation
None *ø
HasFieldXpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.HasField"
builtins.bool"builtins.bool*­
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry*Á

field_name°
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Œ

ClearFieldZpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.ClearField"
None*­
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry*ç

field_nameÖ
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrq

DESCRIPTORZpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.DESCRIPTOR
Anyr’
KEY_FIELD_NUMBER`pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr–
VALUE_FIELD_NUMBERbpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrx
keySpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.key
builtins.str"builtins.str*¢
__annotations__6pyspark.sql.connect.proto.commands_pb2.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
collectionscollections *@
google-pyspark.sql.connect.proto.commands_pb2.google
Any*
pysparkpyspark *H

DESCRIPTOR1pyspark.sql.connect.proto.commands_pb2.DESCRIPTOR
Any