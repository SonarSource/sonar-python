
torch._C._functorch™
TransformType!torch._C._functorch.TransformType"	enum.EnumHrx
Torch'torch._C._functorch.TransformType.TorchF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTyperv
Vmap&torch._C._functorch.TransformType.VmapF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTyperv
Grad&torch._C._functorch.TransformType.GradF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTypert
Jvp%torch._C._functorch.TransformType.JvpF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTyperà
Functionalize/torch._C._functorch.TransformType.FunctionalizeF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTypeπ
RandomnessType"torch._C._functorch.RandomnessType"	enum.EnumHry
Error(torch._C._functorch.RandomnessType.ErrorF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTyperw
Same'torch._C._functorch.RandomnessType.SameF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTyperÅ
	Different,torch._C._functorch.RandomnessType.DifferentF
!torch._C._functorch.TransformType"!torch._C._functorch.TransformTypeß
CInterpreter torch._C._functorch.CInterpreter"builtins.object*√
key$torch._C._functorch.CInterpreter.key"F
!torch._C._functorch.TransformType"!torch._C._functorch.TransformType*N
selfD
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreter*ù
level&torch._C._functorch.CInterpreter.level"
builtins.int"builtins.int*N
selfD
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreterÍ
CGradInterpreterPtr'torch._C._functorch.CGradInterpreterPtr"builtins.object*˚
__init__0torch._C._functorch.CGradInterpreterPtr.__init__"
None*\
selfR
'torch._C._functorch.CGradInterpreterPtr"'torch._C._functorch.CGradInterpreterPtr*U
interpreterD
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreter*’
lift,torch._C._functorch.CGradInterpreterPtr.lift",
torch._tensor.Tensor"torch._tensor.Tensor*\
selfR
'torch._C._functorch.CGradInterpreterPtr"'torch._C._functorch.CGradInterpreterPtr*
Tensor
Any*¬
prevGradMode4torch._C._functorch.CGradInterpreterPtr.prevGradMode"
builtins.bool"builtins.bool*\
selfR
'torch._C._functorch.CGradInterpreterPtr"'torch._C._functorch.CGradInterpreterPtrÂ
CJvpInterpreterPtr&torch._C._functorch.CJvpInterpreterPtr"builtins.object*¯
__init__/torch._C._functorch.CJvpInterpreterPtr.__init__"
None*Z
selfP
&torch._C._functorch.CJvpInterpreterPtr"&torch._C._functorch.CJvpInterpreterPtr*U
interpreterD
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreter*“
lift+torch._C._functorch.CJvpInterpreterPtr.lift",
torch._tensor.Tensor"torch._tensor.Tensor*Z
selfP
&torch._C._functorch.CJvpInterpreterPtr"&torch._C._functorch.CJvpInterpreterPtr*
Tensor
Any*≈
prevFwdGradMode6torch._C._functorch.CJvpInterpreterPtr.prevFwdGradMode"
builtins.bool"builtins.bool*Z
selfP
&torch._C._functorch.CJvpInterpreterPtr"&torch._C._functorch.CJvpInterpreterPtr∫
CFunctionalizeInterpreterPtr0torch._C._functorch.CFunctionalizeInterpreterPtr"builtins.object*ñ
__init__9torch._C._functorch.CFunctionalizeInterpreterPtr.__init__"
None*n
selfd
0torch._C._functorch.CFunctionalizeInterpreterPtr"0torch._C._functorch.CFunctionalizeInterpreterPtr*U
interpreterD
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreter*Û
key4torch._C._functorch.CFunctionalizeInterpreterPtr.key"F
!torch._C._functorch.TransformType"!torch._C._functorch.TransformType*n
selfd
0torch._C._functorch.CFunctionalizeInterpreterPtr"0torch._C._functorch.CFunctionalizeInterpreterPtr*Õ
level6torch._C._functorch.CFunctionalizeInterpreterPtr.level"
builtins.int"builtins.int*n
selfd
0torch._C._functorch.CFunctionalizeInterpreterPtr"0torch._C._functorch.CFunctionalizeInterpreterPtr*˜
functionalizeAddBackViewsJtorch._C._functorch.CFunctionalizeInterpreterPtr.functionalizeAddBackViews"
builtins.bool"builtins.bool*n
selfd
0torch._C._functorch.CFunctionalizeInterpreterPtr"0torch._C._functorch.CFunctionalizeInterpreterPtrÖ	
CVmapInterpreterPtr'torch._C._functorch.CVmapInterpreterPtr"builtins.object*˚
__init__0torch._C._functorch.CVmapInterpreterPtr.__init__"
None*\
selfR
'torch._C._functorch.CVmapInterpreterPtr"'torch._C._functorch.CVmapInterpreterPtr*U
interpreterD
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreter*ÿ
key+torch._C._functorch.CVmapInterpreterPtr.key"F
!torch._C._functorch.TransformType"!torch._C._functorch.TransformType*\
selfR
'torch._C._functorch.CVmapInterpreterPtr"'torch._C._functorch.CVmapInterpreterPtr*≤
level-torch._C._functorch.CVmapInterpreterPtr.level"
builtins.int"builtins.int*\
selfR
'torch._C._functorch.CVmapInterpreterPtr"'torch._C._functorch.CVmapInterpreterPtr*∫
	batchSize1torch._C._functorch.CVmapInterpreterPtr.batchSize"
builtins.int"builtins.int*\
selfR
'torch._C._functorch.CVmapInterpreterPtr"'torch._C._functorch.CVmapInterpreterPtr*Ë

randomness2torch._C._functorch.CVmapInterpreterPtr.randomness"H
"torch._C._functorch.RandomnessType""torch._C._functorch.RandomnessType*\
selfR
'torch._C._functorch.CVmapInterpreterPtr"'torch._C._functorch.CVmapInterpreterPtrA
DynamicLayer torch._C._functorch.DynamicLayer"builtins.objectê
 _set_dynamic_layer_keys_included4torch._C._functorch._set_dynamic_layer_keys_included"
None*,
included
builtins.bool"builtins.boolö
get_unwrapped!torch._C._functorch.get_unwrapped",
torch._tensor.Tensor"torch._tensor.Tensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensorí
is_batchedtensor$torch._C._functorch.is_batchedtensor"
builtins.bool"builtins.bool*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensorò
is_functionaltensor'torch._C._functorch.is_functionaltensor"
builtins.bool"builtins.bool*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor®
is_functorch_wrapped_tensor/torch._C._functorch.is_functorch_wrapped_tensor"
builtins.bool"builtins.bool*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensorú
is_gradtrackingtensor)torch._C._functorch.is_gradtrackingtensor"
builtins.bool"builtins.bool*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor†
is_legacy_batchedtensor+torch._C._functorch.is_legacy_batchedtensor"
builtins.bool"builtins.bool*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensorå
maybe_get_bdim"torch._C._functorch.maybe_get_bdim"
builtins.int"builtins.int*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensoré
maybe_get_level#torch._C._functorch.maybe_get_level"
builtins.int"builtins.int*8
tensor,
torch._tensor.Tensor"torch._tensor.TensorÑ
maybe_current_level'torch._C._functorch.maybe_current_level"D
Union[builtins.int,None]
builtins.int"builtins.int
Noneú
unwrap_if_dead"torch._C._functorch.unwrap_if_dead",
torch._tensor.Tensor"torch._tensor.Tensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor…
_unwrap_for_grad$torch._C._functorch._unwrap_for_grad",
torch._tensor.Tensor"torch._tensor.Tensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*'
level
builtins.int"builtins.int≈
_wrap_for_grad"torch._C._functorch._wrap_for_grad",
torch._tensor.Tensor"torch._tensor.Tensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*'
level
builtins.int"builtins.int»
_unwrap_batched#torch._C._functorch._unwrap_batched"¨
4Tuple[torch._tensor.Tensor,Union[builtins.int,None]],
torch._tensor.Tensor"torch._tensor.TensorD
Union[builtins.int,None]
builtins.int"builtins.int
None*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*'
level
builtins.int"builtins.intP
current_level!torch._C._functorch.current_level"
builtins.int"builtins.intb
count_jvp_interpreters*torch._C._functorch.count_jvp_interpreters"
builtins.int"builtins.intÌ
_add_batch_dim"torch._C._functorch._add_batch_dim",
torch._tensor.Tensor"torch._tensor.Tensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
bdim
builtins.int"builtins.int*'
level
builtins.int"builtins.int£
*set_single_level_autograd_function_allowed>torch._C._functorch.set_single_level_autograd_function_allowed"
None*+
allowed
builtins.bool"builtins.boolå
*get_single_level_autograd_function_allowed>torch._C._functorch.get_single_level_autograd_function_allowed"
builtins.bool"builtins.boolÂ
_unwrap_functional_tensor-torch._C._functorch._unwrap_functional_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*1
reapply_views
builtins.bool"builtins.bool◊
_wrap_functional_tensor+torch._C._functorch._wrap_functional_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*'
level
builtins.int"builtins.int¿
_vmap_increment_nesting+torch._C._functorch._vmap_increment_nesting"
builtins.int"builtins.int*,

batch_size
builtins.int"builtins.int*,

randomness
builtins.str"builtins.strd
_vmap_decrement_nesting+torch._C._functorch._vmap_decrement_nesting"
builtins.int"builtins.intd
_grad_increment_nesting+torch._C._functorch._grad_increment_nesting"
builtins.int"builtins.intd
_grad_decrement_nesting+torch._C._functorch._grad_decrement_nesting"
builtins.int"builtins.intb
_jvp_increment_nesting*torch._C._functorch._jvp_increment_nesting"
builtins.int"builtins.intb
_jvp_decrement_nesting*torch._C._functorch._jvp_decrement_nesting"
builtins.int"builtins.intp
get_dynamic_layer_stack_depth1torch._C._functorch.get_dynamic_layer_stack_depth"
builtins.int"builtins.intÀ
get_interpreter_stack)torch._C._functorch.get_interpreter_stack"Ü
/builtins.list[torch._C._functorch.CInterpreter]D
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreter"builtins.listä
peek_interpreter_stack*torch._C._functorch.peek_interpreter_stack"D
 torch._C._functorch.CInterpreter" torch._C._functorch.CInterpreterå
pop_dynamic_layer_stack+torch._C._functorch.pop_dynamic_layer_stack"D
 torch._C._functorch.DynamicLayer" torch._C._functorch.DynamicLayerÜ
)pop_dynamic_layer_stack_and_undo_to_depth=torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth"
None*
int
Any¥
push_dynamic_layer_stack,torch._C._functorch.push_dynamic_layer_stack"
builtins.int"builtins.int*L
dlD
 torch._C._functorch.DynamicLayer" torch._C._functorch.DynamicLayer*è
__annotations__#torch._C._functorch.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict