
pyspark.pandas.spark.accessorsúr
PySparkColumnpyspark.sql.column.Column"builtins.object*ã
__init__"pyspark.sql.column.Column.__init__"
None*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
jc
Any*∏
__eq__ pyspark.sql.column.Column.__eq__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*ôñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],_decimal.Decimal,TypeAlias[Union[datetime.datetime,datetime.date]]]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType$
_decimal.Decimal"_decimal.DecimalŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral*ß
__ne__ pyspark.sql.column.Column.__ne__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*Ö
__contains__&pyspark.sql.column.Column.__contains__"
None*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*∏
getItem!pyspark.sql.column.Column.getItem"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
key
Any*ª
getField"pyspark.sql.column.Column.getField"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
name
Any*ò
	withField#pyspark.sql.column.Column.withField"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*+
	fieldName
builtins.str"builtins.str*?
col6
pyspark.sql.column.Column"pyspark.sql.column.Column*⁄

dropFields$pyspark.sql.column.Column.dropFields"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*,

fieldNames
builtins.str"builtins.str*±
__getattr__%pyspark.sql.column.Column.__getattr__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*±
__getitem__%pyspark.sql.column.Column.__getitem__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*r
__iter__"pyspark.sql.column.Column.__iter__"
None*86
pyspark.sql.column.Column"pyspark.sql.column.Column*…
likepyspark.sql.column.Column.like"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*À
rlikepyspark.sql.column.Column.rlike"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*À
ilikepyspark.sql.column.Column.ilike"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*≥
isinpyspark.sql.column.Column.isin"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
cols
Any*‡
aliaspyspark.sql.column.Column.alias"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
alias
builtins.str"builtins.str*
kwargs
Any*º
castpyspark.sql.column.Column.cast"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*ô
dataTypeä
.Union[pyspark.sql.types.DataType,builtins.str]8
pyspark.sql.types.DataType"pyspark.sql.types.DataType
builtins.str"builtins.str*˙
between!pyspark.sql.column.Column.between"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*ß

lowerBoundñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[datetime.datetime,datetime.date]],_decimal.Decimal]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral$
_decimal.Decimal"_decimal.Decimal*ß

upperBoundñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[datetime.datetime,datetime.date]],_decimal.Decimal]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral$
_decimal.Decimal"_decimal.Decimal*˚
whenpyspark.sql.column.Column.when"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*E
	condition6
pyspark.sql.column.Column"pyspark.sql.column.Column*
value
Any*æ
	otherwise#pyspark.sql.column.Column.otherwise"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
value
Any*Ï
overpyspark.sql.column.Column.over"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*J
window>
pyspark.sql.window.WindowSpec"pyspark.sql.window.WindowSpec*Ä
__nonzero__%pyspark.sql.column.Column.__nonzero__"
None*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*Ü
__repr__"pyspark.sql.column.Column.__repr__"
builtins.str"builtins.str*86
pyspark.sql.column.Column"pyspark.sql.column.Column2Ù
substr pyspark.sql.column.Column.substrà
substr pyspark.sql.column.Column.substr"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column**
startPos
builtins.int"builtins.int*(
length
builtins.int"builtins.int0:overloadXº
substr pyspark.sql.column.Column.substr"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*D
startPos6
pyspark.sql.column.Column"pyspark.sql.column.Column*B
length6
pyspark.sql.column.Column"pyspark.sql.column.Column0:overloadXry
__neg__!pyspark.sql.column.Column.__neg__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__add__!pyspark.sql.column.Column.__add__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__sub__!pyspark.sql.column.Column.__sub__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__mul__!pyspark.sql.column.Column.__mul__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__div__!pyspark.sql.column.Column.__div__K
CallableType[builtins.function]&
builtins.function"builtins.functionrÅ
__truediv__%pyspark.sql.column.Column.__truediv__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__mod__!pyspark.sql.column.Column.__mod__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__radd__"pyspark.sql.column.Column.__radd__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rsub__"pyspark.sql.column.Column.__rsub__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rmul__"pyspark.sql.column.Column.__rmul__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rdiv__"pyspark.sql.column.Column.__rdiv__K
CallableType[builtins.function]&
builtins.function"builtins.functionrÉ
__rtruediv__&pyspark.sql.column.Column.__rtruediv__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rmod__"pyspark.sql.column.Column.__rmod__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__pow__!pyspark.sql.column.Column.__pow__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rpow__"pyspark.sql.column.Column.__rpow__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__lt__ pyspark.sql.column.Column.__lt__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__le__ pyspark.sql.column.Column.__le__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__ge__ pyspark.sql.column.Column.__ge__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__gt__ pyspark.sql.column.Column.__gt__K
CallableType[builtins.function]&
builtins.function"builtins.functionrZ
_eqNullSafe_doc)pyspark.sql.column.Column._eqNullSafe_doc
builtins.str"builtins.strr

eqNullSafe$pyspark.sql.column.Column.eqNullSafeK
CallableType[builtins.function]&
builtins.function"builtins.functionry
__and__!pyspark.sql.column.Column.__and__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__or__ pyspark.sql.column.Column.__or__K
CallableType[builtins.function]&
builtins.function"builtins.functionr

__invert__$pyspark.sql.column.Column.__invert__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rand__"pyspark.sql.column.Column.__rand__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__ror__!pyspark.sql.column.Column.__ror__K
CallableType[builtins.function]&
builtins.function"builtins.functionrX
_bitwiseOR_doc(pyspark.sql.column.Column._bitwiseOR_doc
builtins.str"builtins.strrZ
_bitwiseAND_doc)pyspark.sql.column.Column._bitwiseAND_doc
builtins.str"builtins.strrZ
_bitwiseXOR_doc)pyspark.sql.column.Column._bitwiseXOR_doc
builtins.str"builtins.strr}
	bitwiseOR#pyspark.sql.column.Column.bitwiseORK
CallableType[builtins.function]&
builtins.function"builtins.functionr

bitwiseAND$pyspark.sql.column.Column.bitwiseANDK
CallableType[builtins.function]&
builtins.function"builtins.functionr

bitwiseXOR$pyspark.sql.column.Column.bitwiseXORK
CallableType[builtins.function]&
builtins.function"builtins.functionrV
_contains_doc'pyspark.sql.column.Column._contains_doc
builtins.str"builtins.strrZ
_startswith_doc)pyspark.sql.column.Column._startswith_doc
builtins.str"builtins.strrV
_endswith_doc'pyspark.sql.column.Column._endswith_doc
builtins.str"builtins.strr{
contains"pyspark.sql.column.Column.containsK
CallableType[builtins.function]&
builtins.function"builtins.functionr

startswith$pyspark.sql.column.Column.startswithK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
endswith"pyspark.sql.column.Column.endswithK
CallableType[builtins.function]&
builtins.function"builtins.functionrL
_asc_doc"pyspark.sql.column.Column._asc_doc
builtins.str"builtins.strrd
_asc_nulls_first_doc.pyspark.sql.column.Column._asc_nulls_first_doc
builtins.str"builtins.strrb
_asc_nulls_last_doc-pyspark.sql.column.Column._asc_nulls_last_doc
builtins.str"builtins.strrN
	_desc_doc#pyspark.sql.column.Column._desc_doc
builtins.str"builtins.strrf
_desc_nulls_first_doc/pyspark.sql.column.Column._desc_nulls_first_doc
builtins.str"builtins.strrd
_desc_nulls_last_doc.pyspark.sql.column.Column._desc_nulls_last_doc
builtins.str"builtins.strrq
ascpyspark.sql.column.Column.ascK
CallableType[builtins.function]&
builtins.function"builtins.functionrâ
asc_nulls_first)pyspark.sql.column.Column.asc_nulls_firstK
CallableType[builtins.function]&
builtins.function"builtins.functionrá
asc_nulls_last(pyspark.sql.column.Column.asc_nulls_lastK
CallableType[builtins.function]&
builtins.function"builtins.functionrs
descpyspark.sql.column.Column.descK
CallableType[builtins.function]&
builtins.function"builtins.functionrã
desc_nulls_first*pyspark.sql.column.Column.desc_nulls_firstK
CallableType[builtins.function]&
builtins.function"builtins.functionrâ
desc_nulls_last)pyspark.sql.column.Column.desc_nulls_lastK
CallableType[builtins.function]&
builtins.function"builtins.functionrR
_isNull_doc%pyspark.sql.column.Column._isNull_doc
builtins.str"builtins.strrX
_isNotNull_doc(pyspark.sql.column.Column._isNotNull_doc
builtins.str"builtins.strrw
isNull pyspark.sql.column.Column.isNullK
CallableType[builtins.function]&
builtins.function"builtins.functionr}
	isNotNull#pyspark.sql.column.Column.isNotNullK
CallableType[builtins.function]&
builtins.function"builtins.functionrs
namepyspark.sql.column.Column.nameK
CallableType[builtins.function]&
builtins.function"builtins.functionrw
astype pyspark.sql.column.Column.astypeK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__bool__"pyspark.sql.column.Column.__bool__K
CallableType[builtins.function]&
builtins.function"builtins.functionr-
_jcpyspark.sql.column.Column._jc
Anyüù
PySparkDataFramepyspark.sql.dataframe.DataFrame",pyspark.sql.pandas.map_ops.PandasMapOpsMixin"3pyspark.sql.pandas.conversion.PandasConversionMixin*Å
__init__(pyspark.sql.dataframe.DataFrame.__init__"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*
jdf
Any*‡
sql_ctx“
FUnion[pyspark.sql.context.SQLContext,pyspark.sql.session.SparkSession]@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContextD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*–
sql_ctx'pyspark.sql.dataframe.DataFrame.sql_ctx"@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContext*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*ﬁ
sparkSession,pyspark.sql.dataframe.DataFrame.sparkSession"D
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*Ò
rdd#pyspark.sql.dataframe.DataFrame.rdd"i
&pyspark.rdd.RDD[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"pyspark.rdd.RDD*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*ﬁ
na"pyspark.sql.dataframe.DataFrame.na"X
*pyspark.sql.dataframe.DataFrameNaFunctions"*pyspark.sql.dataframe.DataFrameNaFunctions*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*Ê
stat$pyspark.sql.dataframe.DataFrame.stat"\
,pyspark.sql.dataframe.DataFrameStatFunctions",pyspark.sql.dataframe.DataFrameStatFunctions*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*Å
toJSON&pyspark.sql.dataframe.DataFrame.toJSON"N
pyspark.rdd.RDD[builtins.str]
builtins.str"builtins.str"pyspark.rdd.RDD*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*1
use_unicode
builtins.bool"builtins.bool *∆
registerTempTable1pyspark.sql.dataframe.DataFrame.registerTempTable"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*¿
createTempView.pyspark.sql.dataframe.DataFrame.createTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*“
createOrReplaceTempView7pyspark.sql.dataframe.DataFrame.createOrReplaceTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*Ã
createGlobalTempView4pyspark.sql.dataframe.DataFrame.createGlobalTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*ﬁ
createOrReplaceGlobalTempView=pyspark.sql.dataframe.DataFrame.createOrReplaceGlobalTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*‹
write%pyspark.sql.dataframe.DataFrame.write"P
&pyspark.sql.readwriter.DataFrameWriter"&pyspark.sql.readwriter.DataFrameWriter*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*˛
writeStream+pyspark.sql.dataframe.DataFrame.writeStream"f
1pyspark.sql.streaming.readwriter.DataStreamWriter"1pyspark.sql.streaming.readwriter.DataStreamWriter*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`* 
schema&pyspark.sql.dataframe.DataFrame.schema"<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*Â
printSchema+pyspark.sql.dataframe.DataFrame.printSchema"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Q
levelD
Union[builtins.int,None]
builtins.int"builtins.int
None *·
explain'pyspark.sql.dataframe.DataFrame.explain"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ç
extendedr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *P
modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *ó
	exceptAll)pyspark.sql.dataframe.DataFrame.exceptAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*†
isLocal'pyspark.sql.dataframe.DataFrame.isLocal"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*∂
isStreaming+pyspark.sql.dataframe.DataFrame.isStreaming"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*†
isEmpty'pyspark.sql.dataframe.DataFrame.isEmpty"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*–
show$pyspark.sql.dataframe.DataFrame.show"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
n
builtins.int"builtins.int *s
truncatec
!Union[builtins.bool,builtins.int]
builtins.bool"builtins.bool
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *Ù
_show_string,pyspark.sql.dataframe.DataFrame._show_string"
builtins.str"builtins.str*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
n
builtins.int"builtins.int *s
truncatec
!Union[builtins.bool,builtins.int]
builtins.bool"builtins.bool
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *ò
__repr__(pyspark.sql.dataframe.DataFrame.__repr__"
builtins.str"builtins.str*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Œ
_repr_html_+pyspark.sql.dataframe.DataFrame._repr_html_"D
Union[builtins.str,None]
builtins.str"builtins.str
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˜

checkpoint*pyspark.sql.dataframe.DataFrame.checkpoint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
eager
builtins.bool"builtins.bool *Å
localCheckpoint/pyspark.sql.dataframe.DataFrame.localCheckpoint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
eager
builtins.bool"builtins.bool *Ø
withWatermark-pyspark.sql.dataframe.DataFrame.withWatermark"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
	eventTime
builtins.str"builtins.str*0
delayThreshold
builtins.str"builtins.str*ø
hint$pyspark.sql.dataframe.DataFrame.hint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*÷

parameters≈
fUnion[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]],builtins.list[Unknown]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType)
builtins.list[Unknown] "builtins.list*ö
count%pyspark.sql.dataframe.DataFrame.count"
builtins.int"builtins.int*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Á
collect'pyspark.sql.dataframe.DataFrame.collect"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*µ
toLocalIterator/pyspark.sql.dataframe.DataFrame.toLocalIterator"i
&typing.Iterator[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"typing.Iterator*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*8
prefetchPartitions
builtins.bool"builtins.bool *Á
limit%pyspark.sql.dataframe.DataFrame.limit"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*È
offset&pyspark.sql.dataframe.DataFrame.offset"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*à
take$pyspark.sql.dataframe.DataFrame.take"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*à
tail$pyspark.sql.dataframe.DataFrame.tail"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*ﬁ
foreach'pyspark.sql.dataframe.DataFrame.foreach"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*
foreachPartition0pyspark.sql.dataframe.DataFrame.foreachPartition"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*¿
cache%pyspark.sql.dataframe.DataFrame.cache"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*†
persist'pyspark.sql.dataframe.DataFrame.persist"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Z
storageLevelF
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel *‡
storageLevel,pyspark.sql.dataframe.DataFrame.storageLevel"F
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*¯
	unpersist)pyspark.sql.dataframe.DataFrame.unpersist"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*.
blocking
builtins.bool"builtins.bool *˜
coalesce(pyspark.sql.dataframe.DataFrame.coalesce"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*∆
distinct(pyspark.sql.dataframe.DataFrame.distinct"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˚
sampleBy(pyspark.sql.dataframe.DataFrame.sampleBy"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ú
colË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*l
	fractions]
!builtins.dict[Any,builtins.float]
Any 
builtins.float"builtins.float"builtins.dict*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *ø
randomSplit+pyspark.sql.dataframe.DataFrame.randomSplit"É
.builtins.list[pyspark.sql.dataframe.DataFrame]B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*]
weightsP
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *±
dtypes&pyspark.sql.dataframe.DataFrame.dtypes"¢
/builtins.list[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*⁄
columns'pyspark.sql.dataframe.DataFrame.columns"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:property`*Â
colRegex(pyspark.sql.dataframe.DataFrame.colRegex"6
pyspark.sql.column.Column"pyspark.sql.column.Column*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*)
colName
builtins.str"builtins.str*Ñ
to"pyspark.sql.dataframe.DataFrame.to"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
schema<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*È
alias%pyspark.sql.dataframe.DataFrame.alias"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
alias
builtins.str"builtins.str*ó
	crossJoin)pyspark.sql.dataframe.DataFrame.crossJoin"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ü
join$pyspark.sql.dataframe.DataFrame.join"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*•
onö
wUnion[builtins.str,builtins.list[builtins.str],pyspark.sql.column.Column,builtins.list[pyspark.sql.column.Column],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list6
pyspark.sql.column.Column"pyspark.sql.column.Columnq
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None *O
howD
Union[builtins.str,None]
builtins.str"builtins.str
None *µ

	_joinAsOf)pyspark.sql.dataframe.DataFrame._joinAsOf"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ú
leftAsOfColumná
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column*ù
rightAsOfColumná
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column*•
onö
wUnion[builtins.str,builtins.list[builtins.str],pyspark.sql.column.Column,builtins.list[pyspark.sql.column.Column],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list6
pyspark.sql.column.Column"pyspark.sql.column.Columnq
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None *O
howD
Union[builtins.str,None]
builtins.str"builtins.str
None *|
	tolerancek
%Union[pyspark.sql.column.Column,None]6
pyspark.sql.column.Column"pyspark.sql.column.Column
None *7
allowExactMatches
builtins.bool"builtins.bool *-
	direction
builtins.str"builtins.str *ü
sortWithinPartitions4pyspark.sql.dataframe.DataFrame.sortWithinPartitions"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*©
colsû
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*
kwargs
Any*ˇ
sort$pyspark.sql.dataframe.DataFrame.sort"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*©
colsû
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*
kwargs
Any*‹
_jseq%pyspark.sql.dataframe.DataFrame._jseq"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*:
cols0
typing.Sequence[Any]
Any"typing.Sequence*ò
	converterÜ
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None *»
_jmap%pyspark.sql.dataframe.DataFrame._jmap"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*A
jm9
builtins.dict[Any,Any]
Any
Any"builtins.dict*˝
_jcols&pyspark.sql.dataframe.DataFrame._jcols"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*±

_sort_cols*pyspark.sql.dataframe.DataFrame._sort_cols"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*∫
colsØ
{typing.Sequence[Union[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]]û
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list"typing.Sequence*c
kwargsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*Ò
describe(pyspark.sql.dataframe.DataFrame.describe"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*®
colsù
/Union[builtins.str,builtins.list[builtins.str]]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*Ú
summary'pyspark.sql.dataframe.DataFrame.summary"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*,

statistics
builtins.str"builtins.str*›
first%pyspark.sql.dataframe.DataFrame.first"_
!Union[pyspark.sql.types.Row,None].
pyspark.sql.types.Row"pyspark.sql.types.Row
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ÿ
__getattr__+pyspark.sql.dataframe.DataFrame.__getattr__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*
builtins.str"builtins.str*Ã
__dir__'pyspark.sql.dataframe.DataFrame.__dir__"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ω
filter&pyspark.sql.dataframe.DataFrame.filter"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*¯
	conditionË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*√	
unpivot'pyspark.sql.dataframe.DataFrame.unpivot"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
idsµ
nUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown]]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple*—
valuesƒ
sUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown],None]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple
None*4
variableColumnName
builtins.str"builtins.str*1
valueColumnName
builtins.str"builtins.str*Ω	
melt$pyspark.sql.dataframe.DataFrame.melt"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
idsµ
nUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown]]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple*—
valuesƒ
sUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown],None]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple
None*4
variableColumnName
builtins.str"builtins.str*1
valueColumnName
builtins.str"builtins.str*«
agg#pyspark.sql.dataframe.DataFrame.agg"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*à
exprs¸
IUnion[pyspark.sql.column.Column,builtins.dict[builtins.str,builtins.str]]6
pyspark.sql.column.Column"pyspark.sql.column.Columnu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict*¡
observe'pyspark.sql.dataframe.DataFrame.observe"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*∑
observation•
7Union[pyspark.sql.observation.Observation,builtins.str]J
#pyspark.sql.observation.Observation"#pyspark.sql.observation.Observation
builtins.str"builtins.str*A
exprs6
pyspark.sql.column.Column"pyspark.sql.column.Column*è
union%pyspark.sql.dataframe.DataFrame.union"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ï
unionAll(pyspark.sql.dataframe.DataFrame.unionAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*÷
unionByName+pyspark.sql.dataframe.DataFrame.unionByName"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*9
allowMissingColumns
builtins.bool"builtins.bool *ó
	intersect)pyspark.sql.dataframe.DataFrame.intersect"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ù
intersectAll,pyspark.sql.dataframe.DataFrame.intersectAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ï
subtract(pyspark.sql.dataframe.DataFrame.subtract"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Â
dropDuplicates.pyspark.sql.dataframe.DataFrame.dropDuplicates"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *É
dropDuplicatesWithinWatermark=pyspark.sql.dataframe.DataFrame.dropDuplicatesWithinWatermark"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *Ë
dropna&pyspark.sql.dataframe.DataFrame.dropna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
how
builtins.str"builtins.str *R
threshD
Union[builtins.int,None]
builtins.int"builtins.int
None *¶
subsetó
QUnion[builtins.str,builtins.tuple[builtins.str],builtins.list[builtins.str],None]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tupleJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *¿
corr$pyspark.sql.dataframe.DataFrame.corr" 
builtins.float"builtins.float*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*R
methodD
Union[builtins.str,None]
builtins.str"builtins.str
None *Í
cov#pyspark.sql.dataframe.DataFrame.cov" 
builtins.float"builtins.float*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*ñ
crosstab(pyspark.sql.dataframe.DataFrame.crosstab"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*Ó
	freqItems)pyspark.sql.dataframe.DataFrame.freqItems"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*»
colsΩ
6Union[builtins.list[builtins.str],Tuple[builtins.str]]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list5
Tuple[builtins.str]
builtins.str"builtins.str*Y
supportJ
Union[builtins.float,None] 
builtins.float"builtins.float
None *
_ipython_key_completions_9pyspark.sql.dataframe.DataFrame._ipython_key_completions_"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˘
withColumns+pyspark.sql.dataframe.DataFrame.withColumns"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*™
colsMapú
5builtins.dict[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.dict*∂

withColumn*pyspark.sql.dataframe.DataFrame.withColumn"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*)
colName
builtins.str"builtins.str*?
col6
pyspark.sql.column.Column"pyspark.sql.column.Column*´
withColumnRenamed1pyspark.sql.dataframe.DataFrame.withColumnRenamed"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame**
existing
builtins.str"builtins.str*%
new
builtins.str"builtins.str*ﬂ
withColumnsRenamed2pyspark.sql.dataframe.DataFrame.withColumnsRenamed"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ç
colsMapu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict*„
withMetadata,pyspark.sql.dataframe.DataFrame.withMetadata"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*,

columnName
builtins.str"builtins.str*e
metadataW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*Ê
toDF$pyspark.sql.dataframe.DataFrame.toDF"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
cols
builtins.str"builtins.str*«
	transform)pyspark.sql.dataframe.DataFrame.transform"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*
args
Any*
kwargs
Any*˚
sameSemantics-pyspark.sql.dataframe.DataFrame.sameSemantics"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*®
semanticHash,pyspark.sql.dataframe.DataFrame.semanticHash"
builtins.int"builtins.int*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*“

inputFiles*pyspark.sql.dataframe.DataFrame.inputFiles"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ˇ
writeTo'pyspark.sql.dataframe.DataFrame.writeTo"T
(pyspark.sql.readwriter.DataFrameWriterV2"(pyspark.sql.readwriter.DataFrameWriterV2*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
table
builtins.str"builtins.str*ß
to_pandas_on_spark2pyspark.sql.dataframe.DataFrame.to_pandas_on_spark"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *ó

pandas_api*pyspark.sql.dataframe.DataFrame.pandas_api"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *ï
	to_koalas)pyspark.sql.dataframe.DataFrame.to_koalas"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 2ë
repartition+pyspark.sql.dataframe.DataFrame.repartitionÅ
repartition+pyspark.sql.dataframe.DataFrame.repartition"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadX–
repartition+pyspark.sql.dataframe.DataFrame.repartition"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadX2ª
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRangeè
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRange"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadXﬁ
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRange"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadX2∏
sample&pyspark.sql.dataframe.DataFrame.sample“
sample&pyspark.sql.dataframe.DataFrame.sample"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*.
fraction 
builtins.float"builtins.float*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None 0:overloadX∞
sample&pyspark.sql.dataframe.DataFrame.sample"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*\
withReplacementG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None*.
fraction 
builtins.float"builtins.float*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None 0:overloadX2Ø
head$pyspark.sql.dataframe.DataFrame.headÈ
head$pyspark.sql.dataframe.DataFrame.head"_
!Union[pyspark.sql.types.Row,None].
pyspark.sql.types.Row"pyspark.sql.types.Row
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:overloadXî
head$pyspark.sql.dataframe.DataFrame.head"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*#
n
builtins.int"builtins.int0:overloadX2£
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__™
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*b`
 Union[builtins.int,builtins.str]
builtins.int"builtins.int
builtins.str"builtins.str0:overloadXπ
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*‰·
GUnion[pyspark.sql.column.Column,builtins.list[Any],builtins.tuple[Any]]6
pyspark.sql.column.Column"pyspark.sql.column.Column,
builtins.list[Any]
Any"builtins.list.
builtins.tuple[Any]
Any"builtins.tuple0:overloadX2‡
select&pyspark.sql.dataframe.DataFrame.select∆
select&pyspark.sql.dataframe.DataFrame.select"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadX‰
select&pyspark.sql.dataframe.DataFrame.select"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:overloadX2Ï

selectExpr*pyspark.sql.dataframe.DataFrame.selectExprÄ

selectExpr*pyspark.sql.dataframe.DataFrame.selectExpr"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
expr
builtins.str"builtins.str0:overloadXÆ

selectExpr*pyspark.sql.dataframe.DataFrame.selectExpr"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*T
exprJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:overloadX2ﬁ
groupBy'pyspark.sql.dataframe.DataFrame.groupByƒ
groupBy'pyspark.sql.dataframe.DataFrame.groupBy">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadX‚
groupBy'pyspark.sql.dataframe.DataFrame.groupBy">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:overloadX2ÿ
rollup&pyspark.sql.dataframe.DataFrame.rollup¬
rollup&pyspark.sql.dataframe.DataFrame.rollup">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadX‡
rollup&pyspark.sql.dataframe.DataFrame.rollup">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:overloadX2Ã
cube$pyspark.sql.dataframe.DataFrame.cubeæ
cube$pyspark.sql.dataframe.DataFrame.cube">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadX‹
cube$pyspark.sql.dataframe.DataFrame.cube">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:overloadX2é
fillna&pyspark.sql.dataframe.DataFrame.fillna∞
fillna&pyspark.sql.dataframe.DataFrame.fillna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*¥
value®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType*¶
subsetó
QUnion[builtins.str,builtins.tuple[builtins.str],builtins.list[builtins.str],None]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tupleJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:overloadX®
fillna&pyspark.sql.dataframe.DataFrame.fillna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*’
value…
obuiltins.dict[builtins.str,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]
builtins.str"builtins.str®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.dict0:overloadX2«(
replace'pyspark.sql.dataframe.DataFrame.replace˝
replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*π

to_replace®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType*Ÿ
valueÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:overloadX„

replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ø

to_replaceû
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.list*…
valueΩ
\builtins.list[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]]Õ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType"builtins.list*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:overloadX∂

replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Œ

to_replaceΩ
∞builtins.dict[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType"builtins.dict*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:overloadXÛ	
replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ø

to_replaceû
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.list*Ÿ
valueÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:overloadX2Ö
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantileÆ
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantile"P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
col
builtins.str"builtins.str*·
probabilitiesÕ
:Union[builtins.list[builtins.float],Tuple[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list;
Tuple[builtins.float] 
builtins.float"builtins.float*3
relativeError 
builtins.float"builtins.float0:overloadXë
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantile"è
,builtins.list[builtins.list[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*«
colΩ
6Union[builtins.list[builtins.str],Tuple[builtins.str]]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list5
Tuple[builtins.str]
builtins.str"builtins.str*·
probabilitiesÕ
:Union[builtins.list[builtins.float],Tuple[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list;
Tuple[builtins.float] 
builtins.float"builtins.float*3
relativeError 
builtins.float"builtins.float0:overloadX2Ë
drop$pyspark.sql.dataframe.DataFrame.drop¬
drop$pyspark.sql.dataframe.DataFrame.drop"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:overloadXÙ
drop$pyspark.sql.dataframe.DataFrame.drop"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
cols
builtins.str"builtins.str0:overloadXr
orderBy'pyspark.sql.dataframe.DataFrame.orderByK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
where%pyspark.sql.dataframe.DataFrame.whereK
CallableType[builtins.function]&
builtins.function"builtins.functionrí
groupby'pyspark.sql.dataframe.DataFrame.groupby^
CallableType[builtins.function]&
builtins.function"builtins.function"builtins.functionrè
drop_duplicates/pyspark.sql.dataframe.DataFrame.drop_duplicatesK
CallableType[builtins.function]&
builtins.function"builtins.functionr∞
_sql_ctx(pyspark.sql.dataframe.DataFrame._sql_ctxz
*Union[pyspark.sql.context.SQLContext,None]@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContext
Nonerz
_session(pyspark.sql.dataframe.DataFrame._sessionD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionrh
_sc#pyspark.sql.dataframe.DataFrame._sc<
pyspark.context.SparkContext"pyspark.context.SparkContextr5
_jdf$pyspark.sql.dataframe.DataFrame._jdf
AnyrV
	is_cached)pyspark.sql.dataframe.DataFrame.is_cached
builtins.bool"builtins.boolr®
_schema'pyspark.sql.dataframe.DataFrame._schemat
(Union[pyspark.sql.types.StructType,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
Noner‰
	_lazy_rdd)pyspark.sql.dataframe.DataFrame._lazy_rdd´
2Union[pyspark.rdd.RDD[pyspark.sql.types.Row],None]i
&pyspark.rdd.RDD[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"pyspark.rdd.RDD
Nonerh
_support_repr_html2pyspark.sql.dataframe.DataFrame._support_repr_html
builtins.bool"builtins.boolº
SparkIndexOpsMethods3pyspark.pandas.spark.accessors.SparkIndexOpsMethods"builtins.object*§
__init__<pyspark.pandas.spark.accessors.SparkIndexOpsMethods.__init__"
None*Ø
self§
Xpyspark.pandas.spark.accessors.SparkIndexOpsMethods[pyspark.pandas._typing.IndexOpsLike]í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods*ù
dataí
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin*ƒ
	data_type=pyspark.pandas.spark.accessors.SparkIndexOpsMethods.data_type"8
pyspark.sql.types.DataType"pyspark.sql.types.DataType*Ø
self§
Xpyspark.pandas.spark.accessors.SparkIndexOpsMethods[pyspark.pandas._typing.IndexOpsLike]í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods0:property`*®
nullable<pyspark.pandas.spark.accessors.SparkIndexOpsMethods.nullable"
builtins.bool"builtins.bool*Ø
self§
Xpyspark.pandas.spark.accessors.SparkIndexOpsMethods[pyspark.pandas._typing.IndexOpsLike]í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods0:property`*º
column:pyspark.pandas.spark.accessors.SparkIndexOpsMethods.column"6
pyspark.sql.column.Column"pyspark.sql.column.Column*Ø
self§
Xpyspark.pandas.spark.accessors.SparkIndexOpsMethods[pyspark.pandas._typing.IndexOpsLike]í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods0:property`*Ë
	transform=pyspark.pandas.spark.accessors.SparkIndexOpsMethods.transform"í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin*Ø
self§
Xpyspark.pandas.spark.accessors.SparkIndexOpsMethods[pyspark.pandas._typing.IndexOpsLike]í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*Ø
analyzed<pyspark.pandas.spark.accessors.SparkIndexOpsMethods.analyzed"í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin*Ø
self§
Xpyspark.pandas.spark.accessors.SparkIndexOpsMethods[pyspark.pandas._typing.IndexOpsLike]í
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods0:property:abstractmethod@`@Pbabc.ABCMetar◊
_data9pyspark.pandas.spark.accessors.SparkIndexOpsMethods._dataí
#pyspark.pandas._typing.IndexOpsLikeF
!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixin"!pyspark.pandas.base.IndexOpsMixinÈ
SparkSeriesMethods1pyspark.pandas.spark.accessors.SparkSeriesMethods"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods*’
apply7pyspark.pandas.spark.accessors.SparkSeriesMethods.apply"J
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series*p
selff
1pyspark.pandas.spark.accessors.SparkSeriesMethods"1pyspark.pandas.spark.accessors.SparkSeriesMethods*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*í
analyzed:pyspark.pandas.spark.accessors.SparkSeriesMethods.analyzed"J
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series*p
selff
1pyspark.pandas.spark.accessors.SparkSeriesMethods"1pyspark.pandas.spark.accessors.SparkSeriesMethods0:property`à
SparkIndexMethods0pyspark.pandas.spark.accessors.SparkIndexMethods"3pyspark.pandas.spark.accessors.SparkIndexOpsMethods*ã
analyzed9pyspark.pandas.spark.accessors.SparkIndexMethods.analyzed"F
!pyspark.pandas.indexes.base.Index"!pyspark.pandas.indexes.base.Index*n
selfd
0pyspark.pandas.spark.accessors.SparkIndexMethods"0pyspark.pandas.spark.accessors.SparkIndexMethods0:property`°<
SparkFrameMethods0pyspark.pandas.spark.accessors.SparkFrameMethods"builtins.object*ö
__init__9pyspark.pandas.spark.accessors.SparkFrameMethods.__init__"
None*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*Y
frameN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*∞
schema7pyspark.pandas.spark.accessors.SparkFrameMethods.schema"<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *à
print_schema=pyspark.pandas.spark.accessors.SparkFrameMethods.print_schema"
None*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *¥
frame6pyspark.pandas.spark.accessors.SparkFrameMethods.frame"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *˝
cache6pyspark.pandas.spark.accessors.SparkFrameMethods.cache"L
$pyspark.pandas.frame.CachedDataFrame"$pyspark.pandas.frame.CachedDataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*ﬁ
persist8pyspark.pandas.spark.accessors.SparkFrameMethods.persist"L
$pyspark.pandas.frame.CachedDataFrame"$pyspark.pandas.frame.CachedDataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*[
storage_levelF
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel *Ê
hint5pyspark.pandas.spark.accessors.SparkFrameMethods.hint"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*&
name
builtins.str"builtins.str*æ

parameters≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType* 
to_table9pyspark.pandas.spark.accessors.SparkFrameMethods.to_table"
None*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*&
name
builtins.str"builtins.str*R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *(
mode
builtins.str"builtins.str *√
partition_cols¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *€
optionsÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*˙
to_spark_io<pyspark.pandas.spark.accessors.SparkFrameMethods.to_spark_io"
None*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *(
mode
builtins.str"builtins.str *√
partition_cols¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *€
optionsÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*Ë
explain8pyspark.pandas.spark.accessors.SparkFrameMethods.explain"
None*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*W
extendedG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *P
modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *ó
apply6pyspark.pandas.spark.accessors.SparkFrameMethods.apply"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *Ω
repartition<pyspark.pandas.spark.accessors.SparkFrameMethods.repartition"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*0
num_partitions
builtins.int"builtins.int*∑
coalesce9pyspark.pandas.spark.accessors.SparkFrameMethods.coalesce"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*0
num_partitions
builtins.int"builtins.int*∂

checkpoint;pyspark.pandas.spark.accessors.SparkFrameMethods.checkpoint"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*+
eager
builtins.bool"builtins.bool *¬
local_checkpointApyspark.pandas.spark.accessors.SparkFrameMethods.local_checkpoint"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*+
eager
builtins.bool"builtins.bool *ì
analyzed9pyspark.pandas.spark.accessors.SparkFrameMethods.analyzed"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*n
selfd
0pyspark.pandas.spark.accessors.SparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods0:property`rè
_psdf6pyspark.pandas.spark.accessors.SparkFrameMethods._psdfN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame∞
CachedSparkFrameMethods6pyspark.pandas.spark.accessors.CachedSparkFrameMethods"0pyspark.pandas.spark.accessors.SparkFrameMethods*™
__init__?pyspark.pandas.spark.accessors.CachedSparkFrameMethods.__init__"
None*z
selfp
6pyspark.pandas.spark.accessors.CachedSparkFrameMethods"6pyspark.pandas.spark.accessors.CachedSparkFrameMethods*W
frameL
$pyspark.pandas.frame.CachedDataFrame"$pyspark.pandas.frame.CachedDataFrame*ß
storage_levelDpyspark.pandas.spark.accessors.CachedSparkFrameMethods.storage_level"F
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel*z
selfp
6pyspark.pandas.spark.accessors.CachedSparkFrameMethods"6pyspark.pandas.spark.accessors.CachedSparkFrameMethods0:property`*”
	unpersist@pyspark.pandas.spark.accessors.CachedSparkFrameMethods.unpersist"
None*z
selfp
6pyspark.pandas.spark.accessors.CachedSparkFrameMethods"6pyspark.pandas.spark.accessors.CachedSparkFrameMethods7
_test$pyspark.pandas.spark.accessors._test"
None*ö
__annotations__.pyspark.pandas.spark.accessors.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
pspyspark.pandas 