
pyspark.pandas.namespace™r
PySparkColumnpyspark.sql.column.Column"builtins.object*ã
__init__"pyspark.sql.column.Column.__init__"
None*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
jc
Any*∏
__eq__ pyspark.sql.column.Column.__eq__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*ôñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],_decimal.Decimal,TypeAlias[Union[datetime.datetime,datetime.date]]]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType$
_decimal.Decimal"_decimal.DecimalŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral*ß
__ne__ pyspark.sql.column.Column.__ne__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*Ö
__contains__&pyspark.sql.column.Column.__contains__"
None*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*∏
getItem!pyspark.sql.column.Column.getItem"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
key
Any*ª
getField"pyspark.sql.column.Column.getField"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
name
Any*ò
	withField#pyspark.sql.column.Column.withField"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*+
	fieldName
builtins.str"builtins.str*?
col6
pyspark.sql.column.Column"pyspark.sql.column.Column*⁄

dropFields$pyspark.sql.column.Column.dropFields"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*,

fieldNames
builtins.str"builtins.str*±
__getattr__%pyspark.sql.column.Column.__getattr__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*±
__getitem__%pyspark.sql.column.Column.__getitem__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*r
__iter__"pyspark.sql.column.Column.__iter__"
None*86
pyspark.sql.column.Column"pyspark.sql.column.Column*…
likepyspark.sql.column.Column.like"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*À
rlikepyspark.sql.column.Column.rlike"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*À
ilikepyspark.sql.column.Column.ilike"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*≥
isinpyspark.sql.column.Column.isin"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
cols
Any*‡
aliaspyspark.sql.column.Column.alias"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
alias
builtins.str"builtins.str*
kwargs
Any*º
castpyspark.sql.column.Column.cast"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*ô
dataTypeä
.Union[pyspark.sql.types.DataType,builtins.str]8
pyspark.sql.types.DataType"pyspark.sql.types.DataType
builtins.str"builtins.str*˙
between!pyspark.sql.column.Column.between"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*ß

lowerBoundñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[datetime.datetime,datetime.date]],_decimal.Decimal]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral$
_decimal.Decimal"_decimal.Decimal*ß

upperBoundñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[datetime.datetime,datetime.date]],_decimal.Decimal]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral$
_decimal.Decimal"_decimal.Decimal*˚
whenpyspark.sql.column.Column.when"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*E
	condition6
pyspark.sql.column.Column"pyspark.sql.column.Column*
value
Any*æ
	otherwise#pyspark.sql.column.Column.otherwise"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
value
Any*Ï
overpyspark.sql.column.Column.over"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*J
window>
pyspark.sql.window.WindowSpec"pyspark.sql.window.WindowSpec*Ä
__nonzero__%pyspark.sql.column.Column.__nonzero__"
None*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*Ü
__repr__"pyspark.sql.column.Column.__repr__"
builtins.str"builtins.str*86
pyspark.sql.column.Column"pyspark.sql.column.Column2Ç
substr pyspark.sql.column.Column.substrè
substr pyspark.sql.column.Column.substr"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column**
startPos
builtins.int"builtins.int*(
length
builtins.int"builtins.int0:typing.overloadX√
substr pyspark.sql.column.Column.substr"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*D
startPos6
pyspark.sql.column.Column"pyspark.sql.column.Column*B
length6
pyspark.sql.column.Column"pyspark.sql.column.Column0:typing.overloadXry
__neg__!pyspark.sql.column.Column.__neg__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__add__!pyspark.sql.column.Column.__add__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__sub__!pyspark.sql.column.Column.__sub__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__mul__!pyspark.sql.column.Column.__mul__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__div__!pyspark.sql.column.Column.__div__K
CallableType[builtins.function]&
builtins.function"builtins.functionrÅ
__truediv__%pyspark.sql.column.Column.__truediv__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__mod__!pyspark.sql.column.Column.__mod__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__radd__"pyspark.sql.column.Column.__radd__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rsub__"pyspark.sql.column.Column.__rsub__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rmul__"pyspark.sql.column.Column.__rmul__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rdiv__"pyspark.sql.column.Column.__rdiv__K
CallableType[builtins.function]&
builtins.function"builtins.functionrÉ
__rtruediv__&pyspark.sql.column.Column.__rtruediv__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rmod__"pyspark.sql.column.Column.__rmod__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__pow__!pyspark.sql.column.Column.__pow__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rpow__"pyspark.sql.column.Column.__rpow__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__lt__ pyspark.sql.column.Column.__lt__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__le__ pyspark.sql.column.Column.__le__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__ge__ pyspark.sql.column.Column.__ge__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__gt__ pyspark.sql.column.Column.__gt__K
CallableType[builtins.function]&
builtins.function"builtins.functionrZ
_eqNullSafe_doc)pyspark.sql.column.Column._eqNullSafe_doc
builtins.str"builtins.strr

eqNullSafe$pyspark.sql.column.Column.eqNullSafeK
CallableType[builtins.function]&
builtins.function"builtins.functionry
__and__!pyspark.sql.column.Column.__and__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__or__ pyspark.sql.column.Column.__or__K
CallableType[builtins.function]&
builtins.function"builtins.functionr

__invert__$pyspark.sql.column.Column.__invert__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rand__"pyspark.sql.column.Column.__rand__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__ror__!pyspark.sql.column.Column.__ror__K
CallableType[builtins.function]&
builtins.function"builtins.functionrX
_bitwiseOR_doc(pyspark.sql.column.Column._bitwiseOR_doc
builtins.str"builtins.strrZ
_bitwiseAND_doc)pyspark.sql.column.Column._bitwiseAND_doc
builtins.str"builtins.strrZ
_bitwiseXOR_doc)pyspark.sql.column.Column._bitwiseXOR_doc
builtins.str"builtins.strr}
	bitwiseOR#pyspark.sql.column.Column.bitwiseORK
CallableType[builtins.function]&
builtins.function"builtins.functionr

bitwiseAND$pyspark.sql.column.Column.bitwiseANDK
CallableType[builtins.function]&
builtins.function"builtins.functionr

bitwiseXOR$pyspark.sql.column.Column.bitwiseXORK
CallableType[builtins.function]&
builtins.function"builtins.functionrV
_contains_doc'pyspark.sql.column.Column._contains_doc
builtins.str"builtins.strrZ
_startswith_doc)pyspark.sql.column.Column._startswith_doc
builtins.str"builtins.strrV
_endswith_doc'pyspark.sql.column.Column._endswith_doc
builtins.str"builtins.strr{
contains"pyspark.sql.column.Column.containsK
CallableType[builtins.function]&
builtins.function"builtins.functionr

startswith$pyspark.sql.column.Column.startswithK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
endswith"pyspark.sql.column.Column.endswithK
CallableType[builtins.function]&
builtins.function"builtins.functionrL
_asc_doc"pyspark.sql.column.Column._asc_doc
builtins.str"builtins.strrd
_asc_nulls_first_doc.pyspark.sql.column.Column._asc_nulls_first_doc
builtins.str"builtins.strrb
_asc_nulls_last_doc-pyspark.sql.column.Column._asc_nulls_last_doc
builtins.str"builtins.strrN
	_desc_doc#pyspark.sql.column.Column._desc_doc
builtins.str"builtins.strrf
_desc_nulls_first_doc/pyspark.sql.column.Column._desc_nulls_first_doc
builtins.str"builtins.strrd
_desc_nulls_last_doc.pyspark.sql.column.Column._desc_nulls_last_doc
builtins.str"builtins.strrq
ascpyspark.sql.column.Column.ascK
CallableType[builtins.function]&
builtins.function"builtins.functionrâ
asc_nulls_first)pyspark.sql.column.Column.asc_nulls_firstK
CallableType[builtins.function]&
builtins.function"builtins.functionrá
asc_nulls_last(pyspark.sql.column.Column.asc_nulls_lastK
CallableType[builtins.function]&
builtins.function"builtins.functionrs
descpyspark.sql.column.Column.descK
CallableType[builtins.function]&
builtins.function"builtins.functionrã
desc_nulls_first*pyspark.sql.column.Column.desc_nulls_firstK
CallableType[builtins.function]&
builtins.function"builtins.functionrâ
desc_nulls_last)pyspark.sql.column.Column.desc_nulls_lastK
CallableType[builtins.function]&
builtins.function"builtins.functionrR
_isNull_doc%pyspark.sql.column.Column._isNull_doc
builtins.str"builtins.strrX
_isNotNull_doc(pyspark.sql.column.Column._isNotNull_doc
builtins.str"builtins.strrw
isNull pyspark.sql.column.Column.isNullK
CallableType[builtins.function]&
builtins.function"builtins.functionr}
	isNotNull#pyspark.sql.column.Column.isNotNullK
CallableType[builtins.function]&
builtins.function"builtins.functionrs
namepyspark.sql.column.Column.nameK
CallableType[builtins.function]&
builtins.function"builtins.functionrw
astype pyspark.sql.column.Column.astypeK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__bool__"pyspark.sql.column.Column.__bool__K
CallableType[builtins.function]&
builtins.function"builtins.functionr-
_jcpyspark.sql.column.Column._jc
Any›ü
PySparkDataFramepyspark.sql.dataframe.DataFrame",pyspark.sql.pandas.map_ops.PandasMapOpsMixin"3pyspark.sql.pandas.conversion.PandasConversionMixin*Å
__init__(pyspark.sql.dataframe.DataFrame.__init__"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*
jdf
Any*‡
sql_ctx“
FUnion[pyspark.sql.context.SQLContext,pyspark.sql.session.SparkSession]@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContextD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*Ÿ
sql_ctx'pyspark.sql.dataframe.DataFrame.sql_ctx"@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContext*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Á
sparkSession,pyspark.sql.dataframe.DataFrame.sparkSession"D
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*˙
rdd#pyspark.sql.dataframe.DataFrame.rdd"i
&pyspark.rdd.RDD[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"pyspark.rdd.RDD*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Á
na"pyspark.sql.dataframe.DataFrame.na"X
*pyspark.sql.dataframe.DataFrameNaFunctions"*pyspark.sql.dataframe.DataFrameNaFunctions*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Ô
stat$pyspark.sql.dataframe.DataFrame.stat"\
,pyspark.sql.dataframe.DataFrameStatFunctions",pyspark.sql.dataframe.DataFrameStatFunctions*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Å
toJSON&pyspark.sql.dataframe.DataFrame.toJSON"N
pyspark.rdd.RDD[builtins.str]
builtins.str"builtins.str"pyspark.rdd.RDD*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*1
use_unicode
builtins.bool"builtins.bool *∆
registerTempTable1pyspark.sql.dataframe.DataFrame.registerTempTable"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*¿
createTempView.pyspark.sql.dataframe.DataFrame.createTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*“
createOrReplaceTempView7pyspark.sql.dataframe.DataFrame.createOrReplaceTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*Ã
createGlobalTempView4pyspark.sql.dataframe.DataFrame.createGlobalTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*ﬁ
createOrReplaceGlobalTempView=pyspark.sql.dataframe.DataFrame.createOrReplaceGlobalTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*Â
write%pyspark.sql.dataframe.DataFrame.write"P
&pyspark.sql.readwriter.DataFrameWriter"&pyspark.sql.readwriter.DataFrameWriter*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*á
writeStream+pyspark.sql.dataframe.DataFrame.writeStream"f
1pyspark.sql.streaming.readwriter.DataStreamWriter"1pyspark.sql.streaming.readwriter.DataStreamWriter*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*”
schema&pyspark.sql.dataframe.DataFrame.schema"<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Â
printSchema+pyspark.sql.dataframe.DataFrame.printSchema"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Q
levelD
Union[builtins.int,None]
builtins.int"builtins.int
None *·
explain'pyspark.sql.dataframe.DataFrame.explain"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ç
extendedr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *P
modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *ó
	exceptAll)pyspark.sql.dataframe.DataFrame.exceptAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*†
isLocal'pyspark.sql.dataframe.DataFrame.isLocal"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
isStreaming+pyspark.sql.dataframe.DataFrame.isStreaming"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*†
isEmpty'pyspark.sql.dataframe.DataFrame.isEmpty"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*–
show$pyspark.sql.dataframe.DataFrame.show"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
n
builtins.int"builtins.int *s
truncatec
!Union[builtins.bool,builtins.int]
builtins.bool"builtins.bool
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *Ù
_show_string,pyspark.sql.dataframe.DataFrame._show_string"
builtins.str"builtins.str*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
n
builtins.int"builtins.int *s
truncatec
!Union[builtins.bool,builtins.int]
builtins.bool"builtins.bool
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *ò
__repr__(pyspark.sql.dataframe.DataFrame.__repr__"
builtins.str"builtins.str*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Œ
_repr_html_+pyspark.sql.dataframe.DataFrame._repr_html_"D
Union[builtins.str,None]
builtins.str"builtins.str
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˜

checkpoint*pyspark.sql.dataframe.DataFrame.checkpoint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
eager
builtins.bool"builtins.bool *Å
localCheckpoint/pyspark.sql.dataframe.DataFrame.localCheckpoint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
eager
builtins.bool"builtins.bool *Ø
withWatermark-pyspark.sql.dataframe.DataFrame.withWatermark"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
	eventTime
builtins.str"builtins.str*0
delayThreshold
builtins.str"builtins.str*ø
hint$pyspark.sql.dataframe.DataFrame.hint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*÷

parameters≈
fUnion[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]],builtins.list[Unknown]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType)
builtins.list[Unknown] "builtins.list*ö
count%pyspark.sql.dataframe.DataFrame.count"
builtins.int"builtins.int*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Á
collect'pyspark.sql.dataframe.DataFrame.collect"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*µ
toLocalIterator/pyspark.sql.dataframe.DataFrame.toLocalIterator"i
&typing.Iterator[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"typing.Iterator*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*8
prefetchPartitions
builtins.bool"builtins.bool *Á
limit%pyspark.sql.dataframe.DataFrame.limit"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*È
offset&pyspark.sql.dataframe.DataFrame.offset"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*à
take$pyspark.sql.dataframe.DataFrame.take"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*à
tail$pyspark.sql.dataframe.DataFrame.tail"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*ﬁ
foreach'pyspark.sql.dataframe.DataFrame.foreach"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*
foreachPartition0pyspark.sql.dataframe.DataFrame.foreachPartition"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*¿
cache%pyspark.sql.dataframe.DataFrame.cache"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*†
persist'pyspark.sql.dataframe.DataFrame.persist"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Z
storageLevelF
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel *È
storageLevel,pyspark.sql.dataframe.DataFrame.storageLevel"F
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*¯
	unpersist)pyspark.sql.dataframe.DataFrame.unpersist"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*.
blocking
builtins.bool"builtins.bool *˜
coalesce(pyspark.sql.dataframe.DataFrame.coalesce"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*∆
distinct(pyspark.sql.dataframe.DataFrame.distinct"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˚
sampleBy(pyspark.sql.dataframe.DataFrame.sampleBy"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ú
colË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*l
	fractions]
!builtins.dict[Any,builtins.float]
Any 
builtins.float"builtins.float"builtins.dict*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *ø
randomSplit+pyspark.sql.dataframe.DataFrame.randomSplit"É
.builtins.list[pyspark.sql.dataframe.DataFrame]B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*]
weightsP
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *∫
dtypes&pyspark.sql.dataframe.DataFrame.dtypes"¢
/builtins.list[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*„
columns'pyspark.sql.dataframe.DataFrame.columns"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Â
colRegex(pyspark.sql.dataframe.DataFrame.colRegex"6
pyspark.sql.column.Column"pyspark.sql.column.Column*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*)
colName
builtins.str"builtins.str*Ñ
to"pyspark.sql.dataframe.DataFrame.to"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
schema<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*È
alias%pyspark.sql.dataframe.DataFrame.alias"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
alias
builtins.str"builtins.str*ó
	crossJoin)pyspark.sql.dataframe.DataFrame.crossJoin"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ü
join$pyspark.sql.dataframe.DataFrame.join"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*•
onö
wUnion[builtins.str,builtins.list[builtins.str],pyspark.sql.column.Column,builtins.list[pyspark.sql.column.Column],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list6
pyspark.sql.column.Column"pyspark.sql.column.Columnq
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None *O
howD
Union[builtins.str,None]
builtins.str"builtins.str
None *µ

	_joinAsOf)pyspark.sql.dataframe.DataFrame._joinAsOf"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ú
leftAsOfColumná
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column*ù
rightAsOfColumná
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column*•
onö
wUnion[builtins.str,builtins.list[builtins.str],pyspark.sql.column.Column,builtins.list[pyspark.sql.column.Column],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list6
pyspark.sql.column.Column"pyspark.sql.column.Columnq
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None *O
howD
Union[builtins.str,None]
builtins.str"builtins.str
None *|
	tolerancek
%Union[pyspark.sql.column.Column,None]6
pyspark.sql.column.Column"pyspark.sql.column.Column
None *7
allowExactMatches
builtins.bool"builtins.bool *-
	direction
builtins.str"builtins.str *ü
sortWithinPartitions4pyspark.sql.dataframe.DataFrame.sortWithinPartitions"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*©
colsû
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*
kwargs
Any*ˇ
sort$pyspark.sql.dataframe.DataFrame.sort"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*©
colsû
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*
kwargs
Any*‹
_jseq%pyspark.sql.dataframe.DataFrame._jseq"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*:
cols0
typing.Sequence[Any]
Any"typing.Sequence*ò
	converterÜ
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None *»
_jmap%pyspark.sql.dataframe.DataFrame._jmap"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*A
jm9
builtins.dict[Any,Any]
Any
Any"builtins.dict*˝
_jcols&pyspark.sql.dataframe.DataFrame._jcols"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*±

_sort_cols*pyspark.sql.dataframe.DataFrame._sort_cols"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*∫
colsØ
{typing.Sequence[Union[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]]û
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list"typing.Sequence*c
kwargsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*Ò
describe(pyspark.sql.dataframe.DataFrame.describe"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*®
colsù
/Union[builtins.str,builtins.list[builtins.str]]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*Ú
summary'pyspark.sql.dataframe.DataFrame.summary"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*,

statistics
builtins.str"builtins.str*›
first%pyspark.sql.dataframe.DataFrame.first"_
!Union[pyspark.sql.types.Row,None].
pyspark.sql.types.Row"pyspark.sql.types.Row
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ÿ
__getattr__+pyspark.sql.dataframe.DataFrame.__getattr__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*
builtins.str"builtins.str*Ã
__dir__'pyspark.sql.dataframe.DataFrame.__dir__"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ω
filter&pyspark.sql.dataframe.DataFrame.filter"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*¯
	conditionË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*√	
unpivot'pyspark.sql.dataframe.DataFrame.unpivot"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
idsµ
nUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown]]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple*—
valuesƒ
sUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown],None]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple
None*4
variableColumnName
builtins.str"builtins.str*1
valueColumnName
builtins.str"builtins.str*Ω	
melt$pyspark.sql.dataframe.DataFrame.melt"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
idsµ
nUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown]]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple*—
valuesƒ
sUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown],None]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple
None*4
variableColumnName
builtins.str"builtins.str*1
valueColumnName
builtins.str"builtins.str*«
agg#pyspark.sql.dataframe.DataFrame.agg"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*à
exprs¸
IUnion[pyspark.sql.column.Column,builtins.dict[builtins.str,builtins.str]]6
pyspark.sql.column.Column"pyspark.sql.column.Columnu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict*¡
observe'pyspark.sql.dataframe.DataFrame.observe"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*∑
observation•
7Union[pyspark.sql.observation.Observation,builtins.str]J
#pyspark.sql.observation.Observation"#pyspark.sql.observation.Observation
builtins.str"builtins.str*A
exprs6
pyspark.sql.column.Column"pyspark.sql.column.Column*è
union%pyspark.sql.dataframe.DataFrame.union"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ï
unionAll(pyspark.sql.dataframe.DataFrame.unionAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*÷
unionByName+pyspark.sql.dataframe.DataFrame.unionByName"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*9
allowMissingColumns
builtins.bool"builtins.bool *ó
	intersect)pyspark.sql.dataframe.DataFrame.intersect"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ù
intersectAll,pyspark.sql.dataframe.DataFrame.intersectAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ï
subtract(pyspark.sql.dataframe.DataFrame.subtract"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Â
dropDuplicates.pyspark.sql.dataframe.DataFrame.dropDuplicates"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *É
dropDuplicatesWithinWatermark=pyspark.sql.dataframe.DataFrame.dropDuplicatesWithinWatermark"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *Ë
dropna&pyspark.sql.dataframe.DataFrame.dropna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
how
builtins.str"builtins.str *R
threshD
Union[builtins.int,None]
builtins.int"builtins.int
None *¶
subsetó
QUnion[builtins.str,builtins.tuple[builtins.str],builtins.list[builtins.str],None]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tupleJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *¿
corr$pyspark.sql.dataframe.DataFrame.corr" 
builtins.float"builtins.float*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*R
methodD
Union[builtins.str,None]
builtins.str"builtins.str
None *Í
cov#pyspark.sql.dataframe.DataFrame.cov" 
builtins.float"builtins.float*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*ñ
crosstab(pyspark.sql.dataframe.DataFrame.crosstab"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*Ó
	freqItems)pyspark.sql.dataframe.DataFrame.freqItems"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*»
colsΩ
6Union[builtins.list[builtins.str],Tuple[builtins.str]]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list5
Tuple[builtins.str]
builtins.str"builtins.str*Y
supportJ
Union[builtins.float,None] 
builtins.float"builtins.float
None *
_ipython_key_completions_9pyspark.sql.dataframe.DataFrame._ipython_key_completions_"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˘
withColumns+pyspark.sql.dataframe.DataFrame.withColumns"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*™
colsMapú
5builtins.dict[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.dict*∂

withColumn*pyspark.sql.dataframe.DataFrame.withColumn"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*)
colName
builtins.str"builtins.str*?
col6
pyspark.sql.column.Column"pyspark.sql.column.Column*´
withColumnRenamed1pyspark.sql.dataframe.DataFrame.withColumnRenamed"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame**
existing
builtins.str"builtins.str*%
new
builtins.str"builtins.str*ﬂ
withColumnsRenamed2pyspark.sql.dataframe.DataFrame.withColumnsRenamed"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ç
colsMapu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict*„
withMetadata,pyspark.sql.dataframe.DataFrame.withMetadata"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*,

columnName
builtins.str"builtins.str*e
metadataW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*Ê
toDF$pyspark.sql.dataframe.DataFrame.toDF"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
cols
builtins.str"builtins.str*«
	transform)pyspark.sql.dataframe.DataFrame.transform"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*
args
Any*
kwargs
Any*˚
sameSemantics-pyspark.sql.dataframe.DataFrame.sameSemantics"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*®
semanticHash,pyspark.sql.dataframe.DataFrame.semanticHash"
builtins.int"builtins.int*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*“

inputFiles*pyspark.sql.dataframe.DataFrame.inputFiles"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ˇ
writeTo'pyspark.sql.dataframe.DataFrame.writeTo"T
(pyspark.sql.readwriter.DataFrameWriterV2"(pyspark.sql.readwriter.DataFrameWriterV2*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
table
builtins.str"builtins.str*ß
to_pandas_on_spark2pyspark.sql.dataframe.DataFrame.to_pandas_on_spark"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *ó

pandas_api*pyspark.sql.dataframe.DataFrame.pandas_api"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *ï
	to_koalas)pyspark.sql.dataframe.DataFrame.to_koalas"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 2ü
repartition+pyspark.sql.dataframe.DataFrame.repartitionà
repartition+pyspark.sql.dataframe.DataFrame.repartition"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX◊
repartition+pyspark.sql.dataframe.DataFrame.repartition"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX2…
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRangeñ
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRange"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÂ
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRange"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX2∆
sample&pyspark.sql.dataframe.DataFrame.sampleŸ
sample&pyspark.sql.dataframe.DataFrame.sample"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*.
fraction 
builtins.float"builtins.float*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None 0:typing.overloadX∑
sample&pyspark.sql.dataframe.DataFrame.sample"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*\
withReplacementG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None*.
fraction 
builtins.float"builtins.float*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None 0:typing.overloadX2Ω
head$pyspark.sql.dataframe.DataFrame.head
head$pyspark.sql.dataframe.DataFrame.head"_
!Union[pyspark.sql.types.Row,None].
pyspark.sql.types.Row"pyspark.sql.types.Row
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:typing.overloadXõ
head$pyspark.sql.dataframe.DataFrame.head"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*#
n
builtins.int"builtins.int0:typing.overloadX2±
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__±
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*b`
 Union[builtins.int,builtins.str]
builtins.int"builtins.int
builtins.str"builtins.str0:typing.overloadX¿
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*‰·
GUnion[pyspark.sql.column.Column,builtins.list[Any],builtins.tuple[Any]]6
pyspark.sql.column.Column"pyspark.sql.column.Column,
builtins.list[Any]
Any"builtins.list.
builtins.tuple[Any]
Any"builtins.tuple0:typing.overloadX2Ó
select&pyspark.sql.dataframe.DataFrame.selectÕ
select&pyspark.sql.dataframe.DataFrame.select"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÎ
select&pyspark.sql.dataframe.DataFrame.select"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2˙

selectExpr*pyspark.sql.dataframe.DataFrame.selectExprá

selectExpr*pyspark.sql.dataframe.DataFrame.selectExpr"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
expr
builtins.str"builtins.str0:typing.overloadXµ

selectExpr*pyspark.sql.dataframe.DataFrame.selectExpr"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*T
exprJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2Ï
groupBy'pyspark.sql.dataframe.DataFrame.groupByÀ
groupBy'pyspark.sql.dataframe.DataFrame.groupBy">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÈ
groupBy'pyspark.sql.dataframe.DataFrame.groupBy">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2Ê
rollup&pyspark.sql.dataframe.DataFrame.rollup…
rollup&pyspark.sql.dataframe.DataFrame.rollup">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÁ
rollup&pyspark.sql.dataframe.DataFrame.rollup">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2⁄
cube$pyspark.sql.dataframe.DataFrame.cube≈
cube$pyspark.sql.dataframe.DataFrame.cube">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX„
cube$pyspark.sql.dataframe.DataFrame.cube">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2ú
fillna&pyspark.sql.dataframe.DataFrame.fillna∑
fillna&pyspark.sql.dataframe.DataFrame.fillna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*¥
value®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType*¶
subsetó
QUnion[builtins.str,builtins.tuple[builtins.str],builtins.list[builtins.str],None]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tupleJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadXØ
fillna&pyspark.sql.dataframe.DataFrame.fillna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*’
value…
obuiltins.dict[builtins.str,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]
builtins.str"builtins.str®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.dict0:typing.overloadX2„(
replace'pyspark.sql.dataframe.DataFrame.replaceÑ	
replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*π

to_replace®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType*Ÿ
valueÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadXÍ

replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ø

to_replaceû
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.list*…
valueΩ
\builtins.list[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]]Õ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType"builtins.list*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadXΩ

replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Œ

to_replaceΩ
∞builtins.dict[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType"builtins.dict*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadX˙	
replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ø

to_replaceû
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.list*Ÿ
valueÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadX2ì
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantileµ
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantile"P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
col
builtins.str"builtins.str*·
probabilitiesÕ
:Union[builtins.list[builtins.float],Tuple[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list;
Tuple[builtins.float] 
builtins.float"builtins.float*3
relativeError 
builtins.float"builtins.float0:typing.overloadXò
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantile"è
,builtins.list[builtins.list[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*«
colΩ
6Union[builtins.list[builtins.str],Tuple[builtins.str]]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list5
Tuple[builtins.str]
builtins.str"builtins.str*·
probabilitiesÕ
:Union[builtins.list[builtins.float],Tuple[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list;
Tuple[builtins.float] 
builtins.float"builtins.float*3
relativeError 
builtins.float"builtins.float0:typing.overloadX2ˆ
drop$pyspark.sql.dataframe.DataFrame.drop…
drop$pyspark.sql.dataframe.DataFrame.drop"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX˚
drop$pyspark.sql.dataframe.DataFrame.drop"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
cols
builtins.str"builtins.str0:typing.overloadXr
orderBy'pyspark.sql.dataframe.DataFrame.orderByK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
where%pyspark.sql.dataframe.DataFrame.whereK
CallableType[builtins.function]&
builtins.function"builtins.functionrí
groupby'pyspark.sql.dataframe.DataFrame.groupby^
CallableType[builtins.function]&
builtins.function"builtins.function"builtins.functionrè
drop_duplicates/pyspark.sql.dataframe.DataFrame.drop_duplicatesK
CallableType[builtins.function]&
builtins.function"builtins.functionr∞
_sql_ctx(pyspark.sql.dataframe.DataFrame._sql_ctxz
*Union[pyspark.sql.context.SQLContext,None]@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContext
Nonerz
_session(pyspark.sql.dataframe.DataFrame._sessionD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionrh
_sc#pyspark.sql.dataframe.DataFrame._sc<
pyspark.context.SparkContext"pyspark.context.SparkContextr5
_jdf$pyspark.sql.dataframe.DataFrame._jdf
AnyrV
	is_cached)pyspark.sql.dataframe.DataFrame.is_cached
builtins.bool"builtins.boolr®
_schema'pyspark.sql.dataframe.DataFrame._schemat
(Union[pyspark.sql.types.StructType,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
Noner‰
	_lazy_rdd)pyspark.sql.dataframe.DataFrame._lazy_rdd´
2Union[pyspark.rdd.RDD[pyspark.sql.types.Row],None]i
&pyspark.rdd.RDD[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"pyspark.rdd.RDD
Nonerh
_support_repr_html2pyspark.sql.dataframe.DataFrame._support_repr_html
builtins.bool"builtins.bool’
from_pandas$pyspark.pandas.namespace.from_pandas"÷
nUnion[pyspark.pandas.series.Series[Any],pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.indexes.base.Index]J
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.SeriesN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameF
!pyspark.pandas.indexes.base.Index"!pyspark.pandas.indexes.base.Index*∆
pobjª
eUnion[pandas.core.frame.DataFrame,pandas.core.series.Series[Any],pandas.core.indexes.base.Index[Any]]:
pandas.core.frame.DataFrame"pandas.core.frame.DataFrameD
pandas.core.series.Series[Any]
Any"pandas.core.series.SeriesN
#pandas.core.indexes.base.Index[Any]
Any"pandas.core.indexes.base.Index˜
rangepyspark.pandas.namespace.range"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*'
start
builtins.int"builtins.int*O
endD
Union[builtins.int,None]
builtins.int"builtins.int
None *(
step
builtins.int"builtins.int *Z
num_partitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None ‰
read_csv!pyspark.pandas.namespace.read_csv"Ï
LUnion[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series*®
pathù
/Union[builtins.str,builtins.list[builtins.str]]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*'
sep
builtins.str"builtins.str *}
headero
%Union[builtins.str,builtins.int,None]
builtins.str"builtins.str
builtins.int"builtins.int
None *∫
names¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *Ê
usecols÷
cUnion[builtins.list[builtins.int],builtins.list[builtins.str],CallableType[builtins.function],None]J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.listK
CallableType[builtins.function]&
builtins.function"builtins.function
None *-
squeeze
builtins.bool"builtins.bool *6
mangle_dupe_cols
builtins.bool"builtins.bool *Æ
dtype†
öUnion[builtins.str,TypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]],builtins.dict[builtins.str,Union[builtins.str,Unknown]],None]
builtins.str"builtins.str¨
ITypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]æ
>Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype](
numpy.dtype[Any]
Any"numpy.dtypeP
&pandas.core.dtypes.base.ExtensionDtype"&pandas.core.dtypes.base.ExtensionDtype"pyspark.pandas._typing.Dtypeß
7builtins.dict[builtins.str,Union[builtins.str,Unknown]]
builtins.str"builtins.str?
Union[builtins.str,Unknown]
builtins.str"builtins.str "builtins.dict
None *Q
nrowsD
Union[builtins.int,None]
builtins.int"builtins.int
None *1
parse_dates
builtins.bool"builtins.bool *U
	quotecharD
Union[builtins.str,None]
builtins.str"builtins.str
None *V

escapecharD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
commentD
Union[builtins.str,None]
builtins.str"builtins.str
None *T
encodingD
Union[builtins.str,None]
builtins.str"builtins.str
None *
options
Any´
	read_json"pyspark.pandas.namespace.read_json"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*&
path
builtins.str"builtins.str*+
lines
builtins.bool"builtins.bool *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *
options
Any¨

read_delta#pyspark.pandas.namespace.read_delta"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*&
path
builtins.str"builtins.str*S
versionD
Union[builtins.str,None]
builtins.str"builtins.str
None *U
	timestampD
Union[builtins.str,None]
builtins.str"builtins.str
None *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *
options
AnyÍ

read_table#pyspark.pandas.namespace.read_table"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*&
name
builtins.str"builtins.str*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None ¶
read_spark_io&pyspark.pandas.namespace.read_spark_io"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *ü
schemaê
0Union[builtins.str,pyspark.sql.types.StructType]
builtins.str"builtins.str<
pyspark.sql.types.StructType"pyspark.sql.types.StructType *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *
options
Any§
read_parquet%pyspark.pandas.namespace.read_parquet"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*&
path
builtins.str"builtins.str*ë
columnsÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *ì
	index_colÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *5
pandas_metadata
builtins.bool"builtins.bool *
options
Any«
read_clipboard'pyspark.pandas.namespace.read_clipboard"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*'
sep
builtins.str"builtins.str *
kwargs
Any≤"

read_excel#pyspark.pandas.namespace.read_excel"ﬂ
µUnion[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any],builtins.dict[builtins.str,Union[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.SeriesÜ
hbuiltins.dict[builtins.str,Union[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]]
builtins.str"builtins.strÏ
LUnion[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series"builtins.dict*J
ioB
Union[builtins.str,Any]
builtins.str"builtins.str
Any*◊

sheet_nameƒ
UUnion[builtins.str,builtins.int,builtins.list[Union[builtins.str,builtins.int]],None]
builtins.str"builtins.str
builtins.int"builtins.int¢
/builtins.list[Union[builtins.str,builtins.int]]`
 Union[builtins.str,builtins.int]
builtins.str"builtins.str
builtins.int"builtins.int"builtins.list
None *¨
headerù
/Union[builtins.int,builtins.list[builtins.int]]
builtins.int"builtins.intJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list *g
namesZ
Union[builtins.list[Any],None],
builtins.list[Any]
Any"builtins.list
None *ì
	index_colÅ
'Union[builtins.list[builtins.int],None]J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
None *¡
usecols±
uUnion[builtins.int,builtins.str,builtins.list[Union[builtins.int,builtins.str]],CallableType[builtins.function],None]
builtins.int"builtins.int
builtins.str"builtins.str¢
/builtins.list[Union[builtins.int,builtins.str]]`
 Union[builtins.int,builtins.str]
builtins.int"builtins.int
builtins.str"builtins.str"builtins.listK
CallableType[builtins.function]&
builtins.function"builtins.function
None *-
squeeze
builtins.bool"builtins.bool *˛
dtype
ÖUnion[builtins.dict[builtins.str,Union[builtins.str,TypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]]],None]Ÿ
ybuiltins.dict[builtins.str,Union[builtins.str,TypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]]]
builtins.str"builtins.strÆ
]Union[builtins.str,TypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]]
builtins.str"builtins.str¨
ITypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]æ
>Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype](
numpy.dtype[Any]
Any"numpy.dtypeP
&pandas.core.dtypes.base.ExtensionDtype"&pandas.core.dtypes.base.ExtensionDtype"pyspark.pandas._typing.Dtype"builtins.dict
None *R
engineD
Union[builtins.str,None]
builtins.str"builtins.str
None *}

convertersk
"Union[builtins.dict[Any,Any],None]9
builtins.dict[Any,Any]
Any
Any"builtins.dict
None *9
true_values&
Union[Any,None]
Any
None *:
false_values&
Union[Any,None]
Any
None *Ω
skiprows¨
4Union[builtins.int,builtins.list[builtins.int],None]
builtins.int"builtins.intJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
None *Q
nrowsD
Union[builtins.int,None]
builtins.int"builtins.int
None *7
	na_values&
Union[Any,None]
Any
None *5
keep_default_na
builtins.bool"builtins.bool *-
verbose
builtins.bool"builtins.bool *ﬂ
parse_datesÀ
>Union[builtins.bool,builtins.list[Any],builtins.dict[Any,Any]]
builtins.bool"builtins.bool,
builtins.list[Any]
Any"builtins.list9
builtins.dict[Any,Any]
Any
Any"builtins.dict *ö
date_parserÜ
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None *U
	thousandsD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
commentD
Union[builtins.str,None]
builtins.str"builtins.str
None *.

skipfooter
builtins.int"builtins.int *3
convert_float
builtins.bool"builtins.bool *6
mangle_dupe_cols
builtins.bool"builtins.bool *
kwds
Any‘
	read_html"pyspark.pandas.namespace.read_html"ì
2builtins.list[pyspark.pandas.frame.DataFrame[Any]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame"builtins.list*J
ioB
Union[builtins.str,Any]
builtins.str"builtins.str
Any*)
match
builtins.str"builtins.str *R
flavorD
Union[builtins.str,None]
builtins.str"builtins.str
None *ª
header¨
4Union[builtins.int,builtins.list[builtins.int],None]
builtins.int"builtins.intJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
None *æ
	index_col¨
4Union[builtins.int,builtins.list[builtins.int],None]
builtins.int"builtins.intJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
None *Ó
skiprows›
CUnion[builtins.int,builtins.list[builtins.int],builtins.slice,None]
builtins.int"builtins.intJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list 
builtins.slice"builtins.slice
None *«
attrsπ
4Union[builtins.dict[builtins.str,builtins.str],None]u
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict
None *1
parse_dates
builtins.bool"builtins.bool *-
	thousands
builtins.str"builtins.str *T
encodingD
Union[builtins.str,None]
builtins.str"builtins.str
None *+
decimal
builtins.str"builtins.str *}

convertersk
"Union[builtins.dict[Any,Any],None]9
builtins.dict[Any,Any]
Any
Any"builtins.dict
None *7
	na_values&
Union[Any,None]
Any
None *5
keep_default_na
builtins.bool"builtins.bool *4
displayed_only
builtins.bool"builtins.bool »
read_sql_table'pyspark.pandas.namespace.read_sql_table"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*,

table_name
builtins.str"builtins.str*%
con
builtins.str"builtins.str*R
schemaD
Union[builtins.str,None]
builtins.str"builtins.str
None *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *º
columns¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *
options
AnyÆ
read_sql_query'pyspark.pandas.namespace.read_sql_query"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*%
sql
builtins.str"builtins.str*%
con
builtins.str"builtins.str*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *
options
Any·
read_sql!pyspark.pandas.namespace.read_sql"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*%
sql
builtins.str"builtins.str*%
con
builtins.str"builtins.str*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *º
columns¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *
options
Anyß
to_datetime$pyspark.pandas.namespace.to_datetime*
arg*
errors *
format *

unit *
infer_datetime_format *
origin 0:typing.no_type_check∆

date_range#pyspark.pandas.namespace.date_range"`
.pyspark.pandas.indexes.datetimes.DatetimeIndex".pyspark.pandas.indexes.datetimes.DatetimeIndex*O
startB
Union[builtins.str,Any]
builtins.str"builtins.str
Any *M
endB
Union[builtins.str,Any]
builtins.str"builtins.str
Any *S
periodsD
Union[builtins.int,None]
builtins.int"builtins.int
None * 
freqΩ
?Union[builtins.str,pandas._libs.tslibs.offsets.DateOffset,None]
builtins.str"builtins.strP
&pandas._libs.tslibs.offsets.DateOffset"&pandas._libs.tslibs.offsets.DateOffset
None *Ç
tzx
(Union[builtins.str,datetime.tzinfo,None]
builtins.str"builtins.str"
datetime.tzinfo"datetime.tzinfo
None */
	normalize
builtins.bool"builtins.bool *P
nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
closedD
Union[builtins.str,None]
builtins.str"builtins.str
None *
kwargs
Anyp
to_timedelta%pyspark.pandas.namespace.to_timedelta*
arg*

unit *
errors 0:typing.no_type_checká
timedelta_range(pyspark.pandas.namespace.timedelta_range"b
/pyspark.pandas.indexes.timedelta.TimedeltaIndex"/pyspark.pandas.indexes.timedelta.TimedeltaIndex*O
startB
Union[builtins.str,Any]
builtins.str"builtins.str
Any *M
endB
Union[builtins.str,Any]
builtins.str"builtins.str
Any *S
periodsD
Union[builtins.int,None]
builtins.int"builtins.int
None * 
freqΩ
?Union[builtins.str,pandas._libs.tslibs.offsets.DateOffset,None]
builtins.str"builtins.strP
&pandas._libs.tslibs.offsets.DateOffset"&pandas._libs.tslibs.offsets.DateOffset
None *P
nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
closedD
Union[builtins.str,None]
builtins.str"builtins.str
None è
get_dummies$pyspark.pandas.namespace.get_dummies"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*˜
dataÏ
LUnion[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series*€
prefixÃ
]Union[builtins.str,builtins.list[builtins.str],builtins.dict[builtins.str,builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.listu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict
None *.

prefix_sep
builtins.str"builtins.str *.
dummy_na
builtins.bool"builtins.bool *£
columnsì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *,
sparse
builtins.bool"builtins.bool *0

drop_first
builtins.bool"builtins.bool *À
dtypeΩ
bUnion[builtins.str,TypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]],None]
builtins.str"builtins.str¨
ITypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]æ
>Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype](
numpy.dtype[Any]
Any"numpy.dtypeP
&pandas.core.dtypes.base.ExtensionDtype"&pandas.core.dtypes.base.ExtensionDtype"pyspark.pandas._typing.Dtype
None …
concatpyspark.pandas.namespace.concat"Ï
LUnion[pyspark.pandas.series.Series[Any],pyspark.pandas.frame.DataFrame[Any]]J
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.SeriesN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*Ê
objs€
[builtins.list[Union[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]]Ï
LUnion[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series"builtins.list*ª
axisÆ
+TypeAlias[Union[builtins.int,builtins.str]]`
 Union[builtins.int,builtins.str]
builtins.int"builtins.int
builtins.str"builtins.str"pyspark.pandas._typing.Axis *(
join
builtins.str"builtins.str *2
ignore_index
builtins.bool"builtins.bool **
sort
builtins.bool"builtins.bool è

meltpyspark.pandas.namespace.melt"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*Y
frameN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*£
id_varsì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *¶

value_varsì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *Ω
var_name¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *.

value_name
builtins.str"builtins.str F
isnapyspark.pandas.namespace.isna*
obj0:typing.no_type_checkH
notnapyspark.pandas.namespace.notna*
obj0:typing.no_type_checkô
mergepyspark.pandas.namespace.merge"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*W
objN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*Y
rightN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*'
how
builtins.str"builtins.str *û
onì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *£
left_onì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *§
right_onì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *0

left_index
builtins.bool"builtins.bool *1
right_index
builtins.bool"builtins.bool *p
suffixes`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str ∏

merge_asof#pyspark.pandas.namespace.merge_asof"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*˜
leftÏ
LUnion[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series*¯
rightÏ
LUnion[pyspark.pandas.frame.DataFrame[Any],pyspark.pandas.series.Series[Any]]N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series*¬
on∑
.Union[Any,TypeAlias[builtins.tuple[Any]],None]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None *«
left_on∑
.Union[Any,TypeAlias[builtins.tuple[Any]],None]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None *»
right_on∑
.Union[Any,TypeAlias[builtins.tuple[Any]],None]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None *0

left_index
builtins.bool"builtins.bool *1
right_index
builtins.bool"builtins.bool *û
byì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *£
left_byì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *§
right_byì
WUnion[TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]],builtins.list[Unknown],None]Ä
4TypeAlias[Union[Any,TypeAlias[builtins.tuple[Any]]]]®
)Union[Any,TypeAlias[builtins.tuple[Any]]]
Anyp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"pyspark.pandas._typing.Name)
builtins.list[Unknown] "builtins.list
None *p
suffixes`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str *7
	tolerance&
Union[Any,None]
Any
None *9
allow_exact_matches
builtins.bool"builtins.bool *-
	direction
builtins.str"builtins.str `

to_numeric#pyspark.pandas.namespace.to_numeric*
arg*
errors 0:typing.no_type_checkÿ
	broadcast"pyspark.pandas.namespace.broadcast"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*W
objN
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrameê
read_orc!pyspark.pandas.namespace.read_orc"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*&
path
builtins.str"builtins.str*ë
columnsÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *
options
Any¯
_get_index_map'pyspark.pandas.namespace._get_index_map"Æ
uTuple[Union[builtins.list[pyspark.sql.column.Column],None],Union[builtins.list[TypeAlias[builtins.tuple[Any]]],None]]µ
4Union[builtins.list[pyspark.sql.column.Column],None]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None˙
9Union[builtins.list[TypeAlias[builtins.tuple[Any]]],None]∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list
None*K
sdfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 1
_testpyspark.pandas.namespace._test"
None*î
__annotations__(pyspark.pandas.namespace.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
npnumpy *
pdpandas **
papyspark.pandas.namespace.pa
Any**
pqpyspark.pandas.namespace.pq
Any*
Fpyspark.sql.functions *
pspyspark.pandas *w
__all__ pyspark.pandas.namespace.__all__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*2
isnullpyspark.pandas.namespace.isnull
Any*4
notnull pyspark.pandas.namespace.notnull
Any*∂
!_get_dummies_default_accept_types:pyspark.pandas.namespace._get_dummies_default_accept_types‘
ÜTuple[CallableType[builtins.type],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton]]?
CallableType[builtins.type]
builtins.type"builtins.typeÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingleton*î
_get_dummies_acceptable_types6pyspark.pandas.namespace._get_dummies_acceptable_types∫
»Tuple[CallableType[builtins.type],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton],CallableType[pyspark.sql.types.DataTypeSingleton]]?
CallableType[builtins.type]
builtins.type"builtins.typeÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingletonÅ
1CallableType[pyspark.sql.types.DataTypeSingleton]J
#pyspark.sql.types.DataTypeSingleton"#pyspark.sql.types.DataTypeSingleton