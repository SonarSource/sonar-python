
pyspark.sql.connect.streamingæ)
StreamingQuery2pyspark.sql.connect.streaming.query.StreamingQuery"builtins.object*Œ
__init__;pyspark.sql.connect.streaming.query.StreamingQuery.__init__"
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*a
sessionT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSession*)
queryId
builtins.str"builtins.str*'
runId
builtins.str"builtins.str*P
nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *€
id5pyspark.sql.connect.streaming.query.StreamingQuery.id"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery0:property`*·
runId8pyspark.sql.connect.streaming.query.StreamingQuery.runId"
builtins.str"builtins.str*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery0:property`*á
name7pyspark.sql.connect.streaming.query.StreamingQuery.name"D
Union[builtins.str,None]
builtins.str"builtins.str
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery0:property`*È
isActive;pyspark.sql.connect.streaming.query.StreamingQuery.isActive"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery0:property`*È
awaitTerminationCpyspark.sql.connect.streaming.query.StreamingQuery.awaitTermination"G
Union[builtins.bool,None]
builtins.bool"builtins.bool
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*S
timeoutD
Union[builtins.int,None]
builtins.int"builtins.int
None *û
status9pyspark.sql.connect.streaming.query.StreamingQuery.status"W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery0:property`*
recentProgressApyspark.sql.connect.streaming.query.StreamingQuery.recentProgress"ò
.builtins.list[builtins.dict[builtins.str,Any]]W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict"builtins.list*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery0:property`*Ê
lastProgress?pyspark.sql.connect.streaming.query.StreamingQuery.lastProgress"í
+Union[builtins.dict[builtins.str,Any],None]W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery0:property`*€
processAllAvailableFpyspark.sql.connect.streaming.query.StreamingQuery.processAllAvailable"
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*Ω
stop7pyspark.sql.connect.streaming.query.StreamingQuery.stop"
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*Û
explain:pyspark.sql.connect.streaming.query.StreamingQuery.explain"
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*.
extended
builtins.bool"builtins.bool *Ç
	exception<pyspark.sql.connect.streaming.query.StreamingQuery.exception"¬
BUnion[pyspark.errors.exceptions.base.StreamingQueryException,None]p
6pyspark.errors.exceptions.base.StreamingQueryException"6pyspark.errors.exceptions.base.StreamingQueryException
None*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*Í
_fetch_status@pyspark.sql.connect.streaming.query.StreamingQuery._fetch_status"¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*ˆ
_execute_streaming_query_cmdOpyspark.sql.connect.streaming.query.StreamingQuery._execute_streaming_query_cmd"à
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*r
selfh
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*Ö
cmd|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandrù
_session;pyspark.sql.connect.streaming.query.StreamingQuery._sessionT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSessionrg
	_query_id<pyspark.sql.connect.streaming.query.StreamingQuery._query_id
builtins.str"builtins.strrc
_run_id:pyspark.sql.connect.streaming.query.StreamingQuery._run_id
builtins.str"builtins.strrá
_name8pyspark.sql.connect.streaming.query.StreamingQuery._nameD
Union[builtins.str,None]
builtins.str"builtins.str
None…n
DataStreamReader9pyspark.sql.connect.streaming.readwriter.DataStreamReader"*pyspark.sql.connect.readwriter.OptionUtils*Ω
__init__Bpyspark.sql.connect.streaming.readwriter.DataStreamReader.__init__"
None*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*`
clientT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSession*Û
_df=pyspark.sql.connect.streaming.readwriter.DataStreamReader._df"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*V
planL
$pyspark.sql.connect.plan.LogicalPlan"$pyspark.sql.connect.plan.LogicalPlan*Ô
format@pyspark.sql.connect.streaming.readwriter.DataStreamReader.format"v
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*(
source
builtins.str"builtins.str*Â
schema@pyspark.sql.connect.streaming.readwriter.DataStreamReader.schema"v
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*ù
schemaê
0Union[pyspark.sql.types.StructType,builtins.str]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str*–
option@pyspark.sql.connect.streaming.readwriter.DataStreamReader.option"v
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*%
key
builtins.str"builtins.str*·
value’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType*≠
optionsApyspark.sql.connect.streaming.readwriter.DataStreamReader.options"v
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*„
options’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType*⁄
load>pyspark.sql.connect.streaming.readwriter.DataStreamReader.load"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *Æ
schemaü
5Union[pyspark.sql.types.StructType,builtins.str,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str
None *„
options’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType*µ
json>pyspark.sql.connect.streaming.readwriter.DataStreamReader.json"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*&
path
builtins.str"builtins.str*Æ
schemaü
5Union[pyspark.sql.types.StructType,builtins.str,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str
None *å
primitivesAsStringr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *à
prefersDecimalr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *á
allowCommentsr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ë
allowUnquotedFieldNamesr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ã
allowSingleQuotesr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ë
allowNumericLeadingZeror
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ú
"allowBackslashEscapingAnyCharacterr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *P
modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *e
columnNameOfCorruptRecordD
Union[builtins.str,None]
builtins.str"builtins.str
None *V

dateFormatD
Union[builtins.str,None]
builtins.str"builtins.str
None *[
timestampFormatD
Union[builtins.str,None]
builtins.str"builtins.str
None *É
	multiLiner
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ì
allowUnquotedControlCharsr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *S
lineSepD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
localeD
Union[builtins.str,None]
builtins.str"builtins.str
None *å
dropFieldIfAllNullr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *T
encodingD
Union[builtins.str,None]
builtins.str"builtins.str
None *à
pathGlobFilterr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ç
recursiveFileLookupr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ê
allowNonNumericNumbersr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *∫
orc=pyspark.sql.connect.streaming.readwriter.DataStreamReader.orc"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*&
path
builtins.str"builtins.str*Z
mergeSchemaG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *à
pathGlobFilterr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ç
recursiveFileLookupr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *›
parquetApyspark.sql.connect.streaming.readwriter.DataStreamReader.parquet"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*&
path
builtins.str"builtins.str*Z
mergeSchemaG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *à
pathGlobFilterr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ç
recursiveFileLookupr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *å
datetimeRebaseModer
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *â
int96RebaseModer
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *Ê
text>pyspark.sql.connect.streaming.readwriter.DataStreamReader.text"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*&
path
builtins.str"builtins.str*/
	wholetext
builtins.bool"builtins.bool *S
lineSepD
Union[builtins.str,None]
builtins.str"builtins.str
None *à
pathGlobFilterr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ç
recursiveFileLookupr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *‚
csv=pyspark.sql.connect.streaming.readwriter.DataStreamReader.csv"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*&
path
builtins.str"builtins.str*Æ
schemaü
5Union[pyspark.sql.types.StructType,builtins.str,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str
None *O
sepD
Union[builtins.str,None]
builtins.str"builtins.str
None *T
encodingD
Union[builtins.str,None]
builtins.str"builtins.str
None *Q
quoteD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
escapeD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
commentD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ä
headerr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *Ö
inferSchemar
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ë
ignoreLeadingWhiteSpacer
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *í
ignoreTrailingWhiteSpacer
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *U
	nullValueD
Union[builtins.str,None]
builtins.str"builtins.str
None *T
nanValueD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
positiveInfD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
negativeInfD
Union[builtins.str,None]
builtins.str"builtins.str
None *V

dateFormatD
Union[builtins.str,None]
builtins.str"builtins.str
None *[
timestampFormatD
Union[builtins.str,None]
builtins.str"builtins.str
None *Å

maxColumnso
%Union[builtins.int,builtins.str,None]
builtins.int"builtins.int
builtins.str"builtins.str
None *à
maxCharsPerColumno
%Union[builtins.int,builtins.str,None]
builtins.int"builtins.int
builtins.str"builtins.str
None *í
maxMalformedLogPerPartitiono
%Union[builtins.int,builtins.str,None]
builtins.int"builtins.int
builtins.str"builtins.str
None *P
modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *e
columnNameOfCorruptRecordD
Union[builtins.str,None]
builtins.str"builtins.str
None *É
	multiLiner
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ì
charToEscapeQuoteEscapingr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *á
enforceSchemar
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *V

emptyValueD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
localeD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
lineSepD
Union[builtins.str,None]
builtins.str"builtins.str
None *à
pathGlobFilterr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *ç
recursiveFileLookupr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *b
unescapedQuoteHandlingD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ã
table?pyspark.sql.connect.streaming.readwriter.DataStreamReader.table"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamReader"9pyspark.sql.connect.streaming.readwriter.DataStreamReader*+
	tableName
builtins.str"builtins.strrí
_formatApyspark.sql.connect.streaming.readwriter.DataStreamReader._formatD
Union[builtins.str,None]
builtins.str"builtins.str
Nonerj
_schemaApyspark.sql.connect.streaming.readwriter.DataStreamReader._schema
builtins.str"builtins.strr¢
_clientApyspark.sql.connect.streaming.readwriter.DataStreamReader._clientT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSessionr≈
_optionsBpyspark.sql.connect.streaming.readwriter.DataStreamReader._optionsu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict‹W
DataStreamWriter9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"builtins.object*ñ
__init__Bpyspark.sql.connect.streaming.readwriter.DataStreamWriter.__init__"
None*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*V
planL
$pyspark.sql.connect.plan.LogicalPlan"$pyspark.sql.connect.plan.LogicalPlan*a
sessionT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSession*˚

outputModeDpyspark.sql.connect.streaming.readwriter.DataStreamWriter.outputMode"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*,

outputMode
builtins.str"builtins.str*Ô
format@pyspark.sql.connect.streaming.readwriter.DataStreamWriter.format"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*(
source
builtins.str"builtins.str*–
option@pyspark.sql.connect.streaming.readwriter.DataStreamWriter.option"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*%
key
builtins.str"builtins.str*·
value’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType*≠
optionsApyspark.sql.connect.streaming.readwriter.DataStreamWriter.options"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*„
options’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType*¯
	queryNameCpyspark.sql.connect.streaming.readwriter.DataStreamWriter.queryName"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*+
	queryName
builtins.str"builtins.str*®
foreachBatchFpyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreachBatch"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*û

_start_internalIpyspark.sql.connect.streaming.readwriter.DataStreamWriter._start_internal"h
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *U
	tableNameD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *V

outputModeD
Union[builtins.str,None]
builtins.str"builtins.str
None *¿
partitionBy¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *U
	queryNameD
Union[builtins.str,None]
builtins.str"builtins.str
None *„
options’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType*≥	
start?pyspark.sql.connect.streaming.readwriter.DataStreamWriter.start"h
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *V

outputModeD
Union[builtins.str,None]
builtins.str"builtins.str
None *¿
partitionBy¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *U
	queryNameD
Union[builtins.str,None]
builtins.str"builtins.str
None *„
options’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType*í	
toTableApyspark.sql.connect.streaming.readwriter.DataStreamWriter.toTable"h
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*+
	tableName
builtins.str"builtins.str*R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *V

outputModeD
Union[builtins.str,None]
builtins.str"builtins.str
None *¿
partitionBy¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *U
	queryNameD
Union[builtins.str,None]
builtins.str"builtins.str
None *„
options’
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None"1pyspark.sql.connect._typing.OptionalPrimitiveType2ä
partitionByEpyspark.sql.connect.streaming.readwriter.DataStreamWriter.partitionByÖ
partitionByEpyspark.sql.connect.streaming.readwriter.DataStreamWriter.partitionBy"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*&
cols
builtins.str"builtins.str0:overloadX´
partitionByEpyspark.sql.connect.streaming.readwriter.DataStreamWriter.partitionBy"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*LJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:overloadX2Ë
triggerApyspark.sql.connect.streaming.readwriter.DataStreamWriter.triggerá
triggerApyspark.sql.connect.streaming.readwriter.DataStreamWriter.trigger"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*0
processingTime
builtins.str"builtins.str0:overloadXˇ
triggerApyspark.sql.connect.streaming.readwriter.DataStreamWriter.trigger"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*(
once
builtins.bool"builtins.bool0:overloadXÉ
triggerApyspark.sql.connect.streaming.readwriter.DataStreamWriter.trigger"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*,

continuous
builtins.str"builtins.str0:overloadXá
triggerApyspark.sql.connect.streaming.readwriter.DataStreamWriter.trigger"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*0
availableNow
builtins.bool"builtins.bool0:overloadX2£
foreachApyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreach©
foreachApyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreach"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function0:overloadX®
foreachApyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreach"v
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Ä
selfv
9pyspark.sql.connect.streaming.readwriter.DataStreamWriter"9pyspark.sql.connect.streaming.readwriter.DataStreamWriter*Q
fJ
#pyspark.sql._typing.SupportsProcess"#pyspark.sql._typing.SupportsProcess0:overloadXr§
_sessionBpyspark.sql.connect.streaming.readwriter.DataStreamWriter._sessionT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSessionr∏
_write_streamGpyspark.sql.connect.streaming.readwriter.DataStreamWriter._write_stream^
-pyspark.sql.connect.plan.WriteStreamOperation"-pyspark.sql.connect.plan.WriteStreamOperationr›
_write_protoFpyspark.sql.connect.streaming.readwriter.DataStreamWriter._write_protoÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartã
StreamingQueryManager9pyspark.sql.connect.streaming.query.StreamingQueryManager"builtins.object*æ
__init__Bpyspark.sql.connect.streaming.query.StreamingQueryManager.__init__"
None*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager*a
sessionT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSession*ö
active@pyspark.sql.connect.streaming.query.StreamingQueryManager.active"º
Abuiltins.list[pyspark.sql.connect.streaming.query.StreamingQuery]h
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery"builtins.list*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager0:property`*¶
get=pyspark.sql.connect.streaming.query.StreamingQueryManager.get"∂
>Union[pyspark.sql.connect.streaming.query.StreamingQuery,None]h
2pyspark.sql.connect.streaming.query.StreamingQuery"2pyspark.sql.connect.streaming.query.StreamingQuery
None*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager*$
id
builtins.str"builtins.str*Ö
awaitAnyTerminationMpyspark.sql.connect.streaming.query.StreamingQueryManager.awaitAnyTermination"G
Union[builtins.bool,None]
builtins.bool"builtins.bool
None*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager*S
timeoutD
Union[builtins.int,None]
builtins.int"builtins.int
None *È
resetTerminatedIpyspark.sql.connect.streaming.query.StreamingQueryManager.resetTerminated"
None*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager*ﬂ
addListenerEpyspark.sql.connect.streaming.query.StreamingQueryManager.addListener"
None*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager*|
listenern
5pyspark.sql.streaming.listener.StreamingQueryListener"5pyspark.sql.streaming.listener.StreamingQueryListener*Â
removeListenerHpyspark.sql.connect.streaming.query.StreamingQueryManager.removeListener"
None*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager*|
listenern
5pyspark.sql.streaming.listener.StreamingQueryListener"5pyspark.sql.streaming.listener.StreamingQueryListener*π
$_execute_streaming_query_manager_cmd^pyspark.sql.connect.streaming.query.StreamingQueryManager._execute_streaming_query_manager_cmd"ñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Ä
selfv
9pyspark.sql.connect.streaming.query.StreamingQueryManager"9pyspark.sql.connect.streaming.query.StreamingQueryManager*î
cmdä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandr§
_sessionBpyspark.sql.connect.streaming.query.StreamingQueryManager._sessionT
(pyspark.sql.connect.session.SparkSession"(pyspark.sql.connect.session.SparkSession*~
__path__&pyspark.sql.connect.streaming.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*ô
__annotations__-pyspark.sql.connect.streaming.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict