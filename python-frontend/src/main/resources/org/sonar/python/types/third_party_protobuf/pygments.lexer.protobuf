
pygments.lexer¬
	LexerMetapygments.lexer.LexerMeta"builtins.type*t
__new__ pygments.lexer.LexerMeta.__new__*
cls*
name*	
bases*
dz36z37z38z39z310z311z312z313*„
analyse_text%pygments.lexer.LexerMeta.analyse_text" 
builtins.float"builtins.float*>
self4
pygments.lexer.LexerMeta"pygments.lexer.LexerMeta*&
text
builtins.str"builtins.strz36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313rg
namepygments.lexer.LexerMeta.name
builtins.str"builtins.str*36*37*38*39*310*311*312*313rü
aliases pygments.lexer.LexerMeta.aliasesN
typing.Sequence[builtins.str]
builtins.str"builtins.str"typing.Sequence*36*37*38*39*310*311*312*313r£
	filenames"pygments.lexer.LexerMeta.filenamesN
typing.Sequence[builtins.str]
builtins.str"builtins.str"typing.Sequence*36*37*38*39*310*311*312*313rØ
alias_filenames(pygments.lexer.LexerMeta.alias_filenamesN
typing.Sequence[builtins.str]
builtins.str"builtins.str"typing.Sequence*36*37*38*39*310*311*312*313r£
	mimetypes"pygments.lexer.LexerMeta.mimetypesN
typing.Sequence[builtins.str]
builtins.str"builtins.str"typing.Sequence*36*37*38*39*310*311*312*313rs
priority!pygments.lexer.LexerMeta.priority 
builtins.float"builtins.float*36*37*38*39*310*311*312*313rç
urlpygments.lexer.LexerMeta.urlD
Union[builtins.str,None]
builtins.str"builtins.str
None*36*37*38*39*310*311*312*313á
Lexerpygments.lexer.Lexer"builtins.object*•
__init__pygments.lexer.Lexer.__init__"
None*6
self,
pygments.lexer.Lexer"pygments.lexer.Lexer*
options
Anyz36z37z38z39z310z311z312z313*ø

add_filterpygments.lexer.Lexer.add_filter"
None*6
self,
pygments.lexer.Lexer"pygments.lexer.Lexer*
filter_
Any*
options
Anyz36z37z38z39z310z311z312z313*¡

get_tokenspygments.lexer.Lexer.get_tokens"€
>typing.Iterator[Tuple[pygments.token._TokenType,builtins.str]]á
-Tuple[pygments.token._TokenType,builtins.str]6
pygments.token._TokenType"pygments.token._TokenType
builtins.str"builtins.str"typing.Iterator*6
self,
pygments.lexer.Lexer"pygments.lexer.Lexer*&
text
builtins.str"builtins.str*0

unfiltered
builtins.bool"builtins.bool z36z37z38z39z310z311z312z313*ﬂ
get_tokens_unprocessed+pygments.lexer.Lexer.get_tokens_unprocessed"ì
Ktyping.Iterator[Tuple[builtins.int,pygments.token._TokenType,builtins.str]]≤
:Tuple[builtins.int,pygments.token._TokenType,builtins.str]
builtins.int"builtins.int6
pygments.token._TokenType"pygments.token._TokenType
builtins.str"builtins.str"typing.Iterator*6
self,
pygments.lexer.Lexer"pygments.lexer.Lexer*&
text
builtins.str"builtins.strz36z37z38z39z310z311z312z313@bpygments.lexer.LexerMetaj36j37j38j39j310j311j312j313r~
optionspygments.lexer.Lexer.options1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313r~
stripnlpygments.lexer.Lexer.stripnl1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313rÄ
stripallpygments.lexer.Lexer.stripall1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313rÄ
ensurenlpygments.lexer.Lexer.ensurenl1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313r~
tabsizepygments.lexer.Lexer.tabsize1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313rÄ
encodingpygments.lexer.Lexer.encoding1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313r~
filterspygments.lexer.Lexer.filters1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313¥

DelegatingLexerpygments.lexer.DelegatingLexer"pygments.lexer.Lexer*ì
__init__'pygments.lexer.DelegatingLexer.__init__"
None*J
self@
pygments.lexer.DelegatingLexer"pygments.lexer.DelegatingLexer*
_root_lexer
Any*
_language_lexer
Any*
_needle
Any *
options
Anyz36z37z38z39z310z311z312z313*˝
get_tokens_unprocessed5pygments.lexer.DelegatingLexer.get_tokens_unprocessed"ì
Ktyping.Iterator[Tuple[builtins.int,pygments.token._TokenType,builtins.str]]≤
:Tuple[builtins.int,pygments.token._TokenType,builtins.str]
builtins.int"builtins.int6
pygments.token._TokenType"pygments.token._TokenType
builtins.str"builtins.str"typing.Iterator*J
self@
pygments.lexer.DelegatingLexer"pygments.lexer.DelegatingLexer*&
text
builtins.str"builtins.strz36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313ré

root_lexer)pygments.lexer.DelegatingLexer.root_lexer1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313rñ
language_lexer-pygments.lexer.DelegatingLexer.language_lexer1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313rÜ
needle%pygments.lexer.DelegatingLexer.needle1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313S
includepygments.lexer.include"builtins.strj36j37j38j39j310j311j312j313X
_inheritpygments.lexer._inherit"builtins.objectj36j37j38j39j310j311j312j313Ë
combinedpygments.lexer.combined"builtins.tuple*a
__new__pygments.lexer.combined.__new__*
cls*
argsz36z37z38z39z310z311z312z313*´
__init__ pygments.lexer.combined.__init__"
None*<
self2
pygments.lexer.combined"pygments.lexer.combined*
args
Anyz36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313Ä

_PseudoMatchpygments.lexer._PseudoMatch"builtins.object*À
__init__$pygments.lexer._PseudoMatch.__init__"
None*D
self:
pygments.lexer._PseudoMatch"pygments.lexer._PseudoMatch*
start
Any*
text
Anyz36z37z38z39z310z311z312z313*Ö
start!pygments.lexer._PseudoMatch.start"
Any*D
self:
pygments.lexer._PseudoMatch"pygments.lexer._PseudoMatch*f
arg[
Union[TypeAlias[Any],None]1
TypeAlias[Any]
Any"_typeshed.Incomplete
None z36z37z38z39z310z311z312z313*Å
endpygments.lexer._PseudoMatch.end"
Any*D
self:
pygments.lexer._PseudoMatch"pygments.lexer._PseudoMatch*f
arg[
Union[TypeAlias[Any],None]1
TypeAlias[Any]
Any"_typeshed.Incomplete
None z36z37z38z39z310z311z312z313*Ö
group!pygments.lexer._PseudoMatch.group"
Any*D
self:
pygments.lexer._PseudoMatch"pygments.lexer._PseudoMatch*f
arg[
Union[TypeAlias[Any],None]1
TypeAlias[Any]
Any"_typeshed.Incomplete
None z36z37z38z39z310z311z312z313*Z
groups"pygments.lexer._PseudoMatch.groups*
selfz36z37z38z39z310z311z312z313*`
	groupdict%pygments.lexer._PseudoMatch.groupdict*
selfz36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313R
_Thispygments.lexer._This"builtins.objectj36j37j38j39j310j311j312j313Ä
defaultpygments.lexer.default"builtins.object*©
__init__pygments.lexer.default.__init__"
None*:
self0
pygments.lexer.default"pygments.lexer.default*
state
Anyz36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313r|
statepygments.lexer.default.state1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313ú
wordspygments.lexer.words"pygments.util.Future*˚
__init__pygments.lexer.words.__init__"
None*6
self,
pygments.lexer.words"pygments.lexer.words*
words
Any**
prefix
builtins.str"builtins.str **
suffix
builtins.str"builtins.str z36z37z38z39z310z311z312z313*M
getpygments.lexer.words.get*
selfz36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313rz
wordspygments.lexer.words.words1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313r|
prefixpygments.lexer.words.prefix1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313r|
suffixpygments.lexer.words.suffix1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313â
RegexLexerMetapygments.lexer.RegexLexerMeta"pygments.lexer.LexerMeta*π
process_tokendef.pygments.lexer.RegexLexerMeta.process_tokendef"
Any*G
cls>
pygments.lexer.RegexLexerMeta"pygments.lexer.RegexLexerMeta*
name
Any*l
	tokendefs[
Union[TypeAlias[Any],None]1
TypeAlias[Any]
Any"_typeshed.Incomplete
None z36z37z38z39z310z311z312z313*i
get_tokendefs+pygments.lexer.RegexLexerMeta.get_tokendefs*
clsz36z37z38z39z310z311z312z313*s
__call__&pygments.lexer.RegexLexerMeta.__call__*
cls*
args*
kwdsz36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313€

RegexLexerpygments.lexer.RegexLexer"pygments.lexer.Lexer*À
get_tokens_unprocessed0pygments.lexer.RegexLexer.get_tokens_unprocessed"ì
Ktyping.Iterator[Tuple[builtins.int,pygments.token._TokenType,builtins.str]]≤
:Tuple[builtins.int,pygments.token._TokenType,builtins.str]
builtins.int"builtins.int6
pygments.token._TokenType"pygments.token._TokenType
builtins.str"builtins.str"typing.Iterator*@
self6
pygments.lexer.RegexLexer"pygments.lexer.RegexLexer*&
text
builtins.str"builtins.str*[
stackN
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable z36z37z38z39z310z311z312z313@bpygments.lexer.RegexLexerMetaj36j37j38j39j310j311j312j313rj
flagspygments.lexer.RegexLexer.flags
re.RegexFlag"re.RegexFlag*36*37*38*39*310*311*312*313rú
tokens pygments.lexer.RegexLexer.tokensÀ
9builtins.dict[builtins.str,builtins.list[TypeAlias[Any]]]
builtins.str"builtins.stra
builtins.list[TypeAlias[Any]]1
TypeAlias[Any]
Any"_typeshed.Incomplete"builtins.list"builtins.dict*36*37*38*39*310*311*312*313Å
LexerContextpygments.lexer.LexerContext"builtins.object*õ
__init__$pygments.lexer.LexerContext.__init__"
None*D
self:
pygments.lexer.LexerContext"pygments.lexer.LexerContext*
text
Any*
pos
Any*h
stack[
Union[TypeAlias[Any],None]1
TypeAlias[Any]
Any"_typeshed.Incomplete
None *f
end[
Union[TypeAlias[Any],None]1
TypeAlias[Any]
Any"_typeshed.Incomplete
None z36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313r
text pygments.lexer.LexerContext.text1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313r}
pospygments.lexer.LexerContext.pos1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313r}
endpygments.lexer.LexerContext.end1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313rÅ
stack!pygments.lexer.LexerContext.stack1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313¨
ExtendedRegexLexer!pygments.lexer.ExtendedRegexLexer"pygments.lexer.RegexLexer*≥
get_tokens_unprocessed8pygments.lexer.ExtendedRegexLexer.get_tokens_unprocessed"ì
Ktyping.Iterator[Tuple[builtins.int,pygments.token._TokenType,builtins.str]]≤
:Tuple[builtins.int,pygments.token._TokenType,builtins.str]
builtins.int"builtins.int6
pygments.token._TokenType"pygments.token._TokenType
builtins.str"builtins.str"typing.Iterator*P
selfF
!pygments.lexer.ExtendedRegexLexer"!pygments.lexer.ExtendedRegexLexer*P
textD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ä
contextq
'Union[pygments.lexer.LexerContext,None]:
pygments.lexer.LexerContext"pygments.lexer.LexerContext
None z36z37z38z39z310z311z312z313j36j37j38j39j310j311j312j313Ñ
ProfilingRegexLexerMeta&pygments.lexer.ProfilingRegexLexerMeta"pygments.lexer.RegexLexerMetaj36j37j38j39j310j311j312j313ã
ProfilingRegexLexer"pygments.lexer.ProfilingRegexLexer"pygments.lexer.RegexLexer*Ê
get_tokens_unprocessed9pygments.lexer.ProfilingRegexLexer.get_tokens_unprocessed"ì
Ktyping.Iterator[Tuple[builtins.int,pygments.token._TokenType,builtins.str]]≤
:Tuple[builtins.int,pygments.token._TokenType,builtins.str]
builtins.int"builtins.int6
pygments.token._TokenType"pygments.token._TokenType
builtins.str"builtins.str"typing.Iterator*R
selfH
"pygments.lexer.ProfilingRegexLexer""pygments.lexer.ProfilingRegexLexer*&
text
builtins.str"builtins.str*[
stackN
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable z36z37z38z39z310z311z312z313@b&pygments.lexer.ProfilingRegexLexerMetaj36j37j38j39j310j311j312j313Q
bygroupspygments.lexer.bygroups*
argsz36z37z38z39z310z311z312z313Y
usingpygments.lexer.using*

_other*

kwargsz36z37z38z39z310z311z312z313*Æ
__annotations__pygments.lexer.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*36*37*38*39*310*311*312*313*x
inheritpygments.lexer.inherit1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313*r
thispygments.lexer.this1
TypeAlias[Any]
Any"_typeshed.Incomplete*36*37*38*39*310*311*312*313