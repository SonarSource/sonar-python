
pyspark.pandas.internal™r
PySparkColumnpyspark.sql.column.Column"builtins.object*ã
__init__"pyspark.sql.column.Column.__init__"
None*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
jc
Any*∏
__eq__ pyspark.sql.column.Column.__eq__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*ôñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],_decimal.Decimal,TypeAlias[Union[datetime.datetime,datetime.date]]]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType$
_decimal.Decimal"_decimal.DecimalŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral*ß
__ne__ pyspark.sql.column.Column.__ne__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*Ö
__contains__&pyspark.sql.column.Column.__contains__"
None*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*∏
getItem!pyspark.sql.column.Column.getItem"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
key
Any*ª
getField"pyspark.sql.column.Column.getField"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
name
Any*ò
	withField#pyspark.sql.column.Column.withField"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*+
	fieldName
builtins.str"builtins.str*?
col6
pyspark.sql.column.Column"pyspark.sql.column.Column*⁄

dropFields$pyspark.sql.column.Column.dropFields"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*,

fieldNames
builtins.str"builtins.str*±
__getattr__%pyspark.sql.column.Column.__getattr__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*±
__getitem__%pyspark.sql.column.Column.__getitem__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*86
pyspark.sql.column.Column"pyspark.sql.column.Column*	
Any*r
__iter__"pyspark.sql.column.Column.__iter__"
None*86
pyspark.sql.column.Column"pyspark.sql.column.Column*…
likepyspark.sql.column.Column.like"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*À
rlikepyspark.sql.column.Column.rlike"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*À
ilikepyspark.sql.column.Column.ilike"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
other
builtins.str"builtins.str*≥
isinpyspark.sql.column.Column.isin"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
cols
Any*‡
aliaspyspark.sql.column.Column.alias"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*'
alias
builtins.str"builtins.str*
kwargs
Any*º
castpyspark.sql.column.Column.cast"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*ô
dataTypeä
.Union[pyspark.sql.types.DataType,builtins.str]8
pyspark.sql.types.DataType"pyspark.sql.types.DataType
builtins.str"builtins.str*˙
between!pyspark.sql.column.Column.between"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*ß

lowerBoundñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[datetime.datetime,datetime.date]],_decimal.Decimal]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral$
_decimal.Decimal"_decimal.Decimal*ß

upperBoundñ
∑Union[pyspark.sql.column.Column,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[datetime.datetime,datetime.date]],_decimal.Decimal]6
pyspark.sql.column.Column"pyspark.sql.column.Column®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeŒ
1TypeAlias[Union[datetime.datetime,datetime.date]]r
&Union[datetime.datetime,datetime.date]&
datetime.datetime"datetime.datetime
datetime.date"datetime.date"#pyspark.sql._typing.DateTimeLiteral$
_decimal.Decimal"_decimal.Decimal*˚
whenpyspark.sql.column.Column.when"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*E
	condition6
pyspark.sql.column.Column"pyspark.sql.column.Column*
value
Any*æ
	otherwise#pyspark.sql.column.Column.otherwise"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*
value
Any*Ï
overpyspark.sql.column.Column.over"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*J
window>
pyspark.sql.window.WindowSpec"pyspark.sql.window.WindowSpec*Ä
__nonzero__%pyspark.sql.column.Column.__nonzero__"
None*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*Ü
__repr__"pyspark.sql.column.Column.__repr__"
builtins.str"builtins.str*86
pyspark.sql.column.Column"pyspark.sql.column.Column2Ç
substr pyspark.sql.column.Column.substrè
substr pyspark.sql.column.Column.substr"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column**
startPos
builtins.int"builtins.int*(
length
builtins.int"builtins.int0:typing.overloadX√
substr pyspark.sql.column.Column.substr"6
pyspark.sql.column.Column"pyspark.sql.column.Column*@
self6
pyspark.sql.column.Column"pyspark.sql.column.Column*D
startPos6
pyspark.sql.column.Column"pyspark.sql.column.Column*B
length6
pyspark.sql.column.Column"pyspark.sql.column.Column0:typing.overloadXry
__neg__!pyspark.sql.column.Column.__neg__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__add__!pyspark.sql.column.Column.__add__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__sub__!pyspark.sql.column.Column.__sub__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__mul__!pyspark.sql.column.Column.__mul__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__div__!pyspark.sql.column.Column.__div__K
CallableType[builtins.function]&
builtins.function"builtins.functionrÅ
__truediv__%pyspark.sql.column.Column.__truediv__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__mod__!pyspark.sql.column.Column.__mod__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__radd__"pyspark.sql.column.Column.__radd__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rsub__"pyspark.sql.column.Column.__rsub__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rmul__"pyspark.sql.column.Column.__rmul__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rdiv__"pyspark.sql.column.Column.__rdiv__K
CallableType[builtins.function]&
builtins.function"builtins.functionrÉ
__rtruediv__&pyspark.sql.column.Column.__rtruediv__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rmod__"pyspark.sql.column.Column.__rmod__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__pow__!pyspark.sql.column.Column.__pow__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rpow__"pyspark.sql.column.Column.__rpow__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__lt__ pyspark.sql.column.Column.__lt__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__le__ pyspark.sql.column.Column.__le__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__ge__ pyspark.sql.column.Column.__ge__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__gt__ pyspark.sql.column.Column.__gt__K
CallableType[builtins.function]&
builtins.function"builtins.functionrZ
_eqNullSafe_doc)pyspark.sql.column.Column._eqNullSafe_doc
builtins.str"builtins.strr

eqNullSafe$pyspark.sql.column.Column.eqNullSafeK
CallableType[builtins.function]&
builtins.function"builtins.functionry
__and__!pyspark.sql.column.Column.__and__K
CallableType[builtins.function]&
builtins.function"builtins.functionrw
__or__ pyspark.sql.column.Column.__or__K
CallableType[builtins.function]&
builtins.function"builtins.functionr

__invert__$pyspark.sql.column.Column.__invert__K
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__rand__"pyspark.sql.column.Column.__rand__K
CallableType[builtins.function]&
builtins.function"builtins.functionry
__ror__!pyspark.sql.column.Column.__ror__K
CallableType[builtins.function]&
builtins.function"builtins.functionrX
_bitwiseOR_doc(pyspark.sql.column.Column._bitwiseOR_doc
builtins.str"builtins.strrZ
_bitwiseAND_doc)pyspark.sql.column.Column._bitwiseAND_doc
builtins.str"builtins.strrZ
_bitwiseXOR_doc)pyspark.sql.column.Column._bitwiseXOR_doc
builtins.str"builtins.strr}
	bitwiseOR#pyspark.sql.column.Column.bitwiseORK
CallableType[builtins.function]&
builtins.function"builtins.functionr

bitwiseAND$pyspark.sql.column.Column.bitwiseANDK
CallableType[builtins.function]&
builtins.function"builtins.functionr

bitwiseXOR$pyspark.sql.column.Column.bitwiseXORK
CallableType[builtins.function]&
builtins.function"builtins.functionrV
_contains_doc'pyspark.sql.column.Column._contains_doc
builtins.str"builtins.strrZ
_startswith_doc)pyspark.sql.column.Column._startswith_doc
builtins.str"builtins.strrV
_endswith_doc'pyspark.sql.column.Column._endswith_doc
builtins.str"builtins.strr{
contains"pyspark.sql.column.Column.containsK
CallableType[builtins.function]&
builtins.function"builtins.functionr

startswith$pyspark.sql.column.Column.startswithK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
endswith"pyspark.sql.column.Column.endswithK
CallableType[builtins.function]&
builtins.function"builtins.functionrL
_asc_doc"pyspark.sql.column.Column._asc_doc
builtins.str"builtins.strrd
_asc_nulls_first_doc.pyspark.sql.column.Column._asc_nulls_first_doc
builtins.str"builtins.strrb
_asc_nulls_last_doc-pyspark.sql.column.Column._asc_nulls_last_doc
builtins.str"builtins.strrN
	_desc_doc#pyspark.sql.column.Column._desc_doc
builtins.str"builtins.strrf
_desc_nulls_first_doc/pyspark.sql.column.Column._desc_nulls_first_doc
builtins.str"builtins.strrd
_desc_nulls_last_doc.pyspark.sql.column.Column._desc_nulls_last_doc
builtins.str"builtins.strrq
ascpyspark.sql.column.Column.ascK
CallableType[builtins.function]&
builtins.function"builtins.functionrâ
asc_nulls_first)pyspark.sql.column.Column.asc_nulls_firstK
CallableType[builtins.function]&
builtins.function"builtins.functionrá
asc_nulls_last(pyspark.sql.column.Column.asc_nulls_lastK
CallableType[builtins.function]&
builtins.function"builtins.functionrs
descpyspark.sql.column.Column.descK
CallableType[builtins.function]&
builtins.function"builtins.functionrã
desc_nulls_first*pyspark.sql.column.Column.desc_nulls_firstK
CallableType[builtins.function]&
builtins.function"builtins.functionrâ
desc_nulls_last)pyspark.sql.column.Column.desc_nulls_lastK
CallableType[builtins.function]&
builtins.function"builtins.functionrR
_isNull_doc%pyspark.sql.column.Column._isNull_doc
builtins.str"builtins.strrX
_isNotNull_doc(pyspark.sql.column.Column._isNotNull_doc
builtins.str"builtins.strrw
isNull pyspark.sql.column.Column.isNullK
CallableType[builtins.function]&
builtins.function"builtins.functionr}
	isNotNull#pyspark.sql.column.Column.isNotNullK
CallableType[builtins.function]&
builtins.function"builtins.functionrs
namepyspark.sql.column.Column.nameK
CallableType[builtins.function]&
builtins.function"builtins.functionrw
astype pyspark.sql.column.Column.astypeK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
__bool__"pyspark.sql.column.Column.__bool__K
CallableType[builtins.function]&
builtins.function"builtins.functionr-
_jcpyspark.sql.column.Column._jc
Any›ü
PySparkDataFramepyspark.sql.dataframe.DataFrame",pyspark.sql.pandas.map_ops.PandasMapOpsMixin"3pyspark.sql.pandas.conversion.PandasConversionMixin*Å
__init__(pyspark.sql.dataframe.DataFrame.__init__"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*
jdf
Any*‡
sql_ctx“
FUnion[pyspark.sql.context.SQLContext,pyspark.sql.session.SparkSession]@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContextD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*Ÿ
sql_ctx'pyspark.sql.dataframe.DataFrame.sql_ctx"@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContext*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Á
sparkSession,pyspark.sql.dataframe.DataFrame.sparkSession"D
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*˙
rdd#pyspark.sql.dataframe.DataFrame.rdd"i
&pyspark.rdd.RDD[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"pyspark.rdd.RDD*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Á
na"pyspark.sql.dataframe.DataFrame.na"X
*pyspark.sql.dataframe.DataFrameNaFunctions"*pyspark.sql.dataframe.DataFrameNaFunctions*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Ô
stat$pyspark.sql.dataframe.DataFrame.stat"\
,pyspark.sql.dataframe.DataFrameStatFunctions",pyspark.sql.dataframe.DataFrameStatFunctions*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Å
toJSON&pyspark.sql.dataframe.DataFrame.toJSON"N
pyspark.rdd.RDD[builtins.str]
builtins.str"builtins.str"pyspark.rdd.RDD*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*1
use_unicode
builtins.bool"builtins.bool *∆
registerTempTable1pyspark.sql.dataframe.DataFrame.registerTempTable"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*¿
createTempView.pyspark.sql.dataframe.DataFrame.createTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*“
createOrReplaceTempView7pyspark.sql.dataframe.DataFrame.createOrReplaceTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*Ã
createGlobalTempView4pyspark.sql.dataframe.DataFrame.createGlobalTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*ﬁ
createOrReplaceGlobalTempView=pyspark.sql.dataframe.DataFrame.createOrReplaceGlobalTempView"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*Â
write%pyspark.sql.dataframe.DataFrame.write"P
&pyspark.sql.readwriter.DataFrameWriter"&pyspark.sql.readwriter.DataFrameWriter*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*á
writeStream+pyspark.sql.dataframe.DataFrame.writeStream"f
1pyspark.sql.streaming.readwriter.DataStreamWriter"1pyspark.sql.streaming.readwriter.DataStreamWriter*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*”
schema&pyspark.sql.dataframe.DataFrame.schema"<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Â
printSchema+pyspark.sql.dataframe.DataFrame.printSchema"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Q
levelD
Union[builtins.int,None]
builtins.int"builtins.int
None *·
explain'pyspark.sql.dataframe.DataFrame.explain"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ç
extendedr
&Union[builtins.bool,builtins.str,None]
builtins.bool"builtins.bool
builtins.str"builtins.str
None *P
modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *ó
	exceptAll)pyspark.sql.dataframe.DataFrame.exceptAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*†
isLocal'pyspark.sql.dataframe.DataFrame.isLocal"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
isStreaming+pyspark.sql.dataframe.DataFrame.isStreaming"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*†
isEmpty'pyspark.sql.dataframe.DataFrame.isEmpty"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*–
show$pyspark.sql.dataframe.DataFrame.show"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
n
builtins.int"builtins.int *s
truncatec
!Union[builtins.bool,builtins.int]
builtins.bool"builtins.bool
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *Ù
_show_string,pyspark.sql.dataframe.DataFrame._show_string"
builtins.str"builtins.str*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
n
builtins.int"builtins.int *s
truncatec
!Union[builtins.bool,builtins.int]
builtins.bool"builtins.bool
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *ò
__repr__(pyspark.sql.dataframe.DataFrame.__repr__"
builtins.str"builtins.str*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Œ
_repr_html_+pyspark.sql.dataframe.DataFrame._repr_html_"D
Union[builtins.str,None]
builtins.str"builtins.str
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˜

checkpoint*pyspark.sql.dataframe.DataFrame.checkpoint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
eager
builtins.bool"builtins.bool *Å
localCheckpoint/pyspark.sql.dataframe.DataFrame.localCheckpoint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
eager
builtins.bool"builtins.bool *Ø
withWatermark-pyspark.sql.dataframe.DataFrame.withWatermark"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*+
	eventTime
builtins.str"builtins.str*0
delayThreshold
builtins.str"builtins.str*ø
hint$pyspark.sql.dataframe.DataFrame.hint"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
name
builtins.str"builtins.str*÷

parameters≈
fUnion[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]],builtins.list[Unknown]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType)
builtins.list[Unknown] "builtins.list*ö
count%pyspark.sql.dataframe.DataFrame.count"
builtins.int"builtins.int*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Á
collect'pyspark.sql.dataframe.DataFrame.collect"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*µ
toLocalIterator/pyspark.sql.dataframe.DataFrame.toLocalIterator"i
&typing.Iterator[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"typing.Iterator*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*8
prefetchPartitions
builtins.bool"builtins.bool *Á
limit%pyspark.sql.dataframe.DataFrame.limit"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*È
offset&pyspark.sql.dataframe.DataFrame.offset"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*à
take$pyspark.sql.dataframe.DataFrame.take"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*à
tail$pyspark.sql.dataframe.DataFrame.tail"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
num
builtins.int"builtins.int*ﬁ
foreach'pyspark.sql.dataframe.DataFrame.foreach"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*
foreachPartition0pyspark.sql.dataframe.DataFrame.foreachPartition"
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*R
fK
CallableType[builtins.function]&
builtins.function"builtins.function*¿
cache%pyspark.sql.dataframe.DataFrame.cache"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*†
persist'pyspark.sql.dataframe.DataFrame.persist"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Z
storageLevelF
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel *È
storageLevel,pyspark.sql.dataframe.DataFrame.storageLevel"F
!pyspark.storagelevel.StorageLevel"!pyspark.storagelevel.StorageLevel*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*¯
	unpersist)pyspark.sql.dataframe.DataFrame.unpersist"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*.
blocking
builtins.bool"builtins.bool *˜
coalesce(pyspark.sql.dataframe.DataFrame.coalesce"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*∆
distinct(pyspark.sql.dataframe.DataFrame.distinct"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˚
sampleBy(pyspark.sql.dataframe.DataFrame.sampleBy"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ú
colË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*l
	fractions]
!builtins.dict[Any,builtins.float]
Any 
builtins.float"builtins.float"builtins.dict*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *ø
randomSplit+pyspark.sql.dataframe.DataFrame.randomSplit"É
.builtins.list[pyspark.sql.dataframe.DataFrame]B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*]
weightsP
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *∫
dtypes&pyspark.sql.dataframe.DataFrame.dtypes"¢
/builtins.list[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*„
columns'pyspark.sql.dataframe.DataFrame.columns"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:builtins.property`*Â
colRegex(pyspark.sql.dataframe.DataFrame.colRegex"6
pyspark.sql.column.Column"pyspark.sql.column.Column*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*)
colName
builtins.str"builtins.str*Ñ
to"pyspark.sql.dataframe.DataFrame.to"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
schema<
pyspark.sql.types.StructType"pyspark.sql.types.StructType*È
alias%pyspark.sql.dataframe.DataFrame.alias"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
alias
builtins.str"builtins.str*ó
	crossJoin)pyspark.sql.dataframe.DataFrame.crossJoin"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ü
join$pyspark.sql.dataframe.DataFrame.join"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*•
onö
wUnion[builtins.str,builtins.list[builtins.str],pyspark.sql.column.Column,builtins.list[pyspark.sql.column.Column],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list6
pyspark.sql.column.Column"pyspark.sql.column.Columnq
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None *O
howD
Union[builtins.str,None]
builtins.str"builtins.str
None *µ

	_joinAsOf)pyspark.sql.dataframe.DataFrame._joinAsOf"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ú
leftAsOfColumná
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column*ù
rightAsOfColumná
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column*•
onö
wUnion[builtins.str,builtins.list[builtins.str],pyspark.sql.column.Column,builtins.list[pyspark.sql.column.Column],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list6
pyspark.sql.column.Column"pyspark.sql.column.Columnq
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None *O
howD
Union[builtins.str,None]
builtins.str"builtins.str
None *|
	tolerancek
%Union[pyspark.sql.column.Column,None]6
pyspark.sql.column.Column"pyspark.sql.column.Column
None *7
allowExactMatches
builtins.bool"builtins.bool *-
	direction
builtins.str"builtins.str *ü
sortWithinPartitions4pyspark.sql.dataframe.DataFrame.sortWithinPartitions"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*©
colsû
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*
kwargs
Any*ˇ
sort$pyspark.sql.dataframe.DataFrame.sort"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*©
colsû
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*
kwargs
Any*‹
_jseq%pyspark.sql.dataframe.DataFrame._jseq"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*:
cols0
typing.Sequence[Any]
Any"typing.Sequence*ò
	converterÜ
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None *»
_jmap%pyspark.sql.dataframe.DataFrame._jmap"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*A
jm9
builtins.dict[Any,Any]
Any
Any"builtins.dict*˝
_jcols&pyspark.sql.dataframe.DataFrame._jcols"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*±

_sort_cols*pyspark.sql.dataframe.DataFrame._sort_cols"
Any*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*∫
colsØ
{typing.Sequence[Union[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]]û
jUnion[builtins.str,pyspark.sql.column.Column,builtins.list[Union[builtins.str,pyspark.sql.column.Column]]]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column◊
<builtins.list[Union[builtins.str,pyspark.sql.column.Column]]á
-Union[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list"typing.Sequence*c
kwargsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*Ò
describe(pyspark.sql.dataframe.DataFrame.describe"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*®
colsù
/Union[builtins.str,builtins.list[builtins.str]]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*Ú
summary'pyspark.sql.dataframe.DataFrame.summary"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*,

statistics
builtins.str"builtins.str*›
first%pyspark.sql.dataframe.DataFrame.first"_
!Union[pyspark.sql.types.Row,None].
pyspark.sql.types.Row"pyspark.sql.types.Row
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ÿ
__getattr__+pyspark.sql.dataframe.DataFrame.__getattr__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*
builtins.str"builtins.str*Ã
__dir__'pyspark.sql.dataframe.DataFrame.__dir__"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ω
filter&pyspark.sql.dataframe.DataFrame.filter"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*¯
	conditionË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName*√	
unpivot'pyspark.sql.dataframe.DataFrame.unpivot"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
idsµ
nUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown]]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple*—
valuesƒ
sUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown],None]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple
None*4
variableColumnName
builtins.str"builtins.str*1
valueColumnName
builtins.str"builtins.str*Ω	
melt$pyspark.sql.dataframe.DataFrame.melt"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ø
idsµ
nUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown]]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple*—
valuesƒ
sUnion[TypeAlias[Union[pyspark.sql.column.Column,builtins.str]],builtins.list[Unknown],builtins.tuple[Unknown],None]Ë
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName)
builtins.list[Unknown] "builtins.list+
builtins.tuple[Unknown] "builtins.tuple
None*4
variableColumnName
builtins.str"builtins.str*1
valueColumnName
builtins.str"builtins.str*«
agg#pyspark.sql.dataframe.DataFrame.agg"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*à
exprs¸
IUnion[pyspark.sql.column.Column,builtins.dict[builtins.str,builtins.str]]6
pyspark.sql.column.Column"pyspark.sql.column.Columnu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict*¡
observe'pyspark.sql.dataframe.DataFrame.observe"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*∑
observation•
7Union[pyspark.sql.observation.Observation,builtins.str]J
#pyspark.sql.observation.Observation"#pyspark.sql.observation.Observation
builtins.str"builtins.str*A
exprs6
pyspark.sql.column.Column"pyspark.sql.column.Column*è
union%pyspark.sql.dataframe.DataFrame.union"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ï
unionAll(pyspark.sql.dataframe.DataFrame.unionAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*÷
unionByName+pyspark.sql.dataframe.DataFrame.unionByName"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*9
allowMissingColumns
builtins.bool"builtins.bool *ó
	intersect)pyspark.sql.dataframe.DataFrame.intersect"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ù
intersectAll,pyspark.sql.dataframe.DataFrame.intersectAll"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ï
subtract(pyspark.sql.dataframe.DataFrame.subtract"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Â
dropDuplicates.pyspark.sql.dataframe.DataFrame.dropDuplicates"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *É
dropDuplicatesWithinWatermark=pyspark.sql.dataframe.DataFrame.dropDuplicatesWithinWatermark"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *Ë
dropna&pyspark.sql.dataframe.DataFrame.dropna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
how
builtins.str"builtins.str *R
threshD
Union[builtins.int,None]
builtins.int"builtins.int
None *¶
subsetó
QUnion[builtins.str,builtins.tuple[builtins.str],builtins.list[builtins.str],None]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tupleJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *¿
corr$pyspark.sql.dataframe.DataFrame.corr" 
builtins.float"builtins.float*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*R
methodD
Union[builtins.str,None]
builtins.str"builtins.str
None *Í
cov#pyspark.sql.dataframe.DataFrame.cov" 
builtins.float"builtins.float*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*ñ
crosstab(pyspark.sql.dataframe.DataFrame.crosstab"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
col1
builtins.str"builtins.str*&
col2
builtins.str"builtins.str*Ó
	freqItems)pyspark.sql.dataframe.DataFrame.freqItems"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*»
colsΩ
6Union[builtins.list[builtins.str],Tuple[builtins.str]]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list5
Tuple[builtins.str]
builtins.str"builtins.str*Y
supportJ
Union[builtins.float,None] 
builtins.float"builtins.float
None *
_ipython_key_completions_9pyspark.sql.dataframe.DataFrame._ipython_key_completions_"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˘
withColumns+pyspark.sql.dataframe.DataFrame.withColumns"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*™
colsMapú
5builtins.dict[builtins.str,pyspark.sql.column.Column]
builtins.str"builtins.str6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.dict*∂

withColumn*pyspark.sql.dataframe.DataFrame.withColumn"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*)
colName
builtins.str"builtins.str*?
col6
pyspark.sql.column.Column"pyspark.sql.column.Column*´
withColumnRenamed1pyspark.sql.dataframe.DataFrame.withColumnRenamed"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame**
existing
builtins.str"builtins.str*%
new
builtins.str"builtins.str*ﬂ
withColumnsRenamed2pyspark.sql.dataframe.DataFrame.withColumnsRenamed"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ç
colsMapu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict*„
withMetadata,pyspark.sql.dataframe.DataFrame.withMetadata"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*,

columnName
builtins.str"builtins.str*e
metadataW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*Ê
toDF$pyspark.sql.dataframe.DataFrame.toDF"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
cols
builtins.str"builtins.str*«
	transform)pyspark.sql.dataframe.DataFrame.transform"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*U
funcK
CallableType[builtins.function]&
builtins.function"builtins.function*
args
Any*
kwargs
Any*˚
sameSemantics-pyspark.sql.dataframe.DataFrame.sameSemantics"
builtins.bool"builtins.bool*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*M
otherB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*®
semanticHash,pyspark.sql.dataframe.DataFrame.semanticHash"
builtins.int"builtins.int*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*“

inputFiles*pyspark.sql.dataframe.DataFrame.inputFiles"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ˇ
writeTo'pyspark.sql.dataframe.DataFrame.writeTo"T
(pyspark.sql.readwriter.DataFrameWriterV2"(pyspark.sql.readwriter.DataFrameWriterV2*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*'
table
builtins.str"builtins.str*ß
to_pandas_on_spark2pyspark.sql.dataframe.DataFrame.to_pandas_on_spark"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *ó

pandas_api*pyspark.sql.dataframe.DataFrame.pandas_api"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *ï
	to_koalas)pyspark.sql.dataframe.DataFrame.to_koalas"N
#pyspark.pandas.frame.DataFrame[Any]
Any"pyspark.pandas.frame.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*æ
	index_col¨
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 2ü
repartition+pyspark.sql.dataframe.DataFrame.repartitionà
repartition+pyspark.sql.dataframe.DataFrame.repartition"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX◊
repartition+pyspark.sql.dataframe.DataFrame.repartition"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX2…
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRangeñ
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRange"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*/
numPartitions
builtins.int"builtins.int*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÂ
repartitionByRange2pyspark.sql.dataframe.DataFrame.repartitionByRange"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX2∆
sample&pyspark.sql.dataframe.DataFrame.sampleŸ
sample&pyspark.sql.dataframe.DataFrame.sample"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*.
fraction 
builtins.float"builtins.float*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None 0:typing.overloadX∑
sample&pyspark.sql.dataframe.DataFrame.sample"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*\
withReplacementG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None*.
fraction 
builtins.float"builtins.float*P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None 0:typing.overloadX2Ω
head$pyspark.sql.dataframe.DataFrame.head
head$pyspark.sql.dataframe.DataFrame.head"_
!Union[pyspark.sql.types.Row,None].
pyspark.sql.types.Row"pyspark.sql.types.Row
None*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame0:typing.overloadXõ
head$pyspark.sql.dataframe.DataFrame.head"e
$builtins.list[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*#
n
builtins.int"builtins.int0:typing.overloadX2±
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__±
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__"6
pyspark.sql.column.Column"pyspark.sql.column.Column*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*b`
 Union[builtins.int,builtins.str]
builtins.int"builtins.int
builtins.str"builtins.str0:typing.overloadX¿
__getitem__+pyspark.sql.dataframe.DataFrame.__getitem__"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*DB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*‰·
GUnion[pyspark.sql.column.Column,builtins.list[Any],builtins.tuple[Any]]6
pyspark.sql.column.Column"pyspark.sql.column.Column,
builtins.list[Any]
Any"builtins.list.
builtins.tuple[Any]
Any"builtins.tuple0:typing.overloadX2Ó
select&pyspark.sql.dataframe.DataFrame.selectÕ
select&pyspark.sql.dataframe.DataFrame.select"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÎ
select&pyspark.sql.dataframe.DataFrame.select"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2˙

selectExpr*pyspark.sql.dataframe.DataFrame.selectExprá

selectExpr*pyspark.sql.dataframe.DataFrame.selectExpr"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
expr
builtins.str"builtins.str0:typing.overloadXµ

selectExpr*pyspark.sql.dataframe.DataFrame.selectExpr"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*T
exprJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2Ï
groupBy'pyspark.sql.dataframe.DataFrame.groupByÀ
groupBy'pyspark.sql.dataframe.DataFrame.groupBy">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÈ
groupBy'pyspark.sql.dataframe.DataFrame.groupBy">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2Ê
rollup&pyspark.sql.dataframe.DataFrame.rollup…
rollup&pyspark.sql.dataframe.DataFrame.rollup">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadXÁ
rollup&pyspark.sql.dataframe.DataFrame.rollup">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2⁄
cube$pyspark.sql.dataframe.DataFrame.cube≈
cube$pyspark.sql.dataframe.DataFrame.cube">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX„
cube$pyspark.sql.dataframe.DataFrame.cube">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*ëé
KUnion[builtins.list[pyspark.sql.column.Column],builtins.list[builtins.str]]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list0:typing.overloadX2ú
fillna&pyspark.sql.dataframe.DataFrame.fillna∑
fillna&pyspark.sql.dataframe.DataFrame.fillna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*¥
value®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType*¶
subsetó
QUnion[builtins.str,builtins.tuple[builtins.str],builtins.list[builtins.str],None]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tupleJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadXØ
fillna&pyspark.sql.dataframe.DataFrame.fillna"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*’
value…
obuiltins.dict[builtins.str,TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]
builtins.str"builtins.str®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.dict0:typing.overloadX2„(
replace'pyspark.sql.dataframe.DataFrame.replaceÑ	
replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*π

to_replace®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType*Ÿ
valueÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadXÍ

replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ø

to_replaceû
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.list*…
valueΩ
\builtins.list[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]]Õ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType"builtins.list*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadXΩ

replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Œ

to_replaceΩ
∞builtins.dict[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]],TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralTypeÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType"builtins.dict*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadX˙	
replace'pyspark.sql.dataframe.DataFrame.replace"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Ø

to_replaceû
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.list*Ÿ
valueÕ
MTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str,None]]Œ
BUnion[builtins.bool,builtins.float,builtins.int,builtins.str,None]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str
None")pyspark.sql._typing.OptionalPrimitiveType*ê
subsetÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:typing.overloadX2ì
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantileµ
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantile"P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*%
col
builtins.str"builtins.str*·
probabilitiesÕ
:Union[builtins.list[builtins.float],Tuple[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list;
Tuple[builtins.float] 
builtins.float"builtins.float*3
relativeError 
builtins.float"builtins.float0:typing.overloadXò
approxQuantile.pyspark.sql.dataframe.DataFrame.approxQuantile"è
,builtins.list[builtins.list[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list"builtins.list*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*«
colΩ
6Union[builtins.list[builtins.str],Tuple[builtins.str]]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list5
Tuple[builtins.str]
builtins.str"builtins.str*·
probabilitiesÕ
:Union[builtins.list[builtins.float],Tuple[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list;
Tuple[builtins.float] 
builtins.float"builtins.float*3
relativeError 
builtins.float"builtins.float0:typing.overloadX2ˆ
drop$pyspark.sql.dataframe.DataFrame.drop…
drop$pyspark.sql.dataframe.DataFrame.drop"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*Û
colsË
8TypeAlias[Union[pyspark.sql.column.Column,builtins.str]]á
-Union[pyspark.sql.column.Column,builtins.str]6
pyspark.sql.column.Column"pyspark.sql.column.Column
builtins.str"builtins.str" pyspark.sql._typing.ColumnOrName0:typing.overloadX˚
drop$pyspark.sql.dataframe.DataFrame.drop"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*L
selfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*&
cols
builtins.str"builtins.str0:typing.overloadXr
orderBy'pyspark.sql.dataframe.DataFrame.orderByK
CallableType[builtins.function]&
builtins.function"builtins.functionr{
where%pyspark.sql.dataframe.DataFrame.whereK
CallableType[builtins.function]&
builtins.function"builtins.functionrí
groupby'pyspark.sql.dataframe.DataFrame.groupby^
CallableType[builtins.function]&
builtins.function"builtins.function"builtins.functionrè
drop_duplicates/pyspark.sql.dataframe.DataFrame.drop_duplicatesK
CallableType[builtins.function]&
builtins.function"builtins.functionr∞
_sql_ctx(pyspark.sql.dataframe.DataFrame._sql_ctxz
*Union[pyspark.sql.context.SQLContext,None]@
pyspark.sql.context.SQLContext"pyspark.sql.context.SQLContext
Nonerz
_session(pyspark.sql.dataframe.DataFrame._sessionD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionrh
_sc#pyspark.sql.dataframe.DataFrame._sc<
pyspark.context.SparkContext"pyspark.context.SparkContextr5
_jdf$pyspark.sql.dataframe.DataFrame._jdf
AnyrV
	is_cached)pyspark.sql.dataframe.DataFrame.is_cached
builtins.bool"builtins.boolr®
_schema'pyspark.sql.dataframe.DataFrame._schemat
(Union[pyspark.sql.types.StructType,None]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
Noner‰
	_lazy_rdd)pyspark.sql.dataframe.DataFrame._lazy_rdd´
2Union[pyspark.rdd.RDD[pyspark.sql.types.Row],None]i
&pyspark.rdd.RDD[pyspark.sql.types.Row].
pyspark.sql.types.Row"pyspark.sql.types.Row"pyspark.rdd.RDD
Nonerh
_support_repr_html2pyspark.sql.dataframe.DataFrame._support_repr_html
builtins.bool"builtins.boolÂ+
InternalField%pyspark.pandas.internal.InternalField"builtins.object*Á
__init__.pyspark.pandas.internal.InternalField.__init__"
None*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*∏
dtype¨
ITypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]æ
>Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype](
numpy.dtype[Any]
Any"numpy.dtypeP
&pandas.core.dtypes.base.ExtensionDtype"&pandas.core.dtypes.base.ExtensionDtype"pyspark.pandas._typing.Dtype*ã
struct_fieldw
)Union[pyspark.sql.types.StructField,None]>
pyspark.sql.types.StructField"pyspark.sql.types.StructField
None *≈
from_struct_field7pyspark.pandas.internal.InternalField.from_struct_field"N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*P
struct_field>
pyspark.sql.types.StructField"pyspark.sql.types.StructField*:
use_extension_dtypes
builtins.bool"builtins.bool 0:builtins.staticmethodh*‘
dtype+pyspark.pandas.internal.InternalField.dtype"¨
ITypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]æ
>Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype](
numpy.dtype[Any]
Any"numpy.dtypeP
&pandas.core.dtypes.base.ExtensionDtype"&pandas.core.dtypes.base.ExtensionDtype"pyspark.pandas._typing.Dtype*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField0:builtins.property`*¨
struct_field2pyspark.pandas.internal.InternalField.struct_field"w
)Union[pyspark.sql.types.StructField,None]>
pyspark.sql.types.StructField"pyspark.sql.types.StructField
None*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField0:builtins.property`*¡
name*pyspark.pandas.internal.InternalField.name"
builtins.str"builtins.str*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField0:builtins.property`*È

spark_type0pyspark.pandas.internal.InternalField.spark_type"8
pyspark.sql.types.DataType"pyspark.sql.types.DataType*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField0:builtins.property`*À
nullable.pyspark.pandas.internal.InternalField.nullable"
builtins.bool"builtins.bool*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField0:builtins.property`*Ñ
metadata.pyspark.pandas.internal.InternalField.metadata"W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField0:builtins.property`*ﬂ
is_extension_dtype8pyspark.pandas.internal.InternalField.is_extension_dtype"
builtins.bool"builtins.bool*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField0:builtins.property`*¸
normalize_spark_type:pyspark.pandas.internal.InternalField.normalize_spark_type"N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*Ú
copy*pyspark.pandas.internal.InternalField.copy"N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*X
selfN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*†
nameì
1Union[builtins.str,pyspark._globals._NoValueType]
builtins.str"builtins.str>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *Ô
dtype·
nUnion[TypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]],pyspark._globals._NoValueType]¨
ITypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]æ
>Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype](
numpy.dtype[Any]
Any"numpy.dtypeP
&pandas.core.dtypes.base.ExtensionDtype"&pandas.core.dtypes.base.ExtensionDtype"pyspark.pandas._typing.Dtype>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *–

spark_typeΩ
?Union[pyspark.sql.types.DataType,pyspark._globals._NoValueType]8
pyspark.sql.types.DataType"pyspark.sql.types.DataType>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *ß
nullableñ
2Union[builtins.bool,pyspark._globals._NoValueType]
builtins.bool"builtins.bool>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *Å
metadata
IUnion[builtins.dict[builtins.str,Any],None,pyspark._globals._NoValueType]W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *≥
__eq__,pyspark.pandas.internal.InternalField.__eq__"
builtins.bool"builtins.bool*PN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*	
Any*™
__repr__.pyspark.pandas.internal.InternalField.__repr__"
builtins.str"builtins.str*PN
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalFieldrÂ
_dtype,pyspark.pandas.internal.InternalField._dtype¨
ITypeAlias[Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype]]æ
>Union[numpy.dtype[Any],pandas.core.dtypes.base.ExtensionDtype](
numpy.dtype[Any]
Any"numpy.dtypeP
&pandas.core.dtypes.base.ExtensionDtype"&pandas.core.dtypes.base.ExtensionDtype"pyspark.pandas._typing.DtyperΩ
_struct_field3pyspark.pandas.internal.InternalField._struct_fieldw
)Union[pyspark.sql.types.StructField,None]>
pyspark.sql.types.StructField"pyspark.sql.types.StructField
Noneê∞
InternalFrame%pyspark.pandas.internal.InternalFrame"builtins.object*ı
__init__.pyspark.pandas.internal.InternalFrame.__init__"
None*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*S
spark_frameB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*œ
index_spark_columnsµ
4Union[builtins.list[pyspark.sql.column.Column],None]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None*·
index_namesÕ
EUnion[builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]],None]˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list
None *˚
index_fieldsÊ
@Union[builtins.list[pyspark.pandas.internal.InternalField],None]ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list
None *ê
column_labels˙
9Union[builtins.list[TypeAlias[builtins.tuple[Any]]],None]∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list
None *–
data_spark_columnsµ
4Union[builtins.list[pyspark.sql.column.Column],None]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None *˙
data_fieldsÊ
@Union[builtins.list[pyspark.pandas.internal.InternalField],None]ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list
None *Ë
column_label_namesÕ
EUnion[builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]],None]˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list
None *ﬁ
attach_default_index:pyspark.pandas.internal.InternalFrame.attach_default_index"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*K
sdfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*^
default_index_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None 0:builtins.staticmethodh*±
attach_sequence_column<pyspark.pandas.internal.InternalFrame.attach_sequence_column"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*K
sdfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*-
column_name
builtins.str"builtins.str0:builtins.staticmethodh*∑
attach_distributed_column?pyspark.pandas.internal.InternalFrame.attach_distributed_column"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*K
sdfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*-
column_name
builtins.str"builtins.str0:builtins.staticmethodh*…
"attach_distributed_sequence_columnHpyspark.pandas.internal.InternalFrame.attach_distributed_sequence_column"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*K
sdfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*-
column_name
builtins.str"builtins.str0:builtins.staticmethodh*Ÿ
spark_column_for6pyspark.pandas.internal.InternalFrame.spark_column_for"6
pyspark.sql.column.Column"pyspark.sql.column.Column*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*{
labelp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label*–
spark_column_name_for;pyspark.pandas.internal.InternalFrame.spark_column_name_for"
builtins.str"builtins.str*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*Å
label_or_scolÌ
?Union[TypeAlias[builtins.tuple[Any]],pyspark.sql.column.Column]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label6
pyspark.sql.column.Column"pyspark.sql.column.Column*ﬁ
spark_type_for4pyspark.pandas.internal.InternalFrame.spark_type_for"8
pyspark.sql.types.DataType"pyspark.sql.types.DataType*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*Å
label_or_scolÌ
?Union[TypeAlias[builtins.tuple[Any]],pyspark.sql.column.Column]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label6
pyspark.sql.column.Column"pyspark.sql.column.Column*⁄
spark_column_nullable_for?pyspark.pandas.internal.InternalFrame.spark_column_nullable_for"
builtins.bool"builtins.bool*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*Å
label_or_scolÌ
?Union[TypeAlias[builtins.tuple[Any]],pyspark.sql.column.Column]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label6
pyspark.sql.column.Column"pyspark.sql.column.Column*„
	field_for/pyspark.pandas.internal.InternalFrame.field_for"N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*{
labelp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label*ı
spark_frame1pyspark.pandas.internal.InternalFrame.spark_frame"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*§
data_spark_column_names=pyspark.pandas.internal.InternalFrame.data_spark_column_names"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*≤
data_spark_columns8pyspark.pandas.internal.InternalFrame.data_spark_columns"q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*ó
index_spark_column_names>pyspark.pandas.internal.InternalFrame.index_spark_column_names"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*¥
index_spark_columns9pyspark.pandas.internal.InternalFrame.index_spark_columns"q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*ö
spark_column_names8pyspark.pandas.internal.InternalFrame.spark_column_names"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*∑
spark_columns3pyspark.pandas.internal.InternalFrame.spark_columns"q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*´
index_names1pyspark.pandas.internal.InternalFrame.index_names"˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*ﬁ
index_level1pyspark.pandas.internal.InternalFrame.index_level"
builtins.int"builtins.int*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*Ë
column_labels3pyspark.pandas.internal.InternalFrame.column_labels"∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*Ó
column_labels_level9pyspark.pandas.internal.InternalFrame.column_labels_level"
builtins.int"builtins.int*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*π
column_label_names8pyspark.pandas.internal.InternalFrame.column_label_names"˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*À
index_fields2pyspark.pandas.internal.InternalFrame.index_fields"ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*…
data_fields1pyspark.pandas.internal.InternalFrame.data_fields"ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:builtins.property`*ú
to_internal_spark_frame=pyspark.pandas.internal.InternalFrame.to_internal_spark_frame"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*Ñ
to_pandas_frame5pyspark.pandas.internal.InternalFrame.to_pandas_frame":
pandas.core.frame.DataFrame"pandas.core.frame.DataFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*õ
arguments_for_restore_indexApyspark.pandas.internal.InternalFrame.arguments_for_restore_index"9
builtins.dict[Any,Any]
Any
Any"builtins.dict*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*ú	
restore_index3pyspark.pandas.internal.InternalFrame.restore_index":
pandas.core.frame.DataFrame"pandas.core.frame.DataFrame*C
pdf:
pandas.core.frame.DataFrame"pandas.core.frame.DataFrame*]
index_columnsJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*¬
index_names∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list*\
data_columnsJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*ƒ
column_labels∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list*…
column_label_names∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list*§
fieldsï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list 0:builtins.staticmethodh*î
resolved_copy3pyspark.pandas.internal.InternalFrame.resolved_copy"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame0:"pyspark.pandas.utils.lazy_property*’
with_new_sdf2pyspark.pandas.internal.InternalFrame.with_new_sdf"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*S
spark_frameB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*˚
index_fieldsÊ
@Union[builtins.list[pyspark.pandas.internal.InternalField],None]ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list
None *ñ
data_columnsÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *˙
data_fieldsÊ
@Union[builtins.list[pyspark.pandas.internal.InternalField],None]ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list
None *À
with_new_columns6pyspark.pandas.internal.InternalFrame.with_new_columns"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*…
scols_or_pssers≥
Styping.Sequence[Union[pyspark.sql.column.Column,pyspark.pandas.series.Series[Any]]] 
BUnion[pyspark.sql.column.Column,pyspark.pandas.series.Series[Any]]6
pyspark.sql.column.Column"pyspark.sql.column.ColumnJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series"typing.Sequence*ê
column_labels˙
9Union[builtins.list[TypeAlias[builtins.tuple[Any]]],None]∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list
None *˙
data_fieldsÊ
@Union[builtins.list[pyspark.pandas.internal.InternalField],None]ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list
None *∆
column_label_names´
cUnion[builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]],None,pyspark._globals._NoValueType]˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *0

keep_order
builtins.bool"builtins.bool *¬
with_filter1pyspark.pandas.internal.InternalFrame.with_filter"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*’
pred 
BUnion[pyspark.sql.column.Column,pyspark.pandas.series.Series[Any]]6
pyspark.sql.column.Column"pyspark.sql.column.ColumnJ
!pyspark.pandas.series.Series[Any]
Any"pyspark.pandas.series.Series*ó
with_new_spark_column;pyspark.pandas.internal.InternalFrame.with_new_spark_column"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*Ç
column_labelp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label*@
scol6
pyspark.sql.column.Column"pyspark.sql.column.Column*ù
fieldè
1Union[pyspark.pandas.internal.InternalField,None]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField
None *0

keep_order
builtins.bool"builtins.bool *Û
select_column3pyspark.pandas.internal.InternalFrame.select_column"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*Ç
column_labelp
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label*∆
copy*pyspark.pandas.internal.InternalFrame.copy"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*X
selfN
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*‡
spark_frameÃ
DUnion[pyspark.sql.dataframe.DataFrame,pyspark._globals._NoValueType]B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *†
index_spark_columnsÑ
MUnion[builtins.list[pyspark.sql.column.Column],pyspark._globals._NoValueType]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *ø
index_names´
cUnion[builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]],None,pyspark._globals._NoValueType]˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *Ÿ
index_fieldsƒ
^Union[builtins.list[pyspark.pandas.internal.InternalField],None,pyspark._globals._NoValueType]ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *Ó
column_labelsÿ
WUnion[builtins.list[TypeAlias[builtins.tuple[Any]]],None,pyspark._globals._NoValueType]∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.list
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *Æ
data_spark_columnsì
RUnion[builtins.list[pyspark.sql.column.Column],None,pyspark._globals._NoValueType]q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *ÿ
data_fieldsƒ
^Union[builtins.list[pyspark.pandas.internal.InternalField],None,pyspark._globals._NoValueType]ï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *∆
column_label_names´
cUnion[builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]],None,pyspark._globals._NoValueType]˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list
None>
pyspark._globals._NoValueType"pyspark._globals._NoValueType *
from_pandas1pyspark.pandas.internal.InternalFrame.from_pandas"N
%pyspark.pandas.internal.InternalFrame"%pyspark.pandas.internal.InternalFrame*C
pdf:
pandas.core.frame.DataFrame"pandas.core.frame.DataFrame0:builtins.staticmethodh*Ú
prepare_pandas_frame:pyspark.pandas.internal.InternalFrame.prepare_pandas_frame"Õ
ƒTuple[pandas.core.frame.DataFrame,builtins.list[builtins.str],builtins.list[pyspark.pandas.internal.InternalField],builtins.list[builtins.str],builtins.list[pyspark.pandas.internal.InternalField]]:
pandas.core.frame.DataFrame"pandas.core.frame.DataFrameJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.listï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.listï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.list*C
pdf:
pandas.core.frame.DataFrame"pandas.core.frame.DataFrame*2
retain_index
builtins.bool"builtins.bool *:
prefer_timestamp_ntz
builtins.bool"builtins.bool 0:builtins.staticmethodhrv
_sdf*pyspark.pandas.internal.InternalFrame._sdfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFramer†
_index_spark_columns:pyspark.pandas.internal.InternalFrame._index_spark_columnsL
"builtins.list[UnboundType[Column]]
UnboundType[Column]"builtins.listrû
_data_spark_columns9pyspark.pandas.internal.InternalFrame._data_spark_columnsL
"builtins.list[UnboundType[Column]]
UnboundType[Column]"builtins.listr‹
_index_fields3pyspark.pandas.internal.InternalFrame._index_fieldsï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.listr⁄
_data_fields2pyspark.pandas.internal.InternalFrame._data_fieldsï
4builtins.list[pyspark.pandas.internal.InternalField]N
%pyspark.pandas.internal.InternalField"%pyspark.pandas.internal.InternalField"builtins.listrº
_index_names2pyspark.pandas.internal.InternalFrame._index_names˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.listr˘
_column_labels4pyspark.pandas.internal.InternalFrame._column_labels∞
-builtins.list[TypeAlias[builtins.tuple[Any]]]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label"builtins.listr 
_column_label_names9pyspark.pandas.internal.InternalFrame._column_label_names˜
9builtins.list[Union[TypeAlias[builtins.tuple[Any]],None]]™
*Union[TypeAlias[builtins.tuple[Any]],None]p
TypeAlias[builtins.tuple[Any]].
builtins.tuple[Any]
Any"builtins.tuple"pyspark.pandas._typing.Label
None"builtins.list0
_testpyspark.pandas.internal._test"
None*ì
__annotations__'pyspark.pandas.internal.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
npnumpy *
pdpandas *
Fpyspark.sql.functions *
pspyspark.pandas *ó
SPARK_INDEX_NAME_FORMAT/pyspark.pandas.internal.SPARK_INDEX_NAME_FORMATK
CallableType[builtins.function]&
builtins.function"builtins.function*j
SPARK_DEFAULT_INDEX_NAME0pyspark.pandas.internal.SPARK_DEFAULT_INDEX_NAME
builtins.str"builtins.str*í
SPARK_INDEX_NAME_PATTERN0pyspark.pandas.internal.SPARK_INDEX_NAME_PATTERND
re.Pattern[builtins.str]
builtins.str"builtins.str"
re.Pattern*l
NATURAL_ORDER_COLUMN_NAME1pyspark.pandas.internal.NATURAL_ORDER_COLUMN_NAME
builtins.str"builtins.str*Ç
HIDDEN_COLUMNS&pyspark.pandas.internal.HIDDEN_COLUMNSH
builtins.set[builtins.str]
builtins.str"builtins.str"builtins.set*`
DEFAULT_SERIES_NAME+pyspark.pandas.internal.DEFAULT_SERIES_NAME
builtins.int"builtins.int*l
SPARK_DEFAULT_SERIES_NAME1pyspark.pandas.internal.SPARK_DEFAULT_SERIES_NAME
builtins.str"builtins.str