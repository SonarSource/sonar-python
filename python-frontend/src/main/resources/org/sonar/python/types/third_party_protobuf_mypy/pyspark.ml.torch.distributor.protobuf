
pyspark.ml.torch.distributorû
Distributor(pyspark.ml.torch.distributor.Distributor"builtins.object*‘
__init__1pyspark.ml.torch.distributor.Distributor.__init__"
None*^
selfT
(pyspark.ml.torch.distributor.Distributor"(pyspark.ml.torch.distributor.Distributor*1
num_processes
builtins.int"builtins.int *0

local_mode
builtins.bool"builtins.bool *-
use_gpu
builtins.bool"builtins.bool *T
ssl_confD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ž
_create_input_params=pyspark.ml.torch.distributor.Distributor._create_input_params"W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*^
selfT
(pyspark.ml.torch.distributor.Distributor"(pyspark.ml.torch.distributor.Distributor*Ç
_get_num_tasks7pyspark.ml.torch.distributor.Distributor._get_num_tasks"
builtins.int"builtins.int*^
selfT
(pyspark.ml.torch.distributor.Distributor"(pyspark.ml.torch.distributor.Distributor*Ã
_validate_input_params?pyspark.ml.torch.distributor.Distributor._validate_input_params"
None*^
selfT
(pyspark.ml.torch.distributor.Distributor"(pyspark.ml.torch.distributor.Distributor*¹
_check_encryption:pyspark.ml.torch.distributor.Distributor._check_encryption"
None*^
selfT
(pyspark.ml.torch.distributor.Distributor"(pyspark.ml.torch.distributor.Distributorr_
	is_remote2pyspark.ml.torch.distributor.Distributor.is_remote
builtins.bool"builtins.boolr}
spark.pyspark.ml.torch.distributor.Distributor.sparkD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionrw
is_spark_local_master>pyspark.ml.torch.distributor.Distributor.is_spark_local_master
builtins.bool"builtins.boolr[
logger/pyspark.ml.torch.distributor.Distributor.logger 
logging.Logger"logging.Loggerre
num_processes6pyspark.ml.torch.distributor.Distributor.num_processes
builtins.int"builtins.intra

local_mode3pyspark.ml.torch.distributor.Distributor.local_mode
builtins.bool"builtins.boolr[
use_gpu0pyspark.ml.torch.distributor.Distributor.use_gpu
builtins.bool"builtins.boolr]
	num_tasks2pyspark.ml.torch.distributor.Distributor.num_tasks
builtins.int"builtins.intrƒ
ssl_conf1pyspark.ml.torch.distributor.Distributor.ssl_confD
Union[builtins.str,None]
builtins.str"builtins.str
NoneºP
TorchDistributor-pyspark.ml.torch.distributor.TorchDistributor"(pyspark.ml.torch.distributor.Distributor*ù
__init__6pyspark.ml.torch.distributor.TorchDistributor.__init__"
None*h
self^
-pyspark.ml.torch.distributor.TorchDistributor"-pyspark.ml.torch.distributor.TorchDistributor*1
num_processes
builtins.int"builtins.int *0

local_mode
builtins.bool"builtins.bool *-
use_gpu
builtins.bool"builtins.bool *-
	_ssl_conf
builtins.str"builtins.str *Ê
_get_torchrun_args@pyspark.ml.torch.distributor.TorchDistributor._get_torchrun_args"v
&Tuple[builtins.list[Any],builtins.int],
builtins.list[Any]
Any"builtins.list
builtins.int"builtins.int*.

local_mode
builtins.bool"builtins.bool*/
num_processes
builtins.int"builtins.int0:builtins.staticmethodh*ý
_create_torchrun_commandFpyspark.ml.torch.distributor.TorchDistributor._create_torchrun_command"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*i
input_paramsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*4
path_to_train_file
builtins.str"builtins.str*
args
Any0:builtins.staticmethodh*ø
_execute_command>pyspark.ml.torch.distributor.TorchDistributor._execute_command"
None*S
cmdJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*,
_prctl
builtins.bool"builtins.bool *8
redirect_to_stdout
builtins.bool"builtins.bool *B
log_streaming_client&
Union[Any,None]
Any
None 0:builtins.staticmethodh*ª
"_get_output_from_framework_wrapperPpyspark.ml.torch.distributor.TorchDistributor._get_output_from_framework_wrapper"&
Union[Any,None]
Any
None*ž
framework_wrapper†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*K
input_params9
builtins.dict[Any,Any]
Any
Any"builtins.dict*µ
train_object¢
3Union[CallableType[builtins.function],builtins.str]K
CallableType[builtins.function]&
builtins.function"builtins.function
builtins.str"builtins.str* 
run_pytorch_file_fn†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*
args
Any*
kwargs
Any0:builtins.staticmethodh*Ô
_run_local_trainingApyspark.ml.torch.distributor.TorchDistributor._run_local_training"&
Union[Any,None]
Any
None*h
self^
-pyspark.ml.torch.distributor.TorchDistributor"-pyspark.ml.torch.distributor.TorchDistributor*e
framework_wrapper_fnK
CallableType[builtins.function]&
builtins.function"builtins.function*µ
train_object¢
3Union[CallableType[builtins.function],builtins.str]K
CallableType[builtins.function]&
builtins.function"builtins.function
builtins.str"builtins.str* 
run_pytorch_file_fn†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*
args
Any*
kwargs
Any*Õ
_get_spark_task_functionFpyspark.ml.torch.distributor.TorchDistributor._get_spark_task_function"K
CallableType[builtins.function]&
builtins.function"builtins.function*h
self^
-pyspark.ml.torch.distributor.TorchDistributor"-pyspark.ml.torch.distributor.TorchDistributor*¡
framework_wrapper_fn†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*µ
train_object¢
3Union[CallableType[builtins.function],builtins.str]K
CallableType[builtins.function]&
builtins.function"builtins.function
builtins.str"builtins.str* 
run_pytorch_file_fn†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*’
input_dataframe}
+Union[pyspark.sql.dataframe.DataFrame,None]B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame
None*
args
Any*
kwargs
Any*õ
_run_distributed_trainingGpyspark.ml.torch.distributor.TorchDistributor._run_distributed_training"&
Union[Any,None]
Any
None*h
self^
-pyspark.ml.torch.distributor.TorchDistributor"-pyspark.ml.torch.distributor.TorchDistributor*e
framework_wrapper_fnK
CallableType[builtins.function]&
builtins.function"builtins.function*µ
train_object¢
3Union[CallableType[builtins.function],builtins.str]K
CallableType[builtins.function]&
builtins.function"builtins.function
builtins.str"builtins.str* 
run_pytorch_file_fn†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*’
spark_dataframe}
+Union[pyspark.sql.dataframe.DataFrame,None]B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame
None*
args
Any*
kwargs
Any*Ò
_run_training_on_pytorch_fileKpyspark.ml.torch.distributor.TorchDistributor._run_training_on_pytorch_file"
None*i
input_paramsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*,

train_path
builtins.str"builtins.str*
args
Any*
kwargs
Any0:builtins.staticmethodh*Ì
_setup_files:pyspark.ml.torch.distributor.TorchDistributor._setup_files"Æ
<typing.Generator[Tuple[builtins.str,builtins.str],None,None]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str
None
None"typing.Generator*Y
train_fnK
CallableType[builtins.function]&
builtins.function"builtins.function*
args
Any*
kwargs
Any0:builtins.staticmethod:contextlib.contextmanagerh*
_setup_spark_partition_dataIpyspark.ml.torch.distributor.TorchDistributor._setup_spark_partition_data"0
typing.Iterator[Any]
Any"typing.Iterator*M
partition_data_iterator0
typing.Iterator[Any]
Any"typing.Iterator*n
input_schema_jsonW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict0:builtins.staticmethod:contextlib.contextmanagerh*©
!_run_training_on_pytorch_functionOpyspark.ml.torch.distributor.TorchDistributor._run_training_on_pytorch_function"
Any*i
input_paramsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*Y
train_fnK
CallableType[builtins.function]&
builtins.function"builtins.function* 
run_pytorch_file_fn†
+Union[CallableType[builtins.function],None]K
CallableType[builtins.function]&
builtins.function"builtins.function
None*
args
Any*
kwargs
Any0:builtins.staticmethodh*á
_create_save_dir>pyspark.ml.torch.distributor.TorchDistributor._create_save_dir"
builtins.str"builtins.str*T
root_dirD
Union[builtins.str,None]
builtins.str"builtins.str
None 0:builtins.staticmethodh*Ÿ
_cleanup_files<pyspark.ml.torch.distributor.TorchDistributor._cleanup_files"
None**
save_dir
builtins.str"builtins.str0:builtins.staticmethodh*Ÿ
_save_pickled_functionDpyspark.ml.torch.distributor.TorchDistributor._save_pickled_function"
builtins.str"builtins.str**
save_dir
builtins.str"builtins.str*±
train_fn¢
3Union[builtins.str,CallableType[builtins.function]]
builtins.str"builtins.strK
CallableType[builtins.function]&
builtins.function"builtins.function*
args
Any*
kwargs
Any0:builtins.staticmethodh*º
_create_torchrun_train_fileIpyspark.ml.torch.distributor.TorchDistributor._create_torchrun_train_file"
builtins.str"builtins.str*/
save_dir_path
builtins.str"builtins.str*2
pickle_file_path
builtins.str"builtins.str*2
output_file_path
builtins.str"builtins.str0:builtins.staticmethodh*°
_get_pickled_outputApyspark.ml.torch.distributor.TorchDistributor._get_pickled_output"
Any*2
output_file_path
builtins.str"builtins.str0:builtins.staticmethodh*ª
run1pyspark.ml.torch.distributor.TorchDistributor.run"&
Union[Any,None]
Any
None*h
self^
-pyspark.ml.torch.distributor.TorchDistributor"-pyspark.ml.torch.distributor.TorchDistributor*µ
train_object¢
3Union[CallableType[builtins.function],builtins.str]K
CallableType[builtins.function]&
builtins.function"builtins.function
builtins.str"builtins.str*
args
Any*
kwargs
Any*’
_run2pyspark.ml.torch.distributor.TorchDistributor._run"&
Union[Any,None]
Any
None*h
self^
-pyspark.ml.torch.distributor.TorchDistributor"-pyspark.ml.torch.distributor.TorchDistributor*µ
train_object¢
3Union[CallableType[builtins.function],builtins.str]K
CallableType[builtins.function]&
builtins.function"builtins.function
builtins.str"builtins.str*d
run_pytorch_file_fnK
CallableType[builtins.function]&
builtins.function"builtins.function*
args
Any*
kwargs
Any*­
_train_on_dataframeApyspark.ml.torch.distributor.TorchDistributor._train_on_dataframe"
Any*h
self^
-pyspark.ml.torch.distributor.TorchDistributor"-pyspark.ml.torch.distributor.TorchDistributor*_
train_functionK
CallableType[builtins.function]&
builtins.function"builtins.function*W
spark_dataframeB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*
args
Any*
kwargs
Anyrt
_PICKLED_FUNC_FILE@pyspark.ml.torch.distributor.TorchDistributor._PICKLED_FUNC_FILE
builtins.str"builtins.strrf
_TRAIN_FILE9pyspark.ml.torch.distributor.TorchDistributor._TRAIN_FILE
builtins.str"builtins.strrx
_PICKLED_OUTPUT_FILEBpyspark.ml.torch.distributor.TorchDistributor._PICKLED_OUTPUT_FILE
builtins.str"builtins.strrn
_TORCH_SSL_CONF=pyspark.ml.torch.distributor.TorchDistributor._TORCH_SSL_CONF
builtins.str"builtins.strr£
input_params:pyspark.ml.torch.distributor.TorchDistributor.input_paramsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dictrl
driver_address<pyspark.ml.torch.distributor.TorchDistributor.driver_address
builtins.str"builtins.strrm
log_streaming_server_portGpyspark.ml.torch.distributor.TorchDistributor.log_streaming_server_port
Anyô
_get_resources+pyspark.ml.torch.distributor._get_resources"á
Lbuiltins.dict[builtins.str,pyspark.resource.information.ResourceInformation]
builtins.str"builtins.strd
0pyspark.resource.information.ResourceInformation"0pyspark.resource.information.ResourceInformation"builtins.dict*Q
sessionD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionú
	_get_conf&pyspark.ml.torch.distributor._get_conf"
builtins.str"builtins.str*O
sparkD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*%
key
builtins.str"builtins.str*/
default_value
builtins.str"builtins.strŒ
_get_conf_boolean.pyspark.ml.torch.distributor._get_conf_boolean"
builtins.bool"builtins.bool*O
sparkD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSession*%
key
builtins.str"builtins.str*/
default_value
builtins.str"builtins.str
_get_logger(pyspark.ml.torch.distributor._get_logger" 
logging.Logger"logging.Logger*&
name
builtins.str"builtins.str†
_get_gpus_owned,pyspark.ml.torch.distributor._get_gpus_owned"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*ø
contextê
NUnion[pyspark.sql.session.SparkSession,pyspark.taskcontext.BarrierTaskContext]D
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionP
&pyspark.taskcontext.BarrierTaskContext"&pyspark.taskcontext.BarrierTaskContext­
 _get_spark_partition_data_loader=pyspark.ml.torch.distributor._get_spark_partition_data_loader"
Any*-
num_samples
builtins.int"builtins.int*,

batch_size
builtins.int"builtins.int*/
num_workers
builtins.int"builtins.int *3
prefetch_factor
builtins.int"builtins.int *˜
__annotations__,pyspark.ml.torch.distributor.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*N
LogStreamingClient/pyspark.ml.torch.distributor.LogStreamingClient
Any*N
LogStreamingServer/pyspark.ml.torch.distributor.LogStreamingServer
Any*}
SPARK_PARTITION_ARROW_DATA_FILE<pyspark.ml.torch.distributor.SPARK_PARTITION_ARROW_DATA_FILE
builtins.str"builtins.str*u
SPARK_DATAFRAME_SCHEMA_FILE8pyspark.ml.torch.distributor.SPARK_DATAFRAME_SCHEMA_FILE
builtins.str"builtins.str