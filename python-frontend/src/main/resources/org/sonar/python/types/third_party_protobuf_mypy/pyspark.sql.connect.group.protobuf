
pyspark.sql.connect.groupâ
PySparkGroupedDatapyspark.sql.group.GroupedData"2pyspark.sql.pandas.group_ops.PandasGroupedOpsMixin*‰
__init__&pyspark.sql.group.GroupedData.__init__"
None*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*
jgd
Any*J
dfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*í
__repr__&pyspark.sql.group.GroupedData.__repr__"
builtins.str"builtins.str*@>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*’
count#pyspark.sql.group.GroupedData.count"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData0:pyspark.sql.group.dfapi*Ñ
mean"pyspark.sql.group.GroupedData.mean"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*&
cols
builtins.str"builtins.str0: pyspark.sql.group.df_varargs_api*Ç
avg!pyspark.sql.group.GroupedData.avg"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*&
cols
builtins.str"builtins.str0: pyspark.sql.group.df_varargs_api*Ç
max!pyspark.sql.group.GroupedData.max"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*&
cols
builtins.str"builtins.str0: pyspark.sql.group.df_varargs_api*Ç
min!pyspark.sql.group.GroupedData.min"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*&
cols
builtins.str"builtins.str0: pyspark.sql.group.df_varargs_api*Ç
sum!pyspark.sql.group.GroupedData.sum"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*&
cols
builtins.str"builtins.str0: pyspark.sql.group.df_varargs_api*í
pivot#pyspark.sql.group.GroupedData.pivot">
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*+
	pivot_col
builtins.str"builtins.str*¨
valuesù
nUnion[builtins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]],None]û
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]®
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]≠
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str"pyspark._typing.PrimitiveType"pyspark.sql._typing.LiteralType"builtins.list
None 2Ä
agg!pyspark.sql.group.GroupedData.aggé
agg!pyspark.sql.group.GroupedData.agg"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*A
exprs6
pyspark.sql.column.Column"pyspark.sql.column.Column0:typing.overloadXƒ
agg!pyspark.sql.group.GroupedData.agg"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*H
self>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*wu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict0:typing.overloadXr3
_jgd"pyspark.sql.group.GroupedData._jgd
Anyrl
_df!pyspark.sql.group.GroupedData._dfB
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFramerv
session%pyspark.sql.group.GroupedData.sessionD
 pyspark.sql.session.SparkSession" pyspark.sql.session.SparkSessionı
PySparkPandasCogroupedOps/pyspark.sql.pandas.group_ops.PandasCogroupedOps"builtins.object*Œ
__init__8pyspark.sql.pandas.group_ops.PandasCogroupedOps.__init__"
None*l
selfb
/pyspark.sql.pandas.group_ops.PandasCogroupedOps"/pyspark.sql.pandas.group_ops.PandasCogroupedOps*G
gd1>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*G
gd2>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData*°
applyInPandas=pyspark.sql.pandas.group_ops.PandasCogroupedOps.applyInPandas"B
pyspark.sql.dataframe.DataFrame"pyspark.sql.dataframe.DataFrame*l
selfb
/pyspark.sql.pandas.group_ops.PandasCogroupedOps"/pyspark.sql.pandas.group_ops.PandasCogroupedOps*˛
funcÛ
QTypeAlias[Union[CallableType[builtins.function],CallableType[builtins.function]]]‰
FUnion[CallableType[builtins.function],CallableType[builtins.function]]K
CallableType[builtins.function]&
builtins.function"builtins.functionK
CallableType[builtins.function]&
builtins.function"builtins.function"5pyspark.sql.pandas._typing.PandasCogroupedMapFunction*ù
schemaê
0Union[pyspark.sql.types.StructType,builtins.str]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str*§
_extract_cols=pyspark.sql.pandas.group_ops.PandasCogroupedOps._extract_cols"q
(builtins.list[pyspark.sql.column.Column]6
pyspark.sql.column.Column"pyspark.sql.column.Column"builtins.list*F
gd>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData0:builtins.staticmethodhr|
_gd14pyspark.sql.pandas.group_ops.PandasCogroupedOps._gd1>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedDatar|
_gd24pyspark.sql.pandas.group_ops.PandasCogroupedOps._gd2>
pyspark.sql.group.GroupedData"pyspark.sql.group.GroupedData„@
GroupedData%pyspark.sql.connect.group.GroupedData"builtins.object*≥

__init__.pyspark.sql.connect.group.GroupedData.__init__"
None*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*Z
dfR
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*,

group_type
builtins.str"builtins.str*°
grouping_colsç
2typing.Sequence[pyspark.sql.connect.column.Column]F
!pyspark.sql.connect.column.Column"!pyspark.sql.connect.column.Column"typing.Sequence*ï
	pivot_colÉ
-Union[pyspark.sql.connect.column.Column,None]F
!pyspark.sql.connect.column.Column"!pyspark.sql.connect.column.Column
None *Ã
pivot_values∑
pUnion[typing.Sequence[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]],None]∂
dtyping.Sequence[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]º
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]π
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str")pyspark.sql.connect._typing.PrimitiveType"'pyspark.sql.connect._typing.LiteralType"typing.Sequence
None *™
__repr__.pyspark.sql.connect.group.GroupedData.__repr__"
builtins.str"builtins.str*PN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*ˆ
_numeric_agg2pyspark.sql.connect.group.GroupedData._numeric_agg"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData**
function
builtins.str"builtins.str*X
colsN
typing.Sequence[builtins.str]
builtins.str"builtins.str"typing.Sequence*Ü
min)pyspark.sql.connect.group.GroupedData.min"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*&
cols
builtins.str"builtins.str*Ü
max)pyspark.sql.connect.group.GroupedData.max"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*&
cols
builtins.str"builtins.str*Ü
sum)pyspark.sql.connect.group.GroupedData.sum"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*&
cols
builtins.str"builtins.str*Ü
avg)pyspark.sql.connect.group.GroupedData.avg"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*&
cols
builtins.str"builtins.str*‚
count+pyspark.sql.connect.group.GroupedData.count"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*Œ
pivot+pyspark.sql.connect.group.GroupedData.pivot"N
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*+
	pivot_col
builtins.str"builtins.str*¿
values±
nUnion[builtins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]],None]≤
bbuiltins.list[TypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]]º
STypeAlias[TypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]]π
HTypeAlias[Union[builtins.bool,builtins.float,builtins.int,builtins.str]]ø
=Union[builtins.bool,builtins.float,builtins.int,builtins.str]
builtins.bool"builtins.bool 
builtins.float"builtins.float
builtins.int"builtins.int
builtins.str"builtins.str")pyspark.sql.connect._typing.PrimitiveType"'pyspark.sql.connect._typing.LiteralType"builtins.list
None *Ò
apply+pyspark.sql.connect.group.GroupedData.apply"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*å
udfÇ
?pyspark.sql.connect._typing.GroupedMapPandasUserDefinedFunction"?pyspark.sql.connect._typing.GroupedMapPandasUserDefinedFunction*í
applyInPandas3pyspark.sql.connect.group.GroupedData.applyInPandas"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*˝
funcÚ
QTypeAlias[Union[CallableType[builtins.function],CallableType[builtins.function]]]‰
FUnion[CallableType[builtins.function],CallableType[builtins.function]]K
CallableType[builtins.function]&
builtins.function"builtins.functionK
CallableType[builtins.function]&
builtins.function"builtins.function"4pyspark.sql.connect._typing.PandasGroupedMapFunction*ù
schemaê
0Union[pyspark.sql.types.StructType,builtins.str]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str*¸
applyInPandasWithState<pyspark.sql.connect.group.GroupedData.applyInPandasWithState"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*≈
func∫
*TypeAlias[CallableType[builtins.function]]K
CallableType[builtins.function]&
builtins.function"builtins.function"=pyspark.sql.connect._typing.PandasGroupedMapFunctionWithState*ß
outputStructTypeê
0Union[pyspark.sql.types.StructType,builtins.str]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str*¶
stateStructTypeê
0Union[pyspark.sql.types.StructType,builtins.str]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str*,

outputMode
builtins.str"builtins.str*-
timeoutConf
builtins.str"builtins.str*À
cogroup-pyspark.sql.connect.group.GroupedData.cogroup"\
,pyspark.sql.connect.group.PandasCogroupedOps",pyspark.sql.connect.group.PandasCogroupedOps*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*Y
otherN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData2Ë
agg)pyspark.sql.connect.group.GroupedData.agg∆
agg)pyspark.sql.connect.group.GroupedData.agg"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*Q
exprsF
!pyspark.sql.connect.column.Column"!pyspark.sql.connect.column.Column0:typing.overloadXÏ
agg)pyspark.sql.connect.group.GroupedData.agg"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*X
selfN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*wu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dict0:typing.overloadXr
mean*pyspark.sql.connect.group.GroupedData.meanK
CallableType[builtins.function]&
builtins.function"builtins.functionrÑ
_df)pyspark.sql.connect.group.GroupedData._dfR
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFramer^
_group_type1pyspark.sql.connect.group.GroupedData._group_type
builtins.str"builtins.strr“
_grouping_cols4pyspark.sql.connect.group.GroupedData._grouping_colsâ
0builtins.list[pyspark.sql.connect.column.Column]F
!pyspark.sql.connect.column.Column"!pyspark.sql.connect.column.Column"builtins.listrƒ

_pivot_col0pyspark.sql.connect.group.GroupedData._pivot_colÉ
-Union[pyspark.sql.connect.column.Column,None]F
!pyspark.sql.connect.column.Column"!pyspark.sql.connect.column.Column
Noner†
_pivot_values3pyspark.sql.connect.group.GroupedData._pivot_valuesZ
Union[builtins.list[Any],None],
builtins.list[Any]
Any"builtins.list
Noneã
PandasCogroupedOps,pyspark.sql.connect.group.PandasCogroupedOps"builtins.object*Â
__init__5pyspark.sql.connect.group.PandasCogroupedOps.__init__"
None*f
self\
,pyspark.sql.connect.group.PandasCogroupedOps",pyspark.sql.connect.group.PandasCogroupedOps*W
gd1N
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*W
gd2N
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData*Ë
applyInPandas:pyspark.sql.connect.group.PandasCogroupedOps.applyInPandas"R
'pyspark.sql.connect.dataframe.DataFrame"'pyspark.sql.connect.dataframe.DataFrame*f
self\
,pyspark.sql.connect.group.PandasCogroupedOps",pyspark.sql.connect.group.PandasCogroupedOps*æ
func≥
*TypeAlias[CallableType[builtins.function]]K
CallableType[builtins.function]&
builtins.function"builtins.function"6pyspark.sql.connect._typing.PandasCogroupedMapFunction*ù
schemaê
0Union[pyspark.sql.types.StructType,builtins.str]<
pyspark.sql.types.StructType"pyspark.sql.types.StructType
builtins.str"builtins.str* 
_extract_cols:pyspark.sql.connect.group.PandasCogroupedOps._extract_cols"â
0builtins.list[pyspark.sql.connect.column.Column]F
!pyspark.sql.connect.column.Column"!pyspark.sql.connect.column.Column"builtins.list*V
gdN
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData0:builtins.staticmethodhrâ
_gd11pyspark.sql.connect.group.PandasCogroupedOps._gd1N
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedDatarâ
_gd21pyspark.sql.connect.group.PandasCogroupedOps._gd2N
%pyspark.sql.connect.group.GroupedData"%pyspark.sql.connect.group.GroupedData2
_testpyspark.sql.connect.group._test"
None*ï
__annotations__)pyspark.sql.connect.group.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*"
planpyspark.sql.connect.plan 