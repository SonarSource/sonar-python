
torch.distributed‹™
ProcessGroup'torch._C._distributed_c10d.ProcessGroup"builtins.object*¶
__init__0torch._C._distributed_c10d.ProcessGroup.__init__"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*O
storeD
 torch._C._distributed_c10d.Store" torch._C._distributed_c10d.Store*&
rank
builtins.int"builtins.int*&
size
builtins.int"builtins.int*o
optionsb
/torch._C._distributed_c10d.ProcessGroup.Options"/torch._C._distributed_c10d.ProcessGroup.Options*°
rank,torch._C._distributed_c10d.ProcessGroup.rank"
builtins.int"builtins.int*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*°
size,torch._C._distributed_c10d.ProcessGroup.size"
builtins.int"builtins.int*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*ú
allreduce_coalesced;torch._C._distributed_c10d.ProcessGroup.allreduce_coalesced"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any *¶
reduce_scatter_tensor_coalescedGtorch._C._distributed_c10d.ProcessGroup.reduce_scatter_tensor_coalesced"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*u
outputTensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*t
inputTensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*º
opts­
;Union[torch._C._distributed_c10d.ReduceScatterOptions,None]b
/torch._C._distributed_c10d.ReduceScatterOptions"/torch._C._distributed_c10d.ReduceScatterOptions
None *ô
_allgather_base7torch._C._distributed_c10d.ProcessGroup._allgather_base"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*8
output,
torch._tensor.Tensor"torch._tensor.Tensor*7
input,
torch._tensor.Tensor"torch._tensor.Tensor*
opts
Any *º
allgather_coalesced;torch._C._distributed_c10d.ProcessGroup.allgather_coalesced"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*º
output_lists§
2builtins.list[builtins.list[torch._tensor.Tensor]]b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.list*r

input_listb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any *‹
allgather_into_tensor_coalescedGtorch._C._distributed_c10d.ProcessGroup.allgather_into_tensor_coalesced"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*t
output_listsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*r

input_listb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any *°
_reduce_scatter_base<torch._C._distributed_c10d.ProcessGroup._reduce_scatter_base"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*>
outputTensor,
torch._tensor.Tensor"torch._tensor.Tensor*=
inputTensor,
torch._tensor.Tensor"torch._tensor.Tensor*¸
opts­
;Union[torch._C._distributed_c10d.ReduceScatterOptions,None]b
/torch._C._distributed_c10d.ReduceScatterOptions"/torch._C._distributed_c10d.ReduceScatterOptions
None*™
send,torch._C._distributed_c10d.ProcessGroup.send"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*)
dstRank
builtins.int"builtins.int*%
tag
builtins.int"builtins.int*™
recv,torch._C._distributed_c10d.ProcessGroup.recv"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*)
srcRank
builtins.int"builtins.int*%
tag
builtins.int"builtins.int*‚
recv_anysource6torch._C._distributed_c10d.ProcessGroup.recv_anysource"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*%
tag
builtins.int"builtins.int*ñ
barrier/torch._C._distributed_c10d.ProcessGroup.barrier"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*
opts
Any *Ä
boxed-torch._C._distributed_c10d.ProcessGroup.boxed".
torch._C.ScriptObject"torch._C.ScriptObject*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*Õ
unbox-torch._C._distributed_c10d.ProcessGroup.unbox"R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*7
obj.
torch._C.ScriptObject"torch._C.ScriptObject0:staticmethodh*æ
_start_coalescing9torch._C._distributed_c10d.ProcessGroup._start_coalescing"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*.
device"
torch._C.device"torch._C.device*œ
_end_coalescing7torch._C._distributed_c10d.ProcessGroup._end_coalescing"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*.
device"
torch._C.device"torch._C.device*Ê
_get_backend_name9torch._C._distributed_c10d.ProcessGroup._get_backend_name"
builtins.str"builtins.str*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*¼
_backend_id3torch._C._distributed_c10d.ProcessGroup._backend_id"
builtins.int"builtins.int*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*|
backend_typej
3torch._C._distributed_c10d.ProcessGroup.BackendType"3torch._C._distributed_c10d.ProcessGroup.BackendType*‡
_device_types5torch._C._distributed_c10d.ProcessGroup._device_types"S
builtins.list[torch._C.device]"
torch._C.device"torch._C.device"builtins.list*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup0:property`*œ
_get_backend4torch._C._distributed_c10d.ProcessGroup._get_backend"H
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*.
device"
torch._C.device"torch._C.device*û
_register_backend9torch._C._distributed_c10d.ProcessGroup._register_backend"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*.
device"
torch._C.device"torch._C.device*|
backend_typej
3torch._C._distributed_c10d.ProcessGroup.BackendType"3torch._C._distributed_c10d.ProcessGroup.BackendType*”
backend†
.Union[torch._C._distributed_c10d.Backend,None]H
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend
None*Ú
_set_group_name7torch._C._distributed_c10d.ProcessGroup._set_group_name"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*&
name
builtins.str"builtins.str*Ú
_set_group_desc7torch._C._distributed_c10d.ProcessGroup._set_group_desc"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*&
desc
builtins.str"builtins.str*°
name,torch._C._distributed_c10d.ProcessGroup.name"
builtins.str"builtins.str*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*¾

_has_hooks2torch._C._distributed_c10d.ProcessGroup._has_hooks"
builtins.bool"builtins.bool*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*Â
_wait_for_pending_works?torch._C._distributed_c10d.ProcessGroup._wait_for_pending_works"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*Ð
_set_sequence_number_for_groupFtorch._C._distributed_c10d.ProcessGroup._set_sequence_number_for_group"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*Ê

group_name2torch._C._distributed_c10d.ProcessGroup.group_name"
builtins.str"builtins.str*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup0:property`*Ê

group_desc2torch._C._distributed_c10d.ProcessGroup.group_desc"
builtins.str"builtins.str*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup0:property`2ˆ
	broadcast1torch._C._distributed_c10d.ProcessGroup.broadcastô
	broadcast1torch._C._distributed_c10d.ProcessGroup.broadcast"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any 0:overloadXÐ
	broadcast1torch._C._distributed_c10d.ProcessGroup.broadcast"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
root
builtins.int"builtins.int0:overloadX2»	
	allreduce1torch._C._distributed_c10d.ProcessGroup.allreduceÇ
	allreduce1torch._C._distributed_c10d.ProcessGroup.allreduce"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*f
optsZ
+torch._C._distributed_c10d.AllreduceOptions"+torch._C._distributed_c10d.AllreduceOptions 0:overloadXò
	allreduce1torch._C._distributed_c10d.ProcessGroup.allreduce"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
op
Any 0:overloadX»
	allreduce1torch._C._distributed_c10d.ProcessGroup.allreduce"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*
op
Any 0:overloadX2‰
reduce.torch._C._distributed_c10d.ProcessGroup.reduceî
reduce.torch._C._distributed_c10d.ProcessGroup.reduce"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*o
tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any 0:overloadXÝ
reduce.torch._C._distributed_c10d.ProcessGroup.reduce"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
root
builtins.int"builtins.int*
op
Any 0:overloadX2£
	allgather1torch._C._distributed_c10d.ProcessGroup.allgather¹
	allgather1torch._C._distributed_c10d.ProcessGroup.allgather"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*¼
output_tensors§
2builtins.list[builtins.list[torch._tensor.Tensor]]b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.list*u
input_tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any 0:overloadX¦
	allgather1torch._C._distributed_c10d.ProcessGroup.allgather"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*v
output_tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*>
input_tensor,
torch._tensor.Tensor"torch._tensor.Tensor0:overloadX2¹
gather.torch._C._distributed_c10d.ProcessGroup.gather³
gather.torch._C._distributed_c10d.ProcessGroup.gather"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*¼
output_tensors§
2builtins.list[builtins.list[torch._tensor.Tensor]]b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.list*u
input_tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any 0:overloadXÈ
gather.torch._C._distributed_c10d.ProcessGroup.gather"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*v
output_tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*>
input_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
root
builtins.int"builtins.int0:overloadX2¿
scatter/torch._C._distributed_c10d.ProcessGroup.scatterµ
scatter/torch._C._distributed_c10d.ProcessGroup.scatter"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*v
output_tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*»
input_tensors§
2builtins.list[builtins.list[torch._tensor.Tensor]]b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.list*
opts
Any 0:overloadXÊ
scatter/torch._C._distributed_c10d.ProcessGroup.scatter"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*?
output_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*u
input_tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*&
root
builtins.int"builtins.int0:overloadX2Á
reduce_scatter6torch._C._distributed_c10d.ProcessGroup.reduce_scatterÃ
reduce_scatter6torch._C._distributed_c10d.ProcessGroup.reduce_scatter"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*v
output_tensorsb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*»
input_tensors§
2builtins.list[builtins.list[torch._tensor.Tensor]]b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list"builtins.list*
opts
Any 0:overloadX°
reduce_scatter6torch._C._distributed_c10d.ProcessGroup.reduce_scatter"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*@
output_tensors,
torch._tensor.Tensor"torch._tensor.Tensor*t
input_tensorb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list0:overloadX2Ï	
alltoall_base5torch._C._distributed_c10d.ProcessGroup.alltoall_baseÓ
alltoall_base5torch._C._distributed_c10d.ProcessGroup.alltoall_base"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*?
output_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*>
input_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*b
output_split_sizesJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*a
input_split_sizesJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*
opts
Any 0:overloadX°
alltoall_base5torch._C._distributed_c10d.ProcessGroup.alltoall_base"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*8
output,
torch._tensor.Tensor"torch._tensor.Tensor*7
input,
torch._tensor.Tensor"torch._tensor.Tensor*b
output_split_sizesJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*a
input_split_sizesJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list0:overloadX2û
alltoall0torch._C._distributed_c10d.ProcessGroup.alltoallî
alltoall0torch._C._distributed_c10d.ProcessGroup.alltoall"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*u
output_tensorb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*t
input_tensorb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*
opts
Any 0:overloadXË
alltoall0torch._C._distributed_c10d.ProcessGroup.alltoall"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*n
outputb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*m
inputb
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list0:overloadX2þ
bound_device_id7torch._C._distributed_c10d.ProcessGroup.bound_device_id‡
bound_device_id7torch._C._distributed_c10d.ProcessGroup.bound_device_id"M
Union[torch._C.device,None]"
torch._C.device"torch._C.device
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup0:propertyX`§
bound_device_id7torch._C._distributed_c10d.ProcessGroup.bound_device_id"
None*\
selfR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*Y
deviceM
Union[torch._C.device,None]"
torch._C.device"torch._C.device
None0:bound_device_id.setterœ

_Backend"torch._C._distributed_c10d.Backend"builtins.object*å
__init__+torch._C._distributed_c10d.Backend.__init__"
None*R
selfH
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend*&
rank
builtins.int"builtins.int*&
size
builtins.int"builtins.int*Í
supports_splitting5torch._C._distributed_c10d.Backend.supports_splitting"
builtins.bool"builtins.bool*R
selfH
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend0:property`*¡
rank'torch._C._distributed_c10d.Backend.rank"
builtins.int"builtins.int*R
selfH
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend*¡
size'torch._C._distributed_c10d.Backend.size"
builtins.int"builtins.int*R
selfH
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend*–
eager_connect_single_device>torch._C._distributed_c10d.Backend.eager_connect_single_device"
None*R
selfH
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend*Y
deviceM
Union[torch._C.device,None]"
torch._C.device"torch._C.device
None*Á
_set_sequence_number_for_groupAtorch._C._distributed_c10d.Backend._set_sequence_number_for_group"
None*R
selfH
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend¨
_Worktorch._C._distributed_c10d.Work"builtins.object*ª
is_completed,torch._C._distributed_c10d.Work.is_completed"
builtins.bool"builtins.bool*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*¦

is_success*torch._C._distributed_c10d.Work.is_success"
builtins.bool"builtins.bool*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*
	exception)torch._C._distributed_c10d.Work.exception"
Any*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*Ó
wait$torch._C._distributed_c10d.Work.wait"
builtins.bool"builtins.bool*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*7
timeout(
datetime.timedelta"datetime.timedelta *Â

get_future*torch._C._distributed_c10d.Work.get_future":
torch.futures.Future[Any]
Any"torch.futures.Future*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*¦
source_rank+torch._C._distributed_c10d.Work.source_rank"
builtins.int"builtins.int*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*¨
_source_rank,torch._C._distributed_c10d.Work._source_rank"
builtins.int"builtins.int*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*â
result&torch._C._distributed_c10d.Work.result"b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.list*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*D
synchronize+torch._C._distributed_c10d.Work.synchronize*
self*¬
boxed%torch._C._distributed_c10d.Work.boxed".
torch._C.ScriptObject"torch._C.ScriptObject*L
selfB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*½
unbox%torch._C._distributed_c10d.Work.unbox"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*7
obj.
torch._C.ScriptObject"torch._C.ScriptObject0:staticmethodh›
_DistributedPdb!torch.distributed._DistributedPdb"pdb.Pdb*\
interaction-torch.distributed._DistributedPdb.interaction*
self*
args*

kwargs~
AllreduceCoalescedOptions4torch._C._distributed_c10d.AllreduceCoalescedOptions"+torch._C._distributed_c10d.AllreduceOptionsÉ
AllreduceOptions+torch._C._distributed_c10d.AllreduceOptions"builtins.objectrŒ
reduceOp4torch._C._distributed_c10d.AllreduceOptions.reduceOpJ
#torch._C._distributed_c10d.ReduceOp"#torch._C._distributed_c10d.ReduceOprh
timeout3torch._C._distributed_c10d.AllreduceOptions.timeout(
datetime.timedelta"datetime.timedelta·
AllToAllOptions*torch._C._distributed_c10d.AllToAllOptions"builtins.objectrg
timeout2torch._C._distributed_c10d.AllToAllOptions.timeout(
datetime.timedelta"datetime.timedelta¥
BarrierOptions)torch._C._distributed_c10d.BarrierOptions"builtins.objectrŽ

device_ids4torch._C._distributed_c10d.BarrierOptions.device_idsJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.listr^
device0torch._C._distributed_c10d.BarrierOptions.device"
torch._C.device"torch._C.devicerf
timeout1torch._C._distributed_c10d.BarrierOptions.timeout(
datetime.timedelta"datetime.timedeltaÞ
BroadcastOptions+torch._C._distributed_c10d.BroadcastOptions"builtins.objectr^
rootRank4torch._C._distributed_c10d.BroadcastOptions.rootRank
builtins.int"builtins.intrb

rootTensor6torch._C._distributed_c10d.BroadcastOptions.rootTensor
builtins.int"builtins.intrh
timeout3torch._C._distributed_c10d.BroadcastOptions.timeout(
datetime.timedelta"datetime.timedeltar^
asyncOp3torch._C._distributed_c10d.BroadcastOptions.asyncOp
builtins.bool"builtins.boolŽ
GatherOptions(torch._C._distributed_c10d.GatherOptions"builtins.objectr[
rootRank1torch._C._distributed_c10d.GatherOptions.rootRank
builtins.int"builtins.intre
timeout0torch._C._distributed_c10d.GatherOptions.timeout(
datetime.timedelta"datetime.timedelta
ReduceOp#torch._C._distributed_c10d.ReduceOp"builtins.object*€
__init__,torch._C._distributed_c10d.ReduceOp.__init__"
None*T
selfJ
#torch._C._distributed_c10d.ReduceOp"#torch._C._distributed_c10d.ReduceOp*f
op^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyperŽ
SUM'torch._C._distributed_c10d.ReduceOp.SUM^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyperŽ
AVG'torch._C._distributed_c10d.ReduceOp.AVG^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyper–
PRODUCT+torch._C._distributed_c10d.ReduceOp.PRODUCT^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyperŽ
MIN'torch._C._distributed_c10d.ReduceOp.MIN^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyperŽ
MAX'torch._C._distributed_c10d.ReduceOp.MAX^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyper
BAND(torch._C._distributed_c10d.ReduceOp.BAND^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyperŽ
BOR'torch._C._distributed_c10d.ReduceOp.BOR^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyper
BXOR(torch._C._distributed_c10d.ReduceOp.BXOR^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyperœ

PREMUL_SUM.torch._C._distributed_c10d.ReduceOp.PREMUL_SUM^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTyper”
UNUSED*torch._C._distributed_c10d.ReduceOp.UNUSED^
-torch._C._distributed_c10d.ReduceOp.RedOpType"-torch._C._distributed_c10d.ReduceOp.RedOpTypeû
ReduceOptions(torch._C._distributed_c10d.ReduceOptions"builtins.objectr‰
reduceOp1torch._C._distributed_c10d.ReduceOptions.reduceOpJ
#torch._C._distributed_c10d.ReduceOp"#torch._C._distributed_c10d.ReduceOpr[
rootRank1torch._C._distributed_c10d.ReduceOptions.rootRank
builtins.int"builtins.intr_

rootTensor3torch._C._distributed_c10d.ReduceOptions.rootTensor
builtins.int"builtins.intre
timeout0torch._C._distributed_c10d.ReduceOptions.timeout(
datetime.timedelta"datetime.timedelta½
ReduceScatterOptions/torch._C._distributed_c10d.ReduceScatterOptions"builtins.objectr
reduceOp8torch._C._distributed_c10d.ReduceScatterOptions.reduceOpJ
#torch._C._distributed_c10d.ReduceOp"#torch._C._distributed_c10d.ReduceOprl
timeout7torch._C._distributed_c10d.ReduceScatterOptions.timeout(
datetime.timedelta"datetime.timedeltarb
asyncOp7torch._C._distributed_c10d.ReduceScatterOptions.asyncOp
builtins.bool"builtins.boolð
ScatterOptions)torch._C._distributed_c10d.ScatterOptions"builtins.objectr\
rootRank2torch._C._distributed_c10d.ScatterOptions.rootRank
builtins.int"builtins.intrf
timeout1torch._C._distributed_c10d.ScatterOptions.timeout(
datetime.timedelta"datetime.timedeltar\
asyncOp1torch._C._distributed_c10d.ScatterOptions.asyncOp
builtins.bool"builtins.boolŒ
ProcessGroupMPI*torch._C._distributed_c10d.ProcessGroupMPI""torch._C._distributed_c10d.Backend*§
__init__3torch._C._distributed_c10d.ProcessGroupMPI.__init__"
None*b
selfX
*torch._C._distributed_c10d.ProcessGroupMPI"*torch._C._distributed_c10d.ProcessGroupMPI*&
rank
builtins.int"builtins.int*&
size
builtins.int"builtins.int*(
pgComm
builtins.int"builtins.int*þ
create1torch._C._distributed_c10d.ProcessGroupMPI.create"X
*torch._C._distributed_c10d.ProcessGroupMPI"*torch._C._distributed_c10d.ProcessGroupMPI*U
ranksJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list0:staticmethodhÁ
ProcessGroupNCCL+torch._C._distributed_c10d.ProcessGroupNCCL""torch._C._distributed_c10d.Backend*ˆ
__init__4torch._C._distributed_c10d.ProcessGroupNCCL.__init__"
None*d
selfZ
+torch._C._distributed_c10d.ProcessGroupNCCL"+torch._C._distributed_c10d.ProcessGroupNCCL*O
storeD
 torch._C._distributed_c10d.Store" torch._C._distributed_c10d.Store*&
rank
builtins.int"builtins.int*&
size
builtins.int"builtins.int*5
timeout(
datetime.timedelta"datetime.timedelta*¸
_group_start8torch._C._distributed_c10d.ProcessGroupNCCL._group_start"
None*d
selfZ
+torch._C._distributed_c10d.ProcessGroupNCCL"+torch._C._distributed_c10d.ProcessGroupNCCL*´

_group_end6torch._C._distributed_c10d.ProcessGroupNCCL._group_end"
None*d
selfZ
+torch._C._distributed_c10d.ProcessGroupNCCL"+torch._C._distributed_c10d.ProcessGroupNCCL*Þ
_set_default_timeout@torch._C._distributed_c10d.ProcessGroupNCCL._set_default_timeout"
None*d
selfZ
+torch._C._distributed_c10d.ProcessGroupNCCL"+torch._C._distributed_c10d.ProcessGroupNCCL*
timeout
Any*²
	_shutdown5torch._C._distributed_c10d.ProcessGroupNCCL._shutdown"
None*d
selfZ
+torch._C._distributed_c10d.ProcessGroupNCCL"+torch._C._distributed_c10d.ProcessGroupNCCL*È
uid/torch._C._distributed_c10d.ProcessGroupNCCL.uid"
builtins.int"builtins.int*d
selfZ
+torch._C._distributed_c10d.ProcessGroupNCCL"+torch._C._distributed_c10d.ProcessGroupNCCL0:property`û
ProcessGroupCudaP2P.torch._C._distributed_c10d.ProcessGroupCudaP2P""torch._C._distributed_c10d.Backend*Ù
__init__7torch._C._distributed_c10d.ProcessGroupCudaP2P.__init__"
None*j
self`
.torch._C._distributed_c10d.ProcessGroupCudaP2P".torch._C._distributed_c10d.ProcessGroupCudaP2P*O
storeD
 torch._C._distributed_c10d.Store" torch._C._distributed_c10d.Store*&
rank
builtins.int"builtins.int*&
size
builtins.int"builtins.int*}
optionsp
6torch._C._distributed_c10d.ProcessGroupCudaP2P.Options"6torch._C._distributed_c10d.ProcessGroupCudaP2P.Options*ß
is_p2p_available?torch._C._distributed_c10d.ProcessGroupCudaP2P.is_p2p_available"
builtins.bool"builtins.bool*j
self`
.torch._C._distributed_c10d.ProcessGroupCudaP2P".torch._C._distributed_c10d.ProcessGroupCudaP2P*Û
get_buffer_size>torch._C._distributed_c10d.ProcessGroupCudaP2P.get_buffer_size"
builtins.int"builtins.int*j
self`
.torch._C._distributed_c10d.ProcessGroupCudaP2P".torch._C._distributed_c10d.ProcessGroupCudaP2P*ã
stream5torch._C._distributed_c10d.ProcessGroupCudaP2P.stream"6
torch.cuda.streams.Stream"torch.cuda.streams.Stream*j
self`
.torch._C._distributed_c10d.ProcessGroupCudaP2P".torch._C._distributed_c10d.ProcessGroupCudaP2P*‡
intra_node_barrierAtorch._C._distributed_c10d.ProcessGroupCudaP2P.intra_node_barrier"B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*j
self`
.torch._C._distributed_c10d.ProcessGroupCudaP2P".torch._C._distributed_c10d.ProcessGroupCudaP2P*Å
get_p2p_buffer=torch._C._distributed_c10d.ProcessGroupCudaP2P.get_p2p_buffer",
torch._tensor.Tensor"torch._tensor.Tensor*j
self`
.torch._C._distributed_c10d.ProcessGroupCudaP2P".torch._C._distributed_c10d.ProcessGroupCudaP2P*&
rank
builtins.int"builtins.int*)
sizes
torch._C.Size"torch._C.Size*+
dtype 
torch._C.dtype"torch._C.dtype*Z
storage_offsetD
Union[builtins.int,None]
builtins.int"builtins.int
None *»
	_shutdown8torch._C._distributed_c10d.ProcessGroupCudaP2P._shutdown"
None*j
self`
.torch._C._distributed_c10d.ProcessGroupCudaP2P".torch._C._distributed_c10d.ProcessGroupCudaP2P¤	
ProcessGroupGloo+torch._C._distributed_c10d.ProcessGroupGloo""torch._C._distributed_c10d.Backend*ˆ
__init__4torch._C._distributed_c10d.ProcessGroupGloo.__init__"
None*d
selfZ
+torch._C._distributed_c10d.ProcessGroupGloo"+torch._C._distributed_c10d.ProcessGroupGloo*O
storeD
 torch._C._distributed_c10d.Store" torch._C._distributed_c10d.Store*&
rank
builtins.int"builtins.int*&
size
builtins.int"builtins.int*5
timeout(
datetime.timedelta"datetime.timedelta*ù
create_device9torch._C._distributed_c10d.ProcessGroupGloo.create_device"h
2torch._C._distributed_c10d.ProcessGroupGloo.Device"2torch._C._distributed_c10d.ProcessGroupGloo.Device*
hostname
Any *
	interface
Any 0:staticmethodh*Ö
create_default_deviceAtorch._C._distributed_c10d.ProcessGroupGloo.create_default_device"h
2torch._C._distributed_c10d.ProcessGroupGloo.Device"2torch._C._distributed_c10d.ProcessGroupGloo.Device0:staticmethodh*Þ
_set_default_timeout@torch._C._distributed_c10d.ProcessGroupGloo._set_default_timeout"
None*d
selfZ
+torch._C._distributed_c10d.ProcessGroupGloo"+torch._C._distributed_c10d.ProcessGroupGloo*
timeout
Anyé
ProcessGroupUCC*torch._C._distributed_c10d.ProcessGroupUCC""torch._C._distributed_c10d.Backend*…
__init__3torch._C._distributed_c10d.ProcessGroupUCC.__init__"
None*b
selfX
*torch._C._distributed_c10d.ProcessGroupUCC"*torch._C._distributed_c10d.ProcessGroupUCC*O
storeD
 torch._C._distributed_c10d.Store" torch._C._distributed_c10d.Store*&
rank
builtins.int"builtins.int*&
size
builtins.int"builtins.int*5
timeout(
datetime.timedelta"datetime.timedelta„
Backend*torch.distributed.distributed_c10d.Backend"builtins.str*
__new__2torch.distributed.distributed_c10d.Backend.__new__"
Any*ž
cls”
0Type[torch.distributed.distributed_c10d.Backend]X
*torch.distributed.distributed_c10d.Backend"*torch.distributed.distributed_c10d.Backend"type*&
name
builtins.str"builtins.str*
register_backend;torch.distributed.distributed_c10d.Backend.register_backend"
None*ž
cls”
0Type[torch.distributed.distributed_c10d.Backend]X
*torch.distributed.distributed_c10d.Backend"*torch.distributed.distributed_c10d.Backend"type*
name
Any*
func
Any*
extended_api
Any *¼
devices¬
4Union[builtins.str,builtins.list[builtins.str],None]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None 0:classmethodpr_
	UNDEFINED4torch.distributed.distributed_c10d.Backend.UNDEFINED
builtins.str"builtins.strrU
GLOO/torch.distributed.distributed_c10d.Backend.GLOO
builtins.str"builtins.strrU
NCCL/torch.distributed.distributed_c10d.Backend.NCCL
builtins.str"builtins.strrS
UCC.torch.distributed.distributed_c10d.Backend.UCC
builtins.str"builtins.strrS
MPI.torch.distributed.distributed_c10d.Backend.MPI
builtins.str"builtins.strr¦
_plugins3torch.distributed.distributed_c10d.Backend._pluginsä
5builtins.dict[builtins.str,TypeAlias[Tuple[Any,Any]]]
builtins.str"builtins.str~
TypeAlias[Tuple[Any,Any]]$
Tuple[Any,Any]
Any
Any"9torch.distributed.distributed_c10d.Backend._BackendPlugin"builtins.dictr“
backend_list7torch.distributed.distributed_c10d.Backend.backend_listJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.listrÚ
default_device_backend_mapEtorch.distributed.distributed_c10d.Backend.default_device_backend_mapu
(builtins.dict[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"builtins.dictrˆ
backend_capability=torch.distributed.distributed_c10d.Backend.backend_capability²
7builtins.dict[builtins.str,builtins.list[builtins.str]]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list"builtins.dictr¼
backend_type_map;torch.distributed.distributed_c10d.Backend.backend_type_mapê
Obuiltins.dict[builtins.str,torch._C._distributed_c10d.ProcessGroup.BackendType]
builtins.str"builtins.strj
3torch._C._distributed_c10d.ProcessGroup.BackendType"3torch._C._distributed_c10d.ProcessGroup.BackendType"builtins.dict˜	
BackendConfig0torch.distributed.distributed_c10d.BackendConfig"builtins.object*¦
__init__9torch.distributed.distributed_c10d.BackendConfig.__init__"
None*n
selfd
0torch.distributed.distributed_c10d.BackendConfig"0torch.distributed.distributed_c10d.BackendConfig*e
backendX
*torch.distributed.distributed_c10d.Backend"*torch.distributed.distributed_c10d.Backend*G
__repr__9torch.distributed.distributed_c10d.BackendConfig.__repr__* *£
get_device_backend_mapGtorch.distributed.distributed_c10d.BackendConfig.get_device_backend_map"Ï
Fbuiltins.dict[builtins.str,torch.distributed.distributed_c10d.Backend]
builtins.str"builtins.strX
*torch.distributed.distributed_c10d.Backend"*torch.distributed.distributed_c10d.Backend"builtins.dict*n
selfd
0torch.distributed.distributed_c10d.BackendConfig"0torch.distributed.distributed_c10d.BackendConfigr«
device_backend_mapCtorch.distributed.distributed_c10d.BackendConfig.device_backend_mapÏ
Fbuiltins.dict[builtins.str,torch.distributed.distributed_c10d.Backend]
builtins.str"builtins.strX
*torch.distributed.distributed_c10d.Backend"*torch.distributed.distributed_c10d.Backend"builtins.dictþ
P2POp(torch.distributed.distributed_c10d.P2POp"builtins.object*­
__init__1torch.distributed.distributed_c10d.P2POp.__init__"
None*^
selfT
(torch.distributed.distributed_c10d.P2POp"(torch.distributed.distributed_c10d.P2POp*S
opK
CallableType[builtins.function]&
builtins.function"builtins.function*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
peer
builtins.int"builtins.int*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None *'
tag
builtins.int"builtins.int *å
__new__0torch.distributed.distributed_c10d.P2POp.__new__"
Any*˜
clsŽ
.Type[torch.distributed.distributed_c10d.P2POp]T
(torch.distributed.distributed_c10d.P2POp"(torch.distributed.distributed_c10d.P2POp"type*S
opK
CallableType[builtins.function]&
builtins.function"builtins.function*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*&
peer
builtins.int"builtins.int*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None *'
tag
builtins.int"builtins.int *?
__repr__1torch.distributed.distributed_c10d.P2POp.__repr__* r~
op+torch.distributed.distributed_c10d.P2POp.opK
CallableType[builtins.function]&
builtins.function"builtins.functionrg
tensor/torch.distributed.distributed_c10d.P2POp.tensor,
torch._tensor.Tensor"torch._tensor.TensorrS
peer-torch.distributed.distributed_c10d.P2POp.peer
builtins.int"builtins.intrÏ
group.torch.distributed.distributed_c10d.P2POp.group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
NonerQ
tag,torch.distributed.distributed_c10d.P2POp.tag
builtins.int"builtins.ints
group(torch.distributed.distributed_c10d.group"builtins.object@b-torch.distributed.distributed_c10d._WorldMetaò
GroupMember.torch.distributed.distributed_c10d.GroupMember"builtins.object@b-torch.distributed.distributed_c10d._WorldMetarq
NON_GROUP_MEMBER?torch.distributed.distributed_c10d.GroupMember.NON_GROUP_MEMBER
builtins.int"builtins.intç
_CoalescingManager5torch.distributed.distributed_c10d._CoalescingManager"builtins.object*T
__init__>torch.distributed.distributed_c10d._CoalescingManager.__init__*
self*—
append<torch.distributed.distributed_c10d._CoalescingManager.append"
Any*x
selfn
5torch.distributed.distributed_c10d._CoalescingManager"5torch.distributed.distributed_c10d._CoalescingManager*L
workB
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work*L
wait:torch.distributed.distributed_c10d._CoalescingManager.wait*
selfrÊ
works;torch.distributed.distributed_c10d._CoalescingManager.worksƒ
.builtins.list[torch._C._distributed_c10d.Work]B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work"builtins.list©
_remote_device.torch.distributed.remote_device._remote_device"builtins.object*·
__init__7torch.distributed.remote_device._remote_device.__init__"
None*j
self`
.torch.distributed.remote_device._remote_device".torch.distributed.remote_device._remote_device*|
remote_devicei
#Union[builtins.str,torch._C.device]
builtins.str"builtins.str"
torch._C.device"torch._C.device*}
_is_valid_local_deviceEtorch.distributed.remote_device._remote_device._is_valid_local_device*

device0:staticmethodh*û
worker_name:torch.distributed.remote_device._remote_device.worker_name"D
Union[builtins.str,None]
builtins.str"builtins.str
None*j
self`
.torch.distributed.remote_device._remote_device".torch.distributed.remote_device._remote_device*í
rank3torch.distributed.remote_device._remote_device.rank"D
Union[builtins.int,None]
builtins.int"builtins.int
None*j
self`
.torch.distributed.remote_device._remote_device".torch.distributed.remote_device._remote_device*Ï
device5torch.distributed.remote_device._remote_device.device""
torch._C.device"torch._C.device*j
self`
.torch.distributed.remote_device._remote_device".torch.distributed.remote_device._remote_device*E
__repr__7torch.distributed.remote_device._remote_device.__repr__* *C
__eq__5torch.distributed.remote_device._remote_device.__eq__* * *M
__hash__7torch.distributed.remote_device._remote_device.__hash__*
selfr‘
_worker_name;torch.distributed.remote_device._remote_device._worker_nameD
Union[builtins.str,None]
builtins.str"builtins.str
Nonerƒ
_rank4torch.distributed.remote_device._remote_device._rankD
Union[builtins.int,None]
builtins.int"builtins.int
Nonerç
_device6torch.distributed.remote_device._remote_device._device£
5Union[builtins.str,builtins.int,torch._C.device,None]
builtins.str"builtins.str
builtins.int"builtins.int"
torch._C.device"torch._C.device
None®V

DeviceMesh(torch.distributed.device_mesh.DeviceMesh"builtins.object*†
__init__1torch.distributed.device_mesh.DeviceMesh.__init__"
None*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*-
device_type
builtins.str"builtins.str*Ú
meshÏ
èUnion[torch._tensor.Tensor,TypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]]],
torch._tensor.Tensor"torch._tensor.Tensor±
ÌTypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]]¸
ÁTypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]Å	
¶Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]Ó
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArray‚
znumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]]Ó
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArray".numpy._typing._nested_sequence._NestedSequenceU
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.objectÕ
Lnumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]U
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.object".numpy._typing._nested_sequence._NestedSequence"(numpy._typing._array_like._DualArrayLike"#numpy._typing._array_like.ArrayLike*›
mesh_dim_names„
(Union[builtins.tuple[builtins.str],None]L
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple
None *3
_init_backend
builtins.bool"builtins.bool *o
_get_or_create_default_groupEtorch.distributed.device_mesh.DeviceMesh._get_or_create_default_group*
self*_
_init_process_groups=torch.distributed.device_mesh.DeviceMesh._init_process_groups*
self*í
	__enter__2torch.distributed.device_mesh.DeviceMesh.__enter__"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*À
__exit__1torch.distributed.device_mesh.DeviceMesh.__exit__"
None*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*	
Any*	
Any*	
Any*³
__repr__1torch.distributed.device_mesh.DeviceMesh.__repr__"
builtins.str"builtins.str*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*G
__hash__1torch.distributed.device_mesh.DeviceMesh.__hash__*
self*×
__eq__/torch.distributed.device_mesh.DeviceMesh.__eq__"
builtins.bool"builtins.bool*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*$"
builtins.object"builtins.object*—
__getitem__4torch.distributed.device_mesh.DeviceMesh.__getitem__"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*£ 
0Union[builtins.str,builtins.tuple[builtins.str]]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple*ô
	get_group2torch.distributed.device_mesh.DeviceMesh.get_group"R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*
mesh_dimo
%Union[builtins.int,builtins.str,None]
builtins.int"builtins.int
builtins.str"builtins.str
None *Ç
get_all_groups7torch.distributed.device_mesh.DeviceMesh.get_all_groups"›
6builtins.list[torch._C._distributed_c10d.ProcessGroup]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup"builtins.list*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*Î

from_group3torch.distributed.device_mesh.DeviceMesh.from_group"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*ç
groupÛ
eUnion[torch._C._distributed_c10d.ProcessGroup,builtins.list[torch._C._distributed_c10d.ProcessGroup]]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup›
6builtins.list[torch._C._distributed_c10d.ProcessGroup]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup"builtins.list*-
device_type
builtins.str"builtins.str*ë
meshÞ
íUnion[torch._tensor.Tensor,TypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]],None],
torch._tensor.Tensor"torch._tensor.Tensor±
ÌTypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]]¸
ÁTypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]Å	
¶Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]Ó
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArray‚
znumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]]Ó
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArray".numpy._typing._nested_sequence._NestedSequenceU
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.objectÕ
Lnumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]U
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.object".numpy._typing._nested_sequence._NestedSequence"(numpy._typing._array_like._DualArrayLike"#numpy._typing._array_like.ArrayLike
None *›
mesh_dim_names„
(Union[builtins.tuple[builtins.str],None]L
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple
None 0:staticmethodh*‰
size-torch.distributed.device_mesh.DeviceMesh.size"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*T
mesh_dimD
Union[builtins.int,None]
builtins.int"builtins.int
None *Á
ndim-torch.distributed.device_mesh.DeviceMesh.ndim"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh0:property`*ó
shape.torch.distributed.device_mesh.DeviceMesh.shape"L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh0:property`*»
get_rank1torch.distributed.device_mesh.DeviceMesh.get_rank"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*È
get_local_rank7torch.distributed.device_mesh.DeviceMesh.get_local_rank"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*
mesh_dimo
%Union[builtins.int,builtins.str,None]
builtins.int"builtins.int
builtins.str"builtins.str
None *­
get_coordinate7torch.distributed.device_mesh.DeviceMesh.get_coordinate"
'Union[builtins.list[builtins.int],None]J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
None*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshra
device_type4torch.distributed.device_mesh.DeviceMesh.device_type
builtins.str"builtins.strrc
mesh-torch.distributed.device_mesh.DeviceMesh.mesh,
torch._tensor.Tensor"torch._tensor.TensorrÐ
mesh_dim_names7torch.distributed.device_mesh.DeviceMesh.mesh_dim_names„
(Union[builtins.tuple[builtins.str],None]L
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple
Noner
_flatten_mesh_list;torch.distributed.device_mesh.DeviceMesh._flatten_mesh_list.
builtins.tuple[Any]
Any"builtins.tuplerà
_parent_mesh5torch.distributed.device_mesh.DeviceMesh._parent_mesh˜
4Union[torch.distributed.device_mesh.DeviceMesh,None]T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh
Noner_

_thread_id3torch.distributed.device_mesh.DeviceMesh._thread_id
builtins.int"builtins.intrÕ
_coordinate_on_dim;torch.distributed.device_mesh.DeviceMesh._coordinate_on_dim
'Union[builtins.list[builtins.int],None]J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
NonerV
_dim_group_infos9torch.distributed.device_mesh.DeviceMesh._dim_group_infos
Anyr@
_hash.torch.distributed.device_mesh.DeviceMesh._hash
AnyI
_ProcessGroupStub#torch.distributed._ProcessGroupStub"builtins.objectN
is_availabletorch.distributed.is_available"
builtins.bool"builtins.bool]

breakpointtorch.distributed.breakpoint"
Any*(
rank
builtins.int"builtins.int Á
supports_complex3torch.distributed.distributed_c10d.supports_complex"
builtins.bool"builtins.bool*X
reduceOpJ
#torch._C._distributed_c10d.ReduceOp"#torch._C._distributed_c10d.ReduceOpï
get_group_rank1torch.distributed.distributed_c10d.get_group_rank"
builtins.int"builtins.int*]
groupR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*-
global_rank
builtins.int"builtins.intð
get_global_rank2torch.distributed.distributed_c10d.get_global_rank"
builtins.int"builtins.int*]
groupR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*,

group_rank
builtins.int"builtins.int€
get_process_group_ranks:torch.distributed.distributed_c10d.get_process_group_ranks"J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*]
groupR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroupg
is_mpi_available3torch.distributed.distributed_c10d.is_mpi_available"
builtins.bool"builtins.booli
is_nccl_available4torch.distributed.distributed_c10d.is_nccl_available"
builtins.bool"builtins.booli
is_gloo_available4torch.distributed.distributed_c10d.is_gloo_available"
builtins.bool"builtins.boolg
is_ucc_available3torch.distributed.distributed_c10d.is_ucc_available"
builtins.bool"builtins.boolš
is_backend_available7torch.distributed.distributed_c10d.is_backend_available"
builtins.bool"builtins.bool*)
backend
builtins.str"builtins.strc
is_initialized1torch.distributed.distributed_c10d.is_initialized"
builtins.bool"builtins.boolw
is_torchelastic_launched;torch.distributed.distributed_c10d.is_torchelastic_launched"
builtins.bool"builtins.bool
get_backend_config5torch.distributed.distributed_c10d.get_backend_config"
builtins.str"builtins.str*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None ½
get_backend.torch.distributed.distributed_c10d.get_backend"X
*torch.distributed.distributed_c10d.Backend"*torch.distributed.distributed_c10d.Backend*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None ]
get_pg_count/torch.distributed.distributed_c10d.get_pg_count"
builtins.int"builtins.intÆ
get_node_local_rank6torch.distributed.distributed_c10d.get_node_local_rank"
builtins.int"builtins.int*Y
fallback_rankD
Union[builtins.int,None]
builtins.int"builtins.int
None €
destroy_process_group8torch.distributed.distributed_c10d.destroy_process_group"
Any*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None û
get_rank+torch.distributed.distributed_c10d.get_rank"
builtins.int"builtins.int*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None ‡
get_world_size1torch.distributed.distributed_c10d.get_world_size"
builtins.int"builtins.int*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None à
isend(torch.distributed.distributed_c10d.isend"}
+Union[torch._C._distributed_c10d.Work,None]B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work
None*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*%
dst
builtins.int"builtins.int*£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None *'
tag
builtins.int"builtins.int Š
irecv(torch.distributed.distributed_c10d.irecv"}
+Union[torch._C._distributed_c10d.Work,None]B
torch._C._distributed_c10d.Work"torch._C._distributed_c10d.Work
None*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*O
srcD
Union[builtins.int,None]
builtins.int"builtins.int
None *£
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
None *'
tag
builtins.int"builtins.int Z
batch_isend_irecv4torch.distributed.distributed_c10d.batch_isend_irecv*
p2p_op_list{
monitored_barrier4torch.distributed.distributed_c10d.monitored_barrier*
group *
timeout *
wait_all_ranks ¢
new_subgroups0torch.distributed.distributed_c10d.new_subgroups*

group_size *
group *
timeout *
backend *

pg_options *

group_desc ¾
new_subgroups_by_enumeration?torch.distributed.distributed_c10d.new_subgroups_by_enumeration*
ranks_per_subgroup_list*
timeout *
backend *

pg_options *

group_desc Ô
_create_process_group_wrapper@torch.distributed.distributed_c10d._create_process_group_wrapper"
Any*X

wrapped_pgH
"torch._C._distributed_c10d.Backend""torch._C._distributed_c10d.Backend*.
store_prefix
builtins.str"builtins.str*O
storeD
 torch._C._distributed_c10d.Store" torch._C._distributed_c10d.Store*&
rank
builtins.int"builtins.int*,

world_size
builtins.int"builtins.int*7
timeout(
datetime.timedelta"datetime.timedelta 
_rank_not_in_group5torch.distributed.distributed_c10d._rank_not_in_group"
builtins.bool"builtins.bool*¡
group•
3Union[torch._C._distributed_c10d.ProcessGroup,None]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup
NoneÏ
_get_process_group_name:torch.distributed.distributed_c10d._get_process_group_name"
builtins.str"builtins.str*Z
pgR
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroupÔ

rendezvous'torch.distributed.rendezvous.rendezvous"
Any*%
url
builtins.str"builtins.str*(
rank
builtins.int"builtins.int *.

world_size
builtins.int"builtins.int *
kwargs
Anyt
_create_store_from_options7torch.distributed.rendezvous._create_store_from_options*
backend_options*
rankp
register_rendezvous_handler8torch.distributed.rendezvous.register_rendezvous_handler*

scheme*
handlerÃ
init_device_mesh.torch.distributed.device_mesh.init_device_mesh"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*-
device_type
builtins.str"builtins.str*\

mesh_shapeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple*›
mesh_dim_names„
(Union[builtins.tuple[builtins.str],None]L
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple
None *r
__path__torch.distributed.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*
__annotations__!torch.distributed.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*n
default_pg_timeout.torch.distributed.constants.default_pg_timeout(
datetime.timedelta"datetime.timedelta*™
	reduce_op,torch.distributed.distributed_c10d.reduce_op^
-torch.distributed.distributed_c10d._reduce_op"-torch.distributed.distributed_c10d._reduce_op