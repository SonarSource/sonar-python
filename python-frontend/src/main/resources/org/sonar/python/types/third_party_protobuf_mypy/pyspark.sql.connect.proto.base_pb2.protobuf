
"pyspark.sql.connect.proto.base_pb2·
Plan'pyspark.sql.connect.proto.base_pb2.Plan"builtins.object*è
root,pyspark.sql.connect.proto.base_pb2.Plan.root"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan0:builtins.property`*ë
command/pyspark.sql.connect.proto.base_pb2.Plan.command"`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan0:builtins.property`*°
__init__0pyspark.sql.connect.proto.base_pb2.Plan.__init__"
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*Ω
root∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *∫
command™
:Union[pyspark.sql.connect.proto.commands_pb2.Command,None]`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command
None *À
HasField0pyspark.sql.connect.proto.base_pb2.Plan.HasField"
builtins.bool"builtins.bool*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearField2pyspark.sql.connect.proto.base_pb2.Plan.ClearField"
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ù

WhichOneof2pyspark.sql.connect.proto.base_pb2.Plan.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrI

DESCRIPTOR2pyspark.sql.connect.proto.base_pb2.Plan.DESCRIPTOR
Anyrl
ROOT_FIELD_NUMBER9pyspark.sql.connect.proto.base_pb2.Plan.ROOT_FIELD_NUMBER
builtins.int"builtins.intrr
COMMAND_FIELD_NUMBER<pyspark.sql.connect.proto.base_pb2.Plan.COMMAND_FIELD_NUMBER
builtins.int"builtins.intî
UserContext.pyspark.sql.connect.proto.base_pb2.UserContext"builtins.object*”

extensions9pyspark.sql.connect.proto.base_pb2.UserContext.extensions"
Any*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext0:builtins.property`*â
__init__7pyspark.sql.connect.proto.base_pb2.UserContext.__init__"
None*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*+
user_id
builtins.str"builtins.str *-
	user_name
builtins.str"builtins.str *r

extensions`
 Union[typing.Iterable[Any],None]0
typing.Iterable[Any]
Any"typing.Iterable
None *Œ

ClearField9pyspark.sql.connect.proto.base_pb2.UserContext.ClearField"
None*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.base_pb2.UserContext.DESCRIPTOR
Anyry
USER_ID_FIELD_NUMBERCpyspark.sql.connect.proto.base_pb2.UserContext.USER_ID_FIELD_NUMBER
builtins.int"builtins.intr}
USER_NAME_FIELD_NUMBEREpyspark.sql.connect.proto.base_pb2.UserContext.USER_NAME_FIELD_NUMBER
builtins.int"builtins.intr
EXTENSIONS_FIELD_NUMBERFpyspark.sql.connect.proto.base_pb2.UserContext.EXTENSIONS_FIELD_NUMBER
builtins.int"builtins.intr_
user_id6pyspark.sql.connect.proto.base_pb2.UserContext.user_id
builtins.str"builtins.strrc
	user_name8pyspark.sql.connect.proto.base_pb2.UserContext.user_name
builtins.str"builtins.strÃ¨
AnalyzePlanRequest5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"builtins.object*≈
user_contextBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*’
schema<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.schema"|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ÿ
explain=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.explain"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ë
tree_stringApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.tree_string"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*€
is_local>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.is_local"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ï
is_streamingBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.is_streaming"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ë
input_filesApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.input_files"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*
spark_versionCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.spark_version"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*‡
	ddl_parse?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.ddl_parse"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ù
same_semanticsDpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.same_semantics"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*
semantic_hashCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.semantic_hash"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ÿ
persist=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.persist"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*‚
	unpersist?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.unpersist"Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*˛
get_storage_levelGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.get_storage_level"é
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*û
__init__>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.__init__"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *„
schema‘
HUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema,None]|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema
None *Á
explain◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain
None *ı
tree_string·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString
None *Ë
is_local◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal
None *˘
is_streaming‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming
None *ı
input_files·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles
None *˝
spark_versionÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion
None *Ì
	ddl_parse€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse
None *Å
same_semanticsÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics
None *˝
semantic_hashÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash
None *Á
persist◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist
None *
	unpersistﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist,None]Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist
None *ä
get_storage_level
QUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel,None]é
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel
None *â
HasField>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¢

field_nameë
îUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ù

ClearField@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*»

field_name∑
¬Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¢

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX¬

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneof"ù
©Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DESCRIPTOR
AnyrÜ
SESSION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.inträ
USER_CONTEXT_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrà
CLIENT_TYPE_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intr~
SCHEMA_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÄ
EXPLAIN_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrà
TREE_STRING_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrÇ
IS_LOCAL_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.inträ
IS_STREAMING_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intrà
INPUT_FILES_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.INPUT_FILES_FIELD_NUMBER
builtins.int"builtins.intrå
SPARK_VERSION_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SPARK_VERSION_FIELD_NUMBER
builtins.int"builtins.intrÑ
DDL_PARSE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDL_PARSE_FIELD_NUMBER
builtins.int"builtins.intré
SAME_SEMANTICS_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SAME_SEMANTICS_FIELD_NUMBER
builtins.int"builtins.intrå
SEMANTIC_HASH_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SEMANTIC_HASH_FIELD_NUMBER
builtins.int"builtins.intrÄ
PERSIST_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.PERSIST_FIELD_NUMBER
builtins.int"builtins.intrÑ
UNPERSIST_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.UNPERSIST_FIELD_NUMBER
builtins.int"builtins.intrî
GET_STORAGE_LEVEL_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GET_STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrl

session_id@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.session_id
builtins.str"builtins.strrn
client_typeApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.client_type
builtins.str"builtins.strz˜
Schema<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"builtins.object*Ω
planApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema0:builtins.property`*â
__init__Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *æ
HasFieldEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.HasField"
builtins.bool"builtins.bool*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

ClearFieldGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.DESCRIPTOR
AnyrÅ
PLAN_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.PLAN_FIELD_NUMBER
builtins.int"builtins.intzŸ9
Explain=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"builtins.object*¿
planBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain0:builtins.property`*–
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *¡
explain_mode¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType *¡
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*’

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.DESCRIPTOR
Anyr°
EXPLAIN_MODE_UNSPECIFIEDVpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_UNSPECIFIED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperó
EXPLAIN_MODE_SIMPLEQpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_SIMPLE¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperõ
EXPLAIN_MODE_EXTENDEDSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_EXTENDED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperô
EXPLAIN_MODE_CODEGENRpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_CODEGEN¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperì
EXPLAIN_MODE_COSTOpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_COST¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperù
EXPLAIN_MODE_FORMATTEDTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_FORMATTED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperÇ
PLAN_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.PLAN_FIELD_NUMBER
builtins.int"builtins.intrí
EXPLAIN_MODE_FIELD_NUMBERWpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_FIELD_NUMBER
builtins.int"builtins.intrâ
explain_modeJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.explain_mode¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTypezµ
_ExplainModeJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode"builtins.objectz«
	ValueTypeTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"builtins.int*’
__init__]pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType.__init__"
None*∑
self¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType*&
item
builtins.int"builtins.intz⁄
_ExplainModeEnumTypeWrapperYpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper"builtins.typer{

DESCRIPTORdpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.DESCRIPTOR
AnyrΩ
EXPLAIN_MODE_UNSPECIFIEDrpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_UNSPECIFIED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyper≥
EXPLAIN_MODE_SIMPLEmpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_SIMPLE¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyper∑
EXPLAIN_MODE_EXTENDEDopyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_EXTENDED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperµ
EXPLAIN_MODE_CODEGENnpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_CODEGEN¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperØ
EXPLAIN_MODE_COSTkpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_COST¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperπ
EXPLAIN_MODE_FORMATTEDppyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_FORMATTED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTypezÅ
ExplainModeIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.ExplainMode"Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode@bYpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapperzæ

TreeString@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"builtins.object* 
planEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString0:builtins.property`*È
__init__Ipyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *Q
levelD
Union[builtins.int,None]
builtins.int"builtins.int
None *ò
HasFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.HasField"
builtins.bool"builtins.bool*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ü

ClearFieldKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ö

WhichOneofKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.DESCRIPTOR
AnyrÖ
PLAN_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.PLAN_FIELD_NUMBER
builtins.int"builtins.intrá
LEVEL_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.LEVEL_FIELD_NUMBER
builtins.int"builtins.intrm
levelFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.level
builtins.int"builtins.intzá
IsLocal=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"builtins.object*¿
planBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal0:builtins.property`*å
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *¡
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ø

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.DESCRIPTOR
AnyrÇ
PLAN_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.PLAN_FIELD_NUMBER
builtins.int"builtins.intzÀ
IsStreamingApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"builtins.object*Õ
planFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming0:builtins.property`*ô
__init__Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *Œ
HasFieldJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.HasField"
builtins.bool"builtins.bool*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*º

ClearFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.DESCRIPTOR
AnyrÜ
PLAN_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.PLAN_FIELD_NUMBER
builtins.int"builtins.intzª

InputFiles@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"builtins.object* 
planEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles0:builtins.property`*ñ
__init__Ipyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *À
HasFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.HasField"
builtins.bool"builtins.bool*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearFieldKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.DESCRIPTOR
AnyrÖ
PLAN_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.PLAN_FIELD_NUMBER
builtins.int"builtins.intz√
SparkVersionBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"builtins.object*˜
__init__Kpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersionrd

DESCRIPTORMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion.DESCRIPTOR
Anyzö	
DDLParse>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse"builtins.object*õ
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse*.

ddl_string
builtins.str"builtins.str *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.DESCRIPTOR
Anyrè
DDL_STRING_FIELD_NUMBERVpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.DDL_STRING_FIELD_NUMBER
builtins.int"builtins.intru

ddl_stringIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.ddl_string
builtins.str"builtins.strz˛
SameSemanticsCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"builtins.object*·
target_planOpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.target_plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics0:builtins.property`*ﬂ

other_planNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.other_plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics0:builtins.property`*—
__init__Lpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*©
target_planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *®

other_planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *˙
HasFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

ClearFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.DESCRIPTOR
Anyrñ
TARGET_PLAN_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.TARGET_PLAN_FIELD_NUMBER
builtins.int"builtins.intrî
OTHER_PLAN_FIELD_NUMBER[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.OTHER_PLAN_FIELD_NUMBER
builtins.int"builtins.intz€
SemanticHashBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"builtins.object*–
planGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash0:builtins.property`*ú
__init__Kpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *—
HasFieldKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.HasField"
builtins.bool"builtins.bool*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ø

ClearFieldMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.DESCRIPTOR
Anyrá
PLAN_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.PLAN_FIELD_NUMBER
builtins.int"builtins.intz¡
Persist=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"builtins.object*⁄
relationFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist0:builtins.property`*Ê
storage_levelKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.storage_level"f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist0:builtins.property`*˜
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *…
storage_level≥
=Union[pyspark.sql.connect.proto.common_pb2.StorageLevel,None]f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel
None *é
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¸

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ê

WhichOneofHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.DESCRIPTOR
Anyrä
RELATION_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.RELATION_FIELD_NUMBER
builtins.int"builtins.intrî
STORAGE_LEVEL_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intz˛
	Unpersist?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"builtins.object*·
relationHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist0:builtins.property`*ã
__init__Hpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *W
blockingG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *ï
HasFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearFieldJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ó

WhichOneofJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.DESCRIPTOR
Anyrå
RELATION_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.RELATION_FIELD_NUMBER
builtins.int"builtins.intrå
BLOCKING_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.BLOCKING_FIELD_NUMBER
builtins.int"builtins.intrt
blockingHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.blocking
builtins.bool"builtins.boolzÃ
GetStorageLevelEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"builtins.object*Û
relationNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel0:builtins.property`*ƒ
__init__Npyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.__init__"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *⁄
HasFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.HasField"
builtins.bool"builtins.bool*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*»

ClearFieldPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.ClearField"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrg

DESCRIPTORPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.DESCRIPTOR
Anyrí
RELATION_FIELD_NUMBER[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.RELATION_FIELD_NUMBER
builtins.int"builtins.int∆ã
AnalyzePlanResponse6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"builtins.object*⁄
schema=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.schema"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ﬂ
explain>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.explain"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Ì
tree_stringBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.tree_string"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*·
is_local?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.is_local"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Ò
is_streamingCpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.is_streaming"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Ì
input_filesBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.input_files"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ı
spark_versionDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.spark_version"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Â
	ddl_parse@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.ddl_parse"Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*˘
same_semanticsEpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.same_semantics"å
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ı
semantic_hashDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.semantic_hash"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ﬂ
persist>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.persist"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Á
	unpersist@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.unpersist"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*É
get_storage_levelHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.get_storage_level"ê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*∞
__init__?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*.

session_id
builtins.str"builtins.str *Ê
schema◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema
None *Î
explain€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain
None *¯
tree_string‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString
None *Ï
is_local€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal
None *¸
is_streamingÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming
None *¯
input_files‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles
None *Ä
spark_versionÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion
None *
	ddl_parseﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse,None]Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse
None *Ñ
same_semanticsÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics,None]å
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics
None *Ä
semantic_hashÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash
None *Î
persist€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist
None *Û
	unpersist·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist
None *ç
get_storage_levelÛ
RUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel,None]ê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel
None *ö
HasField?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*∞

field_nameü
äUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*÷

field_name≈
∏Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∞

WhichOneofApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.WhichOneof"ù
©Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intr
SCHEMA_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÅ
EXPLAIN_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrâ
TREE_STRING_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrÉ
IS_LOCAL_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.intrã
IS_STREAMING_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intrâ
INPUT_FILES_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.INPUT_FILES_FIELD_NUMBER
builtins.int"builtins.intrç
SPARK_VERSION_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SPARK_VERSION_FIELD_NUMBER
builtins.int"builtins.intrÖ
DDL_PARSE_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDL_PARSE_FIELD_NUMBER
builtins.int"builtins.intrè
SAME_SEMANTICS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SAME_SEMANTICS_FIELD_NUMBER
builtins.int"builtins.intrç
SEMANTIC_HASH_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SEMANTIC_HASH_FIELD_NUMBER
builtins.int"builtins.intrÅ
PERSIST_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.PERSIST_FIELD_NUMBER
builtins.int"builtins.intrÖ
UNPERSIST_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.UNPERSIST_FIELD_NUMBER
builtins.int"builtins.intrï
GET_STORAGE_LEVEL_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GET_STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.session_id
builtins.str"builtins.strz©
Schema=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"builtins.object*Œ
schemaDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema0:builtins.property`*ù
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *¡
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ø

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.DESCRIPTOR
AnyrÜ
SCHEMA_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intz≠	
Explain>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain"builtins.object*ü
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain*2
explain_string
builtins.str"builtins.str *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.DESCRIPTOR
Anyró
EXPLAIN_STRING_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.EXPLAIN_STRING_FIELD_NUMBER
builtins.int"builtins.intr}
explain_stringMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.explain_string
builtins.str"builtins.strzø	

TreeStringApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"builtins.object*•
__init__Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString*/
tree_string
builtins.str"builtins.str *º

ClearFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.DESCRIPTOR
Anyrî
TREE_STRING_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrz
tree_stringMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.tree_string
builtins.str"builtins.strzì	
IsLocal>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal"builtins.object*õ
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal*.
is_local
builtins.bool"builtins.bool *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.DESCRIPTOR
Anyrã
IS_LOCAL_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.intrs
is_localGpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.is_local
builtins.bool"builtins.boolz”	
IsStreamingBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"builtins.object*´
__init__Kpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming*2
is_streaming
builtins.bool"builtins.bool *ø

ClearFieldMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.DESCRIPTOR
Anyró
IS_STREAMING_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intr
is_streamingOpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.is_streaming
builtins.bool"builtins.boolz•

InputFilesApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"builtins.object*Ñ
filesGpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.files"
Any*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles0:builtins.property`*å
__init__Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles*ï
filesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *º

ClearFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.DESCRIPTOR
Anyrà
FILES_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.FILES_FIELD_NUMBER
builtins.int"builtins.intz¡	
SparkVersionCpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"builtins.object*ß
__init__Lpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion*+
version
builtins.str"builtins.str *¬

ClearFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.DESCRIPTOR
Anyré
VERSION_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.VERSION_FIELD_NUMBER
builtins.int"builtins.intrt
versionKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.version
builtins.str"builtins.strzÕ
DDLParse?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"builtins.object*’
parsedFpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.parsed"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse0:builtins.property`*§
__init__Hpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*≥
parsed§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *»
HasFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearFieldJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.DESCRIPTOR
Anyrà
PARSED_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.PARSED_FIELD_NUMBER
builtins.int"builtins.intzÀ	
SameSemanticsDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"builtins.object*´
__init__Mpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics*,
result
builtins.bool"builtins.bool *≈

ClearFieldOpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.DESCRIPTOR
Anyrç
RESULT_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.RESULT_FIELD_NUMBER
builtins.int"builtins.intru
resultKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.result
builtins.bool"builtins.boolzº	
SemanticHashCpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"builtins.object*¶
__init__Lpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash**
result
builtins.int"builtins.int *¬

ClearFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.DESCRIPTOR
Anyrå
RESULT_FIELD_NUMBERWpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.RESULT_FIELD_NUMBER
builtins.int"builtins.intrr
resultJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.result
builtins.int"builtins.intz™
Persist>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist"builtins.object*Î
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persistr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist.DESCRIPTOR
Anyz∂
	Unpersist@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"builtins.object*Ò
__init__Ipyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersistrb

DESCRIPTORKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist.DESCRIPTOR
Anyz˘
GetStorageLevelFpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"builtins.object*Ç
storage_levelTpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.storage_level"f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel0:builtins.property`*œ
__init__Opyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*…
storage_level≥
=Union[pyspark.sql.connect.proto.common_pb2.StorageLevel,None]f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel
None *›
HasFieldOpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.HasField"
builtins.bool"builtins.bool*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*À

ClearFieldQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.ClearField"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.DESCRIPTOR
Anyrù
STORAGE_LEVEL_FIELD_NUMBERapyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.int≠]
ExecutePlanRequest5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"builtins.object*≈
user_contextBpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*ß
plan:pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*Ú
request_optionsEpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.request_options"
Any*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*‹
tags:pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.tags"
Any*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*Ø

__init__>pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.__init__"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *X
operation_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *˝
request_optionsÂ
`Union[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption],None]Ù
Ttyping.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption]ä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"typing.Iterable
None *î
tagsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Á	
HasField>pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*«

ClearField@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ï

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXå

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.DESCRIPTOR
AnyrÜ
SESSION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.inträ
USER_CONTEXT_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.inträ
OPERATION_ID_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrz
PLAN_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.PLAN_FIELD_NUMBER
builtins.int"builtins.intrà
CLIENT_TYPE_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrê
REQUEST_OPTIONS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.REQUEST_OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrz
TAGS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.TAGS_FIELD_NUMBER
builtins.int"builtins.intrl

session_id@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.session_id
builtins.str"builtins.strrp
operation_idBpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.operation_id
builtins.str"builtins.strrn
client_typeApyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.client_type
builtins.str"builtins.strz—
RequestOptionCpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"builtins.object*Å
reattach_optionsTpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.reattach_options"h
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption0:builtins.property`*í
	extensionMpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.extension"
Any*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption0:builtins.property`*Ö
__init__Lpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*œ
reattach_options∂
>Union[pyspark.sql.connect.proto.base_pb2.ReattachOptions,None]h
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions
None *7
	extension&
Union[Any,None]
Any
None *°
HasFieldLpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*è

ClearFieldNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Û

WhichOneofNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.DESCRIPTOR
Anyr†
REATTACH_OPTIONS_FIELD_NUMBERapyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.REATTACH_OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrí
EXTENSION_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intùˇ
ExecutePlanResponse6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"builtins.object*Ì
arrow_batchBpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.arrow_batch"Ü
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*á
sql_command_resultIpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.sql_command_result"í
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ß
#write_stream_operation_start_resultZpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.write_stream_operation_start_result"ê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ï
streaming_query_command_resultUpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.streaming_query_command_result"à
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ç
get_resources_command_resultSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.get_resources_command_result"Ñ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*≥
&streaming_query_manager_command_result]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.streaming_query_manager_command_result"ñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*˝
result_completeFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.result_complete"é
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*È
	extension@pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.extension"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ﬂ
metrics>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.metrics"Ä
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*˜
observed_metricsGpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.observed_metrics"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*∏
schema=pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*“
__init__?pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*.

session_id
builtins.str"builtins.str *0
operation_id
builtins.str"builtins.str */
response_id
builtins.str"builtins.str *¯
arrow_batch‰
MUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch,None]Ü
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch
None *ë
sql_command_resultˆ
SUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult,None]í
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult
None *ü
#write_stream_operation_start_resultÛ
RUnion[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult,None]ê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult
None *é
streaming_query_command_resultÁ
NUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult,None]à
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult
None *Ü
get_resources_command_result·
LUnion[pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult,None]Ñ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult
None *´
&streaming_query_manager_command_result¸
UUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult,None]ñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult
None *à
result_complete
QUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete,None]é
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete
None *7
	extension&
Union[Any,None]
Any
None *Î
metrics€
JUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics,None]Ä
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics
None *ä
observed_metricsÒ
cUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics],None]˝
Wtyping.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics]ê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"typing.Iterable
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *®
HasField?pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*æ

field_name≠
ÄUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*÷

field_name≈
∏Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*•

WhichOneofApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.WhichOneof"í
ªUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
OPERATION_ID_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrâ
RESPONSE_ID_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intrâ
ARROW_BATCH_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ARROW_BATCH_FIELD_NUMBER
builtins.int"builtins.intró
SQL_COMMAND_RESULT_FIELD_NUMBERVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SQL_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrπ
0WRITE_STREAM_OPERATION_START_RESULT_FIELD_NUMBERgpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.WRITE_STREAM_OPERATION_START_RESULT_FIELD_NUMBER
builtins.int"builtins.intrØ
+STREAMING_QUERY_COMMAND_RESULT_FIELD_NUMBERbpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.STREAMING_QUERY_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intr´
)GET_RESOURCES_COMMAND_RESULT_FIELD_NUMBER`pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.GET_RESOURCES_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrø
3STREAMING_QUERY_MANAGER_COMMAND_RESULT_FIELD_NUMBERjpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.STREAMING_QUERY_MANAGER_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrë
RESULT_COMPLETE_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.RESULT_COMPLETE_FIELD_NUMBER
builtins.int"builtins.intrÖ
EXTENSION_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intrÅ
METRICS_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.METRICS_FIELD_NUMBER
builtins.int"builtins.intrì
OBSERVED_METRICS_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.OBSERVED_METRICS_FIELD_NUMBER
builtins.int"builtins.intr
SCHEMA_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.session_id
builtins.str"builtins.strrq
operation_idCpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.operation_id
builtins.str"builtins.strro
response_idBpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.response_id
builtins.str"builtins.strzÎ
SqlCommandResultGpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"builtins.object*˘
relationPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult0:builtins.property`* 
__init__Ppyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.__init__"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *‡
HasFieldPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.HasField"
builtins.bool"builtins.bool*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Œ

ClearFieldRpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.ClearField"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesri

DESCRIPTORRpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.DESCRIPTOR
Anyrî
RELATION_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.RELATION_FIELD_NUMBER
builtins.int"builtins.intzÑ

ArrowBatchApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"builtins.object*—
__init__Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch*-
	row_count
builtins.int"builtins.int *,
data 
builtins.bytes"builtins.bytes *‚

ClearFieldLpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.DESCRIPTOR
Anyrê
ROW_COUNT_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.ROW_COUNT_FIELD_NUMBER
builtins.int"builtins.intrÜ
DATA_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.DATA_FIELD_NUMBER
builtins.int"builtins.intrv
	row_countKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.row_count
builtins.int"builtins.intrp
dataFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.data 
builtins.bytes"builtins.byteszÜR
Metrics>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics"builtins.object*ˇ
metricsFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.metrics"
Any*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics0:builtins.property`*É
__init__Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*ï
metricsÖ
hUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject],None]å
\typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject]ö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"typing.Iterable
None *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.DESCRIPTOR
Anyrâ
METRICS_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.METRICS_FIELD_NUMBER
builtins.int"builtins.intzß3
MetricObjectKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"builtins.object*∫
execution_metrics]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.execution_metrics"
Any*•
selfö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject0:builtins.property`*Ë
__init__Tpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.__init__"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject*(
name
builtins.str"builtins.str *+
plan_id
builtins.int"builtins.int **
parent
builtins.int"builtins.int *–
execution_metrics∂
sUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue],None]≤
gtyping.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue]
builtins.str"builtins.strò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"typing.Mapping
None *Õ

ClearFieldVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ClearField"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrm

DESCRIPTORVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.DESCRIPTOR
Anyrê
NAME_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.NAME_FIELD_NUMBER
builtins.int"builtins.intrñ
PLAN_ID_FIELD_NUMBER`pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.PLAN_ID_FIELD_NUMBER
builtins.int"builtins.intrî
PARENT_FIELD_NUMBER_pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.PARENT_FIELD_NUMBER
builtins.int"builtins.intr™
EXECUTION_METRICS_FIELD_NUMBERjpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.EXECUTION_METRICS_FIELD_NUMBER
builtins.int"builtins.intrv
namePpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.name
builtins.str"builtins.strr|
plan_idSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.plan_id
builtins.int"builtins.intrz
parentRpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.parent
builtins.int"builtins.intzÔ
ExecutionMetricsEntryapyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"builtins.object*ˆ
valuegpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.value"ò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry0:builtins.property`*ç
__init__jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.__init__"
None*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry*'
key
builtins.str"builtins.str *ç
valueˇ
VUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue,None]ò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue
None *Æ
HasFieldjpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.HasField"
builtins.bool"builtins.bool*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¬

ClearFieldlpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.ClearField"
None*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrÉ

DESCRIPTORlpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.DESCRIPTOR
Anyr§
KEY_FIELD_NUMBERrpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr®
VALUE_FIELD_NUMBERtpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.inträ
keyepyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.key
builtins.str"builtins.strz”
MetricValueJpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"builtins.object*ï
__init__Spyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.__init__"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue*(
name
builtins.str"builtins.str *)
value
builtins.int"builtins.int */
metric_type
builtins.str"builtins.str *§

ClearFieldUpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.ClearField"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrl

DESCRIPTORUpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.DESCRIPTOR
Anyrè
NAME_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.NAME_FIELD_NUMBER
builtins.int"builtins.intrë
VALUE_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.VALUE_FIELD_NUMBER
builtins.int"builtins.intrù
METRIC_TYPE_FIELD_NUMBERcpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.METRIC_TYPE_FIELD_NUMBER
builtins.int"builtins.intru
nameOpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.name
builtins.str"builtins.strrw
valuePpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.value
builtins.int"builtins.intrÉ
metric_typeVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.metric_type
builtins.str"builtins.strz˝
ObservedMetricsFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"builtins.object*ï
valuesMpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.values"
Any*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics0:builtins.property`*á
__init__Opyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics*(
name
builtins.str"builtins.str *◊
values»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *Ò

ClearFieldQpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.ClearField"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.DESCRIPTOR
Anyrã
NAME_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.NAME_FIELD_NUMBER
builtins.int"builtins.intrè
VALUES_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.VALUES_FIELD_NUMBER
builtins.int"builtins.intrq
nameKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.name
builtins.str"builtins.strz‘
ResultCompleteEpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"builtins.object*Ä
__init__Npyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete.__init__"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultCompleterg

DESCRIPTORPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete.DESCRIPTOR
Any±
KeyValue+pyspark.sql.connect.proto.base_pb2.KeyValue"builtins.object*¨
__init__4pyspark.sql.connect.proto.base_pb2.KeyValue.__init__"
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*'
key
builtins.str"builtins.str *Q
valueD
Union[builtins.str,None]
builtins.str"builtins.str
None *∞
HasField4pyspark.sql.connect.proto.base_pb2.KeyValue.HasField"
builtins.bool"builtins.bool*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≈

ClearField6pyspark.sql.connect.proto.base_pb2.KeyValue.ClearField"
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ÿ

WhichOneof6pyspark.sql.connect.proto.base_pb2.KeyValue.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrM

DESCRIPTOR6pyspark.sql.connect.proto.base_pb2.KeyValue.DESCRIPTOR
Anyrn
KEY_FIELD_NUMBER<pyspark.sql.connect.proto.base_pb2.KeyValue.KEY_FIELD_NUMBER
builtins.int"builtins.intrr
VALUE_FIELD_NUMBER>pyspark.sql.connect.proto.base_pb2.KeyValue.VALUE_FIELD_NUMBER
builtins.int"builtins.intrT
key/pyspark.sql.connect.proto.base_pb2.KeyValue.key
builtins.str"builtins.strrX
value1pyspark.sql.connect.proto.base_pb2.KeyValue.value
builtins.str"builtins.strË√
ConfigRequest0pyspark.sql.connect.proto.base_pb2.ConfigRequest"builtins.object*∂
user_context=pyspark.sql.connect.proto.base_pb2.ConfigRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest0:builtins.property`*»
	operation:pyspark.sql.connect.proto.base_pb2.ConfigRequest.operation"x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest0:builtins.property`*Ì
__init__9pyspark.sql.connect.proto.base_pb2.ConfigRequest.__init__"
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *‡
	operationŒ
FUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation,None]x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *å
HasField9pyspark.sql.connect.proto.base_pb2.ConfigRequest.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*†

ClearField;pyspark.sql.connect.proto.base_pb2.ConfigRequest.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

WhichOneof;pyspark.sql.connect.proto.base_pb2.ConfigRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.base_pb2.ConfigRequest.DESCRIPTOR
AnyrÅ
SESSION_ID_FIELD_NUMBERHpyspark.sql.connect.proto.base_pb2.ConfigRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrÖ
USER_CONTEXT_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.ConfigRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intr
OPERATION_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigRequest.OPERATION_FIELD_NUMBER
builtins.int"builtins.intrÉ
CLIENT_TYPE_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.ConfigRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrg

session_id;pyspark.sql.connect.proto.base_pb2.ConfigRequest.session_id
builtins.str"builtins.strri
client_type<pyspark.sql.connect.proto.base_pb2.ConfigRequest.client_type
builtins.str"builtins.strzëK
	Operation:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation"builtins.object*œ
set>pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.set"l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*œ
get>pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get"l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*Ä
get_with_defaultKpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get_with_default"Ç
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*È

get_optionEpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get_option"x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*›
get_allBpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get_all"r
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*◊
unset@pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.unset"p
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*ı
is_modifiableHpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.is_modifiable"~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*Ì
__init__Cpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*»
setº
@Union[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set,None]l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set
None *»
getº
@Union[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get,None]l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get
None *˜
get_with_defaultﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault,None]Ç
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault
None *·

get_optionŒ
FUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption,None]x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption
None *’
get_all≈
CUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll,None]r
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll
None *–
unset¬
BUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset,None]p
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset
None *Ì
is_modifiable◊
IUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable,None]~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable
None *√
HasFieldCpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*±

ClearFieldEpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*„

WhichOneofEpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.WhichOneof"√
•Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.DESCRIPTOR
Anyr}
SET_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.SET_FIELD_NUMBER
builtins.int"builtins.intr}
GET_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_FIELD_NUMBER
builtins.int"builtins.intró
GET_WITH_DEFAULT_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_WITH_DEFAULT_FIELD_NUMBER
builtins.int"builtins.intrã
GET_OPTION_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_OPTION_FIELD_NUMBER
builtins.int"builtins.intrÖ
GET_ALL_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_ALL_FIELD_NUMBER
builtins.int"builtins.intrÅ
UNSET_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.UNSET_FIELD_NUMBER
builtins.int"builtins.intrë
IS_MODIFIABLE_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.IS_MODIFIABLE_FIELD_NUMBER
builtins.int"builtins.intz¯

Set4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"builtins.object*€
pairs:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.pairs"
Any*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set0:builtins.property`*‡
__init__=pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.__init__"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set*í
pairsÑ
HUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue],None]´
<typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue]Z
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue"typing.Iterable
None *ì

ClearField?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.DESCRIPTOR
Anyr{
PAIRS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.PAIRS_FIELD_NUMBER
builtins.int"builtins.intzˆ	
Get4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"builtins.object*Ÿ
keys9pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.keys"
Any*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get0:builtins.property`*‚
__init__=pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.__init__"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ì

ClearField?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.DESCRIPTOR
Anyry
KEYS_FIELD_NUMBERFpyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.KEYS_FIELD_NUMBER
builtins.int"builtins.intzé
GetWithDefault?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"builtins.object*˛
pairsEpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.pairs"
Any*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault0:builtins.property`*É
__init__Hpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault*í
pairsÑ
HUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue],None]´
<typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue]Z
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue"typing.Iterable
None *∂

ClearFieldJpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.DESCRIPTOR
AnyrÜ
PAIRS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.PAIRS_FIELD_NUMBER
builtins.int"builtins.intz«

	GetOption:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption"builtins.object*Ï
keys?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.keys"
Any*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption0:builtins.property`*ı
__init__Cpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *¶

ClearFieldEpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.DESCRIPTOR
Anyr
KEYS_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.KEYS_FIELD_NUMBER
builtins.int"builtins.intzﬂ
GetAll7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"builtins.object*®
__init__@pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.__init__"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*R
prefixD
Union[builtins.str,None]
builtins.str"builtins.str
None *‘
HasField@pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.HasField"
builtins.bool"builtins.bool*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¬

ClearFieldBpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

WhichOneofBpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.DESCRIPTOR
AnyrÄ
PREFIX_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.PREFIX_FIELD_NUMBER
builtins.int"builtins.intrf
prefix>pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.prefix
builtins.str"builtins.strzê

Unset6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"builtins.object*ﬂ
keys;pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.keys"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset0:builtins.property`*Ë
__init__?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ô

ClearFieldApyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.DESCRIPTOR
Anyr{
KEYS_FIELD_NUMBERHpyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.KEYS_FIELD_NUMBER
builtins.int"builtins.intzÔ

IsModifiable=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"builtins.object*ı
keysBpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.keys"
Any*à
self~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable0:builtins.property`*˛
__init__Fpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ø

ClearFieldHpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.DESCRIPTOR
AnyrÇ
KEYS_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.KEYS_FIELD_NUMBER
builtins.int"builtins.int¡
ConfigResponse1pyspark.sql.connect.proto.base_pb2.ConfigResponse"builtins.object*“
pairs7pyspark.sql.connect.proto.base_pb2.ConfigResponse.pairs"
Any*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse0:builtins.property`*ÿ
warnings:pyspark.sql.connect.proto.base_pb2.ConfigResponse.warnings"
Any*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse0:builtins.property`*¢
__init__:pyspark.sql.connect.proto.base_pb2.ConfigResponse.__init__"
None*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse*.

session_id
builtins.str"builtins.str *í
pairsÑ
HUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue],None]´
<typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue]Z
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue"typing.Iterable
None *ò
warningsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *◊

ClearField<pyspark.sql.connect.proto.base_pb2.ConfigResponse.ClearField"
None*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.base_pb2.ConfigResponse.DESCRIPTOR
AnyrÇ
SESSION_ID_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.ConfigResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrx
PAIRS_FIELD_NUMBERDpyspark.sql.connect.proto.base_pb2.ConfigResponse.PAIRS_FIELD_NUMBER
builtins.int"builtins.intr~
WARNINGS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigResponse.WARNINGS_FIELD_NUMBER
builtins.int"builtins.intrh

session_id<pyspark.sql.connect.proto.base_pb2.ConfigResponse.session_id
builtins.str"builtins.strèé
AddArtifactsRequest6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"builtins.object*»
user_contextCpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*÷
batch<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.batch"|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*Å
begin_chunkBpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.begin_chunk"ö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*Á
chunk<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.chunk"å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*ò

__init__?pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *‚
batch‘
HUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch,None]|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch
None *ñ
begin_chunkÇ
WUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact,None]ö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact
None *˚
chunkÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk,None]å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk
None *ê
HasField?pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearFieldApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2í


WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneofè

WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÆ

WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneof"Ü
MUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
USER_CONTEXT_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrâ
CLIENT_TYPE_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intr}
BATCH_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BATCH_FIELD_NUMBER
builtins.int"builtins.intrâ
BEGIN_CHUNK_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BEGIN_CHUNK_FIELD_NUMBER
builtins.int"builtins.intr}
CHUNK_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.CHUNK_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.session_id
builtins.str"builtins.strro
client_typeBpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.client_type
builtins.str"builtins.strzç
ArtifactChunkDpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"builtins.object*‘
__init__Mpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*,
data 
builtins.bytes"builtins.bytes *'
crc
builtins.int"builtins.int *Î

ClearFieldOpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.DESCRIPTOR
Anyrâ
DATA_FIELD_NUMBERVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.DATA_FIELD_NUMBER
builtins.int"builtins.intrá
CRC_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.CRC_FIELD_NUMBER
builtins.int"builtins.intrs
dataIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.data 
builtins.bytes"builtins.bytesrm
crcHpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.crc
builtins.int"builtins.intz∆
SingleChunkArtifactJpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"builtins.object*£
dataOpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.data"å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact0:builtins.property`*∂
__init__Spyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.__init__"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact*(
name
builtins.str"builtins.str *˙
dataÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk,None]å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk
None *È
HasFieldSpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.HasField"
builtins.bool"builtins.bool*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

ClearFieldUpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.ClearField"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrl

DESCRIPTORUpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.DESCRIPTOR
Anyrè
NAME_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.NAME_FIELD_NUMBER
builtins.int"builtins.intrè
DATA_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.DATA_FIELD_NUMBER
builtins.int"builtins.intru
nameOpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.name
builtins.str"builtins.strzÔ
Batch<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"builtins.object*¸
	artifactsFpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.artifacts"
Any*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch0:builtins.property`*˙
__init__Epyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch*ì
	artifactsÅ
gUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact],None]â
[typing.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact]ò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"typing.Iterable
None *¨

ClearFieldGpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.DESCRIPTOR
Anyrã
ARTIFACTS_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.ARTIFACTS_FIELD_NUMBER
builtins.int"builtins.intzˇ
BeginChunkedArtifactKpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"builtins.object*∏
initial_chunkYpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.initial_chunk"å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact0:builtins.property`*£
__init__Tpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.__init__"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*(
name
builtins.str"builtins.str */
total_bytes
builtins.int"builtins.int *.

num_chunks
builtins.int"builtins.int *É
initial_chunkÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk,None]å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk
None *Ï
HasFieldTpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.HasField"
builtins.bool"builtins.bool*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Õ

ClearFieldVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.ClearField"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrm

DESCRIPTORVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.DESCRIPTOR
Anyrê
NAME_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.NAME_FIELD_NUMBER
builtins.int"builtins.intrû
TOTAL_BYTES_FIELD_NUMBERdpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.TOTAL_BYTES_FIELD_NUMBER
builtins.int"builtins.intrú
NUM_CHUNKS_FIELD_NUMBERcpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.NUM_CHUNKS_FIELD_NUMBER
builtins.int"builtins.intr¢
INITIAL_CHUNK_FIELD_NUMBERfpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.INITIAL_CHUNK_FIELD_NUMBER
builtins.int"builtins.intrv
namePpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.name
builtins.str"builtins.strrÑ
total_bytesWpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.total_bytes
builtins.int"builtins.intrÇ

num_chunksVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.num_chunks
builtins.int"builtins.int¨
AddArtifactsResponse7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"builtins.object*Ï
	artifactsApyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.artifacts"
Any*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse0:builtins.property`*ﬁ
__init__@pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.__init__"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse*á
	artifactsı
dUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary],None]Ä
Xtyping.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary]í
Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"typing.Iterable
None *ú

ClearFieldBpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.DESCRIPTOR
AnyrÜ
ARTIFACTS_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ARTIFACTS_FIELD_NUMBER
builtins.int"builtins.intzˆ
ArtifactSummaryGpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"builtins.object*È
__init__Ppyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.__init__"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary*(
name
builtins.str"builtins.str *7
is_crc_successful
builtins.bool"builtins.bool *Ù

ClearFieldRpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.ClearField"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesri

DESCRIPTORRpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.DESCRIPTOR
Anyrå
NAME_FIELD_NUMBERYpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.NAME_FIELD_NUMBER
builtins.int"builtins.intr¶
IS_CRC_SUCCESSFUL_FIELD_NUMBERfpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.IS_CRC_SUCCESSFUL_FIELD_NUMBER
builtins.int"builtins.intrr
nameLpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.name
builtins.str"builtins.strré
is_crc_successfulYpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.is_crc_successful
builtins.bool"builtins.bool¡$
ArtifactStatusesRequest:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest"builtins.object*’
user_contextGpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest0:builtins.property`*Ó
names@pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.names"
Any*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest0:builtins.property`*¡
__init__Cpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *ï
namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ö
HasFieldCpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ø

ClearFieldEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*á

WhichOneofEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.DESCRIPTOR
Anyrã
SESSION_ID_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrè
USER_CONTEXT_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrç
CLIENT_TYPE_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÅ
NAMES_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.NAMES_FIELD_NUMBER
builtins.int"builtins.intrq

session_idEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.session_id
builtins.str"builtins.strrs
client_typeFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.client_type
builtins.str"builtins.strÅ-
ArtifactStatusesResponse;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse"builtins.object*˜
statusesDpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.statuses"
Any*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse0:builtins.property`*´
__init__Dpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.__init__"
None*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse*«
statuses∂
sUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus],None]≤
gtyping.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus]
builtins.str"builtins.strò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"typing.Mapping
None *©

ClearFieldFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ClearField"
None*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.DESCRIPTOR
Anyrà
STATUSES_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.STATUSES_FIELD_NUMBER
builtins.int"builtins.intzà

ArtifactStatusJpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"builtins.object*Ω
__init__Spyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.__init__"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus*,
exists
builtins.bool"builtins.bool *◊

ClearFieldUpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.ClearField"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrl

DESCRIPTORUpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.DESCRIPTOR
Anyrì
EXISTS_FIELD_NUMBER^pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.EXISTS_FIELD_NUMBER
builtins.int"builtins.intr{
existsQpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.exists
builtins.bool"builtins.boolzÕ
StatusesEntryIpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"builtins.object*Æ
valueOpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.value"ò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry0:builtins.property`*≈
__init__Rpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry*'
key
builtins.str"builtins.str *ç
valueˇ
VUnion[pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus,None]ò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus
None *Ê
HasFieldRpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.HasField"
builtins.bool"builtins.bool*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

ClearFieldTpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.ClearField"
None*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrk

DESCRIPTORTpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.DESCRIPTOR
Anyrå
KEY_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrê
VALUE_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrr
keyMpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.key
builtins.str"builtins.strÓN
InterruptRequest3pyspark.sql.connect.proto.base_pb2.InterruptRequest"builtins.object*ø
user_context@pyspark.sql.connect.proto.base_pb2.InterruptRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest0:builtins.property`*Æ
__init__<pyspark.sql.connect.proto.base_pb2.InterruptRequest.__init__"
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *≥
interrupt_typeú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType *1
operation_tag
builtins.str"builtins.str *0
operation_id
builtins.str"builtins.str *·	
HasField<pyspark.sql.connect.proto.base_pb2.InterruptRequest.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*õ

ClearField>pyspark.sql.connect.proto.base_pb2.InterruptRequest.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Æ	

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneofÜ

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX÷

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrU

DESCRIPTOR>pyspark.sql.connect.proto.base_pb2.InterruptRequest.DESCRIPTOR
Anyrã
INTERRUPT_TYPE_UNSPECIFIEDNpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_UNSPECIFIEDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper˚
INTERRUPT_TYPE_ALLFpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_ALLú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper˚
INTERRUPT_TYPE_TAGFpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_TAGú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperç
INTERRUPT_TYPE_OPERATION_IDOpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_OPERATION_IDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperÑ
SESSION_ID_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.InterruptRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrà
USER_CONTEXT_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.InterruptRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrÜ
CLIENT_TYPE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.InterruptRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrå
INTERRUPT_TYPE_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_FIELD_NUMBER
builtins.int"builtins.inträ
OPERATION_TAG_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.InterruptRequest.OPERATION_TAG_FIELD_NUMBER
builtins.int"builtins.intrà
OPERATION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.InterruptRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrj

session_id>pyspark.sql.connect.proto.base_pb2.InterruptRequest.session_id
builtins.str"builtins.strrl
client_type?pyspark.sql.connect.proto.base_pb2.InterruptRequest.client_type
builtins.str"builtins.strrÛ
interrupt_typeBpyspark.sql.connect.proto.base_pb2.InterruptRequest.interrupt_typeú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperp
operation_tagApyspark.sql.connect.proto.base_pb2.InterruptRequest.operation_tag
builtins.str"builtins.strrn
operation_id@pyspark.sql.connect.proto.base_pb2.InterruptRequest.operation_id
builtins.str"builtins.strzè
_InterruptTypeBpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType"builtins.objectzß
	ValueTypeLpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"builtins.int*Ω
__init__Upyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType.__init__"
None*ß
selfú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType*&
item
builtins.int"builtins.intzà
_InterruptTypeEnumTypeWrapperQpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper"builtins.typers

DESCRIPTOR\pyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.DESCRIPTOR
Anyr©
INTERRUPT_TYPE_UNSPECIFIEDlpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_UNSPECIFIEDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperô
INTERRUPT_TYPE_ALLdpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_ALLú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperô
INTERRUPT_TYPE_TAGdpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_TAGú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper´
INTERRUPT_TYPE_OPERATION_IDmpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_OPERATION_IDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTypezÎ
InterruptTypeApyspark.sql.connect.proto.base_pb2.InterruptRequest.InterruptType"Bpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType@bQpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapperá
InterruptResponse4pyspark.sql.connect.proto.base_pb2.InterruptResponse"builtins.object*Ô
interrupted_idsDpyspark.sql.connect.proto.base_pb2.InterruptResponse.interrupted_ids"
Any*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse0:builtins.property`*ù
__init__=pyspark.sql.connect.proto.base_pb2.InterruptResponse.__init__"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse*.

session_id
builtins.str"builtins.str *ü
interrupted_idsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *π

ClearField?pyspark.sql.connect.proto.base_pb2.InterruptResponse.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.base_pb2.InterruptResponse.DESCRIPTOR
AnyrÖ
SESSION_ID_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.InterruptResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrè
INTERRUPTED_IDS_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.InterruptResponse.INTERRUPTED_IDS_FIELD_NUMBER
builtins.int"builtins.intrk

session_id?pyspark.sql.connect.proto.base_pb2.InterruptResponse.session_id
builtins.str"builtins.str≥
ReattachOptions2pyspark.sql.connect.proto.base_pb2.ReattachOptions"builtins.object*˘
__init__;pyspark.sql.connect.proto.base_pb2.ReattachOptions.__init__"
None*r
selfh
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*2
reattachable
builtins.bool"builtins.bool *ç

ClearField=pyspark.sql.connect.proto.base_pb2.ReattachOptions.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.base_pb2.ReattachOptions.DESCRIPTOR
Anyrá
REATTACHABLE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.ReattachOptions.REATTACHABLE_FIELD_NUMBER
builtins.int"builtins.intro
reattachable?pyspark.sql.connect.proto.base_pb2.ReattachOptions.reattachable
builtins.bool"builtins.boolÈ/
ReattachExecuteRequest9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"builtins.object*“
user_contextFpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest0:builtins.property`*∂
__init__Bpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *0
operation_id
builtins.str"builtins.str *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *\
last_response_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *Œ
HasFieldBpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*à

ClearFieldDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ä	

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneofô

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXô

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXr[

DESCRIPTORDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.DESCRIPTOR
Anyrä
SESSION_ID_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intré
USER_CONTEXT_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intré
OPERATION_ID_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrå
CLIENT_TYPE_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrñ
LAST_RESPONSE_ID_FIELD_NUMBERWpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.LAST_RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intrp

session_idDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.session_id
builtins.str"builtins.strrt
operation_idFpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.operation_id
builtins.str"builtins.strrr
client_typeEpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.client_type
builtins.str"builtins.strr|
last_response_idJpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.last_response_id
builtins.str"builtins.str»I
ReleaseExecuteRequest8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"builtins.object*Œ
user_contextEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:builtins.property`*˜
release_allDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.release_all"ä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:builtins.property`*ˇ
release_untilFpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.release_until"é
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:builtins.property`*ﬁ
__init__Apyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.__init__"
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *0
operation_id
builtins.str"builtins.str *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *˛
release_allÍ
OUnion[pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll,None]ä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll
None *Ü
release_until
QUnion[pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil,None]é
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil
None *	
HasFieldApyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.HasField"
builtins.bool"builtins.bool*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*™

ClearFieldCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ClearField"
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2—	

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneofï

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÂ

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrZ

DESCRIPTORCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.DESCRIPTOR
Anyrâ
SESSION_ID_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrç
USER_CONTEXT_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrç
OPERATION_ID_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
CLIENT_TYPE_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrã
RELEASE_ALL_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.RELEASE_ALL_FIELD_NUMBER
builtins.int"builtins.intrè
RELEASE_UNTIL_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.RELEASE_UNTIL_FIELD_NUMBER
builtins.int"builtins.intro

session_idCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.session_id
builtins.str"builtins.strrs
operation_idEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.operation_id
builtins.str"builtins.strrq
client_typeDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.client_type
builtins.str"builtins.strz∆

ReleaseAllCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"builtins.object*˙
__init__Lpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAllre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll.DESCRIPTOR
AnyzÈ	
ReleaseUntilEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"builtins.object*±
__init__Npyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.__init__"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil*/
response_id
builtins.str"builtins.str *»

ClearFieldPpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.ClearField"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrg

DESCRIPTORPpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.DESCRIPTOR
Anyrò
RESPONSE_ID_FIELD_NUMBER^pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intr~
response_idQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.response_id
builtins.str"builtins.strá
ReleaseExecuteResponse9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"builtins.object*Â
__init__Bpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*.

session_id
builtins.str"builtins.str *X
operation_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *€
HasFieldBpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*

ClearFieldDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ñ

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr[

DESCRIPTORDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.DESCRIPTOR
Anyrä
SESSION_ID_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intré
OPERATION_ID_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrp

session_idDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.session_id
builtins.str"builtins.strrt
operation_idFpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.operation_id
builtins.str"builtins.str*û
__annotations__2pyspark.sql.connect.proto.base_pb2.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*
collectionscollections *<
google)pyspark.sql.connect.proto.base_pb2.google
Any*
pysparkpyspark *D

DESCRIPTOR-pyspark.sql.connect.proto.base_pb2.DESCRIPTOR
Any