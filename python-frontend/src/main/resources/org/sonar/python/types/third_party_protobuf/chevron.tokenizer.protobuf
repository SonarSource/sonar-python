
chevron.tokenizer`
ChevronErrorchevron.tokenizer.ChevronError"builtins.SyntaxErrorj38j39j310j311j312j313©
grab_literalchevron.tokenizer.grab_literal"`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str**
template
builtins.str"builtins.str*O
l_delD
Union[builtins.str,None]
builtins.str"builtins.str
Nonez38z39z310z311z312z313™

l_sa_checkchevron.tokenizer.l_sa_check"G
Union[builtins.bool,None]
builtins.bool"builtins.bool
None**
template
builtins.str"builtins.str*)
literal
builtins.str"builtins.str*1
is_standalone
builtins.bool"builtins.boolz38z39z310z311z312z313ñ

r_sa_checkchevron.tokenizer.r_sa_check"
builtins.bool"builtins.bool**
template
builtins.str"builtins.str**
tag_type
builtins.str"builtins.str*1
is_standalone
builtins.bool"builtins.boolz38z39z310z311z312z313Í
	parse_tagchevron.tokenizer.parse_tag"¸
4Tuple[Tuple[builtins.str,builtins.str],builtins.str]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str
builtins.str"builtins.str**
template
builtins.str"builtins.str*O
l_delD
Union[builtins.str,None]
builtins.str"builtins.str
None*O
r_delD
Union[builtins.str,None]
builtins.str"builtins.str
Nonez38z39z310z311z312z313Ã
tokenizechevron.tokenizer.tokenize"¦
1typing.Iterator[Tuple[builtins.str,builtins.str]]`
 Tuple[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Iterator**
template
builtins.str"builtins.str*T
def_ldelD
Union[builtins.str,None]
builtins.str"builtins.str
None *T
def_rdelD
Union[builtins.str,None]
builtins.str"builtins.str
None z38z39z310z311z312z313*©
__annotations__!chevron.tokenizer.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*38*39*310*311*312*313