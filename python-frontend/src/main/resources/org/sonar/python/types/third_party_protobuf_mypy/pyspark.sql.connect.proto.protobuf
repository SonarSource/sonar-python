
pyspark.sql.connect.protoà
SparkConnectServiceStub?pyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub"builtins.object*k
__init__Hpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.__init__*
self*
channelrc
ExecutePlanKpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ExecutePlan
Anyrc
AnalyzePlanKpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.AnalyzePlan
AnyrY
ConfigFpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.Config
Anyre
AddArtifactsLpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.AddArtifacts
Anyri
ArtifactStatusNpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ArtifactStatus
Anyr_
	InterruptIpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.Interrupt
Anyrk
ReattachExecuteOpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ReattachExecute
Anyri
ReleaseExecuteNpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ReleaseExecute
Any™	
SparkConnectServiceServicerCpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer"builtins.object*Ç
ExecutePlanOpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ExecutePlan*
self*
request*
context*Ç
AnalyzePlanOpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.AnalyzePlan*
self*
request*
context*x
ConfigJpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.Config*
self*
request*
context*ç
AddArtifactsPpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.AddArtifacts*
self*
request_iterator*
context*à
ArtifactStatusRpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ArtifactStatus*
self*
request*
context*~
	InterruptMpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.Interrupt*
self*
request*
context*ä
ReattachExecuteSpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ReattachExecute*
self*
request*
context*à
ReleaseExecuteRpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ReleaseExecute*
self*
request*
context¨
SparkConnectService;pyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService"builtins.object*§
ExecutePlanGpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ExecutePlan*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh*§
AnalyzePlanGpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.AnalyzePlan*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh*ö
ConfigBpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.Config*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh*Ø
AddArtifactsHpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.AddArtifacts*
request_iterator*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh*™
ArtifactStatusJpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ArtifactStatus*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh*†
	InterruptEpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.Interrupt*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh*¨
ReattachExecuteKpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ReattachExecute*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh*™
ReleaseExecuteJpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ReleaseExecute*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:builtins.staticmethodh·
Plan'pyspark.sql.connect.proto.base_pb2.Plan"builtins.object*è
root,pyspark.sql.connect.proto.base_pb2.Plan.root"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan0:builtins.property`*ë
command/pyspark.sql.connect.proto.base_pb2.Plan.command"`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan0:builtins.property`*°
__init__0pyspark.sql.connect.proto.base_pb2.Plan.__init__"
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*Ω
root∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *∫
command™
:Union[pyspark.sql.connect.proto.commands_pb2.Command,None]`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command
None *À
HasField0pyspark.sql.connect.proto.base_pb2.Plan.HasField"
builtins.bool"builtins.bool*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearField2pyspark.sql.connect.proto.base_pb2.Plan.ClearField"
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ù

WhichOneof2pyspark.sql.connect.proto.base_pb2.Plan.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrI

DESCRIPTOR2pyspark.sql.connect.proto.base_pb2.Plan.DESCRIPTOR
Anyrl
ROOT_FIELD_NUMBER9pyspark.sql.connect.proto.base_pb2.Plan.ROOT_FIELD_NUMBER
builtins.int"builtins.intrr
COMMAND_FIELD_NUMBER<pyspark.sql.connect.proto.base_pb2.Plan.COMMAND_FIELD_NUMBER
builtins.int"builtins.intî
UserContext.pyspark.sql.connect.proto.base_pb2.UserContext"builtins.object*”

extensions9pyspark.sql.connect.proto.base_pb2.UserContext.extensions"
Any*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext0:builtins.property`*â
__init__7pyspark.sql.connect.proto.base_pb2.UserContext.__init__"
None*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*+
user_id
builtins.str"builtins.str *-
	user_name
builtins.str"builtins.str *r

extensions`
 Union[typing.Iterable[Any],None]0
typing.Iterable[Any]
Any"typing.Iterable
None *Œ

ClearField9pyspark.sql.connect.proto.base_pb2.UserContext.ClearField"
None*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.base_pb2.UserContext.DESCRIPTOR
Anyry
USER_ID_FIELD_NUMBERCpyspark.sql.connect.proto.base_pb2.UserContext.USER_ID_FIELD_NUMBER
builtins.int"builtins.intr}
USER_NAME_FIELD_NUMBEREpyspark.sql.connect.proto.base_pb2.UserContext.USER_NAME_FIELD_NUMBER
builtins.int"builtins.intr
EXTENSIONS_FIELD_NUMBERFpyspark.sql.connect.proto.base_pb2.UserContext.EXTENSIONS_FIELD_NUMBER
builtins.int"builtins.intr_
user_id6pyspark.sql.connect.proto.base_pb2.UserContext.user_id
builtins.str"builtins.strrc
	user_name8pyspark.sql.connect.proto.base_pb2.UserContext.user_name
builtins.str"builtins.strÃ¨
AnalyzePlanRequest5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"builtins.object*≈
user_contextBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*’
schema<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.schema"|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ÿ
explain=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.explain"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ë
tree_stringApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.tree_string"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*€
is_local>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.is_local"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ï
is_streamingBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.is_streaming"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ë
input_filesApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.input_files"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*
spark_versionCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.spark_version"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*‡
	ddl_parse?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.ddl_parse"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ù
same_semanticsDpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.same_semantics"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*
semantic_hashCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.semantic_hash"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*Ÿ
persist=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.persist"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*‚
	unpersist?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.unpersist"Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*˛
get_storage_levelGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.get_storage_level"é
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:builtins.property`*û
__init__>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.__init__"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *„
schema‘
HUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema,None]|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema
None *Á
explain◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain
None *ı
tree_string·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString
None *Ë
is_local◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal
None *˘
is_streaming‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming
None *ı
input_files·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles
None *˝
spark_versionÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion
None *Ì
	ddl_parse€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse
None *Å
same_semanticsÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics
None *˝
semantic_hashÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash
None *Á
persist◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist
None *
	unpersistﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist,None]Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist
None *ä
get_storage_level
QUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel,None]é
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel
None *â
HasField>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¢

field_nameë
îUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ù

ClearField@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*»

field_name∑
¬Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¢

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX¬

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneof"ù
©Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DESCRIPTOR
AnyrÜ
SESSION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.inträ
USER_CONTEXT_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrà
CLIENT_TYPE_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intr~
SCHEMA_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÄ
EXPLAIN_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrà
TREE_STRING_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrÇ
IS_LOCAL_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.inträ
IS_STREAMING_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intrà
INPUT_FILES_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.INPUT_FILES_FIELD_NUMBER
builtins.int"builtins.intrå
SPARK_VERSION_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SPARK_VERSION_FIELD_NUMBER
builtins.int"builtins.intrÑ
DDL_PARSE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDL_PARSE_FIELD_NUMBER
builtins.int"builtins.intré
SAME_SEMANTICS_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SAME_SEMANTICS_FIELD_NUMBER
builtins.int"builtins.intrå
SEMANTIC_HASH_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SEMANTIC_HASH_FIELD_NUMBER
builtins.int"builtins.intrÄ
PERSIST_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.PERSIST_FIELD_NUMBER
builtins.int"builtins.intrÑ
UNPERSIST_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.UNPERSIST_FIELD_NUMBER
builtins.int"builtins.intrî
GET_STORAGE_LEVEL_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GET_STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrl

session_id@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.session_id
builtins.str"builtins.strrn
client_typeApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.client_type
builtins.str"builtins.strz˜
Schema<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"builtins.object*Ω
planApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema0:builtins.property`*â
__init__Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *æ
HasFieldEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.HasField"
builtins.bool"builtins.bool*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

ClearFieldGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.DESCRIPTOR
AnyrÅ
PLAN_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema.PLAN_FIELD_NUMBER
builtins.int"builtins.intzŸ9
Explain=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"builtins.object*¿
planBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain0:builtins.property`*–
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *¡
explain_mode¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType *¡
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*’

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.DESCRIPTOR
Anyr°
EXPLAIN_MODE_UNSPECIFIEDVpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_UNSPECIFIED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperó
EXPLAIN_MODE_SIMPLEQpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_SIMPLE¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperõ
EXPLAIN_MODE_EXTENDEDSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_EXTENDED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperô
EXPLAIN_MODE_CODEGENRpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_CODEGEN¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperì
EXPLAIN_MODE_COSTOpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_COST¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperù
EXPLAIN_MODE_FORMATTEDTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_FORMATTED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperÇ
PLAN_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.PLAN_FIELD_NUMBER
builtins.int"builtins.intrí
EXPLAIN_MODE_FIELD_NUMBERWpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.EXPLAIN_MODE_FIELD_NUMBER
builtins.int"builtins.intrâ
explain_modeJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.explain_mode¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTypezµ
_ExplainModeJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode"builtins.objectz«
	ValueTypeTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"builtins.int*’
__init__]pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType.__init__"
None*∑
self¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType*&
item
builtins.int"builtins.intz⁄
_ExplainModeEnumTypeWrapperYpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper"builtins.typer{

DESCRIPTORdpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.DESCRIPTOR
AnyrΩ
EXPLAIN_MODE_UNSPECIFIEDrpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_UNSPECIFIED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyper≥
EXPLAIN_MODE_SIMPLEmpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_SIMPLE¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyper∑
EXPLAIN_MODE_EXTENDEDopyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_EXTENDED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperµ
EXPLAIN_MODE_CODEGENnpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_CODEGEN¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperØ
EXPLAIN_MODE_COSTkpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_COST¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTyperπ
EXPLAIN_MODE_FORMATTEDppyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapper.EXPLAIN_MODE_FORMATTED¨
Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueType"Tpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode.ValueTypezÅ
ExplainModeIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain.ExplainMode"Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainMode@bYpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain._ExplainModeEnumTypeWrapperzæ

TreeString@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"builtins.object* 
planEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString0:builtins.property`*È
__init__Ipyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *Q
levelD
Union[builtins.int,None]
builtins.int"builtins.int
None *ò
HasFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.HasField"
builtins.bool"builtins.bool*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ü

ClearFieldKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ö

WhichOneofKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.DESCRIPTOR
AnyrÖ
PLAN_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.PLAN_FIELD_NUMBER
builtins.int"builtins.intrá
LEVEL_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.LEVEL_FIELD_NUMBER
builtins.int"builtins.intrm
levelFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString.level
builtins.int"builtins.intzá
IsLocal=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"builtins.object*¿
planBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal0:builtins.property`*å
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *¡
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ø

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.DESCRIPTOR
AnyrÇ
PLAN_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal.PLAN_FIELD_NUMBER
builtins.int"builtins.intzÀ
IsStreamingApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"builtins.object*Õ
planFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming0:builtins.property`*ô
__init__Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *Œ
HasFieldJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.HasField"
builtins.bool"builtins.bool*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*º

ClearFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.DESCRIPTOR
AnyrÜ
PLAN_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming.PLAN_FIELD_NUMBER
builtins.int"builtins.intzª

InputFiles@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"builtins.object* 
planEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles0:builtins.property`*ñ
__init__Ipyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *À
HasFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.HasField"
builtins.bool"builtins.bool*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearFieldKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.DESCRIPTOR
AnyrÖ
PLAN_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles.PLAN_FIELD_NUMBER
builtins.int"builtins.intz√
SparkVersionBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"builtins.object*˜
__init__Kpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersionrd

DESCRIPTORMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion.DESCRIPTOR
Anyzö	
DDLParse>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse"builtins.object*õ
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse*.

ddl_string
builtins.str"builtins.str *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.DESCRIPTOR
Anyrè
DDL_STRING_FIELD_NUMBERVpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.DDL_STRING_FIELD_NUMBER
builtins.int"builtins.intru

ddl_stringIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse.ddl_string
builtins.str"builtins.strz˛
SameSemanticsCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"builtins.object*·
target_planOpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.target_plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics0:builtins.property`*ﬂ

other_planNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.other_plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics0:builtins.property`*—
__init__Lpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*©
target_planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *®

other_planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *˙
HasFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

ClearFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.DESCRIPTOR
Anyrñ
TARGET_PLAN_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.TARGET_PLAN_FIELD_NUMBER
builtins.int"builtins.intrî
OTHER_PLAN_FIELD_NUMBER[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics.OTHER_PLAN_FIELD_NUMBER
builtins.int"builtins.intz€
SemanticHashBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"builtins.object*–
planGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash0:builtins.property`*ú
__init__Kpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *—
HasFieldKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.HasField"
builtins.bool"builtins.bool*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ø

ClearFieldMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.DESCRIPTOR
Anyrá
PLAN_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash.PLAN_FIELD_NUMBER
builtins.int"builtins.intz¡
Persist=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"builtins.object*⁄
relationFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist0:builtins.property`*Ê
storage_levelKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.storage_level"f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist0:builtins.property`*˜
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *…
storage_level≥
=Union[pyspark.sql.connect.proto.common_pb2.StorageLevel,None]f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel
None *é
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¸

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ê

WhichOneofHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.DESCRIPTOR
Anyrä
RELATION_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.RELATION_FIELD_NUMBER
builtins.int"builtins.intrî
STORAGE_LEVEL_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist.STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intz˛
	Unpersist?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"builtins.object*·
relationHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist0:builtins.property`*ã
__init__Hpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *W
blockingG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *ï
HasFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearFieldJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ó

WhichOneofJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.DESCRIPTOR
Anyrå
RELATION_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.RELATION_FIELD_NUMBER
builtins.int"builtins.intrå
BLOCKING_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.BLOCKING_FIELD_NUMBER
builtins.int"builtins.intrt
blockingHpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist.blocking
builtins.bool"builtins.boolzÃ
GetStorageLevelEpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"builtins.object*Û
relationNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel0:builtins.property`*ƒ
__init__Npyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.__init__"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *⁄
HasFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.HasField"
builtins.bool"builtins.bool*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*»

ClearFieldPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.ClearField"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrg

DESCRIPTORPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.DESCRIPTOR
Anyrí
RELATION_FIELD_NUMBER[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel.RELATION_FIELD_NUMBER
builtins.int"builtins.int∆ã
AnalyzePlanResponse6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"builtins.object*⁄
schema=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.schema"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ﬂ
explain>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.explain"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Ì
tree_stringBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.tree_string"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*·
is_local?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.is_local"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Ò
is_streamingCpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.is_streaming"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Ì
input_filesBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.input_files"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ı
spark_versionDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.spark_version"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Â
	ddl_parse@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.ddl_parse"Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*˘
same_semanticsEpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.same_semantics"å
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ı
semantic_hashDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.semantic_hash"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*ﬂ
persist>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.persist"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*Á
	unpersist@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.unpersist"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*É
get_storage_levelHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.get_storage_level"ê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:builtins.property`*∞
__init__?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*.

session_id
builtins.str"builtins.str *Ê
schema◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema
None *Î
explain€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain
None *¯
tree_string‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString
None *Ï
is_local€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal
None *¸
is_streamingÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming
None *¯
input_files‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles
None *Ä
spark_versionÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion
None *
	ddl_parseﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse,None]Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse
None *Ñ
same_semanticsÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics,None]å
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics
None *Ä
semantic_hashÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash
None *Î
persist€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist
None *Û
	unpersist·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist
None *ç
get_storage_levelÛ
RUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel,None]ê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel
None *ö
HasField?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*∞

field_nameü
äUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*÷

field_name≈
∏Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∞

WhichOneofApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.WhichOneof"ù
©Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intr
SCHEMA_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÅ
EXPLAIN_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrâ
TREE_STRING_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrÉ
IS_LOCAL_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.intrã
IS_STREAMING_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intrâ
INPUT_FILES_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.INPUT_FILES_FIELD_NUMBER
builtins.int"builtins.intrç
SPARK_VERSION_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SPARK_VERSION_FIELD_NUMBER
builtins.int"builtins.intrÖ
DDL_PARSE_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDL_PARSE_FIELD_NUMBER
builtins.int"builtins.intrè
SAME_SEMANTICS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SAME_SEMANTICS_FIELD_NUMBER
builtins.int"builtins.intrç
SEMANTIC_HASH_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SEMANTIC_HASH_FIELD_NUMBER
builtins.int"builtins.intrÅ
PERSIST_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.PERSIST_FIELD_NUMBER
builtins.int"builtins.intrÖ
UNPERSIST_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.UNPERSIST_FIELD_NUMBER
builtins.int"builtins.intrï
GET_STORAGE_LEVEL_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GET_STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.session_id
builtins.str"builtins.strz©
Schema=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"builtins.object*Œ
schemaDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema0:builtins.property`*ù
__init__Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *¡
HasFieldFpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ø

ClearFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.DESCRIPTOR
AnyrÜ
SCHEMA_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intz≠	
Explain>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain"builtins.object*ü
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain*2
explain_string
builtins.str"builtins.str *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.DESCRIPTOR
Anyró
EXPLAIN_STRING_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.EXPLAIN_STRING_FIELD_NUMBER
builtins.int"builtins.intr}
explain_stringMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain.explain_string
builtins.str"builtins.strzø	

TreeStringApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"builtins.object*•
__init__Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString*/
tree_string
builtins.str"builtins.str *º

ClearFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.DESCRIPTOR
Anyrî
TREE_STRING_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrz
tree_stringMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString.tree_string
builtins.str"builtins.strzì	
IsLocal>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal"builtins.object*õ
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal*.
is_local
builtins.bool"builtins.bool *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.DESCRIPTOR
Anyrã
IS_LOCAL_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.intrs
is_localGpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal.is_local
builtins.bool"builtins.boolz”	
IsStreamingBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"builtins.object*´
__init__Kpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming*2
is_streaming
builtins.bool"builtins.bool *ø

ClearFieldMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.DESCRIPTOR
Anyró
IS_STREAMING_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intr
is_streamingOpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming.is_streaming
builtins.bool"builtins.boolz•

InputFilesApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"builtins.object*Ñ
filesGpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.files"
Any*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles0:builtins.property`*å
__init__Jpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles*ï
filesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *º

ClearFieldLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.DESCRIPTOR
Anyrà
FILES_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles.FILES_FIELD_NUMBER
builtins.int"builtins.intz¡	
SparkVersionCpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"builtins.object*ß
__init__Lpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion*+
version
builtins.str"builtins.str *¬

ClearFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.DESCRIPTOR
Anyré
VERSION_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.VERSION_FIELD_NUMBER
builtins.int"builtins.intrt
versionKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion.version
builtins.str"builtins.strzÕ
DDLParse?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"builtins.object*’
parsedFpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.parsed"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse0:builtins.property`*§
__init__Hpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*≥
parsed§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *»
HasFieldHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearFieldJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.DESCRIPTOR
Anyrà
PARSED_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse.PARSED_FIELD_NUMBER
builtins.int"builtins.intzÀ	
SameSemanticsDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"builtins.object*´
__init__Mpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics*,
result
builtins.bool"builtins.bool *≈

ClearFieldOpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.DESCRIPTOR
Anyrç
RESULT_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.RESULT_FIELD_NUMBER
builtins.int"builtins.intru
resultKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics.result
builtins.bool"builtins.boolzº	
SemanticHashCpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"builtins.object*¶
__init__Lpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash**
result
builtins.int"builtins.int *¬

ClearFieldNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.DESCRIPTOR
Anyrå
RESULT_FIELD_NUMBERWpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.RESULT_FIELD_NUMBER
builtins.int"builtins.intrr
resultJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash.result
builtins.int"builtins.intz™
Persist>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist"builtins.object*Î
__init__Gpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persistr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist.DESCRIPTOR
Anyz∂
	Unpersist@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"builtins.object*Ò
__init__Ipyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersistrb

DESCRIPTORKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist.DESCRIPTOR
Anyz˘
GetStorageLevelFpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"builtins.object*Ç
storage_levelTpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.storage_level"f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel0:builtins.property`*œ
__init__Opyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*…
storage_level≥
=Union[pyspark.sql.connect.proto.common_pb2.StorageLevel,None]f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel
None *›
HasFieldOpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.HasField"
builtins.bool"builtins.bool*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*À

ClearFieldQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.ClearField"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.DESCRIPTOR
Anyrù
STORAGE_LEVEL_FIELD_NUMBERapyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel.STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.int≠]
ExecutePlanRequest5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"builtins.object*≈
user_contextBpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*ß
plan:pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*Ú
request_optionsEpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.request_options"
Any*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*‹
tags:pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.tags"
Any*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:builtins.property`*Ø

__init__>pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.__init__"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *X
operation_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *˝
request_optionsÂ
`Union[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption],None]Ù
Ttyping.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption]ä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"typing.Iterable
None *î
tagsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Á	
HasField>pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*«

ClearField@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ï

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXå

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.DESCRIPTOR
AnyrÜ
SESSION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.inträ
USER_CONTEXT_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.inträ
OPERATION_ID_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrz
PLAN_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.PLAN_FIELD_NUMBER
builtins.int"builtins.intrà
CLIENT_TYPE_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrê
REQUEST_OPTIONS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.REQUEST_OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrz
TAGS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.TAGS_FIELD_NUMBER
builtins.int"builtins.intrl

session_id@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.session_id
builtins.str"builtins.strrp
operation_idBpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.operation_id
builtins.str"builtins.strrn
client_typeApyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.client_type
builtins.str"builtins.strz—
RequestOptionCpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"builtins.object*Å
reattach_optionsTpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.reattach_options"h
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption0:builtins.property`*í
	extensionMpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.extension"
Any*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption0:builtins.property`*Ö
__init__Lpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*œ
reattach_options∂
>Union[pyspark.sql.connect.proto.base_pb2.ReattachOptions,None]h
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions
None *7
	extension&
Union[Any,None]
Any
None *°
HasFieldLpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*è

ClearFieldNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Û

WhichOneofNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.DESCRIPTOR
Anyr†
REATTACH_OPTIONS_FIELD_NUMBERapyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.REATTACH_OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrí
EXTENSION_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intùˇ
ExecutePlanResponse6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"builtins.object*Ì
arrow_batchBpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.arrow_batch"Ü
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*á
sql_command_resultIpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.sql_command_result"í
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ß
#write_stream_operation_start_resultZpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.write_stream_operation_start_result"ê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ï
streaming_query_command_resultUpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.streaming_query_command_result"à
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ç
get_resources_command_resultSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.get_resources_command_result"Ñ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*≥
&streaming_query_manager_command_result]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.streaming_query_manager_command_result"ñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*˝
result_completeFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.result_complete"é
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*È
	extension@pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.extension"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*ﬂ
metrics>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.metrics"Ä
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*˜
observed_metricsGpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.observed_metrics"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*∏
schema=pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:builtins.property`*“
__init__?pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*.

session_id
builtins.str"builtins.str *0
operation_id
builtins.str"builtins.str */
response_id
builtins.str"builtins.str *¯
arrow_batch‰
MUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch,None]Ü
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch
None *ë
sql_command_resultˆ
SUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult,None]í
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult
None *ü
#write_stream_operation_start_resultÛ
RUnion[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult,None]ê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult
None *é
streaming_query_command_resultÁ
NUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult,None]à
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult
None *Ü
get_resources_command_result·
LUnion[pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult,None]Ñ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult
None *´
&streaming_query_manager_command_result¸
UUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult,None]ñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult
None *à
result_complete
QUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete,None]é
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete
None *7
	extension&
Union[Any,None]
Any
None *Î
metrics€
JUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics,None]Ä
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics
None *ä
observed_metricsÒ
cUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics],None]˝
Wtyping.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics]ê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"typing.Iterable
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *®
HasField?pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*æ

field_name≠
ÄUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*÷

field_name≈
∏Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*•

WhichOneofApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.WhichOneof"í
ªUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
OPERATION_ID_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrâ
RESPONSE_ID_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intrâ
ARROW_BATCH_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ARROW_BATCH_FIELD_NUMBER
builtins.int"builtins.intró
SQL_COMMAND_RESULT_FIELD_NUMBERVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SQL_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrπ
0WRITE_STREAM_OPERATION_START_RESULT_FIELD_NUMBERgpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.WRITE_STREAM_OPERATION_START_RESULT_FIELD_NUMBER
builtins.int"builtins.intrØ
+STREAMING_QUERY_COMMAND_RESULT_FIELD_NUMBERbpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.STREAMING_QUERY_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intr´
)GET_RESOURCES_COMMAND_RESULT_FIELD_NUMBER`pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.GET_RESOURCES_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrø
3STREAMING_QUERY_MANAGER_COMMAND_RESULT_FIELD_NUMBERjpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.STREAMING_QUERY_MANAGER_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrë
RESULT_COMPLETE_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.RESULT_COMPLETE_FIELD_NUMBER
builtins.int"builtins.intrÖ
EXTENSION_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intrÅ
METRICS_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.METRICS_FIELD_NUMBER
builtins.int"builtins.intrì
OBSERVED_METRICS_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.OBSERVED_METRICS_FIELD_NUMBER
builtins.int"builtins.intr
SCHEMA_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.session_id
builtins.str"builtins.strrq
operation_idCpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.operation_id
builtins.str"builtins.strro
response_idBpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.response_id
builtins.str"builtins.strzÎ
SqlCommandResultGpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"builtins.object*˘
relationPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.relation"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult0:builtins.property`* 
__init__Ppyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.__init__"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*¡
relation∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *‡
HasFieldPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.HasField"
builtins.bool"builtins.bool*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Œ

ClearFieldRpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.ClearField"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesri

DESCRIPTORRpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.DESCRIPTOR
Anyrî
RELATION_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult.RELATION_FIELD_NUMBER
builtins.int"builtins.intzÑ

ArrowBatchApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"builtins.object*—
__init__Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch*-
	row_count
builtins.int"builtins.int *,
data 
builtins.bytes"builtins.bytes *‚

ClearFieldLpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.DESCRIPTOR
Anyrê
ROW_COUNT_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.ROW_COUNT_FIELD_NUMBER
builtins.int"builtins.intrÜ
DATA_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.DATA_FIELD_NUMBER
builtins.int"builtins.intrv
	row_countKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.row_count
builtins.int"builtins.intrp
dataFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch.data 
builtins.bytes"builtins.byteszÜR
Metrics>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics"builtins.object*ˇ
metricsFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.metrics"
Any*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics0:builtins.property`*É
__init__Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*ï
metricsÖ
hUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject],None]å
\typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject]ö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"typing.Iterable
None *≥

ClearFieldIpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.DESCRIPTOR
Anyrâ
METRICS_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.METRICS_FIELD_NUMBER
builtins.int"builtins.intzß3
MetricObjectKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"builtins.object*∫
execution_metrics]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.execution_metrics"
Any*•
selfö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject0:builtins.property`*Ë
__init__Tpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.__init__"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject*(
name
builtins.str"builtins.str *+
plan_id
builtins.int"builtins.int **
parent
builtins.int"builtins.int *–
execution_metrics∂
sUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue],None]≤
gtyping.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue]
builtins.str"builtins.strò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"typing.Mapping
None *Õ

ClearFieldVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ClearField"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject"Kpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrm

DESCRIPTORVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.DESCRIPTOR
Anyrê
NAME_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.NAME_FIELD_NUMBER
builtins.int"builtins.intrñ
PLAN_ID_FIELD_NUMBER`pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.PLAN_ID_FIELD_NUMBER
builtins.int"builtins.intrî
PARENT_FIELD_NUMBER_pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.PARENT_FIELD_NUMBER
builtins.int"builtins.intr™
EXECUTION_METRICS_FIELD_NUMBERjpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.EXECUTION_METRICS_FIELD_NUMBER
builtins.int"builtins.intrv
namePpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.name
builtins.str"builtins.strr|
plan_idSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.plan_id
builtins.int"builtins.intrz
parentRpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.parent
builtins.int"builtins.intzÔ
ExecutionMetricsEntryapyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"builtins.object*ˆ
valuegpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.value"ò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry0:builtins.property`*ç
__init__jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.__init__"
None*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry*'
key
builtins.str"builtins.str *ç
valueˇ
VUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue,None]ò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue
None *Æ
HasFieldjpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.HasField"
builtins.bool"builtins.bool*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¬

ClearFieldlpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.ClearField"
None*—
self∆
apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry"apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrÉ

DESCRIPTORlpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.DESCRIPTOR
Anyr§
KEY_FIELD_NUMBERrpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr®
VALUE_FIELD_NUMBERtpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.inträ
keyepyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricObject.ExecutionMetricsEntry.key
builtins.str"builtins.strz”
MetricValueJpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"builtins.object*ï
__init__Spyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.__init__"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue*(
name
builtins.str"builtins.str *)
value
builtins.int"builtins.int */
metric_type
builtins.str"builtins.str *§

ClearFieldUpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.ClearField"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue"Jpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrl

DESCRIPTORUpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.DESCRIPTOR
Anyrè
NAME_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.NAME_FIELD_NUMBER
builtins.int"builtins.intrë
VALUE_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.VALUE_FIELD_NUMBER
builtins.int"builtins.intrù
METRIC_TYPE_FIELD_NUMBERcpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.METRIC_TYPE_FIELD_NUMBER
builtins.int"builtins.intru
nameOpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.name
builtins.str"builtins.strrw
valuePpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.value
builtins.int"builtins.intrÉ
metric_typeVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics.MetricValue.metric_type
builtins.str"builtins.strz˝
ObservedMetricsFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"builtins.object*ï
valuesMpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.values"
Any*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics0:builtins.property`*á
__init__Opyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics*(
name
builtins.str"builtins.str *◊
values»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *Ò

ClearFieldQpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.ClearField"
None*õ
selfê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.DESCRIPTOR
Anyrã
NAME_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.NAME_FIELD_NUMBER
builtins.int"builtins.intrè
VALUES_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.VALUES_FIELD_NUMBER
builtins.int"builtins.intrq
nameKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics.name
builtins.str"builtins.strz‘
ResultCompleteEpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"builtins.object*Ä
__init__Npyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete.__init__"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultCompleterg

DESCRIPTORPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete.DESCRIPTOR
Any±
KeyValue+pyspark.sql.connect.proto.base_pb2.KeyValue"builtins.object*¨
__init__4pyspark.sql.connect.proto.base_pb2.KeyValue.__init__"
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*'
key
builtins.str"builtins.str *Q
valueD
Union[builtins.str,None]
builtins.str"builtins.str
None *∞
HasField4pyspark.sql.connect.proto.base_pb2.KeyValue.HasField"
builtins.bool"builtins.bool*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≈

ClearField6pyspark.sql.connect.proto.base_pb2.KeyValue.ClearField"
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ÿ

WhichOneof6pyspark.sql.connect.proto.base_pb2.KeyValue.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrM

DESCRIPTOR6pyspark.sql.connect.proto.base_pb2.KeyValue.DESCRIPTOR
Anyrn
KEY_FIELD_NUMBER<pyspark.sql.connect.proto.base_pb2.KeyValue.KEY_FIELD_NUMBER
builtins.int"builtins.intrr
VALUE_FIELD_NUMBER>pyspark.sql.connect.proto.base_pb2.KeyValue.VALUE_FIELD_NUMBER
builtins.int"builtins.intrT
key/pyspark.sql.connect.proto.base_pb2.KeyValue.key
builtins.str"builtins.strrX
value1pyspark.sql.connect.proto.base_pb2.KeyValue.value
builtins.str"builtins.strË√
ConfigRequest0pyspark.sql.connect.proto.base_pb2.ConfigRequest"builtins.object*∂
user_context=pyspark.sql.connect.proto.base_pb2.ConfigRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest0:builtins.property`*»
	operation:pyspark.sql.connect.proto.base_pb2.ConfigRequest.operation"x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest0:builtins.property`*Ì
__init__9pyspark.sql.connect.proto.base_pb2.ConfigRequest.__init__"
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *‡
	operationŒ
FUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation,None]x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *å
HasField9pyspark.sql.connect.proto.base_pb2.ConfigRequest.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*†

ClearField;pyspark.sql.connect.proto.base_pb2.ConfigRequest.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

WhichOneof;pyspark.sql.connect.proto.base_pb2.ConfigRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.base_pb2.ConfigRequest.DESCRIPTOR
AnyrÅ
SESSION_ID_FIELD_NUMBERHpyspark.sql.connect.proto.base_pb2.ConfigRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrÖ
USER_CONTEXT_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.ConfigRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intr
OPERATION_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigRequest.OPERATION_FIELD_NUMBER
builtins.int"builtins.intrÉ
CLIENT_TYPE_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.ConfigRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrg

session_id;pyspark.sql.connect.proto.base_pb2.ConfigRequest.session_id
builtins.str"builtins.strri
client_type<pyspark.sql.connect.proto.base_pb2.ConfigRequest.client_type
builtins.str"builtins.strzëK
	Operation:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation"builtins.object*œ
set>pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.set"l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*œ
get>pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get"l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*Ä
get_with_defaultKpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get_with_default"Ç
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*È

get_optionEpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get_option"x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*›
get_allBpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.get_all"r
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*◊
unset@pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.unset"p
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*ı
is_modifiableHpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.is_modifiable"~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation0:builtins.property`*Ì
__init__Cpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*»
setº
@Union[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set,None]l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set
None *»
getº
@Union[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get,None]l
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get
None *˜
get_with_defaultﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault,None]Ç
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault
None *·

get_optionŒ
FUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption,None]x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption
None *’
get_all≈
CUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll,None]r
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll
None *–
unset¬
BUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset,None]p
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset
None *Ì
is_modifiable◊
IUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable,None]~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable
None *√
HasFieldCpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*±

ClearFieldEpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*„

WhichOneofEpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.WhichOneof"√
•Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.DESCRIPTOR
Anyr}
SET_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.SET_FIELD_NUMBER
builtins.int"builtins.intr}
GET_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_FIELD_NUMBER
builtins.int"builtins.intró
GET_WITH_DEFAULT_FIELD_NUMBERXpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_WITH_DEFAULT_FIELD_NUMBER
builtins.int"builtins.intrã
GET_OPTION_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_OPTION_FIELD_NUMBER
builtins.int"builtins.intrÖ
GET_ALL_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.GET_ALL_FIELD_NUMBER
builtins.int"builtins.intrÅ
UNSET_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.UNSET_FIELD_NUMBER
builtins.int"builtins.intrë
IS_MODIFIABLE_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation.IS_MODIFIABLE_FIELD_NUMBER
builtins.int"builtins.intz¯

Set4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"builtins.object*€
pairs:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.pairs"
Any*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set0:builtins.property`*‡
__init__=pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.__init__"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set*í
pairsÑ
HUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue],None]´
<typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue]Z
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue"typing.Iterable
None *ì

ClearField?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.DESCRIPTOR
Anyr{
PAIRS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigRequest.Set.PAIRS_FIELD_NUMBER
builtins.int"builtins.intzˆ	
Get4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"builtins.object*Ÿ
keys9pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.keys"
Any*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get0:builtins.property`*‚
__init__=pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.__init__"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ì

ClearField?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get"4pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.DESCRIPTOR
Anyry
KEYS_FIELD_NUMBERFpyspark.sql.connect.proto.base_pb2.ConfigRequest.Get.KEYS_FIELD_NUMBER
builtins.int"builtins.intzé
GetWithDefault?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"builtins.object*˛
pairsEpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.pairs"
Any*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault0:builtins.property`*É
__init__Hpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault*í
pairsÑ
HUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue],None]´
<typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue]Z
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue"typing.Iterable
None *∂

ClearFieldJpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault"?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.DESCRIPTOR
AnyrÜ
PAIRS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetWithDefault.PAIRS_FIELD_NUMBER
builtins.int"builtins.intz«

	GetOption:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption"builtins.object*Ï
keys?pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.keys"
Any*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption0:builtins.property`*ı
__init__Cpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *¶

ClearFieldEpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption":pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.DESCRIPTOR
Anyr
KEYS_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetOption.KEYS_FIELD_NUMBER
builtins.int"builtins.intzﬂ
GetAll7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"builtins.object*®
__init__@pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.__init__"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*R
prefixD
Union[builtins.str,None]
builtins.str"builtins.str
None *‘
HasField@pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.HasField"
builtins.bool"builtins.bool*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¬

ClearFieldBpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

WhichOneofBpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll"7pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.DESCRIPTOR
AnyrÄ
PREFIX_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.PREFIX_FIELD_NUMBER
builtins.int"builtins.intrf
prefix>pyspark.sql.connect.proto.base_pb2.ConfigRequest.GetAll.prefix
builtins.str"builtins.strzê

Unset6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"builtins.object*ﬂ
keys;pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.keys"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset0:builtins.property`*Ë
__init__?pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ô

ClearFieldApyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset"6pyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.DESCRIPTOR
Anyr{
KEYS_FIELD_NUMBERHpyspark.sql.connect.proto.base_pb2.ConfigRequest.Unset.KEYS_FIELD_NUMBER
builtins.int"builtins.intzÔ

IsModifiable=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"builtins.object*ı
keysBpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.keys"
Any*à
self~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable0:builtins.property`*˛
__init__Fpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.__init__"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable*î
keysá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ø

ClearFieldHpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.ClearField"
None*à
self~
=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable"=pyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.DESCRIPTOR
AnyrÇ
KEYS_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ConfigRequest.IsModifiable.KEYS_FIELD_NUMBER
builtins.int"builtins.int¡
ConfigResponse1pyspark.sql.connect.proto.base_pb2.ConfigResponse"builtins.object*“
pairs7pyspark.sql.connect.proto.base_pb2.ConfigResponse.pairs"
Any*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse0:builtins.property`*ÿ
warnings:pyspark.sql.connect.proto.base_pb2.ConfigResponse.warnings"
Any*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse0:builtins.property`*¢
__init__:pyspark.sql.connect.proto.base_pb2.ConfigResponse.__init__"
None*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse*.

session_id
builtins.str"builtins.str *í
pairsÑ
HUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue],None]´
<typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue]Z
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue"typing.Iterable
None *ò
warningsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *◊

ClearField<pyspark.sql.connect.proto.base_pb2.ConfigResponse.ClearField"
None*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.base_pb2.ConfigResponse.DESCRIPTOR
AnyrÇ
SESSION_ID_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.ConfigResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrx
PAIRS_FIELD_NUMBERDpyspark.sql.connect.proto.base_pb2.ConfigResponse.PAIRS_FIELD_NUMBER
builtins.int"builtins.intr~
WARNINGS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigResponse.WARNINGS_FIELD_NUMBER
builtins.int"builtins.intrh

session_id<pyspark.sql.connect.proto.base_pb2.ConfigResponse.session_id
builtins.str"builtins.strèé
AddArtifactsRequest6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"builtins.object*»
user_contextCpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*÷
batch<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.batch"|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*Å
begin_chunkBpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.begin_chunk"ö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*Á
chunk<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.chunk"å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:builtins.property`*ò

__init__?pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *‚
batch‘
HUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch,None]|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch
None *ñ
begin_chunkÇ
WUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact,None]ö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact
None *˚
chunkÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk,None]å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk
None *ê
HasField?pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearFieldApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2í


WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneofè

WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÆ

WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneof"Ü
MUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
USER_CONTEXT_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrâ
CLIENT_TYPE_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intr}
BATCH_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BATCH_FIELD_NUMBER
builtins.int"builtins.intrâ
BEGIN_CHUNK_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BEGIN_CHUNK_FIELD_NUMBER
builtins.int"builtins.intr}
CHUNK_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.CHUNK_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.session_id
builtins.str"builtins.strro
client_typeBpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.client_type
builtins.str"builtins.strzç
ArtifactChunkDpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"builtins.object*‘
__init__Mpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*,
data 
builtins.bytes"builtins.bytes *'
crc
builtins.int"builtins.int *Î

ClearFieldOpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.DESCRIPTOR
Anyrâ
DATA_FIELD_NUMBERVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.DATA_FIELD_NUMBER
builtins.int"builtins.intrá
CRC_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.CRC_FIELD_NUMBER
builtins.int"builtins.intrs
dataIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.data 
builtins.bytes"builtins.bytesrm
crcHpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk.crc
builtins.int"builtins.intz∆
SingleChunkArtifactJpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"builtins.object*£
dataOpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.data"å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact0:builtins.property`*∂
__init__Spyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.__init__"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact*(
name
builtins.str"builtins.str *˙
dataÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk,None]å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk
None *È
HasFieldSpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.HasField"
builtins.bool"builtins.bool*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

ClearFieldUpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.ClearField"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrl

DESCRIPTORUpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.DESCRIPTOR
Anyrè
NAME_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.NAME_FIELD_NUMBER
builtins.int"builtins.intrè
DATA_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.DATA_FIELD_NUMBER
builtins.int"builtins.intru
nameOpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact.name
builtins.str"builtins.strzÔ
Batch<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"builtins.object*¸
	artifactsFpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.artifacts"
Any*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch0:builtins.property`*˙
__init__Epyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch*ì
	artifactsÅ
gUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact],None]â
[typing.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact]ò
Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"Jpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SingleChunkArtifact"typing.Iterable
None *¨

ClearFieldGpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.DESCRIPTOR
Anyrã
ARTIFACTS_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch.ARTIFACTS_FIELD_NUMBER
builtins.int"builtins.intzˇ
BeginChunkedArtifactKpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"builtins.object*∏
initial_chunkYpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.initial_chunk"å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact0:builtins.property`*£
__init__Tpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.__init__"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*(
name
builtins.str"builtins.str */
total_bytes
builtins.int"builtins.int *.

num_chunks
builtins.int"builtins.int *É
initial_chunkÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk,None]å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk
None *Ï
HasFieldTpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.HasField"
builtins.bool"builtins.bool*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Õ

ClearFieldVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.ClearField"
None*•
selfö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrm

DESCRIPTORVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.DESCRIPTOR
Anyrê
NAME_FIELD_NUMBER]pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.NAME_FIELD_NUMBER
builtins.int"builtins.intrû
TOTAL_BYTES_FIELD_NUMBERdpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.TOTAL_BYTES_FIELD_NUMBER
builtins.int"builtins.intrú
NUM_CHUNKS_FIELD_NUMBERcpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.NUM_CHUNKS_FIELD_NUMBER
builtins.int"builtins.intr¢
INITIAL_CHUNK_FIELD_NUMBERfpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.INITIAL_CHUNK_FIELD_NUMBER
builtins.int"builtins.intrv
namePpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.name
builtins.str"builtins.strrÑ
total_bytesWpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.total_bytes
builtins.int"builtins.intrÇ

num_chunksVpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact.num_chunks
builtins.int"builtins.int¨
AddArtifactsResponse7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"builtins.object*Ï
	artifactsApyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.artifacts"
Any*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse0:builtins.property`*ﬁ
__init__@pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.__init__"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse*á
	artifactsı
dUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary],None]Ä
Xtyping.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary]í
Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"typing.Iterable
None *ú

ClearFieldBpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.DESCRIPTOR
AnyrÜ
ARTIFACTS_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ARTIFACTS_FIELD_NUMBER
builtins.int"builtins.intzˆ
ArtifactSummaryGpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"builtins.object*È
__init__Ppyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.__init__"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary*(
name
builtins.str"builtins.str *7
is_crc_successful
builtins.bool"builtins.bool *Ù

ClearFieldRpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.ClearField"
None*ù
selfí
Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesri

DESCRIPTORRpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.DESCRIPTOR
Anyrå
NAME_FIELD_NUMBERYpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.NAME_FIELD_NUMBER
builtins.int"builtins.intr¶
IS_CRC_SUCCESSFUL_FIELD_NUMBERfpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.IS_CRC_SUCCESSFUL_FIELD_NUMBER
builtins.int"builtins.intrr
nameLpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.name
builtins.str"builtins.strré
is_crc_successfulYpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary.is_crc_successful
builtins.bool"builtins.bool¡$
ArtifactStatusesRequest:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest"builtins.object*’
user_contextGpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest0:builtins.property`*Ó
names@pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.names"
Any*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest0:builtins.property`*¡
__init__Cpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *ï
namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ö
HasFieldCpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ø

ClearFieldEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*á

WhichOneofEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.DESCRIPTOR
Anyrã
SESSION_ID_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrè
USER_CONTEXT_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrç
CLIENT_TYPE_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÅ
NAMES_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.NAMES_FIELD_NUMBER
builtins.int"builtins.intrq

session_idEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.session_id
builtins.str"builtins.strrs
client_typeFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.client_type
builtins.str"builtins.strÅ-
ArtifactStatusesResponse;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse"builtins.object*˜
statusesDpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.statuses"
Any*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse0:builtins.property`*´
__init__Dpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.__init__"
None*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse*«
statuses∂
sUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus],None]≤
gtyping.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus]
builtins.str"builtins.strò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"typing.Mapping
None *©

ClearFieldFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ClearField"
None*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.DESCRIPTOR
Anyrà
STATUSES_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.STATUSES_FIELD_NUMBER
builtins.int"builtins.intzà

ArtifactStatusJpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"builtins.object*Ω
__init__Spyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.__init__"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus*,
exists
builtins.bool"builtins.bool *◊

ClearFieldUpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.ClearField"
None*£
selfò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrl

DESCRIPTORUpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.DESCRIPTOR
Anyrì
EXISTS_FIELD_NUMBER^pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.EXISTS_FIELD_NUMBER
builtins.int"builtins.intr{
existsQpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus.exists
builtins.bool"builtins.boolzÕ
StatusesEntryIpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"builtins.object*Æ
valueOpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.value"ò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry0:builtins.property`*≈
__init__Rpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry*'
key
builtins.str"builtins.str *ç
valueˇ
VUnion[pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus,None]ò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus
None *Ê
HasFieldRpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.HasField"
builtins.bool"builtins.bool*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

ClearFieldTpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.ClearField"
None*°
selfñ
Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry"Ipyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrk

DESCRIPTORTpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.DESCRIPTOR
Anyrå
KEY_FIELD_NUMBERZpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrê
VALUE_FIELD_NUMBER\pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrr
keyMpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.StatusesEntry.key
builtins.str"builtins.strÓN
InterruptRequest3pyspark.sql.connect.proto.base_pb2.InterruptRequest"builtins.object*ø
user_context@pyspark.sql.connect.proto.base_pb2.InterruptRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest0:builtins.property`*Æ
__init__<pyspark.sql.connect.proto.base_pb2.InterruptRequest.__init__"
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *≥
interrupt_typeú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType *1
operation_tag
builtins.str"builtins.str *0
operation_id
builtins.str"builtins.str *·	
HasField<pyspark.sql.connect.proto.base_pb2.InterruptRequest.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*õ

ClearField>pyspark.sql.connect.proto.base_pb2.InterruptRequest.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Æ	

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneofÜ

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX÷

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrU

DESCRIPTOR>pyspark.sql.connect.proto.base_pb2.InterruptRequest.DESCRIPTOR
Anyrã
INTERRUPT_TYPE_UNSPECIFIEDNpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_UNSPECIFIEDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper˚
INTERRUPT_TYPE_ALLFpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_ALLú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper˚
INTERRUPT_TYPE_TAGFpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_TAGú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperç
INTERRUPT_TYPE_OPERATION_IDOpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_OPERATION_IDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperÑ
SESSION_ID_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.InterruptRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrà
USER_CONTEXT_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.InterruptRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrÜ
CLIENT_TYPE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.InterruptRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrå
INTERRUPT_TYPE_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_FIELD_NUMBER
builtins.int"builtins.inträ
OPERATION_TAG_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.InterruptRequest.OPERATION_TAG_FIELD_NUMBER
builtins.int"builtins.intrà
OPERATION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.InterruptRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrj

session_id>pyspark.sql.connect.proto.base_pb2.InterruptRequest.session_id
builtins.str"builtins.strrl
client_type?pyspark.sql.connect.proto.base_pb2.InterruptRequest.client_type
builtins.str"builtins.strrÛ
interrupt_typeBpyspark.sql.connect.proto.base_pb2.InterruptRequest.interrupt_typeú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperp
operation_tagApyspark.sql.connect.proto.base_pb2.InterruptRequest.operation_tag
builtins.str"builtins.strrn
operation_id@pyspark.sql.connect.proto.base_pb2.InterruptRequest.operation_id
builtins.str"builtins.strzè
_InterruptTypeBpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType"builtins.objectzß
	ValueTypeLpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"builtins.int*Ω
__init__Upyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType.__init__"
None*ß
selfú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType*&
item
builtins.int"builtins.intzà
_InterruptTypeEnumTypeWrapperQpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper"builtins.typers

DESCRIPTOR\pyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.DESCRIPTOR
Anyr©
INTERRUPT_TYPE_UNSPECIFIEDlpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_UNSPECIFIEDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperô
INTERRUPT_TYPE_ALLdpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_ALLú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperô
INTERRUPT_TYPE_TAGdpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_TAGú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper´
INTERRUPT_TYPE_OPERATION_IDmpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapper.INTERRUPT_TYPE_OPERATION_IDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTypezÎ
InterruptTypeApyspark.sql.connect.proto.base_pb2.InterruptRequest.InterruptType"Bpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType@bQpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptTypeEnumTypeWrapperá
InterruptResponse4pyspark.sql.connect.proto.base_pb2.InterruptResponse"builtins.object*Ô
interrupted_idsDpyspark.sql.connect.proto.base_pb2.InterruptResponse.interrupted_ids"
Any*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse0:builtins.property`*ù
__init__=pyspark.sql.connect.proto.base_pb2.InterruptResponse.__init__"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse*.

session_id
builtins.str"builtins.str *ü
interrupted_idsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *π

ClearField?pyspark.sql.connect.proto.base_pb2.InterruptResponse.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.base_pb2.InterruptResponse.DESCRIPTOR
AnyrÖ
SESSION_ID_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.InterruptResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrè
INTERRUPTED_IDS_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.InterruptResponse.INTERRUPTED_IDS_FIELD_NUMBER
builtins.int"builtins.intrk

session_id?pyspark.sql.connect.proto.base_pb2.InterruptResponse.session_id
builtins.str"builtins.str≥
ReattachOptions2pyspark.sql.connect.proto.base_pb2.ReattachOptions"builtins.object*˘
__init__;pyspark.sql.connect.proto.base_pb2.ReattachOptions.__init__"
None*r
selfh
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*2
reattachable
builtins.bool"builtins.bool *ç

ClearField=pyspark.sql.connect.proto.base_pb2.ReattachOptions.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.base_pb2.ReattachOptions.DESCRIPTOR
Anyrá
REATTACHABLE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.ReattachOptions.REATTACHABLE_FIELD_NUMBER
builtins.int"builtins.intro
reattachable?pyspark.sql.connect.proto.base_pb2.ReattachOptions.reattachable
builtins.bool"builtins.boolÈ/
ReattachExecuteRequest9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"builtins.object*“
user_contextFpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest0:builtins.property`*∂
__init__Bpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *0
operation_id
builtins.str"builtins.str *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *\
last_response_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *Œ
HasFieldBpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*à

ClearFieldDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ä	

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneofô

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXô

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXr[

DESCRIPTORDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.DESCRIPTOR
Anyrä
SESSION_ID_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intré
USER_CONTEXT_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intré
OPERATION_ID_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrå
CLIENT_TYPE_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrñ
LAST_RESPONSE_ID_FIELD_NUMBERWpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.LAST_RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intrp

session_idDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.session_id
builtins.str"builtins.strrt
operation_idFpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.operation_id
builtins.str"builtins.strrr
client_typeEpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.client_type
builtins.str"builtins.strr|
last_response_idJpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.last_response_id
builtins.str"builtins.str»I
ReleaseExecuteRequest8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"builtins.object*Œ
user_contextEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:builtins.property`*˜
release_allDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.release_all"ä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:builtins.property`*ˇ
release_untilFpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.release_until"é
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:builtins.property`*ﬁ
__init__Apyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.__init__"
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *0
operation_id
builtins.str"builtins.str *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *˛
release_allÍ
OUnion[pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll,None]ä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll
None *Ü
release_until
QUnion[pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil,None]é
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil
None *	
HasFieldApyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.HasField"
builtins.bool"builtins.bool*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*™

ClearFieldCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ClearField"
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2—	

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneofï

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÂ

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrZ

DESCRIPTORCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.DESCRIPTOR
Anyrâ
SESSION_ID_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrç
USER_CONTEXT_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrç
OPERATION_ID_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
CLIENT_TYPE_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrã
RELEASE_ALL_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.RELEASE_ALL_FIELD_NUMBER
builtins.int"builtins.intrè
RELEASE_UNTIL_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.RELEASE_UNTIL_FIELD_NUMBER
builtins.int"builtins.intro

session_idCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.session_id
builtins.str"builtins.strrs
operation_idEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.operation_id
builtins.str"builtins.strrq
client_typeDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.client_type
builtins.str"builtins.strz∆

ReleaseAllCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"builtins.object*˙
__init__Lpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAllre

DESCRIPTORNpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll.DESCRIPTOR
AnyzÈ	
ReleaseUntilEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"builtins.object*±
__init__Npyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.__init__"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil*/
response_id
builtins.str"builtins.str *»

ClearFieldPpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.ClearField"
None*ô
selfé
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrg

DESCRIPTORPpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.DESCRIPTOR
Anyrò
RESPONSE_ID_FIELD_NUMBER^pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intr~
response_idQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil.response_id
builtins.str"builtins.strá
ReleaseExecuteResponse9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"builtins.object*Â
__init__Bpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*.

session_id
builtins.str"builtins.str *X
operation_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *€
HasFieldBpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*

ClearFieldDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ñ

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr[

DESCRIPTORDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.DESCRIPTOR
Anyrä
SESSION_ID_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intré
OPERATION_ID_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrp

session_idDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.session_id
builtins.str"builtins.strrt
operation_idFpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.operation_id
builtins.str"builtins.str’ı
DataType,pyspark.sql.connect.proto.types_pb2.DataType"builtins.object*†
null1pyspark.sql.connect.proto.types_pb2.DataType.null"f
1pyspark.sql.connect.proto.types_pb2.DataType.NULL"1pyspark.sql.connect.proto.types_pb2.DataType.NULL*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*®
binary3pyspark.sql.connect.proto.types_pb2.DataType.binary"j
3pyspark.sql.connect.proto.types_pb2.DataType.Binary"3pyspark.sql.connect.proto.types_pb2.DataType.Binary*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*¨
boolean4pyspark.sql.connect.proto.types_pb2.DataType.boolean"l
4pyspark.sql.connect.proto.types_pb2.DataType.Boolean"4pyspark.sql.connect.proto.types_pb2.DataType.Boolean*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*†
byte1pyspark.sql.connect.proto.types_pb2.DataType.byte"f
1pyspark.sql.connect.proto.types_pb2.DataType.Byte"1pyspark.sql.connect.proto.types_pb2.DataType.Byte*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*§
short2pyspark.sql.connect.proto.types_pb2.DataType.short"h
2pyspark.sql.connect.proto.types_pb2.DataType.Short"2pyspark.sql.connect.proto.types_pb2.DataType.Short*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*¨
integer4pyspark.sql.connect.proto.types_pb2.DataType.integer"l
4pyspark.sql.connect.proto.types_pb2.DataType.Integer"4pyspark.sql.connect.proto.types_pb2.DataType.Integer*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*†
long1pyspark.sql.connect.proto.types_pb2.DataType.long"f
1pyspark.sql.connect.proto.types_pb2.DataType.Long"1pyspark.sql.connect.proto.types_pb2.DataType.Long*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*§
float2pyspark.sql.connect.proto.types_pb2.DataType.float"h
2pyspark.sql.connect.proto.types_pb2.DataType.Float"2pyspark.sql.connect.proto.types_pb2.DataType.Float*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*®
double3pyspark.sql.connect.proto.types_pb2.DataType.double"j
3pyspark.sql.connect.proto.types_pb2.DataType.Double"3pyspark.sql.connect.proto.types_pb2.DataType.Double*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*¨
decimal4pyspark.sql.connect.proto.types_pb2.DataType.decimal"l
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*®
string3pyspark.sql.connect.proto.types_pb2.DataType.string"j
3pyspark.sql.connect.proto.types_pb2.DataType.String"3pyspark.sql.connect.proto.types_pb2.DataType.String*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*†
char1pyspark.sql.connect.proto.types_pb2.DataType.char"f
1pyspark.sql.connect.proto.types_pb2.DataType.Char"1pyspark.sql.connect.proto.types_pb2.DataType.Char*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*Æ
var_char5pyspark.sql.connect.proto.types_pb2.DataType.var_char"l
4pyspark.sql.connect.proto.types_pb2.DataType.VarChar"4pyspark.sql.connect.proto.types_pb2.DataType.VarChar*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*†
date1pyspark.sql.connect.proto.types_pb2.DataType.date"f
1pyspark.sql.connect.proto.types_pb2.DataType.Date"1pyspark.sql.connect.proto.types_pb2.DataType.Date*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*¥
	timestamp6pyspark.sql.connect.proto.types_pb2.DataType.timestamp"p
6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp"6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*¬
timestamp_ntz:pyspark.sql.connect.proto.types_pb2.DataType.timestamp_ntz"v
9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ"9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*“
calendar_interval>pyspark.sql.connect.proto.types_pb2.DataType.calendar_interval"~
=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval"=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*Ÿ
year_month_interval@pyspark.sql.connect.proto.types_pb2.DataType.year_month_interval"Ä
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*–
day_time_interval>pyspark.sql.connect.proto.types_pb2.DataType.day_time_interval"|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*§
array2pyspark.sql.connect.proto.types_pb2.DataType.array"h
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*®
struct3pyspark.sql.connect.proto.types_pb2.DataType.struct"j
3pyspark.sql.connect.proto.types_pb2.DataType.Struct"3pyspark.sql.connect.proto.types_pb2.DataType.Struct*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*ú
map0pyspark.sql.connect.proto.types_pb2.DataType.map"d
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*ú
udt0pyspark.sql.connect.proto.types_pb2.DataType.udt"d
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*∞
unparsed5pyspark.sql.connect.proto.types_pb2.DataType.unparsed"n
5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed"5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:builtins.property`*´(
__init__5pyspark.sql.connect.proto.types_pb2.DataType.__init__"
None*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*¿
null≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.NULL,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.NULL"1pyspark.sql.connect.proto.types_pb2.DataType.NULL
None *»
binaryπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.Binary,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.Binary"3pyspark.sql.connect.proto.types_pb2.DataType.Binary
None *Ã
booleanº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.Boolean,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.Boolean"4pyspark.sql.connect.proto.types_pb2.DataType.Boolean
None *¿
byte≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Byte,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Byte"1pyspark.sql.connect.proto.types_pb2.DataType.Byte
None *ƒ
short∂
>Union[pyspark.sql.connect.proto.types_pb2.DataType.Short,None]h
2pyspark.sql.connect.proto.types_pb2.DataType.Short"2pyspark.sql.connect.proto.types_pb2.DataType.Short
None *Ã
integerº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.Integer,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.Integer"4pyspark.sql.connect.proto.types_pb2.DataType.Integer
None *¿
long≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Long,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Long"1pyspark.sql.connect.proto.types_pb2.DataType.Long
None *ƒ
float∂
>Union[pyspark.sql.connect.proto.types_pb2.DataType.Float,None]h
2pyspark.sql.connect.proto.types_pb2.DataType.Float"2pyspark.sql.connect.proto.types_pb2.DataType.Float
None *»
doubleπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.Double,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.Double"3pyspark.sql.connect.proto.types_pb2.DataType.Double
None *Ã
decimalº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.Decimal,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal
None *»
stringπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.String,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.String"3pyspark.sql.connect.proto.types_pb2.DataType.String
None *¿
char≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Char,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Char"1pyspark.sql.connect.proto.types_pb2.DataType.Char
None *Õ
var_charº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.VarChar,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.VarChar"4pyspark.sql.connect.proto.types_pb2.DataType.VarChar
None *¿
date≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Date,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Date"1pyspark.sql.connect.proto.types_pb2.DataType.Date
None *‘
	timestamp¬
BUnion[pyspark.sql.connect.proto.types_pb2.DataType.Timestamp,None]p
6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp"6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp
None *·
timestamp_ntzÀ
EUnion[pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ,None]v
9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ"9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ
None *Ò
calendar_interval◊
IUnion[pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval,None]~
=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval"=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval
None *˜
year_month_interval€
JUnion[pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval,None]Ä
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval
None *Ó
day_time_interval‘
HUnion[pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval,None]|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval
None *ƒ
array∂
>Union[pyspark.sql.connect.proto.types_pb2.DataType.Array,None]h
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array
None *»
structπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.Struct,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.Struct"3pyspark.sql.connect.proto.types_pb2.DataType.Struct
None *º
map∞
<Union[pyspark.sql.connect.proto.types_pb2.DataType.Map,None]d
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map
None *º
udt∞
<Union[pyspark.sql.connect.proto.types_pb2.DataType.UDT,None]d
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT
None *–
unparsedø
AUnion[pyspark.sql.connect.proto.types_pb2.DataType.Unparsed,None]n
5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed"5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed
None *û"
HasField5pyspark.sql.connect.proto.types_pb2.DataType.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*“ 

field_name¡ 
Ñ	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*å"

ClearField7pyspark.sql.connect.proto.types_pb2.DataType.ClearField"
None*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*“ 

field_name¡ 
Ñ	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˜

WhichOneof7pyspark.sql.connect.proto.types_pb2.DataType.WhichOneof"Ç
õUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.types_pb2.DataType.DESCRIPTOR
Anyrq
NULL_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.NULL_FIELD_NUMBER
builtins.int"builtins.intru
BINARY_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.BINARY_FIELD_NUMBER
builtins.int"builtins.intrw
BOOLEAN_FIELD_NUMBERApyspark.sql.connect.proto.types_pb2.DataType.BOOLEAN_FIELD_NUMBER
builtins.int"builtins.intrq
BYTE_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.BYTE_FIELD_NUMBER
builtins.int"builtins.intrs
SHORT_FIELD_NUMBER?pyspark.sql.connect.proto.types_pb2.DataType.SHORT_FIELD_NUMBER
builtins.int"builtins.intrw
INTEGER_FIELD_NUMBERApyspark.sql.connect.proto.types_pb2.DataType.INTEGER_FIELD_NUMBER
builtins.int"builtins.intrq
LONG_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.LONG_FIELD_NUMBER
builtins.int"builtins.intrs
FLOAT_FIELD_NUMBER?pyspark.sql.connect.proto.types_pb2.DataType.FLOAT_FIELD_NUMBER
builtins.int"builtins.intru
DOUBLE_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.DOUBLE_FIELD_NUMBER
builtins.int"builtins.intrw
DECIMAL_FIELD_NUMBERApyspark.sql.connect.proto.types_pb2.DataType.DECIMAL_FIELD_NUMBER
builtins.int"builtins.intru
STRING_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.STRING_FIELD_NUMBER
builtins.int"builtins.intrq
CHAR_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.CHAR_FIELD_NUMBER
builtins.int"builtins.intry
VAR_CHAR_FIELD_NUMBERBpyspark.sql.connect.proto.types_pb2.DataType.VAR_CHAR_FIELD_NUMBER
builtins.int"builtins.intrq
DATE_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.DATE_FIELD_NUMBER
builtins.int"builtins.intr{
TIMESTAMP_FIELD_NUMBERCpyspark.sql.connect.proto.types_pb2.DataType.TIMESTAMP_FIELD_NUMBER
builtins.int"builtins.intrÉ
TIMESTAMP_NTZ_FIELD_NUMBERGpyspark.sql.connect.proto.types_pb2.DataType.TIMESTAMP_NTZ_FIELD_NUMBER
builtins.int"builtins.intrã
CALENDAR_INTERVAL_FIELD_NUMBERKpyspark.sql.connect.proto.types_pb2.DataType.CALENDAR_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrè
 YEAR_MONTH_INTERVAL_FIELD_NUMBERMpyspark.sql.connect.proto.types_pb2.DataType.YEAR_MONTH_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrã
DAY_TIME_INTERVAL_FIELD_NUMBERKpyspark.sql.connect.proto.types_pb2.DataType.DAY_TIME_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrs
ARRAY_FIELD_NUMBER?pyspark.sql.connect.proto.types_pb2.DataType.ARRAY_FIELD_NUMBER
builtins.int"builtins.intru
STRUCT_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.STRUCT_FIELD_NUMBER
builtins.int"builtins.intro
MAP_FIELD_NUMBER=pyspark.sql.connect.proto.types_pb2.DataType.MAP_FIELD_NUMBER
builtins.int"builtins.intro
UDT_FIELD_NUMBER=pyspark.sql.connect.proto.types_pb2.DataType.UDT_FIELD_NUMBER
builtins.int"builtins.intry
UNPARSED_FIELD_NUMBERBpyspark.sql.connect.proto.types_pb2.DataType.UNPARSED_FIELD_NUMBER
builtins.int"builtins.intz¯
Boolean4pyspark.sql.connect.proto.types_pb2.DataType.Boolean"builtins.object*â
__init__=pyspark.sql.connect.proto.types_pb2.DataType.Boolean.__init__"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Boolean"4pyspark.sql.connect.proto.types_pb2.DataType.Boolean*<
type_variation_reference
builtins.int"builtins.int *ì

ClearField?pyspark.sql.connect.proto.types_pb2.DataType.Boolean.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Boolean"4pyspark.sql.connect.proto.types_pb2.DataType.Boolean*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.types_pb2.DataType.Boolean.DESCRIPTOR
Anyr°
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERZpyspark.sql.connect.proto.types_pb2.DataType.Boolean.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrá
type_variation_referenceMpyspark.sql.connect.proto.types_pb2.DataType.Boolean.type_variation_reference
builtins.int"builtins.intz◊
Byte1pyspark.sql.connect.proto.types_pb2.DataType.Byte"builtins.object*Ä
__init__:pyspark.sql.connect.proto.types_pb2.DataType.Byte.__init__"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Byte"1pyspark.sql.connect.proto.types_pb2.DataType.Byte*<
type_variation_reference
builtins.int"builtins.int *ä

ClearField<pyspark.sql.connect.proto.types_pb2.DataType.Byte.ClearField"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Byte"1pyspark.sql.connect.proto.types_pb2.DataType.Byte*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.types_pb2.DataType.Byte.DESCRIPTOR
Anyrû
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERWpyspark.sql.connect.proto.types_pb2.DataType.Byte.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÑ
type_variation_referenceJpyspark.sql.connect.proto.types_pb2.DataType.Byte.type_variation_reference
builtins.int"builtins.intz‚
Short2pyspark.sql.connect.proto.types_pb2.DataType.Short"builtins.object*É
__init__;pyspark.sql.connect.proto.types_pb2.DataType.Short.__init__"
None*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Short"2pyspark.sql.connect.proto.types_pb2.DataType.Short*<
type_variation_reference
builtins.int"builtins.int *ç

ClearField=pyspark.sql.connect.proto.types_pb2.DataType.Short.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Short"2pyspark.sql.connect.proto.types_pb2.DataType.Short*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.types_pb2.DataType.Short.DESCRIPTOR
Anyrü
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERXpyspark.sql.connect.proto.types_pb2.DataType.Short.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÖ
type_variation_referenceKpyspark.sql.connect.proto.types_pb2.DataType.Short.type_variation_reference
builtins.int"builtins.intz¯
Integer4pyspark.sql.connect.proto.types_pb2.DataType.Integer"builtins.object*â
__init__=pyspark.sql.connect.proto.types_pb2.DataType.Integer.__init__"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Integer"4pyspark.sql.connect.proto.types_pb2.DataType.Integer*<
type_variation_reference
builtins.int"builtins.int *ì

ClearField?pyspark.sql.connect.proto.types_pb2.DataType.Integer.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Integer"4pyspark.sql.connect.proto.types_pb2.DataType.Integer*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.types_pb2.DataType.Integer.DESCRIPTOR
Anyr°
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERZpyspark.sql.connect.proto.types_pb2.DataType.Integer.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrá
type_variation_referenceMpyspark.sql.connect.proto.types_pb2.DataType.Integer.type_variation_reference
builtins.int"builtins.intz◊
Long1pyspark.sql.connect.proto.types_pb2.DataType.Long"builtins.object*Ä
__init__:pyspark.sql.connect.proto.types_pb2.DataType.Long.__init__"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Long"1pyspark.sql.connect.proto.types_pb2.DataType.Long*<
type_variation_reference
builtins.int"builtins.int *ä

ClearField<pyspark.sql.connect.proto.types_pb2.DataType.Long.ClearField"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Long"1pyspark.sql.connect.proto.types_pb2.DataType.Long*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.types_pb2.DataType.Long.DESCRIPTOR
Anyrû
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERWpyspark.sql.connect.proto.types_pb2.DataType.Long.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÑ
type_variation_referenceJpyspark.sql.connect.proto.types_pb2.DataType.Long.type_variation_reference
builtins.int"builtins.intz‚
Float2pyspark.sql.connect.proto.types_pb2.DataType.Float"builtins.object*É
__init__;pyspark.sql.connect.proto.types_pb2.DataType.Float.__init__"
None*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Float"2pyspark.sql.connect.proto.types_pb2.DataType.Float*<
type_variation_reference
builtins.int"builtins.int *ç

ClearField=pyspark.sql.connect.proto.types_pb2.DataType.Float.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Float"2pyspark.sql.connect.proto.types_pb2.DataType.Float*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.types_pb2.DataType.Float.DESCRIPTOR
Anyrü
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERXpyspark.sql.connect.proto.types_pb2.DataType.Float.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÖ
type_variation_referenceKpyspark.sql.connect.proto.types_pb2.DataType.Float.type_variation_reference
builtins.int"builtins.intzÌ
Double3pyspark.sql.connect.proto.types_pb2.DataType.Double"builtins.object*Ü
__init__<pyspark.sql.connect.proto.types_pb2.DataType.Double.__init__"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.Double"3pyspark.sql.connect.proto.types_pb2.DataType.Double*<
type_variation_reference
builtins.int"builtins.int *ê

ClearField>pyspark.sql.connect.proto.types_pb2.DataType.Double.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.Double"3pyspark.sql.connect.proto.types_pb2.DataType.Double*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.types_pb2.DataType.Double.DESCRIPTOR
Anyr†
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERYpyspark.sql.connect.proto.types_pb2.DataType.Double.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÜ
type_variation_referenceLpyspark.sql.connect.proto.types_pb2.DataType.Double.type_variation_reference
builtins.int"builtins.intzÌ
String3pyspark.sql.connect.proto.types_pb2.DataType.String"builtins.object*Ü
__init__<pyspark.sql.connect.proto.types_pb2.DataType.String.__init__"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.String"3pyspark.sql.connect.proto.types_pb2.DataType.String*<
type_variation_reference
builtins.int"builtins.int *ê

ClearField>pyspark.sql.connect.proto.types_pb2.DataType.String.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.String"3pyspark.sql.connect.proto.types_pb2.DataType.String*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.types_pb2.DataType.String.DESCRIPTOR
Anyr†
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERYpyspark.sql.connect.proto.types_pb2.DataType.String.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÜ
type_variation_referenceLpyspark.sql.connect.proto.types_pb2.DataType.String.type_variation_reference
builtins.int"builtins.intzÌ
Binary3pyspark.sql.connect.proto.types_pb2.DataType.Binary"builtins.object*Ü
__init__<pyspark.sql.connect.proto.types_pb2.DataType.Binary.__init__"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.Binary"3pyspark.sql.connect.proto.types_pb2.DataType.Binary*<
type_variation_reference
builtins.int"builtins.int *ê

ClearField>pyspark.sql.connect.proto.types_pb2.DataType.Binary.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.Binary"3pyspark.sql.connect.proto.types_pb2.DataType.Binary*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.types_pb2.DataType.Binary.DESCRIPTOR
Anyr†
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERYpyspark.sql.connect.proto.types_pb2.DataType.Binary.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÜ
type_variation_referenceLpyspark.sql.connect.proto.types_pb2.DataType.Binary.type_variation_reference
builtins.int"builtins.intz◊
NULL1pyspark.sql.connect.proto.types_pb2.DataType.NULL"builtins.object*Ä
__init__:pyspark.sql.connect.proto.types_pb2.DataType.NULL.__init__"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.NULL"1pyspark.sql.connect.proto.types_pb2.DataType.NULL*<
type_variation_reference
builtins.int"builtins.int *ä

ClearField<pyspark.sql.connect.proto.types_pb2.DataType.NULL.ClearField"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.NULL"1pyspark.sql.connect.proto.types_pb2.DataType.NULL*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.types_pb2.DataType.NULL.DESCRIPTOR
Anyrû
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERWpyspark.sql.connect.proto.types_pb2.DataType.NULL.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÑ
type_variation_referenceJpyspark.sql.connect.proto.types_pb2.DataType.NULL.type_variation_reference
builtins.int"builtins.intzé	
	Timestamp6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp"builtins.object*è
__init__?pyspark.sql.connect.proto.types_pb2.DataType.Timestamp.__init__"
None*z
selfp
6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp"6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp*<
type_variation_reference
builtins.int"builtins.int *ô

ClearFieldApyspark.sql.connect.proto.types_pb2.DataType.Timestamp.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp"6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.types_pb2.DataType.Timestamp.DESCRIPTOR
Anyr£
%TYPE_VARIATION_REFERENCE_FIELD_NUMBER\pyspark.sql.connect.proto.types_pb2.DataType.Timestamp.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrâ
type_variation_referenceOpyspark.sql.connect.proto.types_pb2.DataType.Timestamp.type_variation_reference
builtins.int"builtins.intz◊
Date1pyspark.sql.connect.proto.types_pb2.DataType.Date"builtins.object*Ä
__init__:pyspark.sql.connect.proto.types_pb2.DataType.Date.__init__"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Date"1pyspark.sql.connect.proto.types_pb2.DataType.Date*<
type_variation_reference
builtins.int"builtins.int *ä

ClearField<pyspark.sql.connect.proto.types_pb2.DataType.Date.ClearField"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Date"1pyspark.sql.connect.proto.types_pb2.DataType.Date*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.types_pb2.DataType.Date.DESCRIPTOR
Anyrû
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERWpyspark.sql.connect.proto.types_pb2.DataType.Date.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÑ
type_variation_referenceJpyspark.sql.connect.proto.types_pb2.DataType.Date.type_variation_reference
builtins.int"builtins.intz±	
TimestampNTZ9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ"builtins.object*ô
__init__Bpyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ"9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ*<
type_variation_reference
builtins.int"builtins.int *£

ClearFieldDpyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ"9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr[

DESCRIPTORDpyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ.DESCRIPTOR
Anyr¶
%TYPE_VARIATION_REFERENCE_FIELD_NUMBER_pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrå
type_variation_referenceRpyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ.type_variation_reference
builtins.int"builtins.intz›	
CalendarInterval=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval"builtins.object*•
__init__Fpyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval.__init__"
None*à
self~
=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval"=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval*<
type_variation_reference
builtins.int"builtins.int *Ø

ClearFieldHpyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval.ClearField"
None*à
self~
=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval"=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval.DESCRIPTOR
Anyr™
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERcpyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrê
type_variation_referenceVpyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval.type_variation_reference
builtins.int"builtins.intz≤%
YearMonthInterval>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval"builtins.object*Ÿ
__init__Gpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval*W
start_fieldD
Union[builtins.int,None]
builtins.int"builtins.int
None *U
	end_fieldD
Union[builtins.int,None]
builtins.int"builtins.int
None *<
type_variation_reference
builtins.int"builtins.int *∏
HasFieldGpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.HasField"
builtins.bool"builtins.bool*ã
selfÄ
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ã

ClearFieldIpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ø	

WhichOneofIpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.WhichOneof©

WhichOneofIpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ã
selfÄ
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX©

WhichOneofIpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ã
selfÄ
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXr`

DESCRIPTORIpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.DESCRIPTOR
Anyrë
START_FIELD_FIELD_NUMBERWpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.START_FIELD_FIELD_NUMBER
builtins.int"builtins.intrç
END_FIELD_FIELD_NUMBERUpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.END_FIELD_FIELD_NUMBER
builtins.int"builtins.intr´
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERdpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrw
start_fieldJpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.start_field
builtins.int"builtins.intrs
	end_fieldHpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.end_field
builtins.int"builtins.intrë
type_variation_referenceWpyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval.type_variation_reference
builtins.int"builtins.intz˚$
DayTimeInterval<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"builtins.object*“
__init__Epyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval*W
start_fieldD
Union[builtins.int,None]
builtins.int"builtins.int
None *U
	end_fieldD
Union[builtins.int,None]
builtins.int"builtins.int
None *<
type_variation_reference
builtins.int"builtins.int *±
HasFieldEpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.HasField"
builtins.bool"builtins.bool*Ü
self|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≈

ClearFieldGpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ü	

WhichOneofGpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.WhichOneof¢

WhichOneofGpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ü
self|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX¢

WhichOneofGpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ü
self|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXr^

DESCRIPTORGpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.DESCRIPTOR
Anyrè
START_FIELD_FIELD_NUMBERUpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.START_FIELD_FIELD_NUMBER
builtins.int"builtins.intrã
END_FIELD_FIELD_NUMBERSpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.END_FIELD_FIELD_NUMBER
builtins.int"builtins.intr©
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERbpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intru
start_fieldHpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.start_field
builtins.int"builtins.intrq
	end_fieldFpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.end_field
builtins.int"builtins.intrè
type_variation_referenceUpyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval.type_variation_reference
builtins.int"builtins.intzá
Char1pyspark.sql.connect.proto.types_pb2.DataType.Char"builtins.object*¨
__init__:pyspark.sql.connect.proto.types_pb2.DataType.Char.__init__"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Char"1pyspark.sql.connect.proto.types_pb2.DataType.Char**
length
builtins.int"builtins.int *<
type_variation_reference
builtins.int"builtins.int *∞

ClearField<pyspark.sql.connect.proto.types_pb2.DataType.Char.ClearField"
None*p
selff
1pyspark.sql.connect.proto.types_pb2.DataType.Char"1pyspark.sql.connect.proto.types_pb2.DataType.Char*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.types_pb2.DataType.Char.DESCRIPTOR
Anyrz
LENGTH_FIELD_NUMBEREpyspark.sql.connect.proto.types_pb2.DataType.Char.LENGTH_FIELD_NUMBER
builtins.int"builtins.intrû
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERWpyspark.sql.connect.proto.types_pb2.DataType.Char.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intr`
length8pyspark.sql.connect.proto.types_pb2.DataType.Char.length
builtins.int"builtins.intrÑ
type_variation_referenceJpyspark.sql.connect.proto.types_pb2.DataType.Char.type_variation_reference
builtins.int"builtins.intzÆ
VarChar4pyspark.sql.connect.proto.types_pb2.DataType.VarChar"builtins.object*µ
__init__=pyspark.sql.connect.proto.types_pb2.DataType.VarChar.__init__"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.VarChar"4pyspark.sql.connect.proto.types_pb2.DataType.VarChar**
length
builtins.int"builtins.int *<
type_variation_reference
builtins.int"builtins.int *π

ClearField?pyspark.sql.connect.proto.types_pb2.DataType.VarChar.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.VarChar"4pyspark.sql.connect.proto.types_pb2.DataType.VarChar*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.types_pb2.DataType.VarChar.DESCRIPTOR
Anyr}
LENGTH_FIELD_NUMBERHpyspark.sql.connect.proto.types_pb2.DataType.VarChar.LENGTH_FIELD_NUMBER
builtins.int"builtins.intr°
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERZpyspark.sql.connect.proto.types_pb2.DataType.VarChar.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrc
length;pyspark.sql.connect.proto.types_pb2.DataType.VarChar.length
builtins.int"builtins.intrá
type_variation_referenceMpyspark.sql.connect.proto.types_pb2.DataType.VarChar.type_variation_reference
builtins.int"builtins.intzè#
Decimal4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"builtins.object*≥
__init__=pyspark.sql.connect.proto.types_pb2.DataType.Decimal.__init__"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal*Q
scaleD
Union[builtins.int,None]
builtins.int"builtins.int
None *U
	precisionD
Union[builtins.int,None]
builtins.int"builtins.int
None *<
type_variation_reference
builtins.int"builtins.int *ò
HasField=pyspark.sql.connect.proto.types_pb2.DataType.Decimal.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

ClearField?pyspark.sql.connect.proto.types_pb2.DataType.Decimal.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Â

WhichOneof?pyspark.sql.connect.proto.types_pb2.DataType.Decimal.WhichOneofâ

WhichOneof?pyspark.sql.connect.proto.types_pb2.DataType.Decimal.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXâ

WhichOneof?pyspark.sql.connect.proto.types_pb2.DataType.Decimal.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrV

DESCRIPTOR?pyspark.sql.connect.proto.types_pb2.DataType.Decimal.DESCRIPTOR
Anyr{
SCALE_FIELD_NUMBERGpyspark.sql.connect.proto.types_pb2.DataType.Decimal.SCALE_FIELD_NUMBER
builtins.int"builtins.intrÉ
PRECISION_FIELD_NUMBERKpyspark.sql.connect.proto.types_pb2.DataType.Decimal.PRECISION_FIELD_NUMBER
builtins.int"builtins.intr°
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERZpyspark.sql.connect.proto.types_pb2.DataType.Decimal.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intra
scale:pyspark.sql.connect.proto.types_pb2.DataType.Decimal.scale
builtins.int"builtins.intri
	precision>pyspark.sql.connect.proto.types_pb2.DataType.Decimal.precision
builtins.int"builtins.intrá
type_variation_referenceMpyspark.sql.connect.proto.types_pb2.DataType.Decimal.type_variation_reference
builtins.int"builtins.intz◊!
StructField8pyspark.sql.connect.proto.types_pb2.DataType.StructField"builtins.object*ƒ
	data_typeBpyspark.sql.connect.proto.types_pb2.DataType.StructField.data_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*~
selft
8pyspark.sql.connect.proto.types_pb2.DataType.StructField"8pyspark.sql.connect.proto.types_pb2.DataType.StructField0:builtins.property`*¿
__init__Apyspark.sql.connect.proto.types_pb2.DataType.StructField.__init__"
None*~
selft
8pyspark.sql.connect.proto.types_pb2.DataType.StructField"8pyspark.sql.connect.proto.types_pb2.DataType.StructField*(
name
builtins.str"builtins.str *∂
	data_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *.
nullable
builtins.bool"builtins.bool *T
metadataD
Union[builtins.str,None]
builtins.str"builtins.str
None *˛
HasFieldApyspark.sql.connect.proto.types_pb2.DataType.StructField.HasField"
builtins.bool"builtins.bool*~
selft
8pyspark.sql.connect.proto.types_pb2.DataType.StructField"8pyspark.sql.connect.proto.types_pb2.DataType.StructField*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∏

ClearFieldCpyspark.sql.connect.proto.types_pb2.DataType.StructField.ClearField"
None*~
selft
8pyspark.sql.connect.proto.types_pb2.DataType.StructField"8pyspark.sql.connect.proto.types_pb2.DataType.StructField*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ä

WhichOneofCpyspark.sql.connect.proto.types_pb2.DataType.StructField.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*~
selft
8pyspark.sql.connect.proto.types_pb2.DataType.StructField"8pyspark.sql.connect.proto.types_pb2.DataType.StructField*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.types_pb2.DataType.StructField.DESCRIPTOR
Anyr}
NAME_FIELD_NUMBERJpyspark.sql.connect.proto.types_pb2.DataType.StructField.NAME_FIELD_NUMBER
builtins.int"builtins.intrá
DATA_TYPE_FIELD_NUMBEROpyspark.sql.connect.proto.types_pb2.DataType.StructField.DATA_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÖ
NULLABLE_FIELD_NUMBERNpyspark.sql.connect.proto.types_pb2.DataType.StructField.NULLABLE_FIELD_NUMBER
builtins.int"builtins.intrÖ
METADATA_FIELD_NUMBERNpyspark.sql.connect.proto.types_pb2.DataType.StructField.METADATA_FIELD_NUMBER
builtins.int"builtins.intrc
name=pyspark.sql.connect.proto.types_pb2.DataType.StructField.name
builtins.str"builtins.strrm
nullableApyspark.sql.connect.proto.types_pb2.DataType.StructField.nullable
builtins.bool"builtins.boolrk
metadataApyspark.sql.connect.proto.types_pb2.DataType.StructField.metadata
builtins.str"builtins.strz∏
Struct3pyspark.sql.connect.proto.types_pb2.DataType.Struct"builtins.object*⁄
fields:pyspark.sql.connect.proto.types_pb2.DataType.Struct.fields"
Any*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.Struct"3pyspark.sql.connect.proto.types_pb2.DataType.Struct0:builtins.property`*–
__init__<pyspark.sql.connect.proto.types_pb2.DataType.Struct.__init__"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.Struct"3pyspark.sql.connect.proto.types_pb2.DataType.Struct*«
fields∏
UUnion[typing.Iterable[pyspark.sql.connect.proto.types_pb2.DataType.StructField],None]“
Ityping.Iterable[pyspark.sql.connect.proto.types_pb2.DataType.StructField]t
8pyspark.sql.connect.proto.types_pb2.DataType.StructField"8pyspark.sql.connect.proto.types_pb2.DataType.StructField"typing.Iterable
None *<
type_variation_reference
builtins.int"builtins.int *∂

ClearField>pyspark.sql.connect.proto.types_pb2.DataType.Struct.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.types_pb2.DataType.Struct"3pyspark.sql.connect.proto.types_pb2.DataType.Struct*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.types_pb2.DataType.Struct.DESCRIPTOR
Anyr|
FIELDS_FIELD_NUMBERGpyspark.sql.connect.proto.types_pb2.DataType.Struct.FIELDS_FIELD_NUMBER
builtins.int"builtins.intr†
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERYpyspark.sql.connect.proto.types_pb2.DataType.Struct.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrÜ
type_variation_referenceLpyspark.sql.connect.proto.types_pb2.DataType.Struct.type_variation_reference
builtins.int"builtins.intzÜ
Array2pyspark.sql.connect.proto.types_pb2.DataType.Array"builtins.object*∏
element_type?pyspark.sql.connect.proto.types_pb2.DataType.Array.element_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array0:builtins.property`*Ù
__init__;pyspark.sql.connect.proto.types_pb2.DataType.Array.__init__"
None*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array*π
element_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *3
contains_null
builtins.bool"builtins.bool *<
type_variation_reference
builtins.int"builtins.int *ü
HasField;pyspark.sql.connect.proto.types_pb2.DataType.Array.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*⁄

ClearField=pyspark.sql.connect.proto.types_pb2.DataType.Array.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.types_pb2.DataType.Array.DESCRIPTOR
Anyrá
ELEMENT_TYPE_FIELD_NUMBERLpyspark.sql.connect.proto.types_pb2.DataType.Array.ELEMENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrâ
CONTAINS_NULL_FIELD_NUMBERMpyspark.sql.connect.proto.types_pb2.DataType.Array.CONTAINS_NULL_FIELD_NUMBER
builtins.int"builtins.intrü
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERXpyspark.sql.connect.proto.types_pb2.DataType.Array.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intrq
contains_null@pyspark.sql.connect.proto.types_pb2.DataType.Array.contains_null
builtins.bool"builtins.boolrÖ
type_variation_referenceKpyspark.sql.connect.proto.types_pb2.DataType.Array.type_variation_reference
builtins.int"builtins.intz¢
Map0pyspark.sql.connect.proto.types_pb2.DataType.Map"builtins.object*™
key_type9pyspark.sql.connect.proto.types_pb2.DataType.Map.key_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map0:builtins.property`*Æ

value_type;pyspark.sql.connect.proto.types_pb2.DataType.Map.value_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map0:builtins.property`*™
__init__9pyspark.sql.connect.proto.types_pb2.DataType.Map.__init__"
None*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map*µ
key_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *∑

value_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *9
value_contains_null
builtins.bool"builtins.bool *<
type_variation_reference
builtins.int"builtins.int *ø
HasField9pyspark.sql.connect.proto.types_pb2.DataType.Map.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

ClearField;pyspark.sql.connect.proto.types_pb2.DataType.Map.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.types_pb2.DataType.Map.DESCRIPTOR
Anyr}
KEY_TYPE_FIELD_NUMBERFpyspark.sql.connect.proto.types_pb2.DataType.Map.KEY_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÅ
VALUE_TYPE_FIELD_NUMBERHpyspark.sql.connect.proto.types_pb2.DataType.Map.VALUE_TYPE_FIELD_NUMBER
builtins.int"builtins.intrì
 VALUE_CONTAINS_NULL_FIELD_NUMBERQpyspark.sql.connect.proto.types_pb2.DataType.Map.VALUE_CONTAINS_NULL_FIELD_NUMBER
builtins.int"builtins.intrù
%TYPE_VARIATION_REFERENCE_FIELD_NUMBERVpyspark.sql.connect.proto.types_pb2.DataType.Map.TYPE_VARIATION_REFERENCE_FIELD_NUMBER
builtins.int"builtins.intr{
value_contains_nullDpyspark.sql.connect.proto.types_pb2.DataType.Map.value_contains_null
builtins.bool"builtins.boolrÉ
type_variation_referenceIpyspark.sql.connect.proto.types_pb2.DataType.Map.type_variation_reference
builtins.int"builtins.intz∑5
UDT0pyspark.sql.connect.proto.types_pb2.DataType.UDT"builtins.object*™
sql_type9pyspark.sql.connect.proto.types_pb2.DataType.UDT.sql_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT0:builtins.property`*∑
__init__9pyspark.sql.connect.proto.types_pb2.DataType.UDT.__init__"
None*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*(
type
builtins.str"builtins.str *U
	jvm_classD
Union[builtins.str,None]
builtins.str"builtins.str
None *X
python_classD
Union[builtins.str,None]
builtins.str"builtins.str
None *c
serialized_python_classD
Union[builtins.str,None]
builtins.str"builtins.str
None *µ
sql_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *˛

HasField9pyspark.sql.connect.proto.types_pb2.DataType.UDT.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*í

ClearField;pyspark.sql.connect.proto.types_pb2.DataType.UDT.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2…

WhichOneof;pyspark.sql.connect.proto.types_pb2.DataType.UDT.WhichOneof˝

WhichOneof;pyspark.sql.connect.proto.types_pb2.DataType.UDT.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.types_pb2.DataType.UDT.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.types_pb2.DataType.UDT.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrR

DESCRIPTOR;pyspark.sql.connect.proto.types_pb2.DataType.UDT.DESCRIPTOR
Anyru
TYPE_FIELD_NUMBERBpyspark.sql.connect.proto.types_pb2.DataType.UDT.TYPE_FIELD_NUMBER
builtins.int"builtins.intr
JVM_CLASS_FIELD_NUMBERGpyspark.sql.connect.proto.types_pb2.DataType.UDT.JVM_CLASS_FIELD_NUMBER
builtins.int"builtins.intrÖ
PYTHON_CLASS_FIELD_NUMBERJpyspark.sql.connect.proto.types_pb2.DataType.UDT.PYTHON_CLASS_FIELD_NUMBER
builtins.int"builtins.intrõ
$SERIALIZED_PYTHON_CLASS_FIELD_NUMBERUpyspark.sql.connect.proto.types_pb2.DataType.UDT.SERIALIZED_PYTHON_CLASS_FIELD_NUMBER
builtins.int"builtins.intr}
SQL_TYPE_FIELD_NUMBERFpyspark.sql.connect.proto.types_pb2.DataType.UDT.SQL_TYPE_FIELD_NUMBER
builtins.int"builtins.intr[
type5pyspark.sql.connect.proto.types_pb2.DataType.UDT.type
builtins.str"builtins.strre
	jvm_class:pyspark.sql.connect.proto.types_pb2.DataType.UDT.jvm_class
builtins.str"builtins.strrk
python_class=pyspark.sql.connect.proto.types_pb2.DataType.UDT.python_class
builtins.str"builtins.strrÅ
serialized_python_classHpyspark.sql.connect.proto.types_pb2.DataType.UDT.serialized_python_class
builtins.str"builtins.strz⁄
Unparsed5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed"builtins.object*Ñ
__init__>pyspark.sql.connect.proto.types_pb2.DataType.Unparsed.__init__"
None*x
selfn
5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed"5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed*4
data_type_string
builtins.str"builtins.str *ñ

ClearField@pyspark.sql.connect.proto.types_pb2.DataType.Unparsed.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed"5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.types_pb2.DataType.Unparsed.DESCRIPTOR
Anyrí
DATA_TYPE_STRING_FIELD_NUMBERSpyspark.sql.connect.proto.types_pb2.DataType.Unparsed.DATA_TYPE_STRING_FIELD_NUMBER
builtins.int"builtins.intrx
data_type_stringFpyspark.sql.connect.proto.types_pb2.DataType.Unparsed.data_type_string
builtins.str"builtins.strÒm
Command.pyspark.sql.connect.proto.commands_pb2.Command"builtins.object*Ò
register_function@pyspark.sql.connect.proto.commands_pb2.Command.register_function"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*ƒ
write_operation>pyspark.sql.connect.proto.commands_pb2.Command.write_operation"n
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*È
create_dataframe_viewDpyspark.sql.connect.proto.commands_pb2.Command.create_dataframe_view"Ü
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*Œ
write_operation_v2Apyspark.sql.connect.proto.commands_pb2.Command.write_operation_v2"r
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*¥
sql_command:pyspark.sql.connect.proto.commands_pb2.Command.sql_command"f
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*ı
write_stream_operation_startKpyspark.sql.connect.proto.commands_pb2.Command.write_stream_operation_start"Ñ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*‚
streaming_query_commandFpyspark.sql.connect.proto.commands_pb2.Command.streaming_query_command"|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*⁄
get_resources_commandDpyspark.sql.connect.proto.commands_pb2.Command.get_resources_command"x
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*Å
streaming_query_manager_commandNpyspark.sql.connect.proto.commands_pb2.Command.streaming_query_manager_command"ä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*É
register_table_functionFpyspark.sql.connect.proto.commands_pb2.Command.register_table_function"ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*—
	extension8pyspark.sql.connect.proto.commands_pb2.Command.extension"
Any*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:builtins.property`*√
__init__7pyspark.sql.connect.proto.commands_pb2.Command.__init__"
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*ñ
register_function¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *◊
write_operationø
AUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation,None]n
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation
None *Ç
create_dataframe_view‰
MUnion[pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand,None]Ü
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand
None *‡
write_operation_v2≈
CUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperationV2,None]r
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2
None *«
sql_command≥
=Union[pyspark.sql.connect.proto.commands_pb2.SqlCommand,None]f
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand
None *Ü
write_stream_operation_start·
LUnion[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart,None]Ñ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart
None *Ù
streaming_query_command‘
HUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand,None]|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand
None *Ï
get_resources_commandŒ
FUnion[pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand,None]x
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand
None *í
streaming_query_manager_commandÍ
OUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand,None]ä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand
None *•
register_table_functionÖ
XUnion[pyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction,None]ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction
None *7
	extension&
Union[Any,None]
Any
None *∂
HasField7pyspark.sql.connect.proto.commands_pb2.Command.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*‰

field_name”
ÆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearField9pyspark.sql.connect.proto.commands_pb2.Command.ClearField"
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*‰

field_name”
ÆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙	

WhichOneof9pyspark.sql.connect.proto.commands_pb2.Command.WhichOneof"ˇ
˝Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.commands_pb2.Command.DESCRIPTOR
Anyrç
REGISTER_FUNCTION_FIELD_NUMBERMpyspark.sql.connect.proto.commands_pb2.Command.REGISTER_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrâ
WRITE_OPERATION_FIELD_NUMBERKpyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_FIELD_NUMBER
builtins.int"builtins.intrï
"CREATE_DATAFRAME_VIEW_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.Command.CREATE_DATAFRAME_VIEW_FIELD_NUMBER
builtins.int"builtins.intrè
WRITE_OPERATION_V2_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_V2_FIELD_NUMBER
builtins.int"builtins.intrÅ
SQL_COMMAND_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.Command.SQL_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr£
)WRITE_STREAM_OPERATION_START_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.Command.WRITE_STREAM_OPERATION_START_FIELD_NUMBER
builtins.int"builtins.intrô
$STREAMING_QUERY_COMMAND_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.Command.STREAMING_QUERY_COMMAND_FIELD_NUMBER
builtins.int"builtins.intrï
"GET_RESOURCES_COMMAND_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.Command.GET_RESOURCES_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr©
,STREAMING_QUERY_MANAGER_COMMAND_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.Command.STREAMING_QUERY_MANAGER_COMMAND_FIELD_NUMBER
builtins.int"builtins.intrô
$REGISTER_TABLE_FUNCTION_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.Command.REGISTER_TABLE_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr}
EXTENSION_FIELD_NUMBEREpyspark.sql.connect.proto.commands_pb2.Command.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intﬂ(

SqlCommand1pyspark.sql.connect.proto.commands_pb2.SqlCommand"builtins.object*–
args6pyspark.sql.connect.proto.commands_pb2.SqlCommand.args"
Any*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand0:builtins.property`*ÿ
pos_args:pyspark.sql.connect.proto.commands_pb2.SqlCommand.pos_args"
Any*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand0:builtins.property`*‘
__init__:pyspark.sql.connect.proto.commands_pb2.SqlCommand.__init__"
None*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*'
sql
builtins.str"builtins.str *ä
args˝
eUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]á
Ytyping.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]
builtins.str"builtins.str|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Mapping
None *Ÿ
pos_args»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *◊

ClearField<pyspark.sql.connect.proto.commands_pb2.SqlCommand.ClearField"
None*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.commands_pb2.SqlCommand.DESCRIPTOR
Anyrt
SQL_FIELD_NUMBERBpyspark.sql.connect.proto.commands_pb2.SqlCommand.SQL_FIELD_NUMBER
builtins.int"builtins.intrv
ARGS_FIELD_NUMBERCpyspark.sql.connect.proto.commands_pb2.SqlCommand.ARGS_FIELD_NUMBER
builtins.int"builtins.intr~
POS_ARGS_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.SqlCommand.POS_ARGS_FIELD_NUMBER
builtins.int"builtins.intrZ
sql5pyspark.sql.connect.proto.commands_pb2.SqlCommand.sql
builtins.str"builtins.strzé
	ArgsEntry;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry"builtins.object*Ê
valueApyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.value"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*Ñ
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry0:builtins.property`*Ô
__init__Dpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.__init__"
None*Ñ
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry*'
key
builtins.str"builtins.str *‚
value‘
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *ª
HasFieldDpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.HasField"
builtins.bool"builtins.bool*Ñ
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*œ

ClearFieldFpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.ClearField"
None*Ñ
selfz
;pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry";pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.DESCRIPTOR
Anyr~
KEY_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrÇ
VALUE_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrd
key?pyspark.sql.connect.proto.commands_pb2.SqlCommand.ArgsEntry.key
builtins.str"builtins.strí
CreateDataFrameViewCommandApyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"builtins.object*·
inputGpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand0:builtins.property`*ø
__init__Jpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
name
builtins.str"builtins.str */
	is_global
builtins.bool"builtins.bool *-
replace
builtins.bool"builtins.bool *Œ
HasFieldJpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.HasField"
builtins.bool"builtins.bool*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ø

ClearFieldLpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.DESCRIPTOR
Anyrà
INPUT_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÜ
NAME_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.NAME_FIELD_NUMBER
builtins.int"builtins.intrê
IS_GLOBAL_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.IS_GLOBAL_FIELD_NUMBER
builtins.int"builtins.intrå
REPLACE_FIELD_NUMBERVpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.REPLACE_FIELD_NUMBER
builtins.int"builtins.intrl
nameFpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.name
builtins.str"builtins.strrx
	is_globalKpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.is_global
builtins.bool"builtins.boolrt
replaceIpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.replace
builtins.bool"builtins.boolÁÆ
WriteOperation5pyspark.sql.connect.proto.commands_pb2.WriteOperation"builtins.object*ª
input;pyspark.sql.connect.proto.commands_pb2.WriteOperation.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:builtins.property`*⁄
table;pyspark.sql.connect.proto.commands_pb2.WriteOperation.table"Ç
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:builtins.property`*ˆ
sort_column_namesGpyspark.sql.connect.proto.commands_pb2.WriteOperation.sort_column_names"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:builtins.property`*¸
partitioning_columnsJpyspark.sql.connect.proto.commands_pb2.WriteOperation.partitioning_columns"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:builtins.property`*‡
	bucket_by?pyspark.sql.connect.proto.commands_pb2.WriteOperation.bucket_by"Ä
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:builtins.property`*‚
options=pyspark.sql.connect.proto.commands_pb2.WriteOperation.options"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:builtins.property`*¨
__init__>pyspark.sql.connect.proto.commands_pb2.WriteOperation.__init__"
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *R
sourceD
Union[builtins.str,None]
builtins.str"builtins.str
None *(
path
builtins.str"builtins.str *Ï
tableﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable,None]Ç
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable
None *£
modeñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType *°
sort_column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *§
partitioning_columnsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ì
	bucket_by€
JUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy,None]Ä
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *ç
HasField>pyspark.sql.connect.proto.commands_pb2.WriteOperation.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ì

ClearField@pyspark.sql.connect.proto.commands_pb2.WriteOperation.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*æ

field_name≠
ÄUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2º	

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX‹

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.commands_pb2.WriteOperation.DESCRIPTOR
Anyr˝
SAVE_MODE_UNSPECIFIEDKpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_UNSPECIFIEDñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperÛ
SAVE_MODE_APPENDFpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_APPENDñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyper˘
SAVE_MODE_OVERWRITEIpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_OVERWRITEñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperÖ
SAVE_MODE_ERROR_IF_EXISTSOpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_ERROR_IF_EXISTSñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperÛ
SAVE_MODE_IGNOREFpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_IGNOREñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyper|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.commands_pb2.WriteOperation.INPUT_FIELD_NUMBER
builtins.int"builtins.intr~
SOURCE_FIELD_NUMBERIpyspark.sql.connect.proto.commands_pb2.WriteOperation.SOURCE_FIELD_NUMBER
builtins.int"builtins.intrz
PATH_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.WriteOperation.PATH_FIELD_NUMBER
builtins.int"builtins.intr|
TABLE_FIELD_NUMBERHpyspark.sql.connect.proto.commands_pb2.WriteOperation.TABLE_FIELD_NUMBER
builtins.int"builtins.intrz
MODE_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.WriteOperation.MODE_FIELD_NUMBER
builtins.int"builtins.intrî
SORT_COLUMN_NAMES_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.WriteOperation.SORT_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intrö
!PARTITIONING_COLUMNS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperation.PARTITIONING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÑ
BUCKET_BY_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.WriteOperation.BUCKET_BY_FIELD_NUMBER
builtins.int"builtins.intrÄ
OPTIONS_FIELD_NUMBERJpyspark.sql.connect.proto.commands_pb2.WriteOperation.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrd
source<pyspark.sql.connect.proto.commands_pb2.WriteOperation.source
builtins.str"builtins.strr`
path:pyspark.sql.connect.proto.commands_pb2.WriteOperation.path
builtins.str"builtins.strr€
mode:pyspark.sql.connect.proto.commands_pb2.WriteOperation.modeñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTypez˚
	_SaveMode?pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode"builtins.objectzõ
	ValueTypeIpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"builtins.int*¥
__init__Rpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType*&
item
builtins.int"builtins.intzÿ
_SaveModeEnumTypeWrapperNpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper"builtins.typerp

DESCRIPTORYpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.DESCRIPTOR
Anyrñ
SAVE_MODE_UNSPECIFIEDdpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_UNSPECIFIEDñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperå
SAVE_MODE_APPEND_pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_APPENDñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperí
SAVE_MODE_OVERWRITEbpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_OVERWRITEñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperû
SAVE_MODE_ERROR_IF_EXISTShpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_ERROR_IF_EXISTSñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperå
SAVE_MODE_IGNORE_pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapper.SAVE_MODE_IGNOREñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTypez›
SaveMode>pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveMode"?pyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode@bNpyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveModeEnumTypeWrapperzÒ
OptionsEntryBpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry"builtins.object*À
__init__Kpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry"Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Â

ClearFieldMpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry"Bpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.DESCRIPTOR
AnyrÖ
KEY_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrâ
VALUE_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrk
keyFpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.key
builtins.str"builtins.strro
valueHpyspark.sql.connect.proto.commands_pb2.WriteOperation.OptionsEntry.value
builtins.str"builtins.strz£(
	SaveTable?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"builtins.object*Ì
__init__Hpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable*.

table_name
builtins.str"builtins.str *Ã
save_method∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType *‹

ClearFieldJpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.DESCRIPTOR
Anyrπ
TABLE_SAVE_METHOD_UNSPECIFIED]pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_UNSPECIFIED∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyperΩ
TABLE_SAVE_METHOD_SAVE_AS_TABLE_pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_SAVE_AS_TABLE∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyperπ
TABLE_SAVE_METHOD_INSERT_INTO]pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_SAVE_METHOD_INSERT_INTO∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyperê
TABLE_NAME_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrí
SAVE_METHOD_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.SAVE_METHOD_FIELD_NUMBER
builtins.int"builtins.intrv

table_nameJpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.table_name
builtins.str"builtins.strrï
save_methodKpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.save_method∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTypez◊
_TableSaveMethodPpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod"builtins.objectzﬂ
	ValueTypeZpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"builtins.int*Á
__init__cpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType.__init__"
None*√
self∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType*&
item
builtins.int"builtins.intz≠

_TableSaveMethodEnumTypeWrapper_pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper"builtins.typerÅ

DESCRIPTORjpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.DESCRIPTOR
AnyrŸ
TABLE_SAVE_METHOD_UNSPECIFIED}pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_UNSPECIFIED∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyper›
TABLE_SAVE_METHOD_SAVE_AS_TABLEpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_SAVE_AS_TABLE∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTyperŸ
TABLE_SAVE_METHOD_INSERT_INTO}pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapper.TABLE_SAVE_METHOD_INSERT_INTO∏
Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueType"Zpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod.ValueTypezó
TableSaveMethodOpyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable.TableSaveMethod"Ppyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethod@b_pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable._TableSaveMethodEnumTypeWrapperz©
BucketBy>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy"builtins.object*ó
bucket_column_namesRpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.bucket_column_names"
Any*ã
selfÄ
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy0:builtins.property`*¬
__init__Gpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy*£
bucket_column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None */
num_buckets
builtins.int"builtins.int *Ÿ

ClearFieldIpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.DESCRIPTOR
Anyr°
 BUCKET_COLUMN_NAMES_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.BUCKET_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intrë
NUM_BUCKETS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.NUM_BUCKETS_FIELD_NUMBER
builtins.int"builtins.intrw
num_bucketsJpyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy.num_buckets
builtins.int"builtins.intÅ}
WriteOperationV27pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"builtins.object*¡
input=pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:builtins.property`*Ç
partitioning_columnsLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.partitioning_columns"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:builtins.property`*Ë
options?pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.options"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:builtins.property`*˙
table_propertiesHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_properties"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:builtins.property`*Â
overwrite_conditionKpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.overwrite_condition"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:builtins.property`*á
__init__@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.__init__"
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *.

table_name
builtins.str"builtins.str *T
providerD
Union[builtins.str,None]
builtins.str"builtins.str
None *≈
partitioning_columns®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *’
table_propertiesº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *ü
modeí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType *ÿ
overwrite_conditionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *°
HasField@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.HasField"
builtins.bool"builtins.bool*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Õ

ClearFieldBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

WhichOneofBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.DESCRIPTOR
AnyrÒ
MODE_UNSPECIFIEDHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_UNSPECIFIEDí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÁ
MODE_CREATECpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÌ
MODE_OVERWRITEFpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÉ
MODE_OVERWRITE_PARTITIONSQpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITE_PARTITIONSí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÁ
MODE_APPENDCpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_APPENDí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÈ
MODE_REPLACEDpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_REPLACEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper˝
MODE_CREATE_OR_REPLACENpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATE_OR_REPLACEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper~
INPUT_FIELD_NUMBERJpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.INPUT_FIELD_NUMBER
builtins.int"builtins.intrà
TABLE_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrÑ
PROVIDER_FIELD_NUMBERMpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PROVIDER_FIELD_NUMBER
builtins.int"builtins.intrú
!PARTITIONING_COLUMNS_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PARTITIONING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÇ
OPTIONS_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrî
TABLE_PROPERTIES_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_PROPERTIES_FIELD_NUMBER
builtins.int"builtins.intr|
MODE_FIELD_NUMBERIpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_FIELD_NUMBER
builtins.int"builtins.intrö
 OVERWRITE_CONDITION_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OVERWRITE_CONDITION_FIELD_NUMBER
builtins.int"builtins.intrn

table_nameBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_name
builtins.str"builtins.strrj
provider@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.provider
builtins.str"builtins.strrŸ
mode<pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.modeí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTypezÌ
_Mode=pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode"builtins.objectzì
	ValueTypeGpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"builtins.int*Æ
__init__Ppyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType.__init__"
None*ù
selfí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType*&
item
builtins.int"builtins.intz†
_ModeEnumTypeWrapperLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper"builtins.typern

DESCRIPTORWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.DESCRIPTOR
AnyrÜ
MODE_UNSPECIFIED]pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_UNSPECIFIEDí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper¸
MODE_CREATEXpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_CREATEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÇ
MODE_OVERWRITE[pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_OVERWRITEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperò
MODE_OVERWRITE_PARTITIONSfpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_OVERWRITE_PARTITIONSí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper¸
MODE_APPENDXpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_APPENDí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper˛
MODE_REPLACEYpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_REPLACEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperí
MODE_CREATE_OR_REPLACEcpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapper.MODE_CREATE_OR_REPLACEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTypez”
Mode<pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.Mode"=pyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode@bLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._ModeEnumTypeWrapperzâ
OptionsEntryDpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry"builtins.object*—
__init__Mpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry"Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Î

ClearFieldOpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry"Dpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.DESCRIPTOR
Anyrá
KEY_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrã
VALUE_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrm
keyHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.key
builtins.str"builtins.strrq
valueJpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OptionsEntry.value
builtins.str"builtins.strzÒ
TablePropertiesEntryLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry"builtins.object*È
__init__Upyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.__init__"
None*ß
selfú
Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry"Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *É

ClearFieldWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.ClearField"
None*ß
selfú
Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry"Lpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrn

DESCRIPTORWpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.DESCRIPTOR
Anyrè
KEY_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrì
VALUE_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intru
keyPpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.key
builtins.str"builtins.strry
valueRpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TablePropertiesEntry.value
builtins.str"builtins.str˝w
WriteStreamOperationStart@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"builtins.object*ﬁ
inputFpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:builtins.property`*Ö
optionsHpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.options"
Any*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:builtins.property`*©
partitioning_column_namesZpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.partitioning_column_names"
Any*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:builtins.property`*è
foreach_writerOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.foreach_writer"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:builtins.property`*ç
foreach_batchNpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.foreach_batch"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:builtins.property`*Ê
__init__Ipyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None **
format
builtins.str"builtins.str *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *©
partitioning_column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *<
processing_time_interval
builtins.str"builtins.str *3
available_now
builtins.bool"builtins.bool **
once
builtins.bool"builtins.bool *B
continuous_checkpoint_interval
builtins.str"builtins.str */
output_mode
builtins.str"builtins.str *.

query_name
builtins.str"builtins.str *(
path
builtins.str"builtins.str *.

table_name
builtins.str"builtins.str *ı
foreach_writerﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction
None *Ù
foreach_batchﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction
None *»
HasFieldIpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.HasField"
builtins.bool"builtins.bool*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*æ

field_name≠
ÄUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

ClearFieldKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¸

field_nameÎ
ÊUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2˚

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneofˇ

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXù

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneof"’
cUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrb

DESCRIPTORKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.DESCRIPTOR
Anyrá
INPUT_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.INPUT_FIELD_NUMBER
builtins.int"builtins.intrâ
FORMAT_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FORMAT_FIELD_NUMBER
builtins.int"builtins.intrã
OPTIONS_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrØ
&PARTITIONING_COLUMN_NAMES_FIELD_NUMBERgpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PARTITIONING_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intr≠
%PROCESSING_TIME_INTERVAL_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PROCESSING_TIME_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intró
AVAILABLE_NOW_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.AVAILABLE_NOW_FIELD_NUMBER
builtins.int"builtins.intrÖ
ONCE_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.ONCE_FIELD_NUMBER
builtins.int"builtins.intrπ
+CONTINUOUS_CHECKPOINT_INTERVAL_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.CONTINUOUS_CHECKPOINT_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrì
OUTPUT_MODE_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OUTPUT_MODE_FIELD_NUMBER
builtins.int"builtins.intrë
QUERY_NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.QUERY_NAME_FIELD_NUMBER
builtins.int"builtins.intrÖ
PATH_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PATH_FIELD_NUMBER
builtins.int"builtins.intrë
TABLE_NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrô
FOREACH_WRITER_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FOREACH_WRITER_FIELD_NUMBER
builtins.int"builtins.intró
FOREACH_BATCH_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FOREACH_BATCH_FIELD_NUMBER
builtins.int"builtins.intro
formatGpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.format
builtins.str"builtins.strrì
processing_time_intervalYpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.processing_time_interval
builtins.str"builtins.strr
available_nowNpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.available_now
builtins.bool"builtins.boolrm
onceEpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.once
builtins.bool"builtins.boolrü
continuous_checkpoint_interval_pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.continuous_checkpoint_interval
builtins.str"builtins.strry
output_modeLpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.output_mode
builtins.str"builtins.strrw

query_nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.query_name
builtins.str"builtins.strrk
pathEpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.path
builtins.str"builtins.strrw

table_nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.table_name
builtins.str"builtins.strzı
OptionsEntryMpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry"builtins.object*Ï
__init__Vpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.__init__"
None*©
selfû
Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry"Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Ü

ClearFieldXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.ClearField"
None*©
selfû
Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry"Mpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesro

DESCRIPTORXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.DESCRIPTOR
Anyrê
KEY_FIELD_NUMBER^pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrî
VALUE_FIELD_NUMBER`pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrv
keyQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.key
builtins.str"builtins.strrz
valueSpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OptionsEntry.value
builtins.str"builtins.strÆ 
StreamingForeachFunction?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"builtins.object*ı
python_functionOpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.python_function"j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction0:builtins.property`*˝
scala_functionNpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.scala_function"t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction0:builtins.property`*§
__init__Hpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*—
python_functionπ
?Union[pyspark.sql.connect.proto.expressions_pb2.PythonUDF,None]j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF
None *ﬂ
scala_function»
DUnion[pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF,None]t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF
None *ï
HasFieldHpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearFieldJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Á

WhichOneofJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.DESCRIPTOR
Anyrö
PYTHON_FUNCTION_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.PYTHON_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrò
SCALA_FUNCTION_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.SCALA_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intâ
WriteStreamOperationStartResultFpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"builtins.object*ï
query_idOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.query_id"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult0:builtins.property`*ü
__init__Opyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*Ô
query_idﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *(
name
builtins.str"builtins.str *›
HasFieldOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.HasField"
builtins.bool"builtins.bool*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ò

ClearFieldQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.ClearField"
None*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.DESCRIPTOR
Anyrì
QUERY_ID_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intrã
NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.NAME_FIELD_NUMBER
builtins.int"builtins.intrq
nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.name
builtins.str"builtins.strŸ
StreamingQueryInstanceId?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"builtins.object*¬
__init__Hpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*&
id
builtins.str"builtins.str **
run_id
builtins.str"builtins.str *‹

ClearFieldJpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.DESCRIPTOR
AnyrÄ
ID_FIELD_NUMBEROpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.ID_FIELD_NUMBER
builtins.int"builtins.intrà
RUN_ID_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.RUN_ID_FIELD_NUMBER
builtins.int"builtins.intrf
idBpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.id
builtins.str"builtins.strrn
run_idFpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.run_id
builtins.str"builtins.str∑m
StreamingQueryCommand<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"builtins.object*ˆ
query_idEpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.query_id"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:builtins.property`*å
explainDpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.explain"ö
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:builtins.property`*≤
await_terminationNpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.await_termination"¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:builtins.property`*Ÿ

__init__Epyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*Ô
query_idﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *,
status
builtins.bool"builtins.bool *3
last_progress
builtins.bool"builtins.bool *5
recent_progress
builtins.bool"builtins.bool **
stop
builtins.bool"builtins.bool *;
process_all_available
builtins.bool"builtins.bool *í
explainÇ
WUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand,None]ö
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand
None */
	exception
builtins.bool"builtins.bool *∑
await_terminationù
`Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand,None]¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand
None *ï
HasFieldEpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.HasField"
builtins.bool"builtins.bool*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*ò

field_nameá
“Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearFieldGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*ò

field_nameá
“Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∏

WhichOneofGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.WhichOneof"í
ªUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.DESCRIPTOR
Anyrâ
QUERY_ID_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intrÖ
STATUS_FIELD_NUMBERPpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.STATUS_FIELD_NUMBER
builtins.int"builtins.intrì
LAST_PROGRESS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.LAST_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intró
RECENT_PROGRESS_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.RECENT_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intrÅ
STOP_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.STOP_FIELD_NUMBER
builtins.int"builtins.intr£
"PROCESS_ALL_AVAILABLE_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.PROCESS_ALL_AVAILABLE_FIELD_NUMBER
builtins.int"builtins.intrá
EXPLAIN_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrã
EXCEPTION_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.EXCEPTION_FIELD_NUMBER
builtins.int"builtins.intrõ
AWAIT_TERMINATION_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AWAIT_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intrm
statusCpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.status
builtins.bool"builtins.boolr{
last_progressJpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.last_progress
builtins.bool"builtins.boolr
recent_progressLpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.recent_progress
builtins.bool"builtins.boolri
stopApyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.stop
builtins.bool"builtins.boolrã
process_all_availableRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.process_all_available
builtins.bool"builtins.boolrs
	exceptionFpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.exception
builtins.bool"builtins.boolzù

ExplainCommandKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"builtins.object*¬
__init__Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.__init__"
None*•
selfö
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand*.
extended
builtins.bool"builtins.bool *⁄

ClearFieldVpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.ClearField"
None*•
selfö
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrm

DESCRIPTORVpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.DESCRIPTOR
Anyrò
EXTENDED_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.EXTENDED_FIELD_NUMBER
builtins.int"builtins.intrÄ
extendedTpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand.extended
builtins.bool"builtins.boolz›
AwaitTerminationCommandTpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"builtins.object*Ö
__init__]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.__init__"
None*∑
self¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*V

timeout_msD
Union[builtins.int,None]
builtins.int"builtins.int
None *≠
HasField]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.HasField"
builtins.bool"builtins.bool*∑
self¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*õ

ClearField_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.ClearField"
None*∑
self¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*÷

WhichOneof_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*∑
self¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrv

DESCRIPTOR_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.DESCRIPTOR
Anyr•
TIMEOUT_MS_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.TIMEOUT_MS_FIELD_NUMBER
builtins.int"builtins.intrã

timeout_ms_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand.timeout_ms
builtins.int"builtins.intÌ∑
StreamingQueryCommandResultBpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"builtins.object*â
query_idKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.query_id"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:builtins.property`*•
statusIpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.status"¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:builtins.property`*«
recent_progressRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.recent_progress"≤
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:builtins.property`*©
explainJpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.explain"§
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:builtins.property`*±
	exceptionLpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.exception"®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:builtins.property`*œ
await_terminationTpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.await_termination"∂
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:builtins.property`*„
__init__Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*Ô
query_idﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *ù
statusé
[Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult,None]¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult
None *æ
recent_progress¶
cUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult,None]≤
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult
None *°
explainë
\Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult,None]§
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult
None *©
	exceptionó
^Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult,None]®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult
None *∆
await_termination¨
eUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult,None]∂
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult
None *∂
HasFieldKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.HasField"
builtins.bool"builtins.bool*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearFieldMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*›

WhichOneofMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.WhichOneof"§
yUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.DESCRIPTOR
Anyrè
QUERY_ID_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intrã
STATUS_FIELD_NUMBERVpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.STATUS_FIELD_NUMBER
builtins.int"builtins.intrù
RECENT_PROGRESS_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RECENT_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intrç
EXPLAIN_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrë
EXCEPTION_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.EXCEPTION_FIELD_NUMBER
builtins.int"builtins.intr°
AWAIT_TERMINATION_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AWAIT_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intz±
StatusResultOpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"builtins.object*ı
__init__Xpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.__init__"
None*≠
self¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*2
status_message
builtins.str"builtins.str *7
is_data_available
builtins.bool"builtins.bool *7
is_trigger_active
builtins.bool"builtins.bool */
	is_active
builtins.bool"builtins.bool *Ÿ

ClearFieldZpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.ClearField"
None*≠
self¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrq

DESCRIPTORZpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.DESCRIPTOR
Anyr®
STATUS_MESSAGE_FIELD_NUMBERkpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.STATUS_MESSAGE_FIELD_NUMBER
builtins.int"builtins.intrÆ
IS_DATA_AVAILABLE_FIELD_NUMBERnpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.IS_DATA_AVAILABLE_FIELD_NUMBER
builtins.int"builtins.intrÆ
IS_TRIGGER_ACTIVE_FIELD_NUMBERnpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.IS_TRIGGER_ACTIVE_FIELD_NUMBER
builtins.int"builtins.intrû
IS_ACTIVE_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.IS_ACTIVE_FIELD_NUMBER
builtins.int"builtins.intré
status_message^pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.status_message
builtins.str"builtins.strrñ
is_data_availableapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.is_data_available
builtins.bool"builtins.boolrñ
is_trigger_activeapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.is_trigger_active
builtins.bool"builtins.boolrÜ
	is_activeYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult.is_active
builtins.bool"builtins.boolzÇ
RecentProgressResultWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"builtins.object*‰
recent_progress_jsonlpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.recent_progress_json"
Any*Ω
self≤
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult0:builtins.property`*›
__init__`pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.__init__"
None*Ω
self≤
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult*§
recent_progress_jsoná
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *˛

ClearFieldbpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.ClearField"
None*Ω
self≤
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesry

DESCRIPTORbpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.DESCRIPTOR
Anyrº
!RECENT_PROGRESS_JSON_FIELD_NUMBERypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult.RECENT_PROGRESS_JSON_FIELD_NUMBER
builtins.int"builtins.intzø

ExplainResultPpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"builtins.object*Õ
__init__Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.__init__"
None*Ø
self§
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult**
result
builtins.str"builtins.str *È

ClearField[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.ClearField"
None*Ø
self§
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrr

DESCRIPTOR[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.DESCRIPTOR
Anyrô
RESULT_FIELD_NUMBERdpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.RESULT_FIELD_NUMBER
builtins.int"builtins.intr
resultWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult.result
builtins.str"builtins.strz˚1
ExceptionResultRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"builtins.object*∏
__init__[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.__init__"
None*≥
self®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*]
exception_messageD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
error_classD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
stack_traceD
Union[builtins.str,None]
builtins.str"builtins.str
None *¿

HasField[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.HasField"
builtins.bool"builtins.bool*≥
self®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ


ClearField]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.ClearField"
None*≥
self®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2£

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneofÂ

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*≥
self®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÂ

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*≥
self®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÂ

WhichOneof]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*≥
self®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrt

DESCRIPTOR]pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.DESCRIPTOR
Anyr±
EXCEPTION_MESSAGE_FIELD_NUMBERqpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.EXCEPTION_MESSAGE_FIELD_NUMBER
builtins.int"builtins.intr•
ERROR_CLASS_FIELD_NUMBERkpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.ERROR_CLASS_FIELD_NUMBER
builtins.int"builtins.intr•
STACK_TRACE_FIELD_NUMBERkpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.STACK_TRACE_FIELD_NUMBER
builtins.int"builtins.intró
exception_messagedpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.exception_message
builtins.str"builtins.strrã
error_class^pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.error_class
builtins.str"builtins.strrã
stack_trace^pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult.stack_trace
builtins.str"builtins.strzª
AwaitTerminationResultYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"builtins.object*Ó
__init__bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.__init__"
None*¡
self∂
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult*0

terminated
builtins.bool"builtins.bool *Ñ

ClearFielddpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.ClearField"
None*¡
self∂
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr{

DESCRIPTORdpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.DESCRIPTOR
Anyr™
TERMINATED_FIELD_NUMBERqpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrí

terminateddpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult.terminated
builtins.bool"builtins.bool⁄É
StreamingQueryManagerCommandCpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"builtins.object*‰
await_any_terminationYpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.await_any_termination"¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:builtins.property`*ÿ
add_listenerPpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.add_listener"∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:builtins.property`*ﬁ
remove_listenerSpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.remove_listener"∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:builtins.property`*‹
__init__Lpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*,
active
builtins.bool"builtins.bool *-
	get_query
builtins.str"builtins.str *Ÿ
await_any_terminationª
jUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand,None]¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand
None *6
reset_terminated
builtins.bool"builtins.bool *Ÿ
add_listenerƒ
mUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand,None]∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand
None *‹
remove_listenerƒ
mUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand,None]∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand
None *4
list_listeners
builtins.bool"builtins.bool *ﬂ
HasFieldLpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Õ

ClearFieldNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ˇ

WhichOneofNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.WhichOneof"√
•Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.DESCRIPTOR
Anyrå
ACTIVE_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ACTIVE_FIELD_NUMBER
builtins.int"builtins.intrí
GET_QUERY_FIELD_NUMBERZpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.GET_QUERY_FIELD_NUMBER
builtins.int"builtins.intr™
"AWAIT_ANY_TERMINATION_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AWAIT_ANY_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intr†
RESET_TERMINATED_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.RESET_TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrò
ADD_LISTENER_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ADD_LISTENER_FIELD_NUMBER
builtins.int"builtins.intrû
REMOVE_LISTENER_FIELD_NUMBER`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.REMOVE_LISTENER_FIELD_NUMBER
builtins.int"builtins.intrú
LIST_LISTENERS_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.LIST_LISTENERS_FIELD_NUMBER
builtins.int"builtins.intrt
activeJpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.active
builtins.bool"builtins.boolrx
	get_queryMpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.get_query
builtins.str"builtins.strrà
reset_terminatedTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.reset_terminated
builtins.bool"builtins.boolrÑ
list_listenersRpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.list_listeners
builtins.bool"builtins.boolzÅ
AwaitAnyTerminationCommand^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"builtins.object*£
__init__gpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.__init__"
None*À
self¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*V

timeout_msD
Union[builtins.int,None]
builtins.int"builtins.int
None *À
HasFieldgpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.HasField"
builtins.bool"builtins.bool*À
self¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearFieldipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.ClearField"
None*À
self¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

WhichOneofipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*À
self¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrÄ

DESCRIPTORipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.DESCRIPTOR
AnyrØ
TIMEOUT_MS_FIELD_NUMBERvpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.TIMEOUT_MS_FIELD_NUMBER
builtins.int"builtins.intrï

timeout_msipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand.timeout_ms
builtins.int"builtins.intzÒ$
StreamingQueryListenerCommandapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"builtins.object*Î
python_listener_payloadypyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.python_listener_payload"j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*—
self∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand0:builtins.property`*í
__init__jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.__init__"
None*—
self∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*8
listener_payload 
builtins.bytes"builtins.bytes *Ÿ
python_listener_payloadπ
?Union[pyspark.sql.connect.proto.expressions_pb2.PythonUDF,None]j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF
None *&
id
builtins.str"builtins.str *‘
HasFieldjpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.HasField"
builtins.bool"builtins.bool*—
self∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*è

ClearFieldlpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.ClearField"
None*—
self∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

WhichOneoflpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*—
self∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrÉ

DESCRIPTORlpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.DESCRIPTOR
Anyræ
LISTENER_PAYLOAD_FIELD_NUMBERpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.LISTENER_PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intrÕ
$PYTHON_LISTENER_PAYLOAD_FIELD_NUMBERÜpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.PYTHON_LISTENER_PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intr¢
ID_FIELD_NUMBERqpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.ID_FIELD_NUMBER
builtins.int"builtins.intr®
listener_payloadrpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.listener_payload 
builtins.bytes"builtins.bytesrà
iddpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand.id
builtins.str"builtins.strê®
"StreamingQueryManagerCommandResultIpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"builtins.object*»
activePpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.active"∞
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:builtins.property`*⁄
queryOpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.query"ƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:builtins.property`*Ä
await_any_termination_pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.await_any_termination" 
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:builtins.property`*Ä
list_listenersXpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.list_listeners"ÿ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:builtins.property`*ö
__init__Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*≤
active£
bUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult,None]∞
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult
None *œ
query¡
lUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance,None]ƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance
None *Ë
await_any_termination 
oUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult,None] 
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult
None *6
reset_terminated
builtins.bool"builtins.bool *2
add_listener
builtins.bool"builtins.bool *5
remove_listener
builtins.bool"builtins.bool *ˆ
list_listenersﬂ
vUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult,None]ÿ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult
None *Ò
HasFieldRpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.HasField"
builtins.bool"builtins.bool*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ﬂ

ClearFieldTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ClearField"
None*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ë

WhichOneofTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.WhichOneof"√
•Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrk

DESCRIPTORTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.DESCRIPTOR
Anyrí
ACTIVE_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ACTIVE_FIELD_NUMBER
builtins.int"builtins.intrê
QUERY_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.QUERY_FIELD_NUMBER
builtins.int"builtins.intr∞
"AWAIT_ANY_TERMINATION_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AWAIT_ANY_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intr¶
RESET_TERMINATED_FIELD_NUMBERgpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.RESET_TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrû
ADD_LISTENER_FIELD_NUMBERcpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ADD_LISTENER_FIELD_NUMBER
builtins.int"builtins.intr§
REMOVE_LISTENER_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.REMOVE_LISTENER_FIELD_NUMBER
builtins.int"builtins.intr¢
LIST_LISTENERS_FIELD_NUMBERepyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.LIST_LISTENERS_FIELD_NUMBER
builtins.int"builtins.intré
reset_terminatedZpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.reset_terminated
builtins.bool"builtins.boolrÜ
add_listenerVpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.add_listener
builtins.bool"builtins.boolrå
remove_listenerYpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.remove_listener
builtins.bool"builtins.boolz¢
ActiveResultVpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"builtins.object*’
active_queriesepyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.active_queries"
Any*ª
self∞
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult0:builtins.property`*¶
__init___pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.__init__"
None*ª
self∞
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult*
active_queriesŸ
}Union[typing.Iterable[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance],None]À
qtyping.Iterable[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance]ƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"typing.Iterable
None *˚

ClearFieldapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.ClearField"
None*ª
self∞
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrx

DESCRIPTORapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.DESCRIPTOR
AnyrØ
ACTIVE_QUERIES_FIELD_NUMBERrpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult.ACTIVE_QUERIES_FIELD_NUMBER
builtins.int"builtins.intz∑!
StreamingQueryInstance`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"builtins.object*◊
idcpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.id"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*œ
selfƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance0:builtins.property`*è
__init__ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.__init__"
None*œ
selfƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*È
idﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *P
nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *¯
HasFieldipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.HasField"
builtins.bool"builtins.bool*œ
selfƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ê

ClearFieldkpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.ClearField"
None*œ
selfƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

WhichOneofkpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*œ
selfƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrÇ

DESCRIPTORkpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.DESCRIPTOR
Anyr°
ID_FIELD_NUMBERppyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.ID_FIELD_NUMBER
builtins.int"builtins.intr•
NAME_FIELD_NUMBERrpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.NAME_FIELD_NUMBER
builtins.int"builtins.intrã
nameepyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance.name
builtins.str"builtins.strz£
AwaitAnyTerminationResultcpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"builtins.object*å
__init__lpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.__init__"
None*’
self 
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult*0

terminated
builtins.bool"builtins.bool *¢

ClearFieldnpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.ClearField"
None*’
self 
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrÖ

DESCRIPTORnpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.DESCRIPTOR
Anyr¥
TERMINATED_FIELD_NUMBER{pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrú

terminatednpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult.terminated
builtins.bool"builtins.boolz˝
StreamingQueryListenerInstancehpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance"builtins.object*£
__init__qpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.__init__"
None*ﬂ
self‘
hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance"hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance*8
listener_payload 
builtins.bytes"builtins.bytes *±

ClearFieldspyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.ClearField"
None*ﬂ
self‘
hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance"hpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrä

DESCRIPTORspyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.DESCRIPTOR
Anyr∆
LISTENER_PAYLOAD_FIELD_NUMBERÜpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.LISTENER_PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intrØ
listener_payloadypyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryListenerInstance.listener_payload 
builtins.bytes"builtins.byteszÃ
 ListStreamingQueryListenerResultjpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"builtins.object*ç
listener_idswpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.listener_ids"
Any*„
selfÿ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult0:builtins.property`*é
__init__spyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.__init__"
None*„
selfÿ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult*ú
listener_idsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *∑

ClearFieldupyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.ClearField"
None*„
selfÿ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrå

DESCRIPTORupyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.DESCRIPTOR
Anyr¿
LISTENER_IDS_FIELD_NUMBERÑpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult.LISTENER_IDS_FIELD_NUMBER
builtins.int"builtins.int°
GetResourcesCommand:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand"builtins.object*ﬁ
__init__Cpyspark.sql.connect.proto.commands_pb2.GetResourcesCommand.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandr\

DESCRIPTOREpyspark.sql.connect.proto.commands_pb2.GetResourcesCommand.DESCRIPTOR
Any˝"
GetResourcesCommandResult@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"builtins.object*â
	resourcesJpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.resources"
Any*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult0:builtins.property`*Û
__init__Ipyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*ˇ
	resourcesÌ
aUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.common_pb2.ResourceInformation],None]˚
Utyping.Mapping[builtins.str,pyspark.sql.connect.proto.common_pb2.ResourceInformation]
builtins.str"builtins.strt
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation"typing.Mapping
None *π

ClearFieldKpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.DESCRIPTOR
Anyrè
RESOURCES_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.RESOURCES_FIELD_NUMBER
builtins.int"builtins.intzÿ
ResourcesEntryOpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"builtins.object*õ
valueUpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.value"t
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation*≠
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry0:builtins.property`*†
__init__Xpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.__init__"
None*≠
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry*'
key
builtins.str"builtins.str *÷
value»
DUnion[pyspark.sql.connect.proto.common_pb2.ResourceInformation,None]t
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation
None *¯
HasFieldXpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.HasField"
builtins.bool"builtins.bool*≠
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*å

ClearFieldZpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.ClearField"
None*≠
self¢
Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry"Opyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrq

DESCRIPTORZpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.DESCRIPTOR
Anyrí
KEY_FIELD_NUMBER`pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrñ
VALUE_FIELD_NUMBERbpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrx
keySpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ResourcesEntry.key
builtins.str"builtins.str·¢

Expression4pyspark.sql.connect.proto.expressions_pb2.Expression"builtins.object*‘
literal<pyspark.sql.connect.proto.expressions_pb2.Expression.literal"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*á
unresolved_attributeIpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_attribute"î
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*É
unresolved_functionHpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_function"í
Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*˚
expression_stringFpyspark.sql.connect.proto.expressions_pb2.Expression.expression_string"é
Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString"Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*Û
unresolved_starDpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_star"ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*Ã
alias:pyspark.sql.connect.proto.expressions_pb2.Expression.alias"x
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*»
cast9pyspark.sql.connect.proto.expressions_pb2.Expression.cast"v
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*˜
unresolved_regexEpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_regex"å
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*ﬂ

sort_order?pyspark.sql.connect.proto.expressions_pb2.Expression.sort_order"Ä
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*Û
lambda_functionDpyspark.sql.connect.proto.expressions_pb2.Expression.lambda_function"ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*–
window;pyspark.sql.connect.proto.expressions_pb2.Expression.window"z
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*ï
unresolved_extract_valueMpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_extract_value"ö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*Î
update_fieldsBpyspark.sql.connect.proto.expressions_pb2.Expression.update_fields"Ü
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*≥
 unresolved_named_lambda_variableUpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_named_lambda_variable"®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*ß
#common_inline_user_defined_functionXpyspark.sql.connect.proto.expressions_pb2.Expression.common_inline_user_defined_function"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*‘
call_functionBpyspark.sql.connect.proto.expressions_pb2.Expression.call_function"p
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*„
	extension>pyspark.sql.connect.proto.expressions_pb2.Expression.extension"
Any*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:builtins.property`*≥"
__init__=pyspark.sql.connect.proto.expressions_pb2.Expression.__init__"
None*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*‰
literal‘
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *ñ
unresolved_attribute˘
TUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute,None]î
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute
None *í
unresolved_functionˆ
SUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction,None]í
Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction
None *ä
expression_string
QUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString,None]é
Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString"Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString
None *Ç
unresolved_starÍ
OUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar,None]ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar
None *‹
aliasŒ
FUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Alias,None]x
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias
None *ÿ
castÀ
EUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Cast,None]v
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast
None *Ü
unresolved_regexÌ
PUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex,None]å
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex
None *Ó

sort_order€
JUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder,None]Ä
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder
None *Ç
lambda_functionÍ
OUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction,None]ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction
None *‡
window—
GUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Window,None]z
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window
None *£
unresolved_extract_valueÇ
WUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue,None]ö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue
None *˙
update_fields‰
MUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields,None]Ü
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields
None *¿
 unresolved_named_lambda_variableó
^Union[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable,None]®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable
None *®
#common_inline_user_defined_function¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *ÿ
call_function¬
BUnion[pyspark.sql.connect.proto.expressions_pb2.CallFunction,None]p
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction
None *7
	extension&
Union[Any,None]
Any
None *¨
HasField=pyspark.sql.connect.proto.expressions_pb2.Expression.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*»

field_name∑
¬Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ö

ClearField?pyspark.sql.connect.proto.expressions_pb2.Expression.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*»

field_name∑
¬Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ê

WhichOneof?pyspark.sql.connect.proto.expressions_pb2.Expression.WhichOneof"Ÿ

ÅUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.expressions_pb2.Expression.DESCRIPTOR
Anyr
LITERAL_FIELD_NUMBERIpyspark.sql.connect.proto.expressions_pb2.Expression.LITERAL_FIELD_NUMBER
builtins.int"builtins.intrô
!UNRESOLVED_ATTRIBUTE_FIELD_NUMBERVpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_ATTRIBUTE_FIELD_NUMBER
builtins.int"builtins.intró
 UNRESOLVED_FUNCTION_FIELD_NUMBERUpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrì
EXPRESSION_STRING_FIELD_NUMBERSpyspark.sql.connect.proto.expressions_pb2.Expression.EXPRESSION_STRING_FIELD_NUMBER
builtins.int"builtins.intrè
UNRESOLVED_STAR_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_STAR_FIELD_NUMBER
builtins.int"builtins.intr{
ALIAS_FIELD_NUMBERGpyspark.sql.connect.proto.expressions_pb2.Expression.ALIAS_FIELD_NUMBER
builtins.int"builtins.intry
CAST_FIELD_NUMBERFpyspark.sql.connect.proto.expressions_pb2.Expression.CAST_FIELD_NUMBER
builtins.int"builtins.intrë
UNRESOLVED_REGEX_FIELD_NUMBERRpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_REGEX_FIELD_NUMBER
builtins.int"builtins.intrÖ
SORT_ORDER_FIELD_NUMBERLpyspark.sql.connect.proto.expressions_pb2.Expression.SORT_ORDER_FIELD_NUMBER
builtins.int"builtins.intrè
LAMBDA_FUNCTION_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.LAMBDA_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr}
WINDOW_FIELD_NUMBERHpyspark.sql.connect.proto.expressions_pb2.Expression.WINDOW_FIELD_NUMBER
builtins.int"builtins.intr°
%UNRESOLVED_EXTRACT_VALUE_FIELD_NUMBERZpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_EXTRACT_VALUE_FIELD_NUMBER
builtins.int"builtins.intrã
UPDATE_FIELDS_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.UPDATE_FIELDS_FIELD_NUMBER
builtins.int"builtins.intr±
-UNRESOLVED_NAMED_LAMBDA_VARIABLE_FIELD_NUMBERbpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_NAMED_LAMBDA_VARIABLE_FIELD_NUMBER
builtins.int"builtins.intr∑
0COMMON_INLINE_USER_DEFINED_FUNCTION_FIELD_NUMBERepyspark.sql.connect.proto.expressions_pb2.Expression.COMMON_INLINE_USER_DEFINED_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrã
CALL_FUNCTION_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.CALL_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrÉ
EXTENSION_FIELD_NUMBERKpyspark.sql.connect.proto.expressions_pb2.Expression.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intz˛Ü
Window;pyspark.sql.connect.proto.expressions_pb2.Expression.Window"builtins.object*Í
window_functionKpyspark.sql.connect.proto.expressions_pb2.Expression.Window.window_function"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*Ñ
selfz
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window0:builtins.property`*É
partition_specJpyspark.sql.connect.proto.expressions_pb2.Expression.Window.partition_spec"
Any*Ñ
selfz
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window0:builtins.property`*˚

order_specFpyspark.sql.connect.proto.expressions_pb2.Expression.Window.order_spec"
Any*Ñ
selfz
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window0:builtins.property`*á

frame_specFpyspark.sql.connect.proto.expressions_pb2.Expression.Window.frame_spec"í
Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame*Ñ
selfz
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window0:builtins.property`*Ì

__init__Dpyspark.sql.connect.proto.expressions_pb2.Expression.Window.__init__"
None*Ñ
selfz
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window*‘
window_functionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *ø
partition_spec®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *‰

order_spec—
[Union[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder],None]Â
Otyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder]Ä
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder"typing.Iterable
None *â

frame_specˆ
SUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame,None]í
Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame
None *·
HasFieldDpyspark.sql.connect.proto.expressions_pb2.Expression.Window.HasField"
builtins.bool"builtins.bool*Ñ
selfz
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ú

ClearFieldFpyspark.sql.connect.proto.expressions_pb2.Expression.Window.ClearField"
None*Ñ
selfz
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.expressions_pb2.Expression.Window.DESCRIPTOR
Anyrñ
WINDOW_FUNCTION_FIELD_NUMBERXpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WINDOW_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrî
PARTITION_SPEC_FIELD_NUMBERWpyspark.sql.connect.proto.expressions_pb2.Expression.Window.PARTITION_SPEC_FIELD_NUMBER
builtins.int"builtins.intrå
ORDER_SPEC_FIELD_NUMBERSpyspark.sql.connect.proto.expressions_pb2.Expression.Window.ORDER_SPEC_FIELD_NUMBER
builtins.int"builtins.intrå
FRAME_SPEC_FIELD_NUMBERSpyspark.sql.connect.proto.expressions_pb2.Expression.Window.FRAME_SPEC_FIELD_NUMBER
builtins.int"builtins.intzä`
WindowFrameGpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"builtins.object*æ
lowerMpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.lower"Æ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame0:builtins.property`*æ
upperMpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.upper"Æ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame0:builtins.property`*∫
__init__Ppyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.__init__"
None*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame*œ

frame_typeº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType *Æ
lower†
aUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary,None]Æ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary
None *Æ
upper†
aUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary,None]Æ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary
None *Ü
HasFieldPpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.HasField"
builtins.bool"builtins.bool*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*õ

ClearFieldRpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.ClearField"
None*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame"Gpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesri

DESCRIPTORRpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.DESCRIPTOR
Anyr≥
FRAME_TYPE_UNDEFINED\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FRAME_TYPE_UNDEFINEDº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueTyperß
FRAME_TYPE_ROWVpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FRAME_TYPE_ROWº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueTyper´
FRAME_TYPE_RANGEXpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FRAME_TYPE_RANGEº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueTyperò
FRAME_TYPE_FIELD_NUMBER_pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FRAME_TYPE_FIELD_NUMBER
builtins.int"builtins.intré
LOWER_FIELD_NUMBERZpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.LOWER_FIELD_NUMBER
builtins.int"builtins.intré
UPPER_FIELD_NUMBERZpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.UPPER_FIELD_NUMBER
builtins.int"builtins.intrü

frame_typeRpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.frame_typeº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueTypez€

_FrameTypeRpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType"builtins.objectzÁ
	ValueType\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"builtins.int*Ì
__init__epyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType.__init__"
None*«
selfº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType*&
item
builtins.int"builtins.intzÔ	
_FrameTypeEnumTypeWrapperapyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameTypeEnumTypeWrapper"builtins.typerÉ

DESCRIPTORlpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameTypeEnumTypeWrapper.DESCRIPTOR
AnyrÕ
FRAME_TYPE_UNDEFINEDvpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameTypeEnumTypeWrapper.FRAME_TYPE_UNDEFINEDº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueTyper¡
FRAME_TYPE_ROWppyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameTypeEnumTypeWrapper.FRAME_TYPE_ROWº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueTyper≈
FRAME_TYPE_RANGErpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameTypeEnumTypeWrapper.FRAME_TYPE_RANGEº
\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueType"\pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType.ValueTypezó
	FrameTypeQpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameType"Rpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameType@bapyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame._FrameTypeEnumTypeWrapperz¯%
FrameBoundaryUpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"builtins.object*•
value[pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.value"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*π
selfÆ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary0:builtins.property`*·
__init__^pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.__init__"
None*π
selfÆ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary*1
current_row
builtins.bool"builtins.bool */
	unbounded
builtins.bool"builtins.bool * 
valueº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *˝
HasField^pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.HasField"
builtins.bool"builtins.bool*π
selfÆ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

ClearField`pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.ClearField"
None*π
selfÆ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¯

WhichOneof`pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.WhichOneof"Ü
MUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*π
selfÆ
Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary"Upyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrw

DESCRIPTOR`pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.DESCRIPTOR
Anyr®
CURRENT_ROW_FIELD_NUMBERnpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.CURRENT_ROW_FIELD_NUMBER
builtins.int"builtins.intr§
UNBOUNDED_FIELD_NUMBERlpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.UNBOUNDED_FIELD_NUMBER
builtins.int"builtins.intrú
VALUE_FIELD_NUMBERhpyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.VALUE_FIELD_NUMBER
builtins.int"builtins.intrê
current_rowapyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.current_row
builtins.bool"builtins.boolrå
	unbounded_pyspark.sql.connect.proto.expressions_pb2.Expression.Window.WindowFrame.FrameBoundary.unbounded
builtins.bool"builtins.boolz±J
	SortOrder>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder"builtins.object*‡
childDpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.child"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*ã
selfÄ
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder0:builtins.property`*»
__init__Gpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder* 
childº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *ƒ
	direction≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType *∆
null_ordering∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType *≈
HasFieldGpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.HasField"
builtins.bool"builtins.bool*ã
selfÄ
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ä

ClearFieldIpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.DESCRIPTOR
Anyr¨
SORT_DIRECTION_UNSPECIFIEDYpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.SORT_DIRECTION_UNSPECIFIED≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueTyper®
SORT_DIRECTION_ASCENDINGWpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.SORT_DIRECTION_ASCENDING≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueTyper™
SORT_DIRECTION_DESCENDINGXpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.SORT_DIRECTION_DESCENDING≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueTyper¢
SORT_NULLS_UNSPECIFIEDUpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.SORT_NULLS_UNSPECIFIED∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueTyperñ
SORT_NULLS_FIRSTOpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.SORT_NULLS_FIRST∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueTyperî
SORT_NULLS_LASTNpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.SORT_NULLS_LAST∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueTyperÖ
CHILD_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.CHILD_FIELD_NUMBER
builtins.int"builtins.intrç
DIRECTION_FIELD_NUMBERUpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.DIRECTION_FIELD_NUMBER
builtins.int"builtins.intrï
NULL_ORDERING_FIELD_NUMBERYpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.NULL_ORDERING_FIELD_NUMBER
builtins.int"builtins.inträ
	directionHpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.direction≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueTyperê
null_orderingLpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.null_ordering∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueTypez∆
_SortDirectionMpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection"builtins.objectz”
	ValueTypeWpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"builtins.int*ﬁ
__init__`pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType.__init__"
None*Ω
self≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType*&
item
builtins.int"builtins.intzÌ	
_SortDirectionEnumTypeWrapper\pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirectionEnumTypeWrapper"builtins.typer~

DESCRIPTORgpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirectionEnumTypeWrapper.DESCRIPTOR
Anyr 
SORT_DIRECTION_UNSPECIFIEDwpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirectionEnumTypeWrapper.SORT_DIRECTION_UNSPECIFIED≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueTyper∆
SORT_DIRECTION_ASCENDINGupyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirectionEnumTypeWrapper.SORT_DIRECTION_ASCENDING≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueTyper»
SORT_DIRECTION_DESCENDINGvpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirectionEnumTypeWrapper.SORT_DIRECTION_DESCENDING≤
Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueType"Wpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection.ValueTypezå
SortDirectionLpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.SortDirection"Mpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirection@b\pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._SortDirectionEnumTypeWrapperz¿
_NullOrderingLpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering"builtins.objectzœ
	ValueTypeVpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"builtins.int*€
__init___pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType.__init__"
None*ª
self∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType*&
item
builtins.int"builtins.intzµ	
_NullOrderingEnumTypeWrapper[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrderingEnumTypeWrapper"builtins.typer}

DESCRIPTORfpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrderingEnumTypeWrapper.DESCRIPTOR
Anyrø
SORT_NULLS_UNSPECIFIEDrpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrderingEnumTypeWrapper.SORT_NULLS_UNSPECIFIED∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueTyper≥
SORT_NULLS_FIRSTlpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrderingEnumTypeWrapper.SORT_NULLS_FIRST∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueTyper±
SORT_NULLS_LASTkpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrderingEnumTypeWrapper.SORT_NULLS_LAST∞
Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueType"Vpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering.ValueTypezà
NullOrderingKpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder.NullOrdering"Lpyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrdering@b[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder._NullOrderingEnumTypeWrapperzﬂ"
Cast9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"builtins.object*Œ
expr>pyspark.sql.connect.proto.expressions_pb2.Expression.Cast.expr"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*Ä
selfv
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast0:builtins.property`*æ
type>pyspark.sql.connect.proto.expressions_pb2.Expression.Cast.type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*Ä
selfv
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast0:builtins.property`*â
__init__Bpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast*…
exprº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *±
type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *,
type_str
builtins.str"builtins.str *®
HasFieldBpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ñ

ClearFieldDpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‘

WhichOneofDpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr[

DESCRIPTORDpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.DESCRIPTOR
Anyr~
EXPR_FIELD_NUMBERKpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.EXPR_FIELD_NUMBER
builtins.int"builtins.intr~
TYPE_FIELD_NUMBERKpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.TYPE_FIELD_NUMBER
builtins.int"builtins.intrÜ
TYPE_STR_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.TYPE_STR_FIELD_NUMBER
builtins.int"builtins.intrl
type_strBpyspark.sql.connect.proto.expressions_pb2.Expression.Cast.type_str
builtins.str"builtins.strzàü
Literal<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"builtins.object*«
nullApyspark.sql.connect.proto.expressions_pb2.Expression.Literal.null"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal0:builtins.property`*˛
decimalDpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.decimal"å
Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal0:builtins.property`*§
calendar_intervalNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.calendar_interval"û
Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval"Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal0:builtins.property`*ˆ
arrayBpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.array"à
Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal0:builtins.property`*Ó
map@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.map"Ñ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal0:builtins.property`*˙
structCpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.struct"ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal0:builtins.property`*≥
__init__Epyspark.sql.connect.proto.expressions_pb2.Expression.Literal.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*±
null§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *.
binary 
builtins.bytes"builtins.bytes *-
boolean
builtins.bool"builtins.bool *(
byte
builtins.int"builtins.int *)
short
builtins.int"builtins.int *+
integer
builtins.int"builtins.int *(
long
builtins.int"builtins.int *-
float 
builtins.float"builtins.float *.
double 
builtins.float"builtins.float *˝
decimalÌ
PUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal,None]å
Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal
None **
string
builtins.str"builtins.str *(
date
builtins.int"builtins.int *-
	timestamp
builtins.int"builtins.int *1
timestamp_ntz
builtins.int"builtins.int *¢
calendar_intervalà
YUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval,None]û
Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval"Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval
None *7
year_month_interval
builtins.int"builtins.int *5
day_time_interval
builtins.int"builtins.int *ı
arrayÁ
NUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array,None]à
Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array
None *Ì
map·
LUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map,None]Ñ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map
None *˘
structÍ
OUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct,None]ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct
None *∑
HasFieldEpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.HasField"
builtins.bool"builtins.bool*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*∫

field_name©
ÃUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*•

ClearFieldGpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*∫

field_name©
ÃUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ï

WhichOneofGpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.WhichOneof"∆
√Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ü
self|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.DESCRIPTOR
AnyrÅ
NULL_FIELD_NUMBERNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.NULL_FIELD_NUMBER
builtins.int"builtins.intrÖ
BINARY_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.BINARY_FIELD_NUMBER
builtins.int"builtins.intrá
BOOLEAN_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.BOOLEAN_FIELD_NUMBER
builtins.int"builtins.intrÅ
BYTE_FIELD_NUMBERNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.BYTE_FIELD_NUMBER
builtins.int"builtins.intrÉ
SHORT_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.SHORT_FIELD_NUMBER
builtins.int"builtins.intrá
INTEGER_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.INTEGER_FIELD_NUMBER
builtins.int"builtins.intrÅ
LONG_FIELD_NUMBERNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.LONG_FIELD_NUMBER
builtins.int"builtins.intrÉ
FLOAT_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.FLOAT_FIELD_NUMBER
builtins.int"builtins.intrÖ
DOUBLE_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.DOUBLE_FIELD_NUMBER
builtins.int"builtins.intrá
DECIMAL_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.DECIMAL_FIELD_NUMBER
builtins.int"builtins.intrÖ
STRING_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.STRING_FIELD_NUMBER
builtins.int"builtins.intrÅ
DATE_FIELD_NUMBERNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.DATE_FIELD_NUMBER
builtins.int"builtins.intrã
TIMESTAMP_FIELD_NUMBERSpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.TIMESTAMP_FIELD_NUMBER
builtins.int"builtins.intrì
TIMESTAMP_NTZ_FIELD_NUMBERWpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.TIMESTAMP_NTZ_FIELD_NUMBER
builtins.int"builtins.intrõ
CALENDAR_INTERVAL_FIELD_NUMBER[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CALENDAR_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrü
 YEAR_MONTH_INTERVAL_FIELD_NUMBER]pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.YEAR_MONTH_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrõ
DAY_TIME_INTERVAL_FIELD_NUMBER[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.DAY_TIME_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrÉ
ARRAY_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.ARRAY_FIELD_NUMBER
builtins.int"builtins.intr
MAP_FIELD_NUMBERMpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.MAP_FIELD_NUMBER
builtins.int"builtins.intrÖ
STRUCT_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.STRUCT_FIELD_NUMBER
builtins.int"builtins.intro
binaryCpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.binary 
builtins.bytes"builtins.bytesro
booleanDpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.boolean
builtins.bool"builtins.boolrg
byteApyspark.sql.connect.proto.expressions_pb2.Expression.Literal.byte
builtins.int"builtins.intri
shortBpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.short
builtins.int"builtins.intrm
integerDpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.integer
builtins.int"builtins.intrg
longApyspark.sql.connect.proto.expressions_pb2.Expression.Literal.long
builtins.int"builtins.intrm
floatBpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.float 
builtins.float"builtins.floatro
doubleCpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.double 
builtins.float"builtins.floatrk
stringCpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.string
builtins.str"builtins.strrg
dateApyspark.sql.connect.proto.expressions_pb2.Expression.Literal.date
builtins.int"builtins.intrq
	timestampFpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.timestamp
builtins.int"builtins.intry
timestamp_ntzJpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.timestamp_ntz
builtins.int"builtins.intrÖ
year_month_intervalPpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.year_month_interval
builtins.int"builtins.intrÅ
day_time_intervalNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.day_time_interval
builtins.int"builtins.intz∫%
DecimalDpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"builtins.object*“
__init__Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal*)
value
builtins.str"builtins.str *U
	precisionD
Union[builtins.int,None]
builtins.int"builtins.int
None *Q
scaleD
Union[builtins.int,None]
builtins.int"builtins.int
None * 
HasFieldMpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.HasField"
builtins.bool"builtins.bool*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ﬁ

ClearFieldOpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ÿ	

WhichOneofOpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.WhichOneofª

WhichOneofOpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXª

WhichOneofOpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal"Dpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrf

DESCRIPTOROpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.DESCRIPTOR
Anyrã
VALUE_FIELD_NUMBERWpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.VALUE_FIELD_NUMBER
builtins.int"builtins.intrì
PRECISION_FIELD_NUMBER[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.PRECISION_FIELD_NUMBER
builtins.int"builtins.intrã
SCALE_FIELD_NUMBERWpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.SCALE_FIELD_NUMBER
builtins.int"builtins.intrq
valueJpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.value
builtins.str"builtins.strry
	precisionNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.precision
builtins.int"builtins.intrq
scaleJpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Decimal.scale
builtins.int"builtins.intzå
CalendarIntervalMpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval"builtins.object*†
__init__Vpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.__init__"
None*©
selfû
Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval"Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval**
months
builtins.int"builtins.int *(
days
builtins.int"builtins.int *0
microseconds
builtins.int"builtins.int *≠

ClearFieldXpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.ClearField"
None*©
selfû
Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval"Mpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesro

DESCRIPTORXpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.DESCRIPTOR
Anyrñ
MONTHS_FIELD_NUMBERapyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.MONTHS_FIELD_NUMBER
builtins.int"builtins.intrí
DAYS_FIELD_NUMBER_pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.DAYS_FIELD_NUMBER
builtins.int"builtins.intr¢
MICROSECONDS_FIELD_NUMBERgpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.MICROSECONDS_FIELD_NUMBER
builtins.int"builtins.intr|
monthsTpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.months
builtins.int"builtins.intrx
daysRpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.days
builtins.int"builtins.intrà
microsecondsZpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.CalendarInterval.microseconds
builtins.int"builtins.intzπ
ArrayBpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"builtins.object*Í
element_typeOpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.element_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*ì
selfà
Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array0:builtins.property`*ç
elementsKpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.elements"
Any*ì
selfà
Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array0:builtins.property`*è
__init__Kpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array*π
element_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ÿ
elements»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *—
HasFieldKpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.HasField"
builtins.bool"builtins.bool*ì
selfà
Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Â

ClearFieldMpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array"Bpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.DESCRIPTOR
Anyró
ELEMENT_TYPE_FIELD_NUMBER\pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.ELEMENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrè
ELEMENTS_FIELD_NUMBERXpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Array.ELEMENTS_FIELD_NUMBER
builtins.int"builtins.intz˘%
Map@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"builtins.object*‹
key_typeIpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.key_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*è
selfÑ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map0:builtins.property`*‡

value_typeKpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.value_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*è
selfÑ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map0:builtins.property`*ˇ
keysEpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.keys"
Any*è
selfÑ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map0:builtins.property`*É
valuesGpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.values"
Any*è
selfÑ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map0:builtins.property`*ï

__init__Ipyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map*µ
key_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *∑

value_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *’
keys»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *◊
values»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *Ò
HasFieldIpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.HasField"
builtins.bool"builtins.bool*è
selfÑ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

ClearFieldKpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map"@pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.DESCRIPTOR
Anyrç
KEY_TYPE_FIELD_NUMBERVpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.KEY_TYPE_FIELD_NUMBER
builtins.int"builtins.intrë
VALUE_TYPE_FIELD_NUMBERXpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.VALUE_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÖ
KEYS_FIELD_NUMBERRpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.KEYS_FIELD_NUMBER
builtins.int"builtins.intrâ
VALUES_FIELD_NUMBERTpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Map.VALUES_FIELD_NUMBER
builtins.int"builtins.intz»
StructCpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"builtins.object*Î
struct_typeOpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.struct_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct0:builtins.property`*ê
elementsLpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.elements"
Any*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct0:builtins.property`*ë
__init__Lpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct*∏
struct_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ÿ
elements»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *‘
HasFieldLpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

ClearFieldNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct"Cpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.DESCRIPTOR
Anyrñ
STRUCT_TYPE_FIELD_NUMBER\pyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.STRUCT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrê
ELEMENTS_FIELD_NUMBERYpyspark.sql.connect.proto.expressions_pb2.Expression.Literal.Struct.ELEMENTS_FIELD_NUMBER
builtins.int"builtins.intz´
UnresolvedAttributeHpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"builtins.object*ó
__init__Qpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.__init__"
None*ü
selfî
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute*7
unparsed_identifier
builtins.str"builtins.str *S
plan_idD
Union[builtins.int,None]
builtins.int"builtins.int
None *â
HasFieldQpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.HasField"
builtins.bool"builtins.bool*ü
selfî
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*û

ClearFieldSpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.ClearField"
None*ü
selfî
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≤

WhichOneofSpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ü
selfî
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrj

DESCRIPTORSpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.DESCRIPTOR
Anyr´
 UNPARSED_IDENTIFIER_FIELD_NUMBERipyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.UNPARSED_IDENTIFIER_FIELD_NUMBER
builtins.int"builtins.intrì
PLAN_ID_FIELD_NUMBER]pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.PLAN_ID_FIELD_NUMBER
builtins.int"builtins.intrë
unparsed_identifier\pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.unparsed_identifier
builtins.str"builtins.strry
plan_idPpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute.plan_id
builtins.int"builtins.intz„
UnresolvedFunctionGpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"builtins.object*û
	argumentsQpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.arguments"
Any*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction0:builtins.property`*È
__init__Ppyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.__init__"
None*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction*1
function_name
builtins.str"builtins.str *∫
	arguments®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *1
is_distinct
builtins.bool"builtins.bool *>
is_user_defined_function
builtins.bool"builtins.bool *¡

ClearFieldRpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.ClearField"
None*ù
selfí
Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesri

DESCRIPTORRpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.DESCRIPTOR
Anyrû
FUNCTION_NAME_FIELD_NUMBERbpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intrñ
ARGUMENTS_FIELD_NUMBER^pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intrö
IS_DISTINCT_FIELD_NUMBER`pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.IS_DISTINCT_FIELD_NUMBER
builtins.int"builtins.intr¥
%IS_USER_DEFINED_FUNCTION_FIELD_NUMBERmpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.IS_USER_DEFINED_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrÑ
function_nameUpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.function_name
builtins.str"builtins.strrÇ
is_distinctSpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.is_distinct
builtins.bool"builtins.boolrú
is_user_defined_function`pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction.is_user_defined_function
builtins.bool"builtins.boolzË	
ExpressionStringEpyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString"builtins.object*∞
__init__Npyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString.__init__"
None*ô
selfé
Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString"Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString*.

expression
builtins.str"builtins.str *»

ClearFieldPpyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString.ClearField"
None*ô
selfé
Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString"Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrg

DESCRIPTORPpyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString.DESCRIPTOR
Anyrñ
EXPRESSION_FIELD_NUMBER]pyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString.EXPRESSION_FIELD_NUMBER
builtins.int"builtins.intr|

expressionPpyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString.expression
builtins.str"builtins.strz›
UnresolvedStarCpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"builtins.object*◊
__init__Lpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar*[
unparsed_targetD
Union[builtins.str,None]
builtins.str"builtins.str
None *˙
HasFieldLpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

ClearFieldNpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*£

WhichOneofNpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar.DESCRIPTOR
Anyrû
UNPARSED_TARGET_FIELD_NUMBER`pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar.UNPARSED_TARGET_FIELD_NUMBER
builtins.int"builtins.intrÑ
unparsed_targetSpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar.unparsed_target
builtins.str"builtins.strzß
UnresolvedRegexDpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"builtins.object*Ä
__init__Mpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex*,
col_name
builtins.str"builtins.str *S
plan_idD
Union[builtins.int,None]
builtins.int"builtins.int
None *˝
HasFieldMpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.HasField"
builtins.bool"builtins.bool*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*í

ClearFieldOpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¶

WhichOneofOpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ó
selfå
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.DESCRIPTOR
Anyrë
COL_NAME_FIELD_NUMBERZpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.COL_NAME_FIELD_NUMBER
builtins.int"builtins.intrè
PLAN_ID_FIELD_NUMBERYpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.PLAN_ID_FIELD_NUMBER
builtins.int"builtins.intrw
col_nameMpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.col_name
builtins.str"builtins.strru
plan_idLpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex.plan_id
builtins.int"builtins.intzÉ
UnresolvedExtractValueKpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"builtins.object*á
childQpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.child"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*•
selfö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue0:builtins.property`*ë

extractionVpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.extraction"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*•
selfö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue0:builtins.property`*±
__init__Tpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.__init__"
None*•
selfö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue* 
childº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *œ

extractionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *í
HasFieldTpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.HasField"
builtins.bool"builtins.bool*•
selfö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ä

ClearFieldVpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.ClearField"
None*•
selfö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrm

DESCRIPTORVpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.DESCRIPTOR
Anyrí
CHILD_FIELD_NUMBER^pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.CHILD_FIELD_NUMBER
builtins.int"builtins.intrú
EXTRACTION_FIELD_NUMBERcpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue.EXTRACTION_FIELD_NUMBER
builtins.int"builtins.intz˚
UpdateFieldsApyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"builtins.object*Å
struct_expressionSpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.struct_expression"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*ë
selfÜ
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields0:builtins.property`*ˇ
value_expressionRpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.value_expression"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*ë
selfÜ
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields0:builtins.property`*’
__init__Jpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields*÷
struct_expressionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *.

field_name
builtins.str"builtins.str *’
value_expressionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *Ù
HasFieldJpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.HasField"
builtins.bool"builtins.bool*ë
selfÜ
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*â

ClearFieldLpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.DESCRIPTOR
Anyr†
STRUCT_EXPRESSION_FIELD_NUMBER`pyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.STRUCT_EXPRESSION_FIELD_NUMBER
builtins.int"builtins.intrí
FIELD_NAME_FIELD_NUMBERYpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.FIELD_NAME_FIELD_NUMBER
builtins.int"builtins.intrû
VALUE_EXPRESSION_FIELD_NUMBER_pyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.VALUE_EXPRESSION_FIELD_NUMBER
builtins.int"builtins.intrx

field_nameLpyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields.field_name
builtins.str"builtins.strz∏ 
Alias:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias"builtins.object*—
expr?pyspark.sql.connect.proto.expressions_pb2.Expression.Alias.expr"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*Ç
selfx
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias0:builtins.property`*Ï
name?pyspark.sql.connect.proto.expressions_pb2.Expression.Alias.name"
Any*Ç
selfx
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias0:builtins.property`*ó
__init__Cpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias*…
exprº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *î
nameá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *T
metadataD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ö
HasFieldCpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ô

ClearFieldEpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*á

WhichOneofEpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ç
selfx
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.DESCRIPTOR
Anyr
EXPR_FIELD_NUMBERLpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.EXPR_FIELD_NUMBER
builtins.int"builtins.intr
NAME_FIELD_NUMBERLpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.NAME_FIELD_NUMBER
builtins.int"builtins.intrá
METADATA_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.METADATA_FIELD_NUMBER
builtins.int"builtins.intrm
metadataCpyspark.sql.connect.proto.expressions_pb2.Expression.Alias.metadata
builtins.str"builtins.strz«
LambdaFunctionCpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"builtins.object*ı
functionLpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.function"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction0:builtins.property`*í
	argumentsMpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.arguments"
Any*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction0:builtins.property`*Ä
__init__Lpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction*Õ
functionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *≥
	arguments°
oUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable],None]°
ctyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable]®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"typing.Iterable
None *‘
HasFieldLpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

ClearFieldNpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.DESCRIPTOR
Anyrê
FUNCTION_FIELD_NUMBERYpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrí
ARGUMENTS_FIELD_NUMBERZpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intzù
UnresolvedNamedLambdaVariableRpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"builtins.object*¡

name_parts]pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable.name_parts"
Any*≥
self®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable0:builtins.property`*ƒ
__init__[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable.__init__"
None*≥
self®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable*ö

name_partsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ô

ClearField]pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable.ClearField"
None*≥
self®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrt

DESCRIPTOR]pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable.DESCRIPTOR
Anyr£
NAME_PARTS_FIELD_NUMBERjpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable.NAME_PARTS_FIELD_NUMBER
builtins.int"builtins.int¥:
CommonInlineUserDefinedFunctionIpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"builtins.object*§
	argumentsSpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.arguments"
Any*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:builtins.property`*â

python_udfTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.python_udf"j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:builtins.property`*ü
scalar_scala_udfZpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.scalar_scala_udf"t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:builtins.property`*Å
java_udfRpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.java_udf"f
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:builtins.property`*´

__init__Rpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*1
function_name
builtins.str"builtins.str *3
deterministic
builtins.bool"builtins.bool *∫
	arguments®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Ã

python_udfπ
?Union[pyspark.sql.connect.proto.expressions_pb2.PythonUDF,None]j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF
None *·
scalar_scala_udf»
DUnion[pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF,None]t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF
None *ƒ
java_udf≥
=Union[pyspark.sql.connect.proto.expressions_pb2.JavaUDF,None]f
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF
None *Ÿ
HasFieldRpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.HasField"
builtins.bool"builtins.bool*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearFieldTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.ClearField"
None*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‘

WhichOneofTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.WhichOneof"Ü
MUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrk

DESCRIPTORTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.DESCRIPTOR
Anyr†
FUNCTION_NAME_FIELD_NUMBERdpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr†
DETERMINISTIC_FIELD_NUMBERdpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.DETERMINISTIC_FIELD_NUMBER
builtins.int"builtins.intrò
ARGUMENTS_FIELD_NUMBER`pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intrö
PYTHON_UDF_FIELD_NUMBERapyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.PYTHON_UDF_FIELD_NUMBER
builtins.int"builtins.intr¶
SCALAR_SCALA_UDF_FIELD_NUMBERgpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.SCALAR_SCALA_UDF_FIELD_NUMBER
builtins.int"builtins.intrñ
JAVA_UDF_FIELD_NUMBER_pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.JAVA_UDF_FIELD_NUMBER
builtins.int"builtins.intrÜ
function_nameWpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.function_name
builtins.str"builtins.strrà
deterministicWpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.deterministic
builtins.bool"builtins.bool˙
	PythonUDF3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"builtins.object*π
output_type?pyspark.sql.connect.proto.expressions_pb2.PythonUDF.output_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF0:builtins.property`*ì
__init__<pyspark.sql.connect.proto.expressions_pb2.PythonUDF.__init__"
None*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*∏
output_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *-
	eval_type
builtins.int"builtins.int */
command 
builtins.bytes"builtins.bytes *.

python_ver
builtins.str"builtins.str *¢
HasField<pyspark.sql.connect.proto.expressions_pb2.PythonUDF.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearField>pyspark.sql.connect.proto.expressions_pb2.PythonUDF.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.expressions_pb2.PythonUDF.DESCRIPTOR
AnyrÜ
OUTPUT_TYPE_FIELD_NUMBERLpyspark.sql.connect.proto.expressions_pb2.PythonUDF.OUTPUT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÇ
EVAL_TYPE_FIELD_NUMBERJpyspark.sql.connect.proto.expressions_pb2.PythonUDF.EVAL_TYPE_FIELD_NUMBER
builtins.int"builtins.intr~
COMMAND_FIELD_NUMBERHpyspark.sql.connect.proto.expressions_pb2.PythonUDF.COMMAND_FIELD_NUMBER
builtins.int"builtins.intrÑ
PYTHON_VER_FIELD_NUMBERKpyspark.sql.connect.proto.expressions_pb2.PythonUDF.PYTHON_VER_FIELD_NUMBER
builtins.int"builtins.intrh
	eval_type=pyspark.sql.connect.proto.expressions_pb2.PythonUDF.eval_type
builtins.int"builtins.intrh
command;pyspark.sql.connect.proto.expressions_pb2.PythonUDF.command 
builtins.bytes"builtins.bytesrj

python_ver>pyspark.sql.connect.proto.expressions_pb2.PythonUDF.python_ver
builtins.str"builtins.str‘
ScalarScalaUDF8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"builtins.object*Ò

inputTypesCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.inputTypes"
Any*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF0:builtins.property`*∆

outputTypeCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.outputType"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF0:builtins.property`*ê
__init__Apyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.__init__"
None*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*/
payload 
builtins.bytes"builtins.bytes *õ

inputTypesà
IUnion[typing.Iterable[pyspark.sql.connect.proto.types_pb2.DataType],None]Æ
=typing.Iterable[pyspark.sql.connect.proto.types_pb2.DataType]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType"typing.Iterable
None *∑

outputType§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *.
nullable
builtins.bool"builtins.bool *±
HasFieldApyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.HasField"
builtins.bool"builtins.bool*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*í

ClearFieldCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.ClearField"
None*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.DESCRIPTOR
AnyrÉ
PAYLOAD_FIELD_NUMBERMpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intrâ
INPUTTYPES_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.INPUTTYPES_FIELD_NUMBER
builtins.int"builtins.intrâ
OUTPUTTYPE_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.OUTPUTTYPE_FIELD_NUMBER
builtins.int"builtins.intrÖ
NULLABLE_FIELD_NUMBERNpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.NULLABLE_FIELD_NUMBER
builtins.int"builtins.intrm
payload@pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.payload 
builtins.bytes"builtins.bytesrm
nullableApyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.nullable
builtins.bool"builtins.boolœ
JavaUDF1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"builtins.object*≥
output_type=pyspark.sql.connect.proto.expressions_pb2.JavaUDF.output_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF0:builtins.property`*ﬁ
__init__:pyspark.sql.connect.proto.expressions_pb2.JavaUDF.__init__"
None*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*.

class_name
builtins.str"builtins.str *∏
output_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None */
	aggregate
builtins.bool"builtins.bool *¬
HasField:pyspark.sql.connect.proto.expressions_pb2.JavaUDF.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

ClearField<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.ClearField"
None*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.DESCRIPTOR
AnyrÇ
CLASS_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.expressions_pb2.JavaUDF.CLASS_NAME_FIELD_NUMBER
builtins.int"builtins.intrÑ
OUTPUT_TYPE_FIELD_NUMBERJpyspark.sql.connect.proto.expressions_pb2.JavaUDF.OUTPUT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÄ
AGGREGATE_FIELD_NUMBERHpyspark.sql.connect.proto.expressions_pb2.JavaUDF.AGGREGATE_FIELD_NUMBER
builtins.int"builtins.intrh

class_name<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.class_name
builtins.str"builtins.strrh
	aggregate;pyspark.sql.connect.proto.expressions_pb2.JavaUDF.aggregate
builtins.bool"builtins.bool∞
CallFunction6pyspark.sql.connect.proto.expressions_pb2.CallFunction"builtins.object*È
	arguments@pyspark.sql.connect.proto.expressions_pb2.CallFunction.arguments"
Any*z
selfp
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction0:builtins.property`*¡
__init__?pyspark.sql.connect.proto.expressions_pb2.CallFunction.__init__"
None*z
selfp
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction*1
function_name
builtins.str"builtins.str *∫
	arguments®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ø

ClearFieldApyspark.sql.connect.proto.expressions_pb2.CallFunction.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.expressions_pb2.CallFunction.DESCRIPTOR
Anyrç
FUNCTION_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.CallFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intrÖ
ARGUMENTS_FIELD_NUMBERMpyspark.sql.connect.proto.expressions_pb2.CallFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intrs
function_nameDpyspark.sql.connect.proto.expressions_pb2.CallFunction.function_name
builtins.str"builtins.str®∫
Relation0pyspark.sql.connect.proto.relations_pb2.Relation"builtins.object*∫
common7pyspark.sql.connect.proto.relations_pb2.Relation.common"p
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¢
read5pyspark.sql.connect.proto.relations_pb2.Relation.read"\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*Æ
project8pyspark.sql.connect.proto.relations_pb2.Relation.project"b
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*™
filter7pyspark.sql.connect.proto.relations_pb2.Relation.filter"`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¢
join5pyspark.sql.connect.proto.relations_pb2.Relation.join"\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*∂
set_op7pyspark.sql.connect.proto.relations_pb2.Relation.set_op"l
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¢
sort5pyspark.sql.connect.proto.relations_pb2.Relation.sort"\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¶
limit6pyspark.sql.connect.proto.relations_pb2.Relation.limit"^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*∂
	aggregate:pyspark.sql.connect.proto.relations_pb2.Relation.aggregate"f
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*û
sql4pyspark.sql.connect.proto.relations_pb2.Relation.sql"Z
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*»
local_relation?pyspark.sql.connect.proto.relations_pb2.Relation.local_relation"n
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*™
sample7pyspark.sql.connect.proto.relations_pb2.Relation.sample"`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*™
offset7pyspark.sql.connect.proto.relations_pb2.Relation.offset"`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*æ
deduplicate<pyspark.sql.connect.proto.relations_pb2.Relation.deduplicate"j
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¶
range6pyspark.sql.connect.proto.relations_pb2.Relation.range"^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*»
subquery_alias?pyspark.sql.connect.proto.relations_pb2.Relation.subquery_alias"n
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*æ
repartition<pyspark.sql.connect.proto.relations_pb2.Relation.repartition"j
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*§
to_df6pyspark.sql.connect.proto.relations_pb2.Relation.to_df"\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*ﬁ
with_columns_renamedEpyspark.sql.connect.proto.relations_pb2.Relation.with_columns_renamed"x
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*º
show_string<pyspark.sql.connect.proto.relations_pb2.Relation.show_string"h
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¢
drop5pyspark.sql.connect.proto.relations_pb2.Relation.drop"\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¢
tail5pyspark.sql.connect.proto.relations_pb2.Relation.tail"\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¿
with_columns=pyspark.sql.connect.proto.relations_pb2.Relation.with_columns"j
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¢
hint5pyspark.sql.connect.proto.relations_pb2.Relation.hint"\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*Æ
unpivot8pyspark.sql.connect.proto.relations_pb2.Relation.unpivot"b
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¥
	to_schema:pyspark.sql.connect.proto.relations_pb2.Relation.to_schema"d
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*Û
repartition_by_expressionJpyspark.sql.connect.proto.relations_pb2.Relation.repartition_by_expression"Ç
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*»
map_partitions?pyspark.sql.connect.proto.relations_pb2.Relation.map_partitions"n
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*Ã
collect_metrics@pyspark.sql.connect.proto.relations_pb2.Relation.collect_metrics"p
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¶
parse6pyspark.sql.connect.proto.relations_pb2.Relation.parse"^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¥
	group_map:pyspark.sql.connect.proto.relations_pb2.Relation.group_map"d
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*æ
co_group_map=pyspark.sql.connect.proto.relations_pb2.Relation.co_group_map"h
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*»
with_watermark?pyspark.sql.connect.proto.relations_pb2.Relation.with_watermark"n
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*Û
apply_in_pandas_with_stateKpyspark.sql.connect.proto.relations_pb2.Relation.apply_in_pandas_with_state"Ä
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*º
html_string<pyspark.sql.connect.proto.relations_pb2.Relation.html_string"h
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*‚
cached_local_relationFpyspark.sql.connect.proto.relations_pb2.Relation.cached_local_relation"z
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*Ê
cached_remote_relationGpyspark.sql.connect.proto.relations_pb2.Relation.cached_remote_relation"|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*≠
)common_inline_user_defined_table_functionZpyspark.sql.connect.proto.relations_pb2.Relation.common_inline_user_defined_table_function"ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¨
fill_na8pyspark.sql.connect.proto.relations_pb2.Relation.fill_na"`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¨
drop_na8pyspark.sql.connect.proto.relations_pb2.Relation.drop_na"`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*≤
replace8pyspark.sql.connect.proto.relations_pb2.Relation.replace"f
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*∂
summary8pyspark.sql.connect.proto.relations_pb2.Relation.summary"j
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*∫
crosstab9pyspark.sql.connect.proto.relations_pb2.Relation.crosstab"l
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*∫
describe9pyspark.sql.connect.proto.relations_pb2.Relation.describe"l
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¶
cov4pyspark.sql.connect.proto.relations_pb2.Relation.cov"b
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*™
corr5pyspark.sql.connect.proto.relations_pb2.Relation.corr"d
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*‘
approx_quantile@pyspark.sql.connect.proto.relations_pb2.Relation.approx_quantile"x
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*¿

freq_items;pyspark.sql.connect.proto.relations_pb2.Relation.freq_items"n
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*º
	sample_by:pyspark.sql.connect.proto.relations_pb2.Relation.sample_by"l
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*™
catalog8pyspark.sql.connect.proto.relations_pb2.Relation.catalog"^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*◊
	extension:pyspark.sql.connect.proto.relations_pb2.Relation.extension"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*Æ
unknown8pyspark.sql.connect.proto.relations_pb2.Relation.unknown"b
/pyspark.sql.connect.proto.relations_pb2.Unknown"/pyspark.sql.connect.proto.relations_pb2.Unknown*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:builtins.property`*ƒS
__init__9pyspark.sql.connect.proto.relations_pb2.Relation.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*—
common¬
BUnion[pyspark.sql.connect.proto.relations_pb2.RelationCommon,None]p
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon
None *±
read§
8Union[pyspark.sql.connect.proto.relations_pb2.Read,None]\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read
None *Ω
project≠
;Union[pyspark.sql.connect.proto.relations_pb2.Project,None]b
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project
None *π
filter™
:Union[pyspark.sql.connect.proto.relations_pb2.Filter,None]`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter
None *±
join§
8Union[pyspark.sql.connect.proto.relations_pb2.Join,None]\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join
None *À
set_opº
@Union[pyspark.sql.connect.proto.relations_pb2.SetOperation,None]l
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation
None *±
sort§
8Union[pyspark.sql.connect.proto.relations_pb2.Sort,None]\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort
None *µ
limitß
9Union[pyspark.sql.connect.proto.relations_pb2.Limit,None]^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit
None *≈
	aggregate≥
=Union[pyspark.sql.connect.proto.relations_pb2.Aggregate,None]f
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate
None *≠
sql°
7Union[pyspark.sql.connect.proto.relations_pb2.SQL,None]Z
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL
None *÷
local_relationø
AUnion[pyspark.sql.connect.proto.relations_pb2.LocalRelation,None]n
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation
None *π
sample™
:Union[pyspark.sql.connect.proto.relations_pb2.Sample,None]`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample
None *π
offset™
:Union[pyspark.sql.connect.proto.relations_pb2.Offset,None]`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset
None *Õ
deduplicateπ
?Union[pyspark.sql.connect.proto.relations_pb2.Deduplicate,None]j
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate
None *µ
rangeß
9Union[pyspark.sql.connect.proto.relations_pb2.Range,None]^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range
None *÷
subquery_aliasø
AUnion[pyspark.sql.connect.proto.relations_pb2.SubqueryAlias,None]n
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias
None *Õ
repartitionπ
?Union[pyspark.sql.connect.proto.relations_pb2.Repartition,None]j
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition
None *≤
to_df§
8Union[pyspark.sql.connect.proto.relations_pb2.ToDF,None]\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF
None *Î
with_columns_renamedŒ
FUnion[pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed,None]x
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed
None * 
show_string∂
>Union[pyspark.sql.connect.proto.relations_pb2.ShowString,None]h
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString
None *±
drop§
8Union[pyspark.sql.connect.proto.relations_pb2.Drop,None]\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop
None *±
tail§
8Union[pyspark.sql.connect.proto.relations_pb2.Tail,None]\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail
None *Œ
with_columnsπ
?Union[pyspark.sql.connect.proto.relations_pb2.WithColumns,None]j
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns
None *±
hint§
8Union[pyspark.sql.connect.proto.relations_pb2.Hint,None]\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint
None *Ω
unpivot≠
;Union[pyspark.sql.connect.proto.relations_pb2.Unpivot,None]b
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot
None *¬
	to_schema∞
<Union[pyspark.sql.connect.proto.relations_pb2.ToSchema,None]d
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema
None *Ä
repartition_by_expressionﬁ
KUnion[pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression,None]Ç
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression
None *÷
map_partitionsø
AUnion[pyspark.sql.connect.proto.relations_pb2.MapPartitions,None]n
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions
None *⁄
collect_metrics¬
BUnion[pyspark.sql.connect.proto.relations_pb2.CollectMetrics,None]p
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics
None *µ
parseß
9Union[pyspark.sql.connect.proto.relations_pb2.Parse,None]^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse
None *¬
	group_map∞
<Union[pyspark.sql.connect.proto.relations_pb2.GroupMap,None]d
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap
None *À
co_group_map∂
>Union[pyspark.sql.connect.proto.relations_pb2.CoGroupMap,None]h
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap
None *÷
with_watermarkø
AUnion[pyspark.sql.connect.proto.relations_pb2.WithWatermark,None]n
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark
None *˛
apply_in_pandas_with_state€
JUnion[pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState,None]Ä
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState
None * 
html_string∂
>Union[pyspark.sql.connect.proto.relations_pb2.HtmlString,None]h
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString
None *Ô
cached_local_relation—
GUnion[pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation,None]z
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation
None *Û
cached_remote_relation‘
HUnion[pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation,None]|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation
None *∑
)common_inline_user_defined_table_functionÖ
XUnion[pyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction,None]ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction
None *∫
fill_na™
:Union[pyspark.sql.connect.proto.relations_pb2.NAFill,None]`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill
None *∫
drop_na™
:Union[pyspark.sql.connect.proto.relations_pb2.NADrop,None]`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop
None *√
replace≥
=Union[pyspark.sql.connect.proto.relations_pb2.NAReplace,None]f
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace
None *…
summaryπ
?Union[pyspark.sql.connect.proto.relations_pb2.StatSummary,None]j
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary
None *Õ
crosstabº
@Union[pyspark.sql.connect.proto.relations_pb2.StatCrosstab,None]l
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab
None *Õ
describeº
@Union[pyspark.sql.connect.proto.relations_pb2.StatDescribe,None]l
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe
None *π
cov≠
;Union[pyspark.sql.connect.proto.relations_pb2.StatCov,None]b
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov
None *Ω
corr∞
<Union[pyspark.sql.connect.proto.relations_pb2.StatCorr,None]d
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr
None *Ê
approx_quantileŒ
FUnion[pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile,None]x
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile
None *“

freq_itemsø
AUnion[pyspark.sql.connect.proto.relations_pb2.StatFreqItems,None]n
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems
None *Œ
	sample_byº
@Union[pyspark.sql.connect.proto.relations_pb2.StatSampleBy,None]l
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy
None *∑
catalogß
9Union[pyspark.sql.connect.proto.catalog_pb2.Catalog,None]^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog
None *7
	extension&
Union[Any,None]
Any
None *Ω
unknown≠
;Union[pyspark.sql.connect.proto.relations_pb2.Unknown,None]b
/pyspark.sql.connect.proto.relations_pb2.Unknown"/pyspark.sql.connect.proto.relations_pb2.Unknown
None *“F
HasField9pyspark.sql.connect.proto.relations_pb2.Relation.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*˙D

field_nameÈD
åUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¿F

ClearField;pyspark.sql.connect.proto.relations_pb2.Relation.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*˙D

field_nameÈD
åUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ÿ"

WhichOneof;pyspark.sql.connect.proto.relations_pb2.Relation.WhichOneof"◊
ÌUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.Relation.DESCRIPTOR
Anyry
COMMON_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.COMMON_FIELD_NUMBER
builtins.int"builtins.intru
READ_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.READ_FIELD_NUMBER
builtins.int"builtins.intr{
PROJECT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.PROJECT_FIELD_NUMBER
builtins.int"builtins.intry
FILTER_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.FILTER_FIELD_NUMBER
builtins.int"builtins.intru
JOIN_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.JOIN_FIELD_NUMBER
builtins.int"builtins.intry
SET_OP_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.SET_OP_FIELD_NUMBER
builtins.int"builtins.intru
SORT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.SORT_FIELD_NUMBER
builtins.int"builtins.intrw
LIMIT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.LIMIT_FIELD_NUMBER
builtins.int"builtins.intr
AGGREGATE_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.AGGREGATE_FIELD_NUMBER
builtins.int"builtins.intrs
SQL_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Relation.SQL_FIELD_NUMBER
builtins.int"builtins.intrâ
LOCAL_RELATION_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.LOCAL_RELATION_FIELD_NUMBER
builtins.int"builtins.intry
SAMPLE_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.SAMPLE_FIELD_NUMBER
builtins.int"builtins.intry
OFFSET_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.OFFSET_FIELD_NUMBER
builtins.int"builtins.intrÉ
DEDUPLICATE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.DEDUPLICATE_FIELD_NUMBER
builtins.int"builtins.intrw
RANGE_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.RANGE_FIELD_NUMBER
builtins.int"builtins.intrâ
SUBQUERY_ALIAS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.SUBQUERY_ALIAS_FIELD_NUMBER
builtins.int"builtins.intrÉ
REPARTITION_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.REPARTITION_FIELD_NUMBER
builtins.int"builtins.intrw
TO_DF_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.TO_DF_FIELD_NUMBER
builtins.int"builtins.intrï
!WITH_COLUMNS_RENAMED_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.Relation.WITH_COLUMNS_RENAMED_FIELD_NUMBER
builtins.int"builtins.intrÉ
SHOW_STRING_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.SHOW_STRING_FIELD_NUMBER
builtins.int"builtins.intru
DROP_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.DROP_FIELD_NUMBER
builtins.int"builtins.intru
TAIL_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.TAIL_FIELD_NUMBER
builtins.int"builtins.intrÖ
WITH_COLUMNS_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.Relation.WITH_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intru
HINT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.HINT_FIELD_NUMBER
builtins.int"builtins.intr{
UNPIVOT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.UNPIVOT_FIELD_NUMBER
builtins.int"builtins.intr
TO_SCHEMA_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.TO_SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrü
&REPARTITION_BY_EXPRESSION_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.Relation.REPARTITION_BY_EXPRESSION_FIELD_NUMBER
builtins.int"builtins.intrâ
MAP_PARTITIONS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.MAP_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intrã
COLLECT_METRICS_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.Relation.COLLECT_METRICS_FIELD_NUMBER
builtins.int"builtins.intrw
PARSE_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.PARSE_FIELD_NUMBER
builtins.int"builtins.intr
GROUP_MAP_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.GROUP_MAP_FIELD_NUMBER
builtins.int"builtins.intrÖ
CO_GROUP_MAP_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.Relation.CO_GROUP_MAP_FIELD_NUMBER
builtins.int"builtins.intrâ
WITH_WATERMARK_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.WITH_WATERMARK_FIELD_NUMBER
builtins.int"builtins.intr°
'APPLY_IN_PANDAS_WITH_STATE_FIELD_NUMBERXpyspark.sql.connect.proto.relations_pb2.Relation.APPLY_IN_PANDAS_WITH_STATE_FIELD_NUMBER
builtins.int"builtins.intrÉ
HTML_STRING_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.HTML_STRING_FIELD_NUMBER
builtins.int"builtins.intró
"CACHED_LOCAL_RELATION_FIELD_NUMBERSpyspark.sql.connect.proto.relations_pb2.Relation.CACHED_LOCAL_RELATION_FIELD_NUMBER
builtins.int"builtins.intrô
#CACHED_REMOTE_RELATION_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.Relation.CACHED_REMOTE_RELATION_FIELD_NUMBER
builtins.int"builtins.intrø
6COMMON_INLINE_USER_DEFINED_TABLE_FUNCTION_FIELD_NUMBERgpyspark.sql.connect.proto.relations_pb2.Relation.COMMON_INLINE_USER_DEFINED_TABLE_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr{
FILL_NA_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.FILL_NA_FIELD_NUMBER
builtins.int"builtins.intr{
DROP_NA_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.DROP_NA_FIELD_NUMBER
builtins.int"builtins.intr{
REPLACE_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.REPLACE_FIELD_NUMBER
builtins.int"builtins.intr{
SUMMARY_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.SUMMARY_FIELD_NUMBER
builtins.int"builtins.intr}
CROSSTAB_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Relation.CROSSTAB_FIELD_NUMBER
builtins.int"builtins.intr}
DESCRIBE_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Relation.DESCRIBE_FIELD_NUMBER
builtins.int"builtins.intrs
COV_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Relation.COV_FIELD_NUMBER
builtins.int"builtins.intru
CORR_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.CORR_FIELD_NUMBER
builtins.int"builtins.intrã
APPROX_QUANTILE_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.Relation.APPROX_QUANTILE_FIELD_NUMBER
builtins.int"builtins.intrÅ
FREQ_ITEMS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Relation.FREQ_ITEMS_FIELD_NUMBER
builtins.int"builtins.intr
SAMPLE_BY_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.SAMPLE_BY_FIELD_NUMBER
builtins.int"builtins.intr{
CATALOG_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.CATALOG_FIELD_NUMBER
builtins.int"builtins.intr
EXTENSION_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intr{
UNKNOWN_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.UNKNOWN_FIELD_NUMBER
builtins.int"builtins.int›
Unknown/pyspark.sql.connect.proto.relations_pb2.Unknown"builtins.object*º
__init__8pyspark.sql.connect.proto.relations_pb2.Unknown.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unknown"/pyspark.sql.connect.proto.relations_pb2.UnknownrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.Unknown.DESCRIPTOR
Any±
RelationCommon6pyspark.sql.connect.proto.relations_pb2.RelationCommon"builtins.object*◊
__init__?pyspark.sql.connect.proto.relations_pb2.RelationCommon.__init__"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*/
source_info
builtins.str"builtins.str *S
plan_idD
Union[builtins.int,None]
builtins.int"builtins.int
None *—
HasField?pyspark.sql.connect.proto.relations_pb2.RelationCommon.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ê

ClearFieldApyspark.sql.connect.proto.relations_pb2.RelationCommon.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

WhichOneofApyspark.sql.connect.proto.relations_pb2.RelationCommon.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.relations_pb2.RelationCommon.DESCRIPTOR
Anyrâ
SOURCE_INFO_FIELD_NUMBEROpyspark.sql.connect.proto.relations_pb2.RelationCommon.SOURCE_INFO_FIELD_NUMBER
builtins.int"builtins.intrÅ
PLAN_ID_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.RelationCommon.PLAN_ID_FIELD_NUMBER
builtins.int"builtins.intro
source_infoBpyspark.sql.connect.proto.relations_pb2.RelationCommon.source_info
builtins.str"builtins.strrg
plan_id>pyspark.sql.connect.proto.relations_pb2.RelationCommon.plan_id
builtins.int"builtins.intã'
SQL+pyspark.sql.connect.proto.relations_pb2.SQL"builtins.object*æ
args0pyspark.sql.connect.proto.relations_pb2.SQL.args"
Any*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL0:builtins.property`*∆
pos_args4pyspark.sql.connect.proto.relations_pb2.SQL.pos_args"
Any*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL0:builtins.property`*ƒ
__init__4pyspark.sql.connect.proto.relations_pb2.SQL.__init__"
None*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL*)
query
builtins.str"builtins.str *ä
args˝
eUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]á
Ytyping.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]
builtins.str"builtins.str|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Mapping
None *Ÿ
pos_args»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *≈

ClearField6pyspark.sql.connect.proto.relations_pb2.SQL.ClearField"
None*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrM

DESCRIPTOR6pyspark.sql.connect.proto.relations_pb2.SQL.DESCRIPTOR
Anyrr
QUERY_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.SQL.QUERY_FIELD_NUMBER
builtins.int"builtins.intrp
ARGS_FIELD_NUMBER=pyspark.sql.connect.proto.relations_pb2.SQL.ARGS_FIELD_NUMBER
builtins.int"builtins.intrx
POS_ARGS_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.SQL.POS_ARGS_FIELD_NUMBER
builtins.int"builtins.intrX
query1pyspark.sql.connect.proto.relations_pb2.SQL.query
builtins.str"builtins.strz£
	ArgsEntry5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry"builtins.object*”
value;pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.value"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry"5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry0:builtins.property`*‹
__init__>pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry"5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry*'
key
builtins.str"builtins.str *‚
value‘
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *®
HasField>pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry"5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*º

ClearField@pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry"5pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.DESCRIPTOR
Anyrx
KEY_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intr|
VALUE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intr^
key9pyspark.sql.connect.proto.relations_pb2.SQL.ArgsEntry.key
builtins.str"builtins.str§y
Read,pyspark.sql.connect.proto.relations_pb2.Read"builtins.object*∫
named_table8pyspark.sql.connect.proto.relations_pb2.Read.named_table"r
7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read0:builtins.property`*∫
data_source8pyspark.sql.connect.proto.relations_pb2.Read.data_source"r
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read0:builtins.property`*ü
__init__5pyspark.sql.connect.proto.relations_pb2.Read.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*Ÿ
named_table≈
CUnion[pyspark.sql.connect.proto.relations_pb2.Read.NamedTable,None]r
7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable
None *Ÿ
data_source≈
CUnion[pyspark.sql.connect.proto.relations_pb2.Read.DataSource,None]r
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource
None *2
is_streaming
builtins.bool"builtins.bool *⁄
HasField5pyspark.sql.connect.proto.relations_pb2.Read.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

ClearField7pyspark.sql.connect.proto.relations_pb2.Read.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

WhichOneof7pyspark.sql.connect.proto.relations_pb2.Read.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Read.DESCRIPTOR
Anyr
NAMED_TABLE_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Read.NAMED_TABLE_FIELD_NUMBER
builtins.int"builtins.intr
DATA_SOURCE_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Read.DATA_SOURCE_FIELD_NUMBER
builtins.int"builtins.intrÅ
IS_STREAMING_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Read.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intri
is_streaming9pyspark.sql.connect.proto.relations_pb2.Read.is_streaming
builtins.bool"builtins.boolzÒ

NamedTable7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"builtins.object*Ë
options?pyspark.sql.connect.proto.relations_pb2.Read.NamedTable.options"
Any*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable0:builtins.property`*‹
__init__@pyspark.sql.connect.proto.relations_pb2.Read.NamedTable.__init__"
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable*7
unparsed_identifier
builtins.str"builtins.str *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *¬

ClearFieldBpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.DESCRIPTOR
Anyrö
 UNPARSED_IDENTIFIER_FIELD_NUMBERXpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.UNPARSED_IDENTIFIER_FIELD_NUMBER
builtins.int"builtins.intrÇ
OPTIONS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrÄ
unparsed_identifierKpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.unparsed_identifier
builtins.str"builtins.strzâ
OptionsEntryDpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry"builtins.object*—
__init__Mpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry"Dpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Î

ClearFieldOpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry"Dpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry.DESCRIPTOR
Anyrá
KEY_FIELD_NUMBERUpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrã
VALUE_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrm
keyHpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry.key
builtins.str"builtins.strrq
valueJpyspark.sql.connect.proto.relations_pb2.Read.NamedTable.OptionsEntry.value
builtins.str"builtins.strzé=

DataSource7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"builtins.object*Ë
options?pyspark.sql.connect.proto.relations_pb2.Read.DataSource.options"
Any*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource0:builtins.property`*‰
paths=pyspark.sql.connect.proto.relations_pb2.Read.DataSource.paths"
Any*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource0:builtins.property`*Ó

predicatesBpyspark.sql.connect.proto.relations_pb2.Read.DataSource.predicates"
Any*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource0:builtins.property`*Ä
__init__@pyspark.sql.connect.proto.relations_pb2.Read.DataSource.__init__"
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource*R
formatD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
schemaD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *ï
pathsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ö

predicatesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *°
HasField@pyspark.sql.connect.proto.relations_pb2.Read.DataSource.HasField"
builtins.bool"builtins.bool*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Å

ClearFieldBpyspark.sql.connect.proto.relations_pb2.Read.DataSource.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2˙

WhichOneofBpyspark.sql.connect.proto.relations_pb2.Read.DataSource.WhichOneofí

WhichOneofBpyspark.sql.connect.proto.relations_pb2.Read.DataSource.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXí

WhichOneofBpyspark.sql.connect.proto.relations_pb2.Read.DataSource.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrY

DESCRIPTORBpyspark.sql.connect.proto.relations_pb2.Read.DataSource.DESCRIPTOR
AnyrÄ
FORMAT_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.Read.DataSource.FORMAT_FIELD_NUMBER
builtins.int"builtins.intrÄ
SCHEMA_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.Read.DataSource.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÇ
OPTIONS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intr~
PATHS_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.Read.DataSource.PATHS_FIELD_NUMBER
builtins.int"builtins.intrà
PREDICATES_FIELD_NUMBEROpyspark.sql.connect.proto.relations_pb2.Read.DataSource.PREDICATES_FIELD_NUMBER
builtins.int"builtins.intrf
format>pyspark.sql.connect.proto.relations_pb2.Read.DataSource.format
builtins.str"builtins.strrf
schema>pyspark.sql.connect.proto.relations_pb2.Read.DataSource.schema
builtins.str"builtins.strzâ
OptionsEntryDpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry"builtins.object*—
__init__Mpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry"Dpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Î

ClearFieldOpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry.ClearField"
None*ó
selfå
Dpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry"Dpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrf

DESCRIPTOROpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry.DESCRIPTOR
Anyrá
KEY_FIELD_NUMBERUpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrã
VALUE_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrm
keyHpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry.key
builtins.str"builtins.strrq
valueJpyspark.sql.connect.proto.relations_pb2.Read.DataSource.OptionsEntry.value
builtins.str"builtins.strß
Project/pyspark.sql.connect.proto.relations_pb2.Project"builtins.object*©
input5pyspark.sql.connect.proto.relations_pb2.Project.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project0:builtins.property`*ÿ
expressions;pyspark.sql.connect.proto.relations_pb2.Project.expressions"
Any*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project0:builtins.property`*º
__init__8pyspark.sql.connect.proto.relations_pb2.Project.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *º
expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ñ
HasField8pyspark.sql.connect.proto.relations_pb2.Project.HasField"
builtins.bool"builtins.bool*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*™

ClearField:pyspark.sql.connect.proto.relations_pb2.Project.ClearField"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.Project.DESCRIPTOR
Anyrv
INPUT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Project.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÇ
EXPRESSIONS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Project.EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intß
Filter.pyspark.sql.connect.proto.relations_pb2.Filter"builtins.object*¶
input4pyspark.sql.connect.proto.relations_pb2.Filter.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter0:builtins.property`*∂
	condition8pyspark.sql.connect.proto.relations_pb2.Filter.condition"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter0:builtins.property`*À
__init__7pyspark.sql.connect.proto.relations_pb2.Filter.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *Œ
	conditionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *π
HasField7pyspark.sql.connect.proto.relations_pb2.Filter.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ß

ClearField9pyspark.sql.connect.proto.relations_pb2.Filter.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.Filter.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Filter.INPUT_FIELD_NUMBER
builtins.int"builtins.intr}
CONDITION_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Filter.CONDITION_FIELD_NUMBER
builtins.int"builtins.int f
Join,pyspark.sql.connect.proto.relations_pb2.Join"builtins.object*û
left1pyspark.sql.connect.proto.relations_pb2.Join.left"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:builtins.property`*†
right2pyspark.sql.connect.proto.relations_pb2.Join.right"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:builtins.property`*∫
join_condition;pyspark.sql.connect.proto.relations_pb2.Join.join_condition"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:builtins.property`*”
using_columns:pyspark.sql.connect.proto.relations_pb2.Join.using_columns"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:builtins.property`*ƒ
join_data_type;pyspark.sql.connect.proto.relations_pb2.Join.join_data_type"v
9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType"9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:builtins.property`*®

__init__5pyspark.sql.connect.proto.relations_pb2.Join.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*Ω
left∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *æ
right∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *”
join_conditionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *ñ
	join_typeÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType *ù
using_columnsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *‚
join_data_typeÀ
EUnion[pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType,None]v
9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType"9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType
None *¶
HasField5pyspark.sql.connect.proto.relations_pb2.Join.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‡


ClearField7pyspark.sql.connect.proto.relations_pb2.Join.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‹

WhichOneof7pyspark.sql.connect.proto.relations_pb2.Join.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Join.DESCRIPTOR
Anyr‚
JOIN_TYPE_UNSPECIFIEDBpyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_UNSPECIFIEDÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper÷
JOIN_TYPE_INNER<pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_INNERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper‡
JOIN_TYPE_FULL_OUTERApyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_FULL_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper‡
JOIN_TYPE_LEFT_OUTERApyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_LEFT_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper‚
JOIN_TYPE_RIGHT_OUTERBpyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_RIGHT_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperﬁ
JOIN_TYPE_LEFT_ANTI@pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_LEFT_ANTIÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperﬁ
JOIN_TYPE_LEFT_SEMI@pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_LEFT_SEMIÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper÷
JOIN_TYPE_CROSS<pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_CROSSÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperq
LEFT_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.Join.LEFT_FIELD_NUMBER
builtins.int"builtins.intrs
RIGHT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Join.RIGHT_FIELD_NUMBER
builtins.int"builtins.intrÖ
JOIN_CONDITION_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Join.JOIN_CONDITION_FIELD_NUMBER
builtins.int"builtins.intr{
JOIN_TYPE_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÉ
USING_COLUMNS_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Join.USING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÖ
JOIN_DATA_TYPE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Join.JOIN_DATA_TYPE_FIELD_NUMBER
builtins.int"builtins.intr 
	join_type6pyspark.sql.connect.proto.relations_pb2.Join.join_typeÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTypezŒ
	_JoinType6pyspark.sql.connect.proto.relations_pb2.Join._JoinType"builtins.objectz˜
	ValueType@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"builtins.int*ô
__init__Ipyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType*&
item
builtins.int"builtins.intz•
_JoinTypeEnumTypeWrapperEpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper"builtins.typerg

DESCRIPTORPpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.DESCRIPTOR
Anyr˚
JOIN_TYPE_UNSPECIFIED[pyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_UNSPECIFIEDÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperÔ
JOIN_TYPE_INNERUpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_INNERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper˘
JOIN_TYPE_FULL_OUTERZpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_FULL_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper˘
JOIN_TYPE_LEFT_OUTERZpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_LEFT_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper˚
JOIN_TYPE_RIGHT_OUTER[pyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_RIGHT_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper˜
JOIN_TYPE_LEFT_ANTIYpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_LEFT_ANTIÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper˜
JOIN_TYPE_LEFT_SEMIYpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_LEFT_SEMIÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperÔ
JOIN_TYPE_CROSSUpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapper.JOIN_TYPE_CROSSÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTypez¬
JoinType5pyspark.sql.connect.proto.relations_pb2.Join.JoinType"6pyspark.sql.connect.proto.relations_pb2.Join._JoinType@bEpyspark.sql.connect.proto.relations_pb2.Join._JoinTypeEnumTypeWrapperzÙ
JoinDataType9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType"builtins.object*»
__init__Bpyspark.sql.connect.proto.relations_pb2.Join.JoinDataType.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType"9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType*4
is_left_struct
builtins.bool"builtins.bool *5
is_right_struct
builtins.bool"builtins.bool *…

ClearFieldDpyspark.sql.connect.proto.relations_pb2.Join.JoinDataType.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType"9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr[

DESCRIPTORDpyspark.sql.connect.proto.relations_pb2.Join.JoinDataType.DESCRIPTOR
Anyrí
IS_LEFT_STRUCT_FIELD_NUMBERUpyspark.sql.connect.proto.relations_pb2.Join.JoinDataType.IS_LEFT_STRUCT_FIELD_NUMBER
builtins.int"builtins.intrî
IS_RIGHT_STRUCT_FIELD_NUMBERVpyspark.sql.connect.proto.relations_pb2.Join.JoinDataType.IS_RIGHT_STRUCT_FIELD_NUMBER
builtins.int"builtins.intrz
is_left_structHpyspark.sql.connect.proto.relations_pb2.Join.JoinDataType.is_left_struct
builtins.bool"builtins.boolr|
is_right_structIpyspark.sql.connect.proto.relations_pb2.Join.JoinDataType.is_right_struct
builtins.bool"builtins.bool⁄X
SetOperation4pyspark.sql.connect.proto.relations_pb2.SetOperation"builtins.object*¬

left_input?pyspark.sql.connect.proto.relations_pb2.SetOperation.left_input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation0:builtins.property`*ƒ
right_input@pyspark.sql.connect.proto.relations_pb2.SetOperation.right_input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation0:builtins.property`*ö
__init__=pyspark.sql.connect.proto.relations_pb2.SetOperation.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*√

left_input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ƒ
right_input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *™
set_op_typeñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType *U
is_allG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *V
by_nameG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *d
allow_missing_columnsG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *∞
HasField=pyspark.sql.connect.proto.relations_pb2.SetOperation.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ƒ

ClearField?pyspark.sql.connect.proto.relations_pb2.SetOperation.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ò

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneofâ

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXâ

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXâ

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.SetOperation.DESCRIPTOR
AnyrÄ
SET_OP_TYPE_UNSPECIFIEDLpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_UNSPECIFIEDñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyper¸
SET_OP_TYPE_INTERSECTJpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_INTERSECTñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperÙ
SET_OP_TYPE_UNIONFpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_UNIONñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperˆ
SET_OP_TYPE_EXCEPTGpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_EXCEPTñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperÖ
LEFT_INPUT_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.SetOperation.LEFT_INPUT_FIELD_NUMBER
builtins.int"builtins.intrá
RIGHT_INPUT_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.SetOperation.RIGHT_INPUT_FIELD_NUMBER
builtins.int"builtins.intrá
SET_OP_TYPE_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_FIELD_NUMBER
builtins.int"builtins.intr}
IS_ALL_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.SetOperation.IS_ALL_FIELD_NUMBER
builtins.int"builtins.intr
BY_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.SetOperation.BY_NAME_FIELD_NUMBER
builtins.int"builtins.intrõ
"ALLOW_MISSING_COLUMNS_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.SetOperation.ALLOW_MISSING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrË
set_op_type@pyspark.sql.connect.proto.relations_pb2.SetOperation.set_op_typeñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTypere
is_all;pyspark.sql.connect.proto.relations_pb2.SetOperation.is_all
builtins.bool"builtins.boolrg
by_name<pyspark.sql.connect.proto.relations_pb2.SetOperation.by_name
builtins.bool"builtins.boolrÉ
allow_missing_columnsJpyspark.sql.connect.proto.relations_pb2.SetOperation.allow_missing_columns
builtins.bool"builtins.boolz¸

_SetOpType?pyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType"builtins.objectzõ
	ValueTypeIpyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"builtins.int*¥
__init__Rpyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType*&
item
builtins.int"builtins.intz∆

_SetOpTypeEnumTypeWrapperNpyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpTypeEnumTypeWrapper"builtins.typerp

DESCRIPTORYpyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpTypeEnumTypeWrapper.DESCRIPTOR
Anyrö
SET_OP_TYPE_UNSPECIFIEDfpyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpTypeEnumTypeWrapper.SET_OP_TYPE_UNSPECIFIEDñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperñ
SET_OP_TYPE_INTERSECTdpyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpTypeEnumTypeWrapper.SET_OP_TYPE_INTERSECTñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperé
SET_OP_TYPE_UNION`pyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpTypeEnumTypeWrapper.SET_OP_TYPE_UNIONñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperê
SET_OP_TYPE_EXCEPTapyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpTypeEnumTypeWrapper.SET_OP_TYPE_EXCEPTñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTypezﬁ
	SetOpType>pyspark.sql.connect.proto.relations_pb2.SetOperation.SetOpType"?pyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType@bNpyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpTypeEnumTypeWrapperÂ
Limit-pyspark.sql.connect.proto.relations_pb2.Limit"builtins.object*£
input3pyspark.sql.connect.proto.relations_pb2.Limit.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit0:builtins.property`*¢
__init__6pyspark.sql.connect.proto.relations_pb2.Limit.__init__"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *)
limit
builtins.int"builtins.int *ê
HasField6pyspark.sql.connect.proto.relations_pb2.Limit.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearField8pyspark.sql.connect.proto.relations_pb2.Limit.ClearField"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrO

DESCRIPTOR8pyspark.sql.connect.proto.relations_pb2.Limit.DESCRIPTOR
Anyrt
INPUT_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Limit.INPUT_FIELD_NUMBER
builtins.int"builtins.intrt
LIMIT_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Limit.LIMIT_FIELD_NUMBER
builtins.int"builtins.intrZ
limit3pyspark.sql.connect.proto.relations_pb2.Limit.limit
builtins.int"builtins.int¸
Offset.pyspark.sql.connect.proto.relations_pb2.Offset"builtins.object*¶
input4pyspark.sql.connect.proto.relations_pb2.Offset.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset0:builtins.property`*¶
__init__7pyspark.sql.connect.proto.relations_pb2.Offset.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None **
offset
builtins.int"builtins.int *ì
HasField7pyspark.sql.connect.proto.relations_pb2.Offset.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ß

ClearField9pyspark.sql.connect.proto.relations_pb2.Offset.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.Offset.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Offset.INPUT_FIELD_NUMBER
builtins.int"builtins.intrw
OFFSET_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Offset.OFFSET_FIELD_NUMBER
builtins.int"builtins.intr]
offset5pyspark.sql.connect.proto.relations_pb2.Offset.offset
builtins.int"builtins.int”
Tail,pyspark.sql.connect.proto.relations_pb2.Tail"builtins.object*†
input2pyspark.sql.connect.proto.relations_pb2.Tail.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail0:builtins.property`*ü
__init__5pyspark.sql.connect.proto.relations_pb2.Tail.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *)
limit
builtins.int"builtins.int *ç
HasField5pyspark.sql.connect.proto.relations_pb2.Tail.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*°

ClearField7pyspark.sql.connect.proto.relations_pb2.Tail.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Tail.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Tail.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
LIMIT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Tail.LIMIT_FIELD_NUMBER
builtins.int"builtins.intrY
limit2pyspark.sql.connect.proto.relations_pb2.Tail.limit
builtins.int"builtins.intÂY
	Aggregate1pyspark.sql.connect.proto.relations_pb2.Aggregate"builtins.object*Ø
input7pyspark.sql.connect.proto.relations_pb2.Aggregate.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:builtins.property`*
grouping_expressionsFpyspark.sql.connect.proto.relations_pb2.Aggregate.grouping_expressions"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:builtins.property`*Ú
aggregate_expressionsGpyspark.sql.connect.proto.relations_pb2.Aggregate.aggregate_expressions"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:builtins.property`*Ω
pivot7pyspark.sql.connect.proto.relations_pb2.Aggregate.pivot"r
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:builtins.property`*ê
__init__:pyspark.sql.connect.proto.relations_pb2.Aggregate.__init__"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *£

group_typeê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType *≈
grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *∆
aggregate_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *”
pivot≈
CUnion[pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot,None]r
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot
None *¬
HasField:pyspark.sql.connect.proto.relations_pb2.Aggregate.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*£

ClearField<pyspark.sql.connect.proto.relations_pb2.Aggregate.ClearField"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.relations_pb2.Aggregate.DESCRIPTOR
Anyrı
GROUP_TYPE_UNSPECIFIEDHpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_UNSPECIFIEDê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÌ
GROUP_TYPE_GROUPBYDpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_GROUPBYê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÎ
GROUP_TYPE_ROLLUPCpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_ROLLUPê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÁ
GROUP_TYPE_CUBEApyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_CUBEê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÈ
GROUP_TYPE_PIVOTBpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_PIVOTê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperx
INPUT_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Aggregate.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÇ
GROUP_TYPE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_FIELD_NUMBER
builtins.int"builtins.intrñ
!GROUPING_EXPRESSIONS_FIELD_NUMBERSpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrò
"AGGREGATE_EXPRESSIONS_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.Aggregate.AGGREGATE_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrx
PIVOT_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Aggregate.PIVOT_FIELD_NUMBER
builtins.int"builtins.intr›

group_type<pyspark.sql.connect.proto.relations_pb2.Aggregate.group_typeê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTypezÌ

_GroupType<pyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType"builtins.objectzè
	ValueTypeFpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"builtins.int*´
__init__Opyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType*&
item
builtins.int"builtins.intzî
_GroupTypeEnumTypeWrapperKpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapper"builtins.typerm

DESCRIPTORVpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapper.DESCRIPTOR
Anyrè
GROUP_TYPE_UNSPECIFIEDbpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapper.GROUP_TYPE_UNSPECIFIEDê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperá
GROUP_TYPE_GROUPBY^pyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapper.GROUP_TYPE_GROUPBYê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÖ
GROUP_TYPE_ROLLUP]pyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapper.GROUP_TYPE_ROLLUPê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÅ
GROUP_TYPE_CUBE[pyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapper.GROUP_TYPE_CUBEê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÉ
GROUP_TYPE_PIVOT\pyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapper.GROUP_TYPE_PIVOTê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTypez’
	GroupType;pyspark.sql.connect.proto.relations_pb2.Aggregate.GroupType"<pyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType@bKpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupTypeEnumTypeWrapperzŒ
Pivot7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"builtins.object*≈
col;pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.col"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot0:builtins.property`*Ê
values>pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.values"
Any*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot0:builtins.property`*˘
__init__@pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.__init__"
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot*»
colº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *◊
values»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *Æ
HasField@pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.HasField"
builtins.bool"builtins.bool*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¬

ClearFieldBpyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.DESCRIPTOR
Anyrz
COL_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.COL_FIELD_NUMBER
builtins.int"builtins.intrÄ
VALUES_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot.VALUES_FIELD_NUMBER
builtins.int"builtins.int™
Sort,pyspark.sql.connect.proto.relations_pb2.Sort"builtins.object*†
input2pyspark.sql.connect.proto.relations_pb2.Sort.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort0:builtins.property`*√
order2pyspark.sql.connect.proto.relations_pb2.Sort.order"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort0:builtins.property`*∞
__init__5pyspark.sql.connect.proto.relations_pb2.Sort.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ﬂ
order—
[Union[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder],None]Â
Otyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder]Ä
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder"typing.Iterable
None *X
	is_globalG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *⁄
HasField5pyspark.sql.connect.proto.relations_pb2.Sort.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

ClearField7pyspark.sql.connect.proto.relations_pb2.Sort.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‹

WhichOneof7pyspark.sql.connect.proto.relations_pb2.Sort.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Sort.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Sort.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
ORDER_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Sort.ORDER_FIELD_NUMBER
builtins.int"builtins.intr{
IS_GLOBAL_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Sort.IS_GLOBAL_FIELD_NUMBER
builtins.int"builtins.intrc
	is_global6pyspark.sql.connect.proto.relations_pb2.Sort.is_global
builtins.bool"builtins.boolÙ
Drop,pyspark.sql.connect.proto.relations_pb2.Drop"builtins.object*†
input2pyspark.sql.connect.proto.relations_pb2.Drop.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop0:builtins.property`*«
columns4pyspark.sql.connect.proto.relations_pb2.Drop.columns"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop0:builtins.property`*—
column_names9pyspark.sql.connect.proto.relations_pb2.Drop.column_names"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop0:builtins.property`*Œ
__init__5pyspark.sql.connect.proto.relations_pb2.Drop.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *∏
columns®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ú
column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ç
HasField5pyspark.sql.connect.proto.relations_pb2.Drop.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*»

ClearField7pyspark.sql.connect.proto.relations_pb2.Drop.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Drop.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Drop.INPUT_FIELD_NUMBER
builtins.int"builtins.intrw
COLUMNS_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Drop.COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÅ
COLUMN_NAMES_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Drop.COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intŸ,
Deduplicate3pyspark.sql.connect.proto.relations_pb2.Deduplicate"builtins.object*µ
input9pyspark.sql.connect.proto.relations_pb2.Deduplicate.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate0:builtins.property`*Ê
column_names@pyspark.sql.connect.proto.relations_pb2.Deduplicate.column_names"
Any*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate0:builtins.property`*Ì
__init__<pyspark.sql.connect.proto.relations_pb2.Deduplicate.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ú
column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *b
all_columns_as_keysG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *_
within_watermarkG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *ª
HasField<pyspark.sql.connect.proto.relations_pb2.Deduplicate.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*œ	

ClearField>pyspark.sql.connect.proto.relations_pb2.Deduplicate.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ﬁ

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Deduplicate.WhichOneofÜ

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Deduplicate.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÜ

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Deduplicate.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.Deduplicate.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Deduplicate.INPUT_FIELD_NUMBER
builtins.int"builtins.intrà
COLUMN_NAMES_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.Deduplicate.COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intrñ
 ALL_COLUMNS_AS_KEYS_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.Deduplicate.ALL_COLUMNS_AS_KEYS_FIELD_NUMBER
builtins.int"builtins.intrê
WITHIN_WATERMARK_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.Deduplicate.WITHIN_WATERMARK_FIELD_NUMBER
builtins.int"builtins.intr~
all_columns_as_keysGpyspark.sql.connect.proto.relations_pb2.Deduplicate.all_columns_as_keys
builtins.bool"builtins.boolrx
within_watermarkDpyspark.sql.connect.proto.relations_pb2.Deduplicate.within_watermark
builtins.bool"builtins.boolé
LocalRelation5pyspark.sql.connect.proto.relations_pb2.LocalRelation"builtins.object*˙
__init__>pyspark.sql.connect.proto.relations_pb2.LocalRelation.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*V
dataJ
Union[builtins.bytes,None] 
builtins.bytes"builtins.bytes
None *R
schemaD
Union[builtins.str,None]
builtins.str"builtins.str
None *õ
HasField>pyspark.sql.connect.proto.relations_pb2.LocalRelation.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*â

ClearField@pyspark.sql.connect.proto.relations_pb2.LocalRelation.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ï

WhichOneof@pyspark.sql.connect.proto.relations_pb2.LocalRelation.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.relations_pb2.LocalRelation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXå

WhichOneof@pyspark.sql.connect.proto.relations_pb2.LocalRelation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.LocalRelation.DESCRIPTOR
Anyrz
DATA_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.LocalRelation.DATA_FIELD_NUMBER
builtins.int"builtins.intr~
SCHEMA_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.LocalRelation.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrd
data:pyspark.sql.connect.proto.relations_pb2.LocalRelation.data 
builtins.bytes"builtins.bytesrd
schema<pyspark.sql.connect.proto.relations_pb2.LocalRelation.schema
builtins.str"builtins.strÁ
CachedLocalRelation;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation"builtins.object*ã
__init__Dpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.__init__"
None*Ñ
selfz
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation*(
hash
builtins.str"builtins.str *©

ClearFieldFpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.ClearField"
None*Ñ
selfz
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.DESCRIPTOR
AnyrÄ
HASH_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.HASH_FIELD_NUMBER
builtins.int"builtins.intrf
hash@pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.hash
builtins.str"builtins.strï	
CachedRemoteRelation<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"builtins.object*ï
__init__Epyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation*/
relation_id
builtins.str"builtins.str *¨

ClearFieldGpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.DESCRIPTOR
Anyrè
RELATION_ID_FIELD_NUMBERUpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.RELATION_ID_FIELD_NUMBER
builtins.int"builtins.intru
relation_idHpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.relation_id
builtins.str"builtins.str–0
Sample.pyspark.sql.connect.proto.relations_pb2.Sample"builtins.object*¶
input4pyspark.sql.connect.proto.relations_pb2.Sample.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample0:builtins.property`*“
__init__7pyspark.sql.connect.proto.relations_pb2.Sample.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *3
lower_bound 
builtins.float"builtins.float *3
upper_bound 
builtins.float"builtins.float *_
with_replacementG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *9
deterministic_order
builtins.bool"builtins.bool *¨
HasField7pyspark.sql.connect.proto.relations_pb2.Sample.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*å

ClearField9pyspark.sql.connect.proto.relations_pb2.Sample.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ª

WhichOneof9pyspark.sql.connect.proto.relations_pb2.Sample.WhichOneof˜

WhichOneof9pyspark.sql.connect.proto.relations_pb2.Sample.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˜

WhichOneof9pyspark.sql.connect.proto.relations_pb2.Sample.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.Sample.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Sample.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÅ
LOWER_BOUND_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Sample.LOWER_BOUND_FIELD_NUMBER
builtins.int"builtins.intrÅ
UPPER_BOUND_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Sample.UPPER_BOUND_FIELD_NUMBER
builtins.int"builtins.intrã
WITH_REPLACEMENT_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Sample.WITH_REPLACEMENT_FIELD_NUMBER
builtins.int"builtins.intrs
SEED_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Sample.SEED_FIELD_NUMBER
builtins.int"builtins.intrë
 DETERMINISTIC_ORDER_FIELD_NUMBEROpyspark.sql.connect.proto.relations_pb2.Sample.DETERMINISTIC_ORDER_FIELD_NUMBER
builtins.int"builtins.intrk
lower_bound:pyspark.sql.connect.proto.relations_pb2.Sample.lower_bound 
builtins.float"builtins.floatrk
upper_bound:pyspark.sql.connect.proto.relations_pb2.Sample.upper_bound 
builtins.float"builtins.floatrs
with_replacement?pyspark.sql.connect.proto.relations_pb2.Sample.with_replacement
builtins.bool"builtins.boolrY
seed3pyspark.sql.connect.proto.relations_pb2.Sample.seed
builtins.int"builtins.intry
deterministic_orderBpyspark.sql.connect.proto.relations_pb2.Sample.deterministic_order
builtins.bool"builtins.bool±$
Range-pyspark.sql.connect.proto.relations_pb2.Range"builtins.object*∏
__init__6pyspark.sql.connect.proto.relations_pb2.Range.__init__"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*Q
startD
Union[builtins.int,None]
builtins.int"builtins.int
None *'
end
builtins.int"builtins.int *(
step
builtins.int"builtins.int *Z
num_partitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *É
HasField6pyspark.sql.connect.proto.relations_pb2.Range.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ω	

ClearField8pyspark.sql.connect.proto.relations_pb2.Range.ClearField"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¥

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Range.WhichOneofÙ

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Range.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÙ

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Range.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrO

DESCRIPTOR8pyspark.sql.connect.proto.relations_pb2.Range.DESCRIPTOR
Anyrt
START_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Range.START_FIELD_NUMBER
builtins.int"builtins.intrp
END_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.Range.END_FIELD_NUMBER
builtins.int"builtins.intrr
STEP_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Range.STEP_FIELD_NUMBER
builtins.int"builtins.intrÜ
NUM_PARTITIONS_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Range.NUM_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intrZ
start3pyspark.sql.connect.proto.relations_pb2.Range.start
builtins.int"builtins.intrV
end1pyspark.sql.connect.proto.relations_pb2.Range.end
builtins.int"builtins.intrX
step2pyspark.sql.connect.proto.relations_pb2.Range.step
builtins.int"builtins.intrl
num_partitions<pyspark.sql.connect.proto.relations_pb2.Range.num_partitions
builtins.int"builtins.int®
SubqueryAlias5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"builtins.object*ª
input;pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias0:builtins.property`*Ê
	qualifier?pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.qualifier"
Any*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias0:builtins.property`*÷
__init__>pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *)
alias
builtins.str"builtins.str *ô
	qualifierá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *®
HasField>pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*„

ClearField@pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.SubqueryAlias.INPUT_FIELD_NUMBER
builtins.int"builtins.intr|
ALIAS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.SubqueryAlias.ALIAS_FIELD_NUMBER
builtins.int"builtins.intrÑ
QUALIFIER_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.SubqueryAlias.QUALIFIER_FIELD_NUMBER
builtins.int"builtins.intrb
alias;pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.alias
builtins.str"builtins.strÕ
Repartition3pyspark.sql.connect.proto.relations_pb2.Repartition"builtins.object*µ
input9pyspark.sql.connect.proto.relations_pb2.Repartition.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition0:builtins.property`*ï
__init__<pyspark.sql.connect.proto.relations_pb2.Repartition.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *2
num_partitions
builtins.int"builtins.int *V
shuffleG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *Ô
HasField<pyspark.sql.connect.proto.relations_pb2.Repartition.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearField>pyspark.sql.connect.proto.relations_pb2.Repartition.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ò

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Repartition.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.Repartition.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Repartition.INPUT_FIELD_NUMBER
builtins.int"builtins.intrå
NUM_PARTITIONS_FIELD_NUMBEROpyspark.sql.connect.proto.relations_pb2.Repartition.NUM_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intr~
SHUFFLE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Repartition.SHUFFLE_FIELD_NUMBER
builtins.int"builtins.intrr
num_partitionsBpyspark.sql.connect.proto.relations_pb2.Repartition.num_partitions
builtins.int"builtins.intrf
shuffle;pyspark.sql.connect.proto.relations_pb2.Repartition.shuffle
builtins.bool"builtins.boolÀ

ShowString2pyspark.sql.connect.proto.relations_pb2.ShowString"builtins.object*≤
input8pyspark.sql.connect.proto.relations_pb2.ShowString.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString0:builtins.property`*í
__init__;pyspark.sql.connect.proto.relations_pb2.ShowString.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *,
num_rows
builtins.int"builtins.int *,
truncate
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *ü
HasField;pyspark.sql.connect.proto.relations_pb2.ShowString.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ä

ClearField=pyspark.sql.connect.proto.relations_pb2.ShowString.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.ShowString.DESCRIPTOR
Anyry
INPUT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.ShowString.INPUT_FIELD_NUMBER
builtins.int"builtins.intr
NUM_ROWS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.ShowString.NUM_ROWS_FIELD_NUMBER
builtins.int"builtins.intr
TRUNCATE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.ShowString.TRUNCATE_FIELD_NUMBER
builtins.int"builtins.intr
VERTICAL_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.ShowString.VERTICAL_FIELD_NUMBER
builtins.int"builtins.intre
num_rows;pyspark.sql.connect.proto.relations_pb2.ShowString.num_rows
builtins.int"builtins.intre
truncate;pyspark.sql.connect.proto.relations_pb2.ShowString.truncate
builtins.int"builtins.intrg
vertical;pyspark.sql.connect.proto.relations_pb2.ShowString.vertical
builtins.bool"builtins.boolã

HtmlString2pyspark.sql.connect.proto.relations_pb2.HtmlString"builtins.object*≤
input8pyspark.sql.connect.proto.relations_pb2.HtmlString.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString0:builtins.property`*‚
__init__;pyspark.sql.connect.proto.relations_pb2.HtmlString.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *,
num_rows
builtins.int"builtins.int *,
truncate
builtins.int"builtins.int *ü
HasField;pyspark.sql.connect.proto.relations_pb2.HtmlString.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*⁄

ClearField=pyspark.sql.connect.proto.relations_pb2.HtmlString.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.HtmlString.DESCRIPTOR
Anyry
INPUT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.HtmlString.INPUT_FIELD_NUMBER
builtins.int"builtins.intr
NUM_ROWS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.HtmlString.NUM_ROWS_FIELD_NUMBER
builtins.int"builtins.intr
TRUNCATE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.HtmlString.TRUNCATE_FIELD_NUMBER
builtins.int"builtins.intre
num_rows;pyspark.sql.connect.proto.relations_pb2.HtmlString.num_rows
builtins.int"builtins.intre
truncate;pyspark.sql.connect.proto.relations_pb2.HtmlString.truncate
builtins.int"builtins.int—
StatSummary3pyspark.sql.connect.proto.relations_pb2.StatSummary"builtins.object*µ
input9pyspark.sql.connect.proto.relations_pb2.StatSummary.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary0:builtins.property`*‚

statistics>pyspark.sql.connect.proto.relations_pb2.StatSummary.statistics"
Any*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary0:builtins.property`*¶
__init__<pyspark.sql.connect.proto.relations_pb2.StatSummary.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ö

statisticsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *¢
HasField<pyspark.sql.connect.proto.relations_pb2.StatSummary.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearField>pyspark.sql.connect.proto.relations_pb2.StatSummary.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.StatSummary.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatSummary.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÑ
STATISTICS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.StatSummary.STATISTICS_FIELD_NUMBER
builtins.int"builtins.int∆
StatDescribe4pyspark.sql.connect.proto.relations_pb2.StatDescribe"builtins.object*∏
input:pyspark.sql.connect.proto.relations_pb2.StatDescribe.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe0:builtins.property`*Ÿ
cols9pyspark.sql.connect.proto.relations_pb2.StatDescribe.cols"
Any*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe0:builtins.property`*£
__init__=pyspark.sql.connect.proto.relations_pb2.StatDescribe.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *•
HasField=pyspark.sql.connect.proto.relations_pb2.StatDescribe.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearField?pyspark.sql.connect.proto.relations_pb2.StatDescribe.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.StatDescribe.DESCRIPTOR
Anyr{
INPUT_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatDescribe.INPUT_FIELD_NUMBER
builtins.int"builtins.intry
COLS_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatDescribe.COLS_FIELD_NUMBER
builtins.int"builtins.intã
StatCrosstab4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"builtins.object*∏
input:pyspark.sql.connect.proto.relations_pb2.StatCrosstab.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab0:builtins.property`*‡
__init__=pyspark.sql.connect.proto.relations_pb2.StatCrosstab.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
col1
builtins.str"builtins.str *(
col2
builtins.str"builtins.str *•
HasField=pyspark.sql.connect.proto.relations_pb2.StatCrosstab.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‡

ClearField?pyspark.sql.connect.proto.relations_pb2.StatCrosstab.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.StatCrosstab.DESCRIPTOR
Anyr{
INPUT_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatCrosstab.INPUT_FIELD_NUMBER
builtins.int"builtins.intry
COL1_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatCrosstab.COL1_FIELD_NUMBER
builtins.int"builtins.intry
COL2_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatCrosstab.COL2_FIELD_NUMBER
builtins.int"builtins.intr_
col19pyspark.sql.connect.proto.relations_pb2.StatCrosstab.col1
builtins.str"builtins.strr_
col29pyspark.sql.connect.proto.relations_pb2.StatCrosstab.col2
builtins.str"builtins.strß
StatCov/pyspark.sql.connect.proto.relations_pb2.StatCov"builtins.object*©
input5pyspark.sql.connect.proto.relations_pb2.StatCov.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov0:builtins.property`*—
__init__8pyspark.sql.connect.proto.relations_pb2.StatCov.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
col1
builtins.str"builtins.str *(
col2
builtins.str"builtins.str *ñ
HasField8pyspark.sql.connect.proto.relations_pb2.StatCov.HasField"
builtins.bool"builtins.bool*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*—

ClearField:pyspark.sql.connect.proto.relations_pb2.StatCov.ClearField"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.StatCov.DESCRIPTOR
Anyrv
INPUT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.StatCov.INPUT_FIELD_NUMBER
builtins.int"builtins.intrt
COL1_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.StatCov.COL1_FIELD_NUMBER
builtins.int"builtins.intrt
COL2_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.StatCov.COL2_FIELD_NUMBER
builtins.int"builtins.intrZ
col14pyspark.sql.connect.proto.relations_pb2.StatCov.col1
builtins.str"builtins.strrZ
col24pyspark.sql.connect.proto.relations_pb2.StatCov.col2
builtins.str"builtins.strÔ
StatCorr0pyspark.sql.connect.proto.relations_pb2.StatCorr"builtins.object*¨
input6pyspark.sql.connect.proto.relations_pb2.StatCorr.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr0:builtins.property`*®
__init__9pyspark.sql.connect.proto.relations_pb2.StatCorr.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
col1
builtins.str"builtins.str *(
col2
builtins.str"builtins.str *R
methodD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ê
HasField9pyspark.sql.connect.proto.relations_pb2.StatCorr.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*†

ClearField;pyspark.sql.connect.proto.relations_pb2.StatCorr.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

WhichOneof;pyspark.sql.connect.proto.relations_pb2.StatCorr.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.StatCorr.DESCRIPTOR
Anyrw
INPUT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.StatCorr.INPUT_FIELD_NUMBER
builtins.int"builtins.intru
COL1_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.StatCorr.COL1_FIELD_NUMBER
builtins.int"builtins.intru
COL2_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.StatCorr.COL2_FIELD_NUMBER
builtins.int"builtins.intry
METHOD_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.StatCorr.METHOD_FIELD_NUMBER
builtins.int"builtins.intr[
col15pyspark.sql.connect.proto.relations_pb2.StatCorr.col1
builtins.str"builtins.strr[
col25pyspark.sql.connect.proto.relations_pb2.StatCorr.col2
builtins.str"builtins.strr_
method7pyspark.sql.connect.proto.relations_pb2.StatCorr.method
builtins.str"builtins.strõ
StatApproxQuantile:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile"builtins.object*À
input@pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile0:builtins.property`*Ï
cols?pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.cols"
Any*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile0:builtins.property`*˛
probabilitiesHpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.probabilities"
Any*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile0:builtins.property`*ñ
__init__Cpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *•
probabilitiesè
+Union[typing.Iterable[builtins.float],None]T
typing.Iterable[builtins.float] 
builtins.float"builtins.float"typing.Iterable
None *6
relative_error 
builtins.float"builtins.float *∏
HasFieldCpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ô

ClearFieldEpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.DESCRIPTOR
AnyrÅ
INPUT_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.INPUT_FIELD_NUMBER
builtins.int"builtins.intr
COLS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.COLS_FIELD_NUMBER
builtins.int"builtins.intrë
PROBABILITIES_FIELD_NUMBERUpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.PROBABILITIES_FIELD_NUMBER
builtins.int"builtins.intrì
RELATIVE_ERROR_FIELD_NUMBERVpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.RELATIVE_ERROR_FIELD_NUMBER
builtins.int"builtins.intr}
relative_errorIpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.relative_error 
builtins.float"builtins.float∏
StatFreqItems5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"builtins.object*ª
input;pyspark.sql.connect.proto.relations_pb2.StatFreqItems.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems0:builtins.property`*‹
cols:pyspark.sql.connect.proto.relations_pb2.StatFreqItems.cols"
Any*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems0:builtins.property`*Å
__init__>pyspark.sql.connect.proto.relations_pb2.StatFreqItems.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Y
supportJ
Union[builtins.float,None] 
builtins.float"builtins.float
None *ı
HasField>pyspark.sql.connect.proto.relations_pb2.StatFreqItems.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*â

ClearField@pyspark.sql.connect.proto.relations_pb2.StatFreqItems.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˜

WhichOneof@pyspark.sql.connect.proto.relations_pb2.StatFreqItems.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.StatFreqItems.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.StatFreqItems.INPUT_FIELD_NUMBER
builtins.int"builtins.intrz
COLS_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatFreqItems.COLS_FIELD_NUMBER
builtins.int"builtins.intrÄ
SUPPORT_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.StatFreqItems.SUPPORT_FIELD_NUMBER
builtins.int"builtins.intrj
support=pyspark.sql.connect.proto.relations_pb2.StatFreqItems.support 
builtins.float"builtins.floatë<
StatSampleBy4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"builtins.object*∏
input:pyspark.sql.connect.proto.relations_pb2.StatSampleBy.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy0:builtins.property`*º
col8pyspark.sql.connect.proto.relations_pb2.StatSampleBy.col"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy0:builtins.property`*„
	fractions>pyspark.sql.connect.proto.relations_pb2.StatSampleBy.fractions"
Any*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy0:builtins.property`*ä
__init__=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *»
colº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *ﬁ
	fractionsÃ
ZUnion[typing.Iterable[pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction],None]·
Ntyping.Iterable[pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction]~
=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"typing.Iterable
None *P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *ò
HasField=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

ClearField?pyspark.sql.connect.proto.relations_pb2.StatSampleBy.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

WhichOneof?pyspark.sql.connect.proto.relations_pb2.StatSampleBy.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.StatSampleBy.DESCRIPTOR
Anyr{
INPUT_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatSampleBy.INPUT_FIELD_NUMBER
builtins.int"builtins.intrw
COL_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.StatSampleBy.COL_FIELD_NUMBER
builtins.int"builtins.intrÉ
FRACTIONS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.StatSampleBy.FRACTIONS_FIELD_NUMBER
builtins.int"builtins.intry
SEED_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatSampleBy.SEED_FIELD_NUMBER
builtins.int"builtins.intr_
seed9pyspark.sql.connect.proto.relations_pb2.StatSampleBy.seed
builtins.int"builtins.intz€
Fraction=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"builtins.object*
stratumEpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.stratum"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*à
self~
=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction0:builtins.property`*Ä
__init__Fpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.__init__"
None*à
self~
=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction*‰
stratum‘
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *0
fraction 
builtins.float"builtins.float *¡
HasFieldFpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*’

ClearFieldHpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.ClearField"
None*à
self~
=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.DESCRIPTOR
Anyrà
STRATUM_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.STRATUM_FIELD_NUMBER
builtins.int"builtins.inträ
FRACTION_FIELD_NUMBERSpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.FRACTION_FIELD_NUMBER
builtins.int"builtins.intrt
fractionFpyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction.fraction 
builtins.float"builtins.floatñ
NAFill.pyspark.sql.connect.proto.relations_pb2.NAFill"builtins.object*¶
input4pyspark.sql.connect.proto.relations_pb2.NAFill.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill0:builtins.property`*«
cols3pyspark.sql.connect.proto.relations_pb2.NAFill.cols"
Any*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill0:builtins.property`*À
values5pyspark.sql.connect.proto.relations_pb2.NAFill.values"
Any*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill0:builtins.property`*Î
__init__7pyspark.sql.connect.proto.relations_pb2.NAFill.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *◊
values»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *ì
HasField7pyspark.sql.connect.proto.relations_pb2.NAFill.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Œ

ClearField9pyspark.sql.connect.proto.relations_pb2.NAFill.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.NAFill.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.NAFill.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
COLS_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.NAFill.COLS_FIELD_NUMBER
builtins.int"builtins.intrw
VALUES_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.NAFill.VALUES_FIELD_NUMBER
builtins.int"builtins.intù
NADrop.pyspark.sql.connect.proto.relations_pb2.NADrop"builtins.object*¶
input4pyspark.sql.connect.proto.relations_pb2.NADrop.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop0:builtins.property`*«
cols3pyspark.sql.connect.proto.relations_pb2.NADrop.cols"
Any*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop0:builtins.property`*Ï
__init__7pyspark.sql.connect.proto.relations_pb2.NADrop.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Y
min_non_nullsD
Union[builtins.int,None]
builtins.int"builtins.int
None *‡
HasField7pyspark.sql.connect.proto.relations_pb2.NADrop.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

ClearField9pyspark.sql.connect.proto.relations_pb2.NADrop.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‚

WhichOneof9pyspark.sql.connect.proto.relations_pb2.NADrop.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.NADrop.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.NADrop.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
COLS_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.NADrop.COLS_FIELD_NUMBER
builtins.int"builtins.intrÖ
MIN_NON_NULLS_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.NADrop.MIN_NON_NULLS_FIELD_NUMBER
builtins.int"builtins.intrk
min_non_nulls<pyspark.sql.connect.proto.relations_pb2.NADrop.min_non_nulls
builtins.int"builtins.intÃ2
	NAReplace1pyspark.sql.connect.proto.relations_pb2.NAReplace"builtins.object*Ø
input7pyspark.sql.connect.proto.relations_pb2.NAReplace.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace0:builtins.property`*–
cols6pyspark.sql.connect.proto.relations_pb2.NAReplace.cols"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace0:builtins.property`*‡
replacements>pyspark.sql.connect.proto.relations_pb2.NAReplace.replacements"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace0:builtins.property`*˛
__init__:pyspark.sql.connect.proto.relations_pb2.NAReplace.__init__"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *·
replacementsÃ
ZUnion[typing.Iterable[pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement],None]·
Ntyping.Iterable[pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement]~
=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"typing.Iterable
None *ú
HasField:pyspark.sql.connect.proto.relations_pb2.NAReplace.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.relations_pb2.NAReplace.ClearField"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.relations_pb2.NAReplace.DESCRIPTOR
Anyrx
INPUT_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.NAReplace.INPUT_FIELD_NUMBER
builtins.int"builtins.intrv
COLS_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.NAReplace.COLS_FIELD_NUMBER
builtins.int"builtins.intrÜ
REPLACEMENTS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.NAReplace.REPLACEMENTS_FIELD_NUMBER
builtins.int"builtins.intz»
Replacement=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"builtins.object*Ù
	old_valueGpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.old_value"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*à
self~
=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement0:builtins.property`*Ù
	new_valueGpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.new_value"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*à
self~
=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement0:builtins.property`*π
__init__Fpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.__init__"
None*à
self~
=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement*Ê
	old_value‘
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *Ê
	new_value‘
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *Á
HasFieldFpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.HasField"
builtins.bool"builtins.bool*à
self~
=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*’

ClearFieldHpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.ClearField"
None*à
self~
=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr_

DESCRIPTORHpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.DESCRIPTOR
Anyrå
OLD_VALUE_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.OLD_VALUE_FIELD_NUMBER
builtins.int"builtins.intrå
NEW_VALUE_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement.NEW_VALUE_FIELD_NUMBER
builtins.int"builtins.intœ
ToDF,pyspark.sql.connect.proto.relations_pb2.ToDF"builtins.object*†
input2pyspark.sql.connect.proto.relations_pb2.ToDF.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF0:builtins.property`*—
column_names9pyspark.sql.connect.proto.relations_pb2.ToDF.column_names"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF0:builtins.property`*ì
__init__5pyspark.sql.connect.proto.relations_pb2.ToDF.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ú
column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ç
HasField5pyspark.sql.connect.proto.relations_pb2.ToDF.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*°

ClearField7pyspark.sql.connect.proto.relations_pb2.ToDF.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.ToDF.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.ToDF.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÅ
COLUMN_NAMES_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.ToDF.COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intÂ#
WithColumnsRenamed:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed"builtins.object*À
input@pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed0:builtins.property`*à
rename_columns_mapMpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.rename_columns_map"
Any*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed0:builtins.property`*˘
__init__Cpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *◊
rename_columns_mapº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *∏
HasFieldCpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ã

ClearFieldEpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.DESCRIPTOR
AnyrÅ
INPUT_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.INPUT_FIELD_NUMBER
builtins.int"builtins.intrõ
RENAME_COLUMNS_MAP_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RENAME_COLUMNS_MAP_FIELD_NUMBER
builtins.int"builtins.intz¢
RenameColumnsMapEntryPpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry"builtins.object*ı
__init__Ypyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry.__init__"
None*Ø
self§
Ppyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry"Ppyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *è

ClearField[pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry.ClearField"
None*Ø
self§
Ppyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry"Ppyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrr

DESCRIPTOR[pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry.DESCRIPTOR
Anyrì
KEY_FIELD_NUMBERapyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intró
VALUE_FIELD_NUMBERcpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intry
keyTpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry.key
builtins.str"builtins.strr}
valueVpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RenameColumnsMapEntry.value
builtins.str"builtins.str˙
WithColumns3pyspark.sql.connect.proto.relations_pb2.WithColumns"builtins.object*µ
input9pyspark.sql.connect.proto.relations_pb2.WithColumns.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns0:builtins.property`*‹
aliases;pyspark.sql.connect.proto.relations_pb2.WithColumns.aliases"
Any*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns0:builtins.property`*‹
__init__<pyspark.sql.connect.proto.relations_pb2.WithColumns.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *–
aliases¿
WUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Alias],None]ÿ
Ktyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Alias]x
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias"typing.Iterable
None *¢
HasField<pyspark.sql.connect.proto.relations_pb2.WithColumns.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearField>pyspark.sql.connect.proto.relations_pb2.WithColumns.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.WithColumns.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.WithColumns.INPUT_FIELD_NUMBER
builtins.int"builtins.intr~
ALIASES_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.WithColumns.ALIASES_FIELD_NUMBER
builtins.int"builtins.intˆ
WithWatermark5pyspark.sql.connect.proto.relations_pb2.WithWatermark"builtins.object*ª
input;pyspark.sql.connect.proto.relations_pb2.WithWatermark.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark0:builtins.property`*Ù
__init__>pyspark.sql.connect.proto.relations_pb2.WithWatermark.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *.

event_time
builtins.str"builtins.str *3
delay_threshold
builtins.str"builtins.str *®
HasField>pyspark.sql.connect.proto.relations_pb2.WithWatermark.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*„

ClearField@pyspark.sql.connect.proto.relations_pb2.WithWatermark.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.WithWatermark.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.WithWatermark.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÜ
EVENT_TIME_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.WithWatermark.EVENT_TIME_FIELD_NUMBER
builtins.int"builtins.intrê
DELAY_THRESHOLD_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.WithWatermark.DELAY_THRESHOLD_FIELD_NUMBER
builtins.int"builtins.intrl

event_time@pyspark.sql.connect.proto.relations_pb2.WithWatermark.event_time
builtins.str"builtins.strrv
delay_thresholdEpyspark.sql.connect.proto.relations_pb2.WithWatermark.delay_threshold
builtins.str"builtins.strÇ
Hint,pyspark.sql.connect.proto.relations_pb2.Hint"builtins.object*†
input2pyspark.sql.connect.proto.relations_pb2.Hint.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint0:builtins.property`*Õ

parameters7pyspark.sql.connect.proto.relations_pb2.Hint.parameters"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint0:builtins.property`*‹
__init__5pyspark.sql.connect.proto.relations_pb2.Hint.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
name
builtins.str"builtins.str *ª

parameters®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ç
HasField5pyspark.sql.connect.proto.relations_pb2.Hint.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*»

ClearField7pyspark.sql.connect.proto.relations_pb2.Hint.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Hint.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Hint.INPUT_FIELD_NUMBER
builtins.int"builtins.intrq
NAME_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.Hint.NAME_FIELD_NUMBER
builtins.int"builtins.intr}
PARAMETERS_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Hint.PARAMETERS_FIELD_NUMBER
builtins.int"builtins.intrW
name1pyspark.sql.connect.proto.relations_pb2.Hint.name
builtins.str"builtins.strû5
Unpivot/pyspark.sql.connect.proto.relations_pb2.Unpivot"builtins.object*©
input5pyspark.sql.connect.proto.relations_pb2.Unpivot.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot0:builtins.property`*»
ids3pyspark.sql.connect.proto.relations_pb2.Unpivot.ids"
Any*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot0:builtins.property`*∑
values6pyspark.sql.connect.proto.relations_pb2.Unpivot.values"p
6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot0:builtins.property`*˘
__init__8pyspark.sql.connect.proto.relations_pb2.Unpivot.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *¥
ids®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *—
values¬
BUnion[pyspark.sql.connect.proto.relations_pb2.Unpivot.Values,None]p
6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values
None *8
variable_column_name
builtins.str"builtins.str *5
value_column_name
builtins.str"builtins.str *„
HasField8pyspark.sql.connect.proto.relations_pb2.Unpivot.HasField"
builtins.bool"builtins.bool*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*√	

ClearField:pyspark.sql.connect.proto.relations_pb2.Unpivot.ClearField"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Â

WhichOneof:pyspark.sql.connect.proto.relations_pb2.Unpivot.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.Unpivot.DESCRIPTOR
Anyrv
INPUT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Unpivot.INPUT_FIELD_NUMBER
builtins.int"builtins.intrr
IDS_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Unpivot.IDS_FIELD_NUMBER
builtins.int"builtins.intrx
VALUES_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Unpivot.VALUES_FIELD_NUMBER
builtins.int"builtins.intrî
!VARIABLE_COLUMN_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.Unpivot.VARIABLE_COLUMN_NAME_FIELD_NUMBER
builtins.int"builtins.intré
VALUE_COLUMN_NAME_FIELD_NUMBERNpyspark.sql.connect.proto.relations_pb2.Unpivot.VALUE_COLUMN_NAME_FIELD_NUMBER
builtins.int"builtins.intrz
variable_column_nameDpyspark.sql.connect.proto.relations_pb2.Unpivot.variable_column_name
builtins.str"builtins.strrt
value_column_nameApyspark.sql.connect.proto.relations_pb2.Unpivot.value_column_name
builtins.str"builtins.strzº
Values6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"builtins.object*„
values=pyspark.sql.connect.proto.relations_pb2.Unpivot.Values.values"
Any*z
selfp
6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values0:builtins.property`*ã
__init__?pyspark.sql.connect.proto.relations_pb2.Unpivot.Values.__init__"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values*∑
values®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ô

ClearFieldApyspark.sql.connect.proto.relations_pb2.Unpivot.Values.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.relations_pb2.Unpivot.Values.DESCRIPTOR
Anyr
VALUES_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.Unpivot.Values.VALUES_FIELD_NUMBER
builtins.int"builtins.intò
ToSchema0pyspark.sql.connect.proto.relations_pb2.ToSchema"builtins.object*¨
input6pyspark.sql.connect.proto.relations_pb2.ToSchema.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema0:builtins.property`*¶
schema7pyspark.sql.connect.proto.relations_pb2.ToSchema.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema0:builtins.property`*∂
__init__9pyspark.sql.connect.proto.relations_pb2.ToSchema.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *ø
HasField9pyspark.sql.connect.proto.relations_pb2.ToSchema.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≠

ClearField;pyspark.sql.connect.proto.relations_pb2.ToSchema.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.ToSchema.DESCRIPTOR
Anyrw
INPUT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.ToSchema.INPUT_FIELD_NUMBER
builtins.int"builtins.intry
SCHEMA_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.ToSchema.SCHEMA_FIELD_NUMBER
builtins.int"builtins.int±#
RepartitionByExpression?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"builtins.object*€
inputEpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression0:builtins.property`*í
partition_exprsOpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.partition_exprs"
Any*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression0:builtins.property`*Œ
__init__Hpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *¿
partition_exprs®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Z
num_partitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *ï
HasFieldHpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*©

ClearFieldJpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ó

WhichOneofJpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.DESCRIPTOR
AnyrÜ
INPUT_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.INPUT_FIELD_NUMBER
builtins.int"builtins.intrö
PARTITION_EXPRS_FIELD_NUMBER\pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.PARTITION_EXPRS_FIELD_NUMBER
builtins.int"builtins.intrò
NUM_PARTITIONS_FIELD_NUMBER[pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.NUM_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intr~
num_partitionsNpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.num_partitions
builtins.int"builtins.intÌ"
MapPartitions5pyspark.sql.connect.proto.relations_pb2.MapPartitions"builtins.object*ª
input;pyspark.sql.connect.proto.relations_pb2.MapPartitions.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions0:builtins.property`*Ï
func:pyspark.sql.connect.proto.relations_pb2.MapPartitions.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions0:builtins.property`*ˆ
__init__>pyspark.sql.connect.proto.relations_pb2.MapPartitions.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *Y

is_barrierG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *õ
HasField>pyspark.sql.connect.proto.relations_pb2.MapPartitions.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*â

ClearField@pyspark.sql.connect.proto.relations_pb2.MapPartitions.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˜

WhichOneof@pyspark.sql.connect.proto.relations_pb2.MapPartitions.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.MapPartitions.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.MapPartitions.INPUT_FIELD_NUMBER
builtins.int"builtins.intrz
FUNC_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.MapPartitions.FUNC_FIELD_NUMBER
builtins.int"builtins.intrÜ
IS_BARRIER_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.MapPartitions.IS_BARRIER_FIELD_NUMBER
builtins.int"builtins.intrn

is_barrier@pyspark.sql.connect.proto.relations_pb2.MapPartitions.is_barrier
builtins.bool"builtins.boolƒW
GroupMap0pyspark.sql.connect.proto.relations_pb2.GroupMap"builtins.object*¨
input6pyspark.sql.connect.proto.relations_pb2.GroupMap.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:builtins.property`*Ì
grouping_expressionsEpyspark.sql.connect.proto.relations_pb2.GroupMap.grouping_expressions"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:builtins.property`*›
func5pyspark.sql.connect.proto.relations_pb2.GroupMap.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:builtins.property`*Î
sorting_expressionsDpyspark.sql.connect.proto.relations_pb2.GroupMap.sorting_expressions"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:builtins.property`*º
initial_input>pyspark.sql.connect.proto.relations_pb2.GroupMap.initial_input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:builtins.property`*˝
initial_grouping_expressionsMpyspark.sql.connect.proto.relations_pb2.GroupMap.initial_grouping_expressions"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:builtins.property`*–
__init__9pyspark.sql.connect.proto.relations_pb2.GroupMap.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *≈
grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *ƒ
sorting_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *∆
initial_input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *Õ
initial_grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *g
is_map_groups_with_stateG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *W
output_modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *X
timeout_confD
Union[builtins.str,None]
builtins.str"builtins.str
None * 
HasField9pyspark.sql.connect.proto.relations_pb2.GroupMap.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*™

ClearField;pyspark.sql.connect.proto.relations_pb2.GroupMap.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*‰

field_name”
ÆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2…

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof˝

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.GroupMap.DESCRIPTOR
Anyrw
INPUT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.GroupMap.INPUT_FIELD_NUMBER
builtins.int"builtins.intrï
!GROUPING_EXPRESSIONS_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.GroupMap.GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intru
FUNC_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.GroupMap.FUNC_FIELD_NUMBER
builtins.int"builtins.intrì
 SORTING_EXPRESSIONS_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.GroupMap.SORTING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrá
INITIAL_INPUT_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.GroupMap.INITIAL_INPUT_FIELD_NUMBER
builtins.int"builtins.intr•
)INITIAL_GROUPING_EXPRESSIONS_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.GroupMap.INITIAL_GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrù
%IS_MAP_GROUPS_WITH_STATE_FIELD_NUMBERVpyspark.sql.connect.proto.relations_pb2.GroupMap.IS_MAP_GROUPS_WITH_STATE_FIELD_NUMBER
builtins.int"builtins.intrÉ
OUTPUT_MODE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.GroupMap.OUTPUT_MODE_FIELD_NUMBER
builtins.int"builtins.intrÖ
TIMEOUT_CONF_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.GroupMap.TIMEOUT_CONF_FIELD_NUMBER
builtins.int"builtins.intrÖ
is_map_groups_with_stateIpyspark.sql.connect.proto.relations_pb2.GroupMap.is_map_groups_with_state
builtins.bool"builtins.boolri
output_mode<pyspark.sql.connect.proto.relations_pb2.GroupMap.output_mode
builtins.str"builtins.strrk
timeout_conf=pyspark.sql.connect.proto.relations_pb2.GroupMap.timeout_conf
builtins.str"builtins.strÓ:

CoGroupMap2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"builtins.object*≤
input8pyspark.sql.connect.proto.relations_pb2.CoGroupMap.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:builtins.property`*ˇ
input_grouping_expressionsMpyspark.sql.connect.proto.relations_pb2.CoGroupMap.input_grouping_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:builtins.property`*≤
other8pyspark.sql.connect.proto.relations_pb2.CoGroupMap.other"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:builtins.property`*ˇ
other_grouping_expressionsMpyspark.sql.connect.proto.relations_pb2.CoGroupMap.other_grouping_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:builtins.property`*„
func7pyspark.sql.connect.proto.relations_pb2.CoGroupMap.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:builtins.property`*˝
input_sorting_expressionsLpyspark.sql.connect.proto.relations_pb2.CoGroupMap.input_sorting_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:builtins.property`*˝
other_sorting_expressionsLpyspark.sql.connect.proto.relations_pb2.CoGroupMap.other_sorting_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:builtins.property`*â
__init__;pyspark.sql.connect.proto.relations_pb2.CoGroupMap.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *À
input_grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *æ
other∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *À
other_grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None * 
input_sorting_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None * 
other_sorting_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Ï
HasField;pyspark.sql.connect.proto.relations_pb2.CoGroupMap.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ú


ClearField=pyspark.sql.connect.proto.relations_pb2.CoGroupMap.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.CoGroupMap.DESCRIPTOR
Anyry
INPUT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.CoGroupMap.INPUT_FIELD_NUMBER
builtins.int"builtins.intr£
'INPUT_GROUPING_EXPRESSIONS_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.CoGroupMap.INPUT_GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intry
OTHER_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.CoGroupMap.OTHER_FIELD_NUMBER
builtins.int"builtins.intr£
'OTHER_GROUPING_EXPRESSIONS_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.CoGroupMap.OTHER_GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrw
FUNC_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.CoGroupMap.FUNC_FIELD_NUMBER
builtins.int"builtins.intr°
&INPUT_SORTING_EXPRESSIONS_FIELD_NUMBERYpyspark.sql.connect.proto.relations_pb2.CoGroupMap.INPUT_SORTING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intr°
&OTHER_SORTING_EXPRESSIONS_FIELD_NUMBERYpyspark.sql.connect.proto.relations_pb2.CoGroupMap.OTHER_SORTING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intö/
ApplyInPandasWithState>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState"builtins.object*ÿ
inputDpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState0:builtins.property`*ô
grouping_expressionsSpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.grouping_expressions"
Any*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState0:builtins.property`*â
funcCpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState0:builtins.property`*»	
__init__Gpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *≈
grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *1
output_schema
builtins.str"builtins.str *0
state_schema
builtins.str"builtins.str */
output_mode
builtins.str"builtins.str *0
timeout_conf
builtins.str"builtins.str *Î
HasFieldGpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.HasField"
builtins.bool"builtins.bool*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ò

ClearFieldIpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.DESCRIPTOR
AnyrÖ
INPUT_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.INPUT_FIELD_NUMBER
builtins.int"builtins.intr£
!GROUPING_EXPRESSIONS_FIELD_NUMBER`pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrÉ
FUNC_FIELD_NUMBERPpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.FUNC_FIELD_NUMBER
builtins.int"builtins.intrï
OUTPUT_SCHEMA_FIELD_NUMBERYpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.OUTPUT_SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrì
STATE_SCHEMA_FIELD_NUMBERXpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.STATE_SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrë
OUTPUT_MODE_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.OUTPUT_MODE_FIELD_NUMBER
builtins.int"builtins.intrì
TIMEOUT_CONF_FIELD_NUMBERXpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.TIMEOUT_CONF_FIELD_NUMBER
builtins.int"builtins.intr{
output_schemaLpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.output_schema
builtins.str"builtins.strry
state_schemaKpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.state_schema
builtins.str"builtins.strrw
output_modeJpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.output_mode
builtins.str"builtins.strry
timeout_confKpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.timeout_conf
builtins.str"builtins.strº(
$CommonInlineUserDefinedTableFunctionLpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"builtins.object*≠
	argumentsVpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.arguments"
Any*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction0:builtins.property`*í
python_udtfXpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.python_udtf"h
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction0:builtins.property`*á
__init__Upyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.__init__"
None*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*1
function_name
builtins.str"builtins.str *3
deterministic
builtins.bool"builtins.bool *∫
	arguments®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None * 
python_udtf∂
>Union[pyspark.sql.connect.proto.relations_pb2.PythonUDTF,None]h
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF
None *ï
HasFieldUpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.HasField"
builtins.bool"builtins.bool*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ˆ

ClearFieldWpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.ClearField"
None*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*æ

WhichOneofWpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrn

DESCRIPTORWpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.DESCRIPTOR
Anyr£
FUNCTION_NAME_FIELD_NUMBERgpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr£
DETERMINISTIC_FIELD_NUMBERgpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.DETERMINISTIC_FIELD_NUMBER
builtins.int"builtins.intrõ
ARGUMENTS_FIELD_NUMBERcpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intrü
PYTHON_UDTF_FIELD_NUMBERepyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.PYTHON_UDTF_FIELD_NUMBER
builtins.int"builtins.intrâ
function_nameZpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.function_name
builtins.str"builtins.strrã
deterministicZpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.deterministic
builtins.bool"builtins.bool£

PythonUDTF2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"builtins.object*∂
return_type>pyspark.sql.connect.proto.relations_pb2.PythonUDTF.return_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF0:builtins.property`*ê
__init__;pyspark.sql.connect.proto.relations_pb2.PythonUDTF.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*∏
return_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *-
	eval_type
builtins.int"builtins.int */
command 
builtins.bytes"builtins.bytes *.

python_ver
builtins.str"builtins.str *≈
HasField;pyspark.sql.connect.proto.relations_pb2.PythonUDTF.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¶

ClearField=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

WhichOneof=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.DESCRIPTOR
AnyrÖ
RETURN_TYPE_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.PythonUDTF.RETURN_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÅ
EVAL_TYPE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.PythonUDTF.EVAL_TYPE_FIELD_NUMBER
builtins.int"builtins.intr}
COMMAND_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.PythonUDTF.COMMAND_FIELD_NUMBER
builtins.int"builtins.intrÉ
PYTHON_VER_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.PythonUDTF.PYTHON_VER_FIELD_NUMBER
builtins.int"builtins.intrg
	eval_type<pyspark.sql.connect.proto.relations_pb2.PythonUDTF.eval_type
builtins.int"builtins.intrg
command:pyspark.sql.connect.proto.relations_pb2.PythonUDTF.command 
builtins.bytes"builtins.bytesri

python_ver=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.python_ver
builtins.str"builtins.str–
CollectMetrics6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"builtins.object*æ
input<pyspark.sql.connect.proto.relations_pb2.CollectMetrics.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics0:builtins.property`*Â
metrics>pyspark.sql.connect.proto.relations_pb2.CollectMetrics.metrics"
Any*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics0:builtins.property`*˜
__init__?pyspark.sql.connect.proto.relations_pb2.CollectMetrics.__init__"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
name
builtins.str"builtins.str *∏
metrics®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *´
HasField?pyspark.sql.connect.proto.relations_pb2.CollectMetrics.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ê

ClearFieldApyspark.sql.connect.proto.relations_pb2.CollectMetrics.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.relations_pb2.CollectMetrics.DESCRIPTOR
Anyr}
INPUT_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.CollectMetrics.INPUT_FIELD_NUMBER
builtins.int"builtins.intr{
NAME_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.CollectMetrics.NAME_FIELD_NUMBER
builtins.int"builtins.intrÅ
METRICS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.CollectMetrics.METRICS_FIELD_NUMBER
builtins.int"builtins.intra
name;pyspark.sql.connect.proto.relations_pb2.CollectMetrics.name
builtins.str"builtins.strÿD
Parse-pyspark.sql.connect.proto.relations_pb2.Parse"builtins.object*£
input3pyspark.sql.connect.proto.relations_pb2.Parse.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse0:builtins.property`*ù
schema4pyspark.sql.connect.proto.relations_pb2.Parse.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse0:builtins.property`* 
options5pyspark.sql.connect.proto.relations_pb2.Parse.options"
Any*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse0:builtins.property`*ö
__init__6pyspark.sql.connect.proto.relations_pb2.Parse.__init__"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *õ
formatå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *›
HasField6pyspark.sql.connect.proto.relations_pb2.Parse.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ó

ClearField8pyspark.sql.connect.proto.relations_pb2.Parse.ClearField"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ﬂ

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Parse.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrO

DESCRIPTOR8pyspark.sql.connect.proto.relations_pb2.Parse.DESCRIPTOR
AnyrÒ
PARSE_FORMAT_UNSPECIFIEDFpyspark.sql.connect.proto.relations_pb2.Parse.PARSE_FORMAT_UNSPECIFIEDå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTyper·
PARSE_FORMAT_CSV>pyspark.sql.connect.proto.relations_pb2.Parse.PARSE_FORMAT_CSVå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTyper„
PARSE_FORMAT_JSON?pyspark.sql.connect.proto.relations_pb2.Parse.PARSE_FORMAT_JSONå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTypert
INPUT_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Parse.INPUT_FIELD_NUMBER
builtins.int"builtins.intrv
FORMAT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Parse.FORMAT_FIELD_NUMBER
builtins.int"builtins.intrv
SCHEMA_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Parse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrx
OPTIONS_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Parse.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrÕ
format4pyspark.sql.connect.proto.relations_pb2.Parse.formatå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTypezÂ
_ParseFormat:pyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat"builtins.objectzá
	ValueTypeDpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"builtins.int*•
__init__Mpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType.__init__"
None*ó
selfå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType*&
item
builtins.int"builtins.intzˆ
_ParseFormatEnumTypeWrapperIpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormatEnumTypeWrapper"builtins.typerk

DESCRIPTORTpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormatEnumTypeWrapper.DESCRIPTOR
Anyrç
PARSE_FORMAT_UNSPECIFIEDbpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormatEnumTypeWrapper.PARSE_FORMAT_UNSPECIFIEDå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTyper˝
PARSE_FORMAT_CSVZpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormatEnumTypeWrapper.PARSE_FORMAT_CSVå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTyperˇ
PARSE_FORMAT_JSON[pyspark.sql.connect.proto.relations_pb2.Parse._ParseFormatEnumTypeWrapper.PARSE_FORMAT_JSONå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTypez—
ParseFormat9pyspark.sql.connect.proto.relations_pb2.Parse.ParseFormat":pyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat@bIpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormatEnumTypeWrapperzé
OptionsEntry:pyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry"builtins.object*≤
__init__Cpyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry":pyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Ã

ClearFieldEpyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry":pyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry.DESCRIPTOR
Anyr}
KEY_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrÅ
VALUE_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrc
key>pyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry.key
builtins.str"builtins.strrg
value@pyspark.sql.connect.proto.relations_pb2.Parse.OptionsEntry.value
builtins.str"builtins.strŸÊ
Catalog-pyspark.sql.connect.proto.catalog_pb2.Catalog"builtins.object*√
current_database>pyspark.sql.connect.proto.catalog_pb2.Catalog.current_database"n
5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*—
set_current_databaseBpyspark.sql.connect.proto.catalog_pb2.Catalog.set_current_database"t
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*ª
list_databases<pyspark.sql.connect.proto.catalog_pb2.Catalog.list_databases"j
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*Ø
list_tables9pyspark.sql.connect.proto.catalog_pb2.Catalog.list_tables"d
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*ª
list_functions<pyspark.sql.connect.proto.catalog_pb2.Catalog.list_functions"j
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*≥
list_columns:pyspark.sql.connect.proto.catalog_pb2.Catalog.list_columns"f
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*≥
get_database:pyspark.sql.connect.proto.catalog_pb2.Catalog.get_database"f
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*ß
	get_table7pyspark.sql.connect.proto.catalog_pb2.Catalog.get_table"`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*≥
get_function:pyspark.sql.connect.proto.catalog_pb2.Catalog.get_function"f
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*ø
database_exists=pyspark.sql.connect.proto.catalog_pb2.Catalog.database_exists"l
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*≥
table_exists:pyspark.sql.connect.proto.catalog_pb2.Catalog.table_exists"f
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*ø
function_exists=pyspark.sql.connect.proto.catalog_pb2.Catalog.function_exists"l
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*’
create_external_tableCpyspark.sql.connect.proto.catalog_pb2.Catalog.create_external_table"v
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*≥
create_table:pyspark.sql.connect.proto.catalog_pb2.Catalog.create_table"f
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*π
drop_temp_view<pyspark.sql.connect.proto.catalog_pb2.Catalog.drop_temp_view"h
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*”
drop_global_temp_viewCpyspark.sql.connect.proto.catalog_pb2.Catalog.drop_global_temp_view"t
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*À
recover_partitions@pyspark.sql.connect.proto.catalog_pb2.Catalog.recover_partitions"r
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*ß
	is_cached7pyspark.sql.connect.proto.catalog_pb2.Catalog.is_cached"`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*Ø
cache_table9pyspark.sql.connect.proto.catalog_pb2.Catalog.cache_table"d
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*∑
uncache_table;pyspark.sql.connect.proto.catalog_pb2.Catalog.uncache_table"h
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*Ø
clear_cache9pyspark.sql.connect.proto.catalog_pb2.Catalog.clear_cache"d
0pyspark.sql.connect.proto.catalog_pb2.ClearCache"0pyspark.sql.connect.proto.catalog_pb2.ClearCache*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*∑
refresh_table;pyspark.sql.connect.proto.catalog_pb2.Catalog.refresh_table"h
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*Ω
refresh_by_path=pyspark.sql.connect.proto.catalog_pb2.Catalog.refresh_by_path"j
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*ø
current_catalog=pyspark.sql.connect.proto.catalog_pb2.Catalog.current_catalog"l
4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*Õ
set_current_catalogApyspark.sql.connect.proto.catalog_pb2.Catalog.set_current_catalog"r
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*∑
list_catalogs;pyspark.sql.connect.proto.catalog_pb2.Catalog.list_catalogs"h
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:builtins.property`*õ,
__init__6pyspark.sql.connect.proto.catalog_pb2.Catalog.__init__"
None*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*ÿ
current_databaseø
AUnion[pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase,None]n
5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase
None *Â
set_current_database»
DUnion[pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase,None]t
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase
None *–
list_databasesπ
?Union[pyspark.sql.connect.proto.catalog_pb2.ListDatabases,None]j
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases
None *ƒ
list_tables∞
<Union[pyspark.sql.connect.proto.catalog_pb2.ListTables,None]d
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables
None *–
list_functionsπ
?Union[pyspark.sql.connect.proto.catalog_pb2.ListFunctions,None]j
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions
None *»
list_columns≥
=Union[pyspark.sql.connect.proto.catalog_pb2.ListColumns,None]f
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns
None *»
get_database≥
=Union[pyspark.sql.connect.proto.catalog_pb2.GetDatabase,None]f
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase
None *º
	get_table™
:Union[pyspark.sql.connect.proto.catalog_pb2.GetTable,None]`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable
None *»
get_function≥
=Union[pyspark.sql.connect.proto.catalog_pb2.GetFunction,None]f
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction
None *‘
database_existsº
@Union[pyspark.sql.connect.proto.catalog_pb2.DatabaseExists,None]l
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists
None *»
table_exists≥
=Union[pyspark.sql.connect.proto.catalog_pb2.TableExists,None]f
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists
None *‘
function_existsº
@Union[pyspark.sql.connect.proto.catalog_pb2.FunctionExists,None]l
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists
None *È
create_external_tableÀ
EUnion[pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable,None]v
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable
None *»
create_table≥
=Union[pyspark.sql.connect.proto.catalog_pb2.CreateTable,None]f
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable
None *Õ
drop_temp_view∂
>Union[pyspark.sql.connect.proto.catalog_pb2.DropTempView,None]h
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView
None *Ê
drop_global_temp_view»
DUnion[pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView,None]t
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView
None *‡
recover_partitions≈
CUnion[pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions,None]r
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions
None *º
	is_cached™
:Union[pyspark.sql.connect.proto.catalog_pb2.IsCached,None]`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached
None *ƒ
cache_table∞
<Union[pyspark.sql.connect.proto.catalog_pb2.CacheTable,None]d
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable
None *Ã
uncache_table∂
>Union[pyspark.sql.connect.proto.catalog_pb2.UncacheTable,None]h
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable
None *ƒ
clear_cache∞
<Union[pyspark.sql.connect.proto.catalog_pb2.ClearCache,None]d
0pyspark.sql.connect.proto.catalog_pb2.ClearCache"0pyspark.sql.connect.proto.catalog_pb2.ClearCache
None *Ã
refresh_table∂
>Union[pyspark.sql.connect.proto.catalog_pb2.RefreshTable,None]h
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable
None *—
refresh_by_pathπ
?Union[pyspark.sql.connect.proto.catalog_pb2.RefreshByPath,None]j
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath
None *‘
current_catalogº
@Union[pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog,None]l
4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog
None *·
set_current_catalog≈
CUnion[pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog,None]r
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog
None *Ã
list_catalogs∂
>Union[pyspark.sql.connect.proto.catalog_pb2.ListCatalogs,None]h
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs
None *Ì$
HasField6pyspark.sql.connect.proto.catalog_pb2.Catalog.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*û#

field_nameç#
‡	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*€$

ClearField8pyspark.sql.connect.proto.catalog_pb2.Catalog.ClearField"
None*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*û#

field_nameç#
‡	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ò

WhichOneof8pyspark.sql.connect.proto.catalog_pb2.Catalog.WhichOneof"†
«Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrO

DESCRIPTOR8pyspark.sql.connect.proto.catalog_pb2.Catalog.DESCRIPTOR
Anyrä
CURRENT_DATABASE_FIELD_NUMBERKpyspark.sql.connect.proto.catalog_pb2.Catalog.CURRENT_DATABASE_FIELD_NUMBER
builtins.int"builtins.intrí
!SET_CURRENT_DATABASE_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.Catalog.SET_CURRENT_DATABASE_FIELD_NUMBER
builtins.int"builtins.intrÜ
LIST_DATABASES_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_DATABASES_FIELD_NUMBER
builtins.int"builtins.intrÄ
LIST_TABLES_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_TABLES_FIELD_NUMBER
builtins.int"builtins.intrÜ
LIST_FUNCTIONS_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_FUNCTIONS_FIELD_NUMBER
builtins.int"builtins.intrÇ
LIST_COLUMNS_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÇ
GET_DATABASE_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.GET_DATABASE_FIELD_NUMBER
builtins.int"builtins.intr|
GET_TABLE_FIELD_NUMBERDpyspark.sql.connect.proto.catalog_pb2.Catalog.GET_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÇ
GET_FUNCTION_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.GET_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrà
DATABASE_EXISTS_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.DATABASE_EXISTS_FIELD_NUMBER
builtins.int"builtins.intrÇ
TABLE_EXISTS_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.TABLE_EXISTS_FIELD_NUMBER
builtins.int"builtins.intrà
FUNCTION_EXISTS_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.FUNCTION_EXISTS_FIELD_NUMBER
builtins.int"builtins.intrî
"CREATE_EXTERNAL_TABLE_FIELD_NUMBERPpyspark.sql.connect.proto.catalog_pb2.Catalog.CREATE_EXTERNAL_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÇ
CREATE_TABLE_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.CREATE_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÜ
DROP_TEMP_VIEW_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.Catalog.DROP_TEMP_VIEW_FIELD_NUMBER
builtins.int"builtins.intrî
"DROP_GLOBAL_TEMP_VIEW_FIELD_NUMBERPpyspark.sql.connect.proto.catalog_pb2.Catalog.DROP_GLOBAL_TEMP_VIEW_FIELD_NUMBER
builtins.int"builtins.intré
RECOVER_PARTITIONS_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.Catalog.RECOVER_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intr|
IS_CACHED_FIELD_NUMBERDpyspark.sql.connect.proto.catalog_pb2.Catalog.IS_CACHED_FIELD_NUMBER
builtins.int"builtins.intrÄ
CACHE_TABLE_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.Catalog.CACHE_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÑ
UNCACHE_TABLE_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.Catalog.UNCACHE_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÄ
CLEAR_CACHE_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.Catalog.CLEAR_CACHE_FIELD_NUMBER
builtins.int"builtins.intrÑ
REFRESH_TABLE_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.Catalog.REFRESH_TABLE_FIELD_NUMBER
builtins.int"builtins.intrà
REFRESH_BY_PATH_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.REFRESH_BY_PATH_FIELD_NUMBER
builtins.int"builtins.intrà
CURRENT_CATALOG_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.CURRENT_CATALOG_FIELD_NUMBER
builtins.int"builtins.intrê
 SET_CURRENT_CATALOG_FIELD_NUMBERNpyspark.sql.connect.proto.catalog_pb2.Catalog.SET_CURRENT_CATALOG_FIELD_NUMBER
builtins.int"builtins.intrÑ
LIST_CATALOGS_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_CATALOGS_FIELD_NUMBER
builtins.int"builtins.intÉ
CurrentDatabase5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"builtins.object*Œ
__init__>pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase.__init__"
None*x
selfn
5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabaserW

DESCRIPTOR@pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase.DESCRIPTOR
Any’
SetCurrentDatabase8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"builtins.object*Ñ
__init__Apyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.__init__"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase*+
db_name
builtins.str"builtins.str *ü

ClearFieldCpyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.ClearField"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.DESCRIPTOR
AnyrÉ
DB_NAME_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intri
db_name@pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.db_name
builtins.str"builtins.str™
ListDatabases3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"builtins.object*ù
__init__<pyspark.sql.connect.proto.catalog_pb2.ListDatabases.__init__"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *»
HasField<pyspark.sql.connect.proto.catalog_pb2.ListDatabases.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearField>pyspark.sql.connect.proto.catalog_pb2.ListDatabases.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ò

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListDatabases.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.catalog_pb2.ListDatabases.DESCRIPTOR
Anyr~
PATTERN_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.ListDatabases.PATTERN_FIELD_NUMBER
builtins.int"builtins.intrd
pattern;pyspark.sql.connect.proto.catalog_pb2.ListDatabases.pattern
builtins.str"builtins.strß

ListTables0pyspark.sql.connect.proto.catalog_pb2.ListTables"builtins.object*È
__init__9pyspark.sql.connect.proto.catalog_pb2.ListTables.__init__"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *å
HasField9pyspark.sql.connect.proto.catalog_pb2.ListTables.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

ClearField;pyspark.sql.connect.proto.catalog_pb2.ListTables.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2…

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.ListTables.WhichOneof˝

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.ListTables.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.ListTables.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrR

DESCRIPTOR;pyspark.sql.connect.proto.catalog_pb2.ListTables.DESCRIPTOR
Anyr{
DB_NAME_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.ListTables.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intr{
PATTERN_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.ListTables.PATTERN_FIELD_NUMBER
builtins.int"builtins.intra
db_name8pyspark.sql.connect.proto.catalog_pb2.ListTables.db_name
builtins.str"builtins.strra
pattern8pyspark.sql.connect.proto.catalog_pb2.ListTables.pattern
builtins.str"builtins.strÏ
ListFunctions3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"builtins.object*Ú
__init__<pyspark.sql.connect.proto.catalog_pb2.ListFunctions.__init__"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *ï
HasField<pyspark.sql.connect.proto.catalog_pb2.ListFunctions.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearField>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ﬁ

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.WhichOneofÜ

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÜ

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrU

DESCRIPTOR>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.DESCRIPTOR
Anyr~
DB_NAME_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.ListFunctions.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intr~
PATTERN_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.ListFunctions.PATTERN_FIELD_NUMBER
builtins.int"builtins.intrd
db_name;pyspark.sql.connect.proto.catalog_pb2.ListFunctions.db_name
builtins.str"builtins.strrd
pattern;pyspark.sql.connect.proto.catalog_pb2.ListFunctions.pattern
builtins.str"builtins.strŒ
ListColumns1pyspark.sql.connect.proto.catalog_pb2.ListColumns"builtins.object*«
__init__:pyspark.sql.connect.proto.catalog_pb2.ListColumns.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*.

table_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *¬
HasField:pyspark.sql.connect.proto.catalog_pb2.ListColumns.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.catalog_pb2.ListColumns.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.ListColumns.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.ListColumns.DESCRIPTOR
AnyrÇ
TABLE_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.ListColumns.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.ListColumns.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrh

table_name<pyspark.sql.connect.proto.catalog_pb2.ListColumns.table_name
builtins.str"builtins.strrb
db_name9pyspark.sql.connect.proto.catalog_pb2.ListColumns.db_name
builtins.str"builtins.strá
GetDatabase1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"builtins.object*Ô
__init__:pyspark.sql.connect.proto.catalog_pb2.GetDatabase.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase*+
db_name
builtins.str"builtins.str *ä

ClearField<pyspark.sql.connect.proto.catalog_pb2.GetDatabase.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.GetDatabase.DESCRIPTOR
Anyr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.GetDatabase.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrb
db_name9pyspark.sql.connect.proto.catalog_pb2.GetDatabase.db_name
builtins.str"builtins.strî
GetTable.pyspark.sql.connect.proto.catalog_pb2.GetTable"builtins.object*æ
__init__7pyspark.sql.connect.proto.catalog_pb2.GetTable.__init__"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*.

table_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *π
HasField7pyspark.sql.connect.proto.catalog_pb2.GetTable.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Œ

ClearField9pyspark.sql.connect.proto.catalog_pb2.GetTable.ClearField"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‚

WhichOneof9pyspark.sql.connect.proto.catalog_pb2.GetTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.catalog_pb2.GetTable.DESCRIPTOR
Anyr
TABLE_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.GetTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intry
DB_NAME_FIELD_NUMBERCpyspark.sql.connect.proto.catalog_pb2.GetTable.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intre

table_name9pyspark.sql.connect.proto.catalog_pb2.GetTable.table_name
builtins.str"builtins.strr_
db_name6pyspark.sql.connect.proto.catalog_pb2.GetTable.db_name
builtins.str"builtins.str›
GetFunction1pyspark.sql.connect.proto.catalog_pb2.GetFunction"builtins.object* 
__init__:pyspark.sql.connect.proto.catalog_pb2.GetFunction.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*1
function_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *¬
HasField:pyspark.sql.connect.proto.catalog_pb2.GetFunction.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.catalog_pb2.GetFunction.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.GetFunction.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.GetFunction.DESCRIPTOR
Anyrà
FUNCTION_NAME_FIELD_NUMBERLpyspark.sql.connect.proto.catalog_pb2.GetFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.GetFunction.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrn
function_name?pyspark.sql.connect.proto.catalog_pb2.GetFunction.function_name
builtins.str"builtins.strrb
db_name9pyspark.sql.connect.proto.catalog_pb2.GetFunction.db_name
builtins.str"builtins.str®
DatabaseExists4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"builtins.object*¯
__init__=pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.__init__"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists*+
db_name
builtins.str"builtins.str *ì

ClearField?pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.DESCRIPTOR
Anyr
DB_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.DatabaseExists.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intre
db_name<pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.db_name
builtins.str"builtins.strŒ
TableExists1pyspark.sql.connect.proto.catalog_pb2.TableExists"builtins.object*«
__init__:pyspark.sql.connect.proto.catalog_pb2.TableExists.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*.

table_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *¬
HasField:pyspark.sql.connect.proto.catalog_pb2.TableExists.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.catalog_pb2.TableExists.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.TableExists.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.TableExists.DESCRIPTOR
AnyrÇ
TABLE_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.TableExists.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.TableExists.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrh

table_name<pyspark.sql.connect.proto.catalog_pb2.TableExists.table_name
builtins.str"builtins.strrb
db_name9pyspark.sql.connect.proto.catalog_pb2.TableExists.db_name
builtins.str"builtins.strñ
FunctionExists4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"builtins.object*”
__init__=pyspark.sql.connect.proto.catalog_pb2.FunctionExists.__init__"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*1
function_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *À
HasField=pyspark.sql.connect.proto.catalog_pb2.FunctionExists.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‡

ClearField?pyspark.sql.connect.proto.catalog_pb2.FunctionExists.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

WhichOneof?pyspark.sql.connect.proto.catalog_pb2.FunctionExists.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.catalog_pb2.FunctionExists.DESCRIPTOR
Anyrã
FUNCTION_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.FunctionExists.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr
DB_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.FunctionExists.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrq
function_nameBpyspark.sql.connect.proto.catalog_pb2.FunctionExists.function_name
builtins.str"builtins.strre
db_name<pyspark.sql.connect.proto.catalog_pb2.FunctionExists.db_name
builtins.str"builtins.strÉE
CreateExternalTable9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"builtins.object*¬
schema@pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable0:builtins.property`*Ô
optionsApyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.options"
Any*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable0:builtins.property`*∂
__init__Bpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*.

table_name
builtins.str"builtins.str *P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
sourceD
Union[builtins.str,None]
builtins.str"builtins.str
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *Ù	
HasFieldBpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¶

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneofô

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXô

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXô

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXr[

DESCRIPTORDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.DESCRIPTOR
Anyrä
TABLE_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr~
PATH_FIELD_NUMBERKpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.PATH_FIELD_NUMBER
builtins.int"builtins.intrÇ
SOURCE_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.SOURCE_FIELD_NUMBER
builtins.int"builtins.intrÇ
SCHEMA_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÑ
OPTIONS_FIELD_NUMBERNpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrp

table_nameDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.table_name
builtins.str"builtins.strrd
path>pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.path
builtins.str"builtins.strrh
source@pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.source
builtins.str"builtins.strz°
OptionsEntryFpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry"builtins.object*◊
__init__Opyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry"Fpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Ò

ClearFieldQpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry.ClearField"
None*õ
selfê
Fpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry"Fpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry.DESCRIPTOR
Anyrâ
KEY_FIELD_NUMBERWpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrç
VALUE_FIELD_NUMBERYpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intro
keyJpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry.key
builtins.str"builtins.strrs
valueLpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OptionsEntry.value
builtins.str"builtins.strﬂM
CreateTable1pyspark.sql.connect.proto.catalog_pb2.CreateTable"builtins.object*©
schema8pyspark.sql.connect.proto.catalog_pb2.CreateTable.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable0:builtins.property`*÷
options9pyspark.sql.connect.proto.catalog_pb2.CreateTable.options"
Any*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable0:builtins.property`*ˆ
__init__:pyspark.sql.connect.proto.catalog_pb2.CreateTable.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*.

table_name
builtins.str"builtins.str *P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
sourceD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
descriptionD
Union[builtins.str,None]
builtins.str"builtins.str
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *ß
HasField:pyspark.sql.connect.proto.catalog_pb2.CreateTable.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*·

ClearField<pyspark.sql.connect.proto.catalog_pb2.CreateTable.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*ò

field_nameá
“Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2÷

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneofÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.CreateTable.DESCRIPTOR
AnyrÇ
TABLE_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.CreateTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrv
PATH_FIELD_NUMBERCpyspark.sql.connect.proto.catalog_pb2.CreateTable.PATH_FIELD_NUMBER
builtins.int"builtins.intrz
SOURCE_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.CreateTable.SOURCE_FIELD_NUMBER
builtins.int"builtins.intrÑ
DESCRIPTION_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.CreateTable.DESCRIPTION_FIELD_NUMBER
builtins.int"builtins.intrz
SCHEMA_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.CreateTable.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intr|
OPTIONS_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.CreateTable.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrh

table_name<pyspark.sql.connect.proto.catalog_pb2.CreateTable.table_name
builtins.str"builtins.strr\
path6pyspark.sql.connect.proto.catalog_pb2.CreateTable.path
builtins.str"builtins.strr`
source8pyspark.sql.connect.proto.catalog_pb2.CreateTable.source
builtins.str"builtins.strrj
description=pyspark.sql.connect.proto.catalog_pb2.CreateTable.description
builtins.str"builtins.strz¡
OptionsEntry>pyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry"builtins.object*ø
__init__Gpyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry">pyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry*'
key
builtins.str"builtins.str *)
value
builtins.str"builtins.str *Ÿ

ClearFieldIpyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry">pyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry.DESCRIPTOR
AnyrÅ
KEY_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry.KEY_FIELD_NUMBER
builtins.int"builtins.intrÖ
VALUE_FIELD_NUMBERQpyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry.VALUE_FIELD_NUMBER
builtins.int"builtins.intrg
keyBpyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry.key
builtins.str"builtins.strrk
valueDpyspark.sql.connect.proto.catalog_pb2.CreateTable.OptionsEntry.value
builtins.str"builtins.strù
DropTempView2pyspark.sql.connect.proto.catalog_pb2.DropTempView"builtins.object*Ù
__init__;pyspark.sql.connect.proto.catalog_pb2.DropTempView.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView*-
	view_name
builtins.str"builtins.str *ç

ClearField=pyspark.sql.connect.proto.catalog_pb2.DropTempView.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.DropTempView.DESCRIPTOR
AnyrÅ
VIEW_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.DropTempView.VIEW_NAME_FIELD_NUMBER
builtins.int"builtins.intrg
	view_name<pyspark.sql.connect.proto.catalog_pb2.DropTempView.view_name
builtins.str"builtins.strﬂ
DropGlobalTempView8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"builtins.object*Ü
__init__Apyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.__init__"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView*-
	view_name
builtins.str"builtins.str *ü

ClearFieldCpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.ClearField"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.DESCRIPTOR
Anyrá
VIEW_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.VIEW_NAME_FIELD_NUMBER
builtins.int"builtins.intrm
	view_nameBpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.view_name
builtins.str"builtins.strŸ
RecoverPartitions7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"builtins.object*Ñ
__init__@pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.__init__"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions*.

table_name
builtins.str"builtins.str *ú

ClearFieldBpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.DESCRIPTOR
Anyrà
TABLE_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrn

table_nameBpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.table_name
builtins.str"builtins.strı
IsCached.pyspark.sql.connect.proto.catalog_pb2.IsCached"builtins.object*È
__init__7pyspark.sql.connect.proto.catalog_pb2.IsCached.__init__"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached*.

table_name
builtins.str"builtins.str *Å

ClearField9pyspark.sql.connect.proto.catalog_pb2.IsCached.ClearField"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.catalog_pb2.IsCached.DESCRIPTOR
Anyr
TABLE_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.IsCached.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intre

table_name9pyspark.sql.connect.proto.catalog_pb2.IsCached.table_name
builtins.str"builtins.strù

CacheTable0pyspark.sql.connect.proto.catalog_pb2.CacheTable"builtins.object*æ
storage_level>pyspark.sql.connect.proto.catalog_pb2.CacheTable.storage_level"f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable0:builtins.property`*ª
__init__9pyspark.sql.connect.proto.catalog_pb2.CacheTable.__init__"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*.

table_name
builtins.str"builtins.str *…
storage_level≥
=Union[pyspark.sql.connect.proto.common_pb2.StorageLevel,None]f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel
None *ø
HasField9pyspark.sql.connect.proto.catalog_pb2.CacheTable.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‘

ClearField;pyspark.sql.connect.proto.catalog_pb2.CacheTable.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.CacheTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.catalog_pb2.CacheTable.DESCRIPTOR
AnyrÅ
TABLE_NAME_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.CacheTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrá
STORAGE_LEVEL_FIELD_NUMBERKpyspark.sql.connect.proto.catalog_pb2.CacheTable.STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrg

table_name;pyspark.sql.connect.proto.catalog_pb2.CacheTable.table_name
builtins.str"builtins.str¢
UncacheTable2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"builtins.object*ı
__init__;pyspark.sql.connect.proto.catalog_pb2.UncacheTable.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable*.

table_name
builtins.str"builtins.str *ç

ClearField=pyspark.sql.connect.proto.catalog_pb2.UncacheTable.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.UncacheTable.DESCRIPTOR
AnyrÉ
TABLE_NAME_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.UncacheTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intri

table_name=pyspark.sql.connect.proto.catalog_pb2.UncacheTable.table_name
builtins.str"builtins.strÂ

ClearCache0pyspark.sql.connect.proto.catalog_pb2.ClearCache"builtins.object*ø
__init__9pyspark.sql.connect.proto.catalog_pb2.ClearCache.__init__"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ClearCache"0pyspark.sql.connect.proto.catalog_pb2.ClearCacherR

DESCRIPTOR;pyspark.sql.connect.proto.catalog_pb2.ClearCache.DESCRIPTOR
Any¢
RefreshTable2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"builtins.object*ı
__init__;pyspark.sql.connect.proto.catalog_pb2.RefreshTable.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable*.

table_name
builtins.str"builtins.str *ç

ClearField=pyspark.sql.connect.proto.catalog_pb2.RefreshTable.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.RefreshTable.DESCRIPTOR
AnyrÉ
TABLE_NAME_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.RefreshTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intri

table_name=pyspark.sql.connect.proto.catalog_pb2.RefreshTable.table_name
builtins.str"builtins.stré
RefreshByPath3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"builtins.object*Ú
__init__<pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.__init__"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath*(
path
builtins.str"builtins.str *ê

ClearField>pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.DESCRIPTOR
Anyrx
PATH_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.RefreshByPath.PATH_FIELD_NUMBER
builtins.int"builtins.intr^
path8pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.path
builtins.str"builtins.str˝
CurrentCatalog4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"builtins.object*À
__init__=pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog.__init__"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalogrV

DESCRIPTOR?pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog.DESCRIPTOR
Any„
SetCurrentCatalog7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"builtins.object*Ü
__init__@pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.__init__"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog*0
catalog_name
builtins.str"builtins.str *ú

ClearFieldBpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.DESCRIPTOR
Anyrå
CATALOG_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.CATALOG_NAME_FIELD_NUMBER
builtins.int"builtins.intrr
catalog_nameDpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.catalog_name
builtins.str"builtins.strô
ListCatalogs2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"builtins.object*ö
__init__;pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *≈
HasField;pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≥

ClearField=pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

WhichOneof=pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.DESCRIPTOR
Anyr}
PATTERN_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.ListCatalogs.PATTERN_FIELD_NUMBER
builtins.int"builtins.intrc
pattern:pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.pattern
builtins.str"builtins.strÀ
StorageLevel1pyspark.sql.connect.proto.common_pb2.StorageLevel"builtins.object*Ω
__init__:pyspark.sql.connect.proto.common_pb2.StorageLevel.__init__"
None*p
selff
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*.
use_disk
builtins.bool"builtins.bool *0

use_memory
builtins.bool"builtins.bool *2
use_off_heap
builtins.bool"builtins.bool *2
deserialized
builtins.bool"builtins.bool */
replication
builtins.int"builtins.int *£

ClearField<pyspark.sql.connect.proto.common_pb2.StorageLevel.ClearField"
None*p
selff
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.common_pb2.StorageLevel.DESCRIPTOR
Anyr~
USE_DISK_FIELD_NUMBERGpyspark.sql.connect.proto.common_pb2.StorageLevel.USE_DISK_FIELD_NUMBER
builtins.int"builtins.intrÇ
USE_MEMORY_FIELD_NUMBERIpyspark.sql.connect.proto.common_pb2.StorageLevel.USE_MEMORY_FIELD_NUMBER
builtins.int"builtins.intrÜ
USE_OFF_HEAP_FIELD_NUMBERKpyspark.sql.connect.proto.common_pb2.StorageLevel.USE_OFF_HEAP_FIELD_NUMBER
builtins.int"builtins.intrÜ
DESERIALIZED_FIELD_NUMBERKpyspark.sql.connect.proto.common_pb2.StorageLevel.DESERIALIZED_FIELD_NUMBER
builtins.int"builtins.intrÑ
REPLICATION_FIELD_NUMBERJpyspark.sql.connect.proto.common_pb2.StorageLevel.REPLICATION_FIELD_NUMBER
builtins.int"builtins.intrf
use_disk:pyspark.sql.connect.proto.common_pb2.StorageLevel.use_disk
builtins.bool"builtins.boolrj

use_memory<pyspark.sql.connect.proto.common_pb2.StorageLevel.use_memory
builtins.bool"builtins.boolrn
use_off_heap>pyspark.sql.connect.proto.common_pb2.StorageLevel.use_off_heap
builtins.bool"builtins.boolrn
deserialized>pyspark.sql.connect.proto.common_pb2.StorageLevel.deserialized
builtins.bool"builtins.boolrj
replication=pyspark.sql.connect.proto.common_pb2.StorageLevel.replication
builtins.int"builtins.intÑ
ResourceInformation8pyspark.sql.connect.proto.common_pb2.ResourceInformation"builtins.object*Ô
	addressesBpyspark.sql.connect.proto.common_pb2.ResourceInformation.addresses"
Any*~
selft
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation0:builtins.property`*ù
__init__Apyspark.sql.connect.proto.common_pb2.ResourceInformation.__init__"
None*~
selft
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation*(
name
builtins.str"builtins.str *ô
	addressesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *≈

ClearFieldCpyspark.sql.connect.proto.common_pb2.ResourceInformation.ClearField"
None*~
selft
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.common_pb2.ResourceInformation.DESCRIPTOR
Anyr}
NAME_FIELD_NUMBERJpyspark.sql.connect.proto.common_pb2.ResourceInformation.NAME_FIELD_NUMBER
builtins.int"builtins.intrá
ADDRESSES_FIELD_NUMBEROpyspark.sql.connect.proto.common_pb2.ResourceInformation.ADDRESSES_FIELD_NUMBER
builtins.int"builtins.intrc
name=pyspark.sql.connect.proto.common_pb2.ResourceInformation.name
builtins.str"builtins.strò
)add_SparkConnectServiceServicer_to_serverQpyspark.sql.connect.proto.base_pb2_grpc.add_SparkConnectServiceServicer_to_server*
servicer*

server*z
__path__"pyspark.sql.connect.proto.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*ï
__annotations__)pyspark.sql.connect.proto.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*=
grpc,pyspark.sql.connect.proto.base_pb2_grpc.grpc
Any*G
spark_dot_connect_dot_base__pb2"pyspark.sql.connect.proto.base_pb2 *D

DESCRIPTOR-pyspark.sql.connect.proto.base_pb2.DESCRIPTOR
Any