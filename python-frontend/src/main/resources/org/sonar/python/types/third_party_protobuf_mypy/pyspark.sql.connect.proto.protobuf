
pyspark.sql.connect.protoà
SparkConnectServiceStub?pyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub"builtins.object*k
__init__Hpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.__init__*
self*
channelrc
ExecutePlanKpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ExecutePlan
Anyrc
AnalyzePlanKpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.AnalyzePlan
AnyrY
ConfigFpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.Config
Anyre
AddArtifactsLpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.AddArtifacts
Anyri
ArtifactStatusNpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ArtifactStatus
Anyr_
	InterruptIpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.Interrupt
Anyrk
ReattachExecuteOpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ReattachExecute
Anyri
ReleaseExecuteNpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceStub.ReleaseExecute
Any™	
SparkConnectServiceServicerCpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer"builtins.object*Ç
ExecutePlanOpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ExecutePlan*
self*
request*
context*Ç
AnalyzePlanOpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.AnalyzePlan*
self*
request*
context*x
ConfigJpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.Config*
self*
request*
context*ç
AddArtifactsPpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.AddArtifacts*
self*
request_iterator*
context*à
ArtifactStatusRpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ArtifactStatus*
self*
request*
context*~
	InterruptMpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.Interrupt*
self*
request*
context*ä
ReattachExecuteSpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ReattachExecute*
self*
request*
context*à
ReleaseExecuteRpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectServiceServicer.ReleaseExecute*
self*
request*
context‰
SparkConnectService;pyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService"builtins.object*õ
ExecutePlanGpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ExecutePlan*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodh*õ
AnalyzePlanGpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.AnalyzePlan*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodh*ë
ConfigBpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.Config*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodh*¶
AddArtifactsHpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.AddArtifacts*
request_iterator*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodh*°
ArtifactStatusJpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ArtifactStatus*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodh*ó
	InterruptEpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.Interrupt*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodh*£
ReattachExecuteKpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ReattachExecute*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodh*°
ReleaseExecuteJpyspark.sql.connect.proto.base_pb2_grpc.SparkConnectService.ReleaseExecute*
request*

target*
options *
channel_credentials *
call_credentials *
insecure *
compression *
wait_for_ready *
timeout *
metadata 0:staticmethodhœ
Plan'pyspark.sql.connect.proto.base_pb2.Plan"builtins.object*Ü
root,pyspark.sql.connect.proto.base_pb2.Plan.root"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan0:property`*à
command/pyspark.sql.connect.proto.base_pb2.Plan.command"`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan0:property`*°
__init__0pyspark.sql.connect.proto.base_pb2.Plan.__init__"
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*Ω
root∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *∫
command™
:Union[pyspark.sql.connect.proto.commands_pb2.Command,None]`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command
None *À
HasField0pyspark.sql.connect.proto.base_pb2.Plan.HasField"
builtins.bool"builtins.bool*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearField2pyspark.sql.connect.proto.base_pb2.Plan.ClearField"
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ù

WhichOneof2pyspark.sql.connect.proto.base_pb2.Plan.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*\
selfR
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrI

DESCRIPTOR2pyspark.sql.connect.proto.base_pb2.Plan.DESCRIPTOR
Anyrl
ROOT_FIELD_NUMBER9pyspark.sql.connect.proto.base_pb2.Plan.ROOT_FIELD_NUMBER
builtins.int"builtins.intrr
COMMAND_FIELD_NUMBER<pyspark.sql.connect.proto.base_pb2.Plan.COMMAND_FIELD_NUMBER
builtins.int"builtins.intã
UserContext.pyspark.sql.connect.proto.base_pb2.UserContext"builtins.object* 

extensions9pyspark.sql.connect.proto.base_pb2.UserContext.extensions"
Any*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext0:property`*â
__init__7pyspark.sql.connect.proto.base_pb2.UserContext.__init__"
None*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*+
user_id
builtins.str"builtins.str *-
	user_name
builtins.str"builtins.str *r

extensions`
 Union[typing.Iterable[Any],None]0
typing.Iterable[Any]
Any"typing.Iterable
None *Œ

ClearField9pyspark.sql.connect.proto.base_pb2.UserContext.ClearField"
None*j
self`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.base_pb2.UserContext.DESCRIPTOR
Anyry
USER_ID_FIELD_NUMBERCpyspark.sql.connect.proto.base_pb2.UserContext.USER_ID_FIELD_NUMBER
builtins.int"builtins.intr}
USER_NAME_FIELD_NUMBEREpyspark.sql.connect.proto.base_pb2.UserContext.USER_NAME_FIELD_NUMBER
builtins.int"builtins.intr
EXTENSIONS_FIELD_NUMBERFpyspark.sql.connect.proto.base_pb2.UserContext.EXTENSIONS_FIELD_NUMBER
builtins.int"builtins.intr_
user_id6pyspark.sql.connect.proto.base_pb2.UserContext.user_id
builtins.str"builtins.strrc
	user_name8pyspark.sql.connect.proto.base_pb2.UserContext.user_name
builtins.str"builtins.strÀô
AnalyzePlanRequest5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"builtins.object*º
user_contextBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*Ã
schema<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.schema"|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*–
explain=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.explain"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*ﬂ
tree_stringApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.tree_string"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*“
is_local>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.is_local"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*„
is_streamingBpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.is_streaming"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*ﬂ
input_filesApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.input_files"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*Á
spark_versionCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.spark_version"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*◊
	ddl_parse?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.ddl_parse"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*Î
same_semanticsDpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.same_semantics"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*Á
semantic_hashCpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.semantic_hash"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*–
persist=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.persist"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*Ÿ
	unpersist?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.unpersist"Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*ı
get_storage_levelGpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.get_storage_level"é
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest0:property`*û
__init__>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.__init__"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *„
schema‘
HUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema,None]|
<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema"<pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Schema
None *Á
explain◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Explain
None *ı
tree_string·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TreeString
None *Ë
is_local◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsLocal
None *˘
is_streaming‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IsStreaming
None *ı
input_files·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.InputFiles
None *˝
spark_versionÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SparkVersion
None *Ì
	ddl_parse€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse">pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDLParse
None *Å
same_semanticsÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SameSemantics
None *˝
semantic_hashÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SemanticHash
None *Á
persist◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Persist
None *
	unpersistﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist,None]Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.Unpersist
None *ä
get_storage_level
QUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel,None]é
Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel"Epyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GetStorageLevel
None *â
HasField>pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¢

field_nameë
îUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ù

ClearField@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*»

field_name∑
¬Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¢

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX¬

WhichOneof@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.WhichOneof"ù
©Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest"5pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DESCRIPTOR
AnyrÜ
SESSION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.inträ
USER_CONTEXT_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrà
CLIENT_TYPE_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intr~
SCHEMA_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÄ
EXPLAIN_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrà
TREE_STRING_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrÇ
IS_LOCAL_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.inträ
IS_STREAMING_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intrà
INPUT_FILES_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.INPUT_FILES_FIELD_NUMBER
builtins.int"builtins.intrå
SPARK_VERSION_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SPARK_VERSION_FIELD_NUMBER
builtins.int"builtins.intrÑ
DDL_PARSE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.DDL_PARSE_FIELD_NUMBER
builtins.int"builtins.intré
SAME_SEMANTICS_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SAME_SEMANTICS_FIELD_NUMBER
builtins.int"builtins.intrå
SEMANTIC_HASH_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.SEMANTIC_HASH_FIELD_NUMBER
builtins.int"builtins.intrÄ
PERSIST_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.PERSIST_FIELD_NUMBER
builtins.int"builtins.intrÑ
UNPERSIST_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.UNPERSIST_FIELD_NUMBER
builtins.int"builtins.intrî
GET_STORAGE_LEVEL_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.GET_STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrl

session_id@pyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.session_id
builtins.str"builtins.strrn
client_typeApyspark.sql.connect.proto.base_pb2.AnalyzePlanRequest.client_type
builtins.str"builtins.strúÜ
AnalyzePlanResponse6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"builtins.object*—
schema=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.schema"~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*÷
explain>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.explain"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*‰
tree_stringBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.tree_string"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*ÿ
is_local?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.is_local"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*Ë
is_streamingCpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.is_streaming"à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*‰
input_filesBpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.input_files"Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*Ï
spark_versionDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.spark_version"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*‹
	ddl_parse@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.ddl_parse"Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*
same_semanticsEpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.same_semantics"å
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*Ï
semantic_hashDpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.semantic_hash"ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*÷
persist>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.persist"Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*ﬁ
	unpersist@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.unpersist"Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*˙
get_storage_levelHpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.get_storage_level"ê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse0:property`*∞
__init__?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*.

session_id
builtins.str"builtins.str *Ê
schema◊
IUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema,None]~
=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema"=pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Schema
None *Î
explain€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Explain
None *¯
tree_string‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TreeString
None *Ï
is_local€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsLocal
None *¸
is_streamingÁ
NUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming,None]à
Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming"Bpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IsStreaming
None *¯
input_files‰
MUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles,None]Ü
Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles"Apyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.InputFiles
None *Ä
spark_versionÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SparkVersion
None *
	ddl_parseﬁ
KUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse,None]Ç
?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse"?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDLParse
None *Ñ
same_semanticsÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics,None]å
Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics"Dpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SameSemantics
None *Ä
semantic_hashÍ
OUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash,None]ä
Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash"Cpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SemanticHash
None *Î
persist€
JUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist,None]Ä
>pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist">pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Persist
None *Û
	unpersist·
LUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist,None]Ñ
@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist"@pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.Unpersist
None *ç
get_storage_levelÛ
RUnion[pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel,None]ê
Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel"Fpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GetStorageLevel
None *ö
HasField?pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*∞

field_nameü
äUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*÷

field_name≈
∏Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∞

WhichOneofApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.WhichOneof"ù
©Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse"6pyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intr
SCHEMA_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÅ
EXPLAIN_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrâ
TREE_STRING_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.TREE_STRING_FIELD_NUMBER
builtins.int"builtins.intrÉ
IS_LOCAL_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IS_LOCAL_FIELD_NUMBER
builtins.int"builtins.intrã
IS_STREAMING_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intrâ
INPUT_FILES_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.INPUT_FILES_FIELD_NUMBER
builtins.int"builtins.intrç
SPARK_VERSION_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SPARK_VERSION_FIELD_NUMBER
builtins.int"builtins.intrÖ
DDL_PARSE_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.DDL_PARSE_FIELD_NUMBER
builtins.int"builtins.intrè
SAME_SEMANTICS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SAME_SEMANTICS_FIELD_NUMBER
builtins.int"builtins.intrç
SEMANTIC_HASH_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.SEMANTIC_HASH_FIELD_NUMBER
builtins.int"builtins.intrÅ
PERSIST_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.PERSIST_FIELD_NUMBER
builtins.int"builtins.intrÖ
UNPERSIST_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.UNPERSIST_FIELD_NUMBER
builtins.int"builtins.intrï
GET_STORAGE_LEVEL_FIELD_NUMBERUpyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.GET_STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.AnalyzePlanResponse.session_id
builtins.str"builtins.strµ>
ExecutePlanRequest5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"builtins.object*º
user_contextBpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:property`*û
plan:pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.plan"R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:property`*È
request_optionsEpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.request_options"
Any*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:property`*”
tags:pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.tags"
Any*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest0:property`*Ø

__init__>pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.__init__"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *X
operation_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *¢
planï
3Union[pyspark.sql.connect.proto.base_pb2.Plan,None]R
'pyspark.sql.connect.proto.base_pb2.Plan"'pyspark.sql.connect.proto.base_pb2.Plan
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *˝
request_optionsÂ
`Union[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption],None]Ù
Ttyping.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption]ä
Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"Cpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.RequestOption"typing.Iterable
None *î
tagsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Á	
HasField>pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*«

ClearField@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ï

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXå

WhichOneof@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest"5pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.DESCRIPTOR
AnyrÜ
SESSION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.inträ
USER_CONTEXT_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.inträ
OPERATION_ID_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrz
PLAN_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.PLAN_FIELD_NUMBER
builtins.int"builtins.intrà
CLIENT_TYPE_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrê
REQUEST_OPTIONS_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.REQUEST_OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrz
TAGS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.TAGS_FIELD_NUMBER
builtins.int"builtins.intrl

session_id@pyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.session_id
builtins.str"builtins.strrp
operation_idBpyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.operation_id
builtins.str"builtins.strrn
client_typeApyspark.sql.connect.proto.base_pb2.ExecutePlanRequest.client_type
builtins.str"builtins.strÂy
ExecutePlanResponse6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"builtins.object*‰
arrow_batchBpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.arrow_batch"Ü
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*˛
sql_command_resultIpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.sql_command_result"í
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*û
#write_stream_operation_start_resultZpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.write_stream_operation_start_result"ê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*å
streaming_query_command_resultUpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.streaming_query_command_result"à
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*Ñ
get_resources_command_resultSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.get_resources_command_result"Ñ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*™
&streaming_query_manager_command_result]pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.streaming_query_manager_command_result"ñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*Ù
result_completeFpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.result_complete"é
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*‡
	extension@pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.extension"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*÷
metrics>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.metrics"Ä
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*Ó
observed_metricsGpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.observed_metrics"
Any*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*Ø
schema=pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse0:property`*“
__init__?pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*.

session_id
builtins.str"builtins.str *0
operation_id
builtins.str"builtins.str */
response_id
builtins.str"builtins.str *¯
arrow_batch‰
MUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch,None]Ü
Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch"Apyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ArrowBatch
None *ë
sql_command_resultˆ
SUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult,None]í
Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult"Gpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SqlCommandResult
None *ü
#write_stream_operation_start_resultÛ
RUnion[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult,None]ê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult
None *é
streaming_query_command_resultÁ
NUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult,None]à
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult
None *Ü
get_resources_command_result·
LUnion[pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult,None]Ñ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult
None *´
&streaming_query_manager_command_result¸
UUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult,None]ñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult
None *à
result_complete
QUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete,None]é
Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete"Epyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ResultComplete
None *7
	extension&
Union[Any,None]
Any
None *Î
metrics€
JUnion[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics,None]Ä
>pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics">pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.Metrics
None *ä
observed_metricsÒ
cUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics],None]˝
Wtyping.Iterable[pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics]ê
Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"Fpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ObservedMetrics"typing.Iterable
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *®
HasField?pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*æ

field_name≠
ÄUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*÷

field_name≈
∏Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*•

WhichOneofApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.WhichOneof"í
ªUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse"6pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
OPERATION_ID_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrâ
RESPONSE_ID_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intrâ
ARROW_BATCH_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.ARROW_BATCH_FIELD_NUMBER
builtins.int"builtins.intró
SQL_COMMAND_RESULT_FIELD_NUMBERVpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SQL_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrπ
0WRITE_STREAM_OPERATION_START_RESULT_FIELD_NUMBERgpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.WRITE_STREAM_OPERATION_START_RESULT_FIELD_NUMBER
builtins.int"builtins.intrØ
+STREAMING_QUERY_COMMAND_RESULT_FIELD_NUMBERbpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.STREAMING_QUERY_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intr´
)GET_RESOURCES_COMMAND_RESULT_FIELD_NUMBER`pyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.GET_RESOURCES_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrø
3STREAMING_QUERY_MANAGER_COMMAND_RESULT_FIELD_NUMBERjpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.STREAMING_QUERY_MANAGER_COMMAND_RESULT_FIELD_NUMBER
builtins.int"builtins.intrë
RESULT_COMPLETE_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.RESULT_COMPLETE_FIELD_NUMBER
builtins.int"builtins.intrÖ
EXTENSION_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intrÅ
METRICS_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.METRICS_FIELD_NUMBER
builtins.int"builtins.intrì
OBSERVED_METRICS_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.OBSERVED_METRICS_FIELD_NUMBER
builtins.int"builtins.intr
SCHEMA_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.session_id
builtins.str"builtins.strrq
operation_idCpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.operation_id
builtins.str"builtins.strro
response_idBpyspark.sql.connect.proto.base_pb2.ExecutePlanResponse.response_id
builtins.str"builtins.str±
KeyValue+pyspark.sql.connect.proto.base_pb2.KeyValue"builtins.object*¨
__init__4pyspark.sql.connect.proto.base_pb2.KeyValue.__init__"
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*'
key
builtins.str"builtins.str *Q
valueD
Union[builtins.str,None]
builtins.str"builtins.str
None *∞
HasField4pyspark.sql.connect.proto.base_pb2.KeyValue.HasField"
builtins.bool"builtins.bool*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≈

ClearField6pyspark.sql.connect.proto.base_pb2.KeyValue.ClearField"
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ÿ

WhichOneof6pyspark.sql.connect.proto.base_pb2.KeyValue.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*d
selfZ
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrM

DESCRIPTOR6pyspark.sql.connect.proto.base_pb2.KeyValue.DESCRIPTOR
Anyrn
KEY_FIELD_NUMBER<pyspark.sql.connect.proto.base_pb2.KeyValue.KEY_FIELD_NUMBER
builtins.int"builtins.intrr
VALUE_FIELD_NUMBER>pyspark.sql.connect.proto.base_pb2.KeyValue.VALUE_FIELD_NUMBER
builtins.int"builtins.intrT
key/pyspark.sql.connect.proto.base_pb2.KeyValue.key
builtins.str"builtins.strrX
value1pyspark.sql.connect.proto.base_pb2.KeyValue.value
builtins.str"builtins.strå%
ConfigRequest0pyspark.sql.connect.proto.base_pb2.ConfigRequest"builtins.object*≠
user_context=pyspark.sql.connect.proto.base_pb2.ConfigRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest0:property`*ø
	operation:pyspark.sql.connect.proto.base_pb2.ConfigRequest.operation"x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest0:property`*Ì
__init__9pyspark.sql.connect.proto.base_pb2.ConfigRequest.__init__"
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *‡
	operationŒ
FUnion[pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation,None]x
:pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation":pyspark.sql.connect.proto.base_pb2.ConfigRequest.Operation
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *å
HasField9pyspark.sql.connect.proto.base_pb2.ConfigRequest.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*†

ClearField;pyspark.sql.connect.proto.base_pb2.ConfigRequest.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

WhichOneof;pyspark.sql.connect.proto.base_pb2.ConfigRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.base_pb2.ConfigRequest"0pyspark.sql.connect.proto.base_pb2.ConfigRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.base_pb2.ConfigRequest.DESCRIPTOR
AnyrÅ
SESSION_ID_FIELD_NUMBERHpyspark.sql.connect.proto.base_pb2.ConfigRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrÖ
USER_CONTEXT_FIELD_NUMBERJpyspark.sql.connect.proto.base_pb2.ConfigRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intr
OPERATION_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigRequest.OPERATION_FIELD_NUMBER
builtins.int"builtins.intrÉ
CLIENT_TYPE_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.ConfigRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrg

session_id;pyspark.sql.connect.proto.base_pb2.ConfigRequest.session_id
builtins.str"builtins.strri
client_type<pyspark.sql.connect.proto.base_pb2.ConfigRequest.client_type
builtins.str"builtins.strØ
ConfigResponse1pyspark.sql.connect.proto.base_pb2.ConfigResponse"builtins.object*…
pairs7pyspark.sql.connect.proto.base_pb2.ConfigResponse.pairs"
Any*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse0:property`*œ
warnings:pyspark.sql.connect.proto.base_pb2.ConfigResponse.warnings"
Any*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse0:property`*¢
__init__:pyspark.sql.connect.proto.base_pb2.ConfigResponse.__init__"
None*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse*.

session_id
builtins.str"builtins.str *í
pairsÑ
HUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue],None]´
<typing.Iterable[pyspark.sql.connect.proto.base_pb2.KeyValue]Z
+pyspark.sql.connect.proto.base_pb2.KeyValue"+pyspark.sql.connect.proto.base_pb2.KeyValue"typing.Iterable
None *ò
warningsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *◊

ClearField<pyspark.sql.connect.proto.base_pb2.ConfigResponse.ClearField"
None*p
selff
1pyspark.sql.connect.proto.base_pb2.ConfigResponse"1pyspark.sql.connect.proto.base_pb2.ConfigResponse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.base_pb2.ConfigResponse.DESCRIPTOR
AnyrÇ
SESSION_ID_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.ConfigResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrx
PAIRS_FIELD_NUMBERDpyspark.sql.connect.proto.base_pb2.ConfigResponse.PAIRS_FIELD_NUMBER
builtins.int"builtins.intr~
WARNINGS_FIELD_NUMBERGpyspark.sql.connect.proto.base_pb2.ConfigResponse.WARNINGS_FIELD_NUMBER
builtins.int"builtins.intrh

session_id<pyspark.sql.connect.proto.base_pb2.ConfigResponse.session_id
builtins.str"builtins.strû@
AddArtifactsRequest6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"builtins.object*ø
user_contextCpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:property`*Õ
batch<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.batch"|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:property`*¯
begin_chunkBpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.begin_chunk"ö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:property`*ﬁ
chunk<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.chunk"å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest0:property`*ò

__init__?pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.__init__"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *‚
batch‘
HUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch,None]|
<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch"<pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.Batch
None *ñ
begin_chunkÇ
WUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact,None]ö
Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact"Kpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BeginChunkedArtifact
None *˚
chunkÌ
PUnion[pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk,None]å
Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk"Dpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ArtifactChunk
None *ê
HasField?pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearFieldApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2í


WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneofè

WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÆ

WhichOneofApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.WhichOneof"Ü
MUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest"6pyspark.sql.connect.proto.base_pb2.AddArtifactsRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrX

DESCRIPTORApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.DESCRIPTOR
Anyrá
SESSION_ID_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
USER_CONTEXT_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrâ
CLIENT_TYPE_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intr}
BATCH_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BATCH_FIELD_NUMBER
builtins.int"builtins.intrâ
BEGIN_CHUNK_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.BEGIN_CHUNK_FIELD_NUMBER
builtins.int"builtins.intr}
CHUNK_FIELD_NUMBERIpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.CHUNK_FIELD_NUMBER
builtins.int"builtins.intrm

session_idApyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.session_id
builtins.str"builtins.strro
client_typeBpyspark.sql.connect.proto.base_pb2.AddArtifactsRequest.client_type
builtins.str"builtins.str™
AddArtifactsResponse7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"builtins.object*„
	artifactsApyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.artifacts"
Any*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse0:property`*ﬁ
__init__@pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.__init__"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse*á
	artifactsı
dUnion[typing.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary],None]Ä
Xtyping.Iterable[pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary]í
Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"Gpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ArtifactSummary"typing.Iterable
None *ú

ClearFieldBpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse"7pyspark.sql.connect.proto.base_pb2.AddArtifactsResponse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.DESCRIPTOR
AnyrÜ
ARTIFACTS_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.AddArtifactsResponse.ARTIFACTS_FIELD_NUMBER
builtins.int"builtins.intØ$
ArtifactStatusesRequest:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest"builtins.object*Ã
user_contextGpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest0:property`*Â
names@pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.names"
Any*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest0:property`*¡
__init__Cpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *ï
namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ö
HasFieldCpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ø

ClearFieldEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*á

WhichOneofEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ç
selfx
:pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest":pyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.DESCRIPTOR
Anyrã
SESSION_ID_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrè
USER_CONTEXT_FIELD_NUMBERTpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrç
CLIENT_TYPE_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÅ
NAMES_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.NAMES_FIELD_NUMBER
builtins.int"builtins.intrq

session_idEpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.session_id
builtins.str"builtins.strrs
client_typeFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesRequest.client_type
builtins.str"builtins.strù
ArtifactStatusesResponse;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse"builtins.object*Ó
statusesDpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.statuses"
Any*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse0:property`*´
__init__Dpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.__init__"
None*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse*«
statuses∂
sUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus],None]≤
gtyping.Mapping[builtins.str,pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus]
builtins.str"builtins.strò
Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"Jpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ArtifactStatus"typing.Mapping
None *©

ClearFieldFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.ClearField"
None*Ñ
selfz
;pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse";pyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.DESCRIPTOR
Anyrà
STATUSES_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ArtifactStatusesResponse.STATUSES_FIELD_NUMBER
builtins.int"builtins.int⁄=
InterruptRequest3pyspark.sql.connect.proto.base_pb2.InterruptRequest"builtins.object*∂
user_context@pyspark.sql.connect.proto.base_pb2.InterruptRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest0:property`*Æ
__init__<pyspark.sql.connect.proto.base_pb2.InterruptRequest.__init__"
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *≥
interrupt_typeú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType *1
operation_tag
builtins.str"builtins.str *0
operation_id
builtins.str"builtins.str *·	
HasField<pyspark.sql.connect.proto.base_pb2.InterruptRequest.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*õ

ClearField>pyspark.sql.connect.proto.base_pb2.InterruptRequest.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Æ	

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneofÜ

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX÷

WhichOneof>pyspark.sql.connect.proto.base_pb2.InterruptRequest.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.base_pb2.InterruptRequest"3pyspark.sql.connect.proto.base_pb2.InterruptRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrU

DESCRIPTOR>pyspark.sql.connect.proto.base_pb2.InterruptRequest.DESCRIPTOR
Anyrã
INTERRUPT_TYPE_UNSPECIFIEDNpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_UNSPECIFIEDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper˚
INTERRUPT_TYPE_ALLFpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_ALLú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyper˚
INTERRUPT_TYPE_TAGFpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_TAGú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperç
INTERRUPT_TYPE_OPERATION_IDOpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_OPERATION_IDú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperÑ
SESSION_ID_FIELD_NUMBERKpyspark.sql.connect.proto.base_pb2.InterruptRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrà
USER_CONTEXT_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.InterruptRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrÜ
CLIENT_TYPE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.InterruptRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrå
INTERRUPT_TYPE_FIELD_NUMBEROpyspark.sql.connect.proto.base_pb2.InterruptRequest.INTERRUPT_TYPE_FIELD_NUMBER
builtins.int"builtins.inträ
OPERATION_TAG_FIELD_NUMBERNpyspark.sql.connect.proto.base_pb2.InterruptRequest.OPERATION_TAG_FIELD_NUMBER
builtins.int"builtins.intrà
OPERATION_ID_FIELD_NUMBERMpyspark.sql.connect.proto.base_pb2.InterruptRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrj

session_id>pyspark.sql.connect.proto.base_pb2.InterruptRequest.session_id
builtins.str"builtins.strrl
client_type?pyspark.sql.connect.proto.base_pb2.InterruptRequest.client_type
builtins.str"builtins.strrÛ
interrupt_typeBpyspark.sql.connect.proto.base_pb2.InterruptRequest.interrupt_typeú
Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueType"Lpyspark.sql.connect.proto.base_pb2.InterruptRequest._InterruptType.ValueTyperp
operation_tagApyspark.sql.connect.proto.base_pb2.InterruptRequest.operation_tag
builtins.str"builtins.strrn
operation_id@pyspark.sql.connect.proto.base_pb2.InterruptRequest.operation_id
builtins.str"builtins.str˛
InterruptResponse4pyspark.sql.connect.proto.base_pb2.InterruptResponse"builtins.object*Ê
interrupted_idsDpyspark.sql.connect.proto.base_pb2.InterruptResponse.interrupted_ids"
Any*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse0:property`*ù
__init__=pyspark.sql.connect.proto.base_pb2.InterruptResponse.__init__"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse*.

session_id
builtins.str"builtins.str *ü
interrupted_idsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *π

ClearField?pyspark.sql.connect.proto.base_pb2.InterruptResponse.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.base_pb2.InterruptResponse"4pyspark.sql.connect.proto.base_pb2.InterruptResponse*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.base_pb2.InterruptResponse.DESCRIPTOR
AnyrÖ
SESSION_ID_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.InterruptResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrè
INTERRUPTED_IDS_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.InterruptResponse.INTERRUPTED_IDS_FIELD_NUMBER
builtins.int"builtins.intrk

session_id?pyspark.sql.connect.proto.base_pb2.InterruptResponse.session_id
builtins.str"builtins.str≥
ReattachOptions2pyspark.sql.connect.proto.base_pb2.ReattachOptions"builtins.object*˘
__init__;pyspark.sql.connect.proto.base_pb2.ReattachOptions.__init__"
None*r
selfh
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*2
reattachable
builtins.bool"builtins.bool *ç

ClearField=pyspark.sql.connect.proto.base_pb2.ReattachOptions.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.base_pb2.ReattachOptions"2pyspark.sql.connect.proto.base_pb2.ReattachOptions*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.base_pb2.ReattachOptions.DESCRIPTOR
Anyrá
REATTACHABLE_FIELD_NUMBERLpyspark.sql.connect.proto.base_pb2.ReattachOptions.REATTACHABLE_FIELD_NUMBER
builtins.int"builtins.intro
reattachable?pyspark.sql.connect.proto.base_pb2.ReattachOptions.reattachable
builtins.bool"builtins.bool‡/
ReattachExecuteRequest9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"builtins.object*…
user_contextFpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest0:property`*∂
__init__Bpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *0
operation_id
builtins.str"builtins.str *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *\
last_response_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *Œ
HasFieldBpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*à

ClearFieldDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ä	

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneofô

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXô

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest"9pyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXr[

DESCRIPTORDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.DESCRIPTOR
Anyrä
SESSION_ID_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intré
USER_CONTEXT_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intré
OPERATION_ID_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrå
CLIENT_TYPE_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrñ
LAST_RESPONSE_ID_FIELD_NUMBERWpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.LAST_RESPONSE_ID_FIELD_NUMBER
builtins.int"builtins.intrp

session_idDpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.session_id
builtins.str"builtins.strrt
operation_idFpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.operation_id
builtins.str"builtins.strrr
client_typeEpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.client_type
builtins.str"builtins.strr|
last_response_idJpyspark.sql.connect.proto.base_pb2.ReattachExecuteRequest.last_response_id
builtins.str"builtins.str¯;
ReleaseExecuteRequest8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"builtins.object*≈
user_contextEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.user_context"`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:property`*Ó
release_allDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.release_all"ä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:property`*ˆ
release_untilFpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.release_until"é
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest0:property`*ﬁ
__init__Apyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.__init__"
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*.

session_id
builtins.str"builtins.str *ø
user_context™
:Union[pyspark.sql.connect.proto.base_pb2.UserContext,None]`
.pyspark.sql.connect.proto.base_pb2.UserContext".pyspark.sql.connect.proto.base_pb2.UserContext
None *0
operation_id
builtins.str"builtins.str *W
client_typeD
Union[builtins.str,None]
builtins.str"builtins.str
None *˛
release_allÍ
OUnion[pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll,None]ä
Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll"Cpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseAll
None *Ü
release_until
QUnion[pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil,None]é
Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil"Epyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ReleaseUntil
None *	
HasFieldApyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.HasField"
builtins.bool"builtins.bool*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*™

ClearFieldCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.ClearField"
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2—	

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneofï

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÂ

WhichOneofCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*~
selft
8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest"8pyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrZ

DESCRIPTORCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.DESCRIPTOR
Anyrâ
SESSION_ID_FIELD_NUMBERPpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intrç
USER_CONTEXT_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.USER_CONTEXT_FIELD_NUMBER
builtins.int"builtins.intrç
OPERATION_ID_FIELD_NUMBERRpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrã
CLIENT_TYPE_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.CLIENT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrã
RELEASE_ALL_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.RELEASE_ALL_FIELD_NUMBER
builtins.int"builtins.intrè
RELEASE_UNTIL_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.RELEASE_UNTIL_FIELD_NUMBER
builtins.int"builtins.intro

session_idCpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.session_id
builtins.str"builtins.strrs
operation_idEpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.operation_id
builtins.str"builtins.strrq
client_typeDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteRequest.client_type
builtins.str"builtins.strá
ReleaseExecuteResponse9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"builtins.object*Â
__init__Bpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*.

session_id
builtins.str"builtins.str *X
operation_idD
Union[builtins.str,None]
builtins.str"builtins.str
None *€
HasFieldBpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*

ClearFieldDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ñ

WhichOneofDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse"9pyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr[

DESCRIPTORDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.DESCRIPTOR
Anyrä
SESSION_ID_FIELD_NUMBERQpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.SESSION_ID_FIELD_NUMBER
builtins.int"builtins.intré
OPERATION_ID_FIELD_NUMBERSpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.OPERATION_ID_FIELD_NUMBER
builtins.int"builtins.intrp

session_idDpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.session_id
builtins.str"builtins.strrt
operation_idFpyspark.sql.connect.proto.base_pb2.ReleaseExecuteResponse.operation_id
builtins.str"builtins.strÜŒ
DataType,pyspark.sql.connect.proto.types_pb2.DataType"builtins.object*ó
null1pyspark.sql.connect.proto.types_pb2.DataType.null"f
1pyspark.sql.connect.proto.types_pb2.DataType.NULL"1pyspark.sql.connect.proto.types_pb2.DataType.NULL*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ü
binary3pyspark.sql.connect.proto.types_pb2.DataType.binary"j
3pyspark.sql.connect.proto.types_pb2.DataType.Binary"3pyspark.sql.connect.proto.types_pb2.DataType.Binary*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*£
boolean4pyspark.sql.connect.proto.types_pb2.DataType.boolean"l
4pyspark.sql.connect.proto.types_pb2.DataType.Boolean"4pyspark.sql.connect.proto.types_pb2.DataType.Boolean*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ó
byte1pyspark.sql.connect.proto.types_pb2.DataType.byte"f
1pyspark.sql.connect.proto.types_pb2.DataType.Byte"1pyspark.sql.connect.proto.types_pb2.DataType.Byte*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*õ
short2pyspark.sql.connect.proto.types_pb2.DataType.short"h
2pyspark.sql.connect.proto.types_pb2.DataType.Short"2pyspark.sql.connect.proto.types_pb2.DataType.Short*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*£
integer4pyspark.sql.connect.proto.types_pb2.DataType.integer"l
4pyspark.sql.connect.proto.types_pb2.DataType.Integer"4pyspark.sql.connect.proto.types_pb2.DataType.Integer*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ó
long1pyspark.sql.connect.proto.types_pb2.DataType.long"f
1pyspark.sql.connect.proto.types_pb2.DataType.Long"1pyspark.sql.connect.proto.types_pb2.DataType.Long*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*õ
float2pyspark.sql.connect.proto.types_pb2.DataType.float"h
2pyspark.sql.connect.proto.types_pb2.DataType.Float"2pyspark.sql.connect.proto.types_pb2.DataType.Float*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ü
double3pyspark.sql.connect.proto.types_pb2.DataType.double"j
3pyspark.sql.connect.proto.types_pb2.DataType.Double"3pyspark.sql.connect.proto.types_pb2.DataType.Double*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*£
decimal4pyspark.sql.connect.proto.types_pb2.DataType.decimal"l
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ü
string3pyspark.sql.connect.proto.types_pb2.DataType.string"j
3pyspark.sql.connect.proto.types_pb2.DataType.String"3pyspark.sql.connect.proto.types_pb2.DataType.String*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ó
char1pyspark.sql.connect.proto.types_pb2.DataType.char"f
1pyspark.sql.connect.proto.types_pb2.DataType.Char"1pyspark.sql.connect.proto.types_pb2.DataType.Char*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*•
var_char5pyspark.sql.connect.proto.types_pb2.DataType.var_char"l
4pyspark.sql.connect.proto.types_pb2.DataType.VarChar"4pyspark.sql.connect.proto.types_pb2.DataType.VarChar*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ó
date1pyspark.sql.connect.proto.types_pb2.DataType.date"f
1pyspark.sql.connect.proto.types_pb2.DataType.Date"1pyspark.sql.connect.proto.types_pb2.DataType.Date*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*´
	timestamp6pyspark.sql.connect.proto.types_pb2.DataType.timestamp"p
6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp"6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*π
timestamp_ntz:pyspark.sql.connect.proto.types_pb2.DataType.timestamp_ntz"v
9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ"9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*…
calendar_interval>pyspark.sql.connect.proto.types_pb2.DataType.calendar_interval"~
=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval"=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*–
year_month_interval@pyspark.sql.connect.proto.types_pb2.DataType.year_month_interval"Ä
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*«
day_time_interval>pyspark.sql.connect.proto.types_pb2.DataType.day_time_interval"|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*õ
array2pyspark.sql.connect.proto.types_pb2.DataType.array"h
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ü
struct3pyspark.sql.connect.proto.types_pb2.DataType.struct"j
3pyspark.sql.connect.proto.types_pb2.DataType.Struct"3pyspark.sql.connect.proto.types_pb2.DataType.Struct*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ì
map0pyspark.sql.connect.proto.types_pb2.DataType.map"d
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ì
udt0pyspark.sql.connect.proto.types_pb2.DataType.udt"d
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*ß
unparsed5pyspark.sql.connect.proto.types_pb2.DataType.unparsed"n
5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed"5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType0:property`*´(
__init__5pyspark.sql.connect.proto.types_pb2.DataType.__init__"
None*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*¿
null≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.NULL,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.NULL"1pyspark.sql.connect.proto.types_pb2.DataType.NULL
None *»
binaryπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.Binary,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.Binary"3pyspark.sql.connect.proto.types_pb2.DataType.Binary
None *Ã
booleanº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.Boolean,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.Boolean"4pyspark.sql.connect.proto.types_pb2.DataType.Boolean
None *¿
byte≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Byte,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Byte"1pyspark.sql.connect.proto.types_pb2.DataType.Byte
None *ƒ
short∂
>Union[pyspark.sql.connect.proto.types_pb2.DataType.Short,None]h
2pyspark.sql.connect.proto.types_pb2.DataType.Short"2pyspark.sql.connect.proto.types_pb2.DataType.Short
None *Ã
integerº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.Integer,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.Integer"4pyspark.sql.connect.proto.types_pb2.DataType.Integer
None *¿
long≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Long,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Long"1pyspark.sql.connect.proto.types_pb2.DataType.Long
None *ƒ
float∂
>Union[pyspark.sql.connect.proto.types_pb2.DataType.Float,None]h
2pyspark.sql.connect.proto.types_pb2.DataType.Float"2pyspark.sql.connect.proto.types_pb2.DataType.Float
None *»
doubleπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.Double,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.Double"3pyspark.sql.connect.proto.types_pb2.DataType.Double
None *Ã
decimalº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.Decimal,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.Decimal"4pyspark.sql.connect.proto.types_pb2.DataType.Decimal
None *»
stringπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.String,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.String"3pyspark.sql.connect.proto.types_pb2.DataType.String
None *¿
char≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Char,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Char"1pyspark.sql.connect.proto.types_pb2.DataType.Char
None *Õ
var_charº
@Union[pyspark.sql.connect.proto.types_pb2.DataType.VarChar,None]l
4pyspark.sql.connect.proto.types_pb2.DataType.VarChar"4pyspark.sql.connect.proto.types_pb2.DataType.VarChar
None *¿
date≥
=Union[pyspark.sql.connect.proto.types_pb2.DataType.Date,None]f
1pyspark.sql.connect.proto.types_pb2.DataType.Date"1pyspark.sql.connect.proto.types_pb2.DataType.Date
None *‘
	timestamp¬
BUnion[pyspark.sql.connect.proto.types_pb2.DataType.Timestamp,None]p
6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp"6pyspark.sql.connect.proto.types_pb2.DataType.Timestamp
None *·
timestamp_ntzÀ
EUnion[pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ,None]v
9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ"9pyspark.sql.connect.proto.types_pb2.DataType.TimestampNTZ
None *Ò
calendar_interval◊
IUnion[pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval,None]~
=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval"=pyspark.sql.connect.proto.types_pb2.DataType.CalendarInterval
None *˜
year_month_interval€
JUnion[pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval,None]Ä
>pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval">pyspark.sql.connect.proto.types_pb2.DataType.YearMonthInterval
None *Ó
day_time_interval‘
HUnion[pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval,None]|
<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval"<pyspark.sql.connect.proto.types_pb2.DataType.DayTimeInterval
None *ƒ
array∂
>Union[pyspark.sql.connect.proto.types_pb2.DataType.Array,None]h
2pyspark.sql.connect.proto.types_pb2.DataType.Array"2pyspark.sql.connect.proto.types_pb2.DataType.Array
None *»
structπ
?Union[pyspark.sql.connect.proto.types_pb2.DataType.Struct,None]j
3pyspark.sql.connect.proto.types_pb2.DataType.Struct"3pyspark.sql.connect.proto.types_pb2.DataType.Struct
None *º
map∞
<Union[pyspark.sql.connect.proto.types_pb2.DataType.Map,None]d
0pyspark.sql.connect.proto.types_pb2.DataType.Map"0pyspark.sql.connect.proto.types_pb2.DataType.Map
None *º
udt∞
<Union[pyspark.sql.connect.proto.types_pb2.DataType.UDT,None]d
0pyspark.sql.connect.proto.types_pb2.DataType.UDT"0pyspark.sql.connect.proto.types_pb2.DataType.UDT
None *–
unparsedø
AUnion[pyspark.sql.connect.proto.types_pb2.DataType.Unparsed,None]n
5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed"5pyspark.sql.connect.proto.types_pb2.DataType.Unparsed
None *û"
HasField5pyspark.sql.connect.proto.types_pb2.DataType.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*“ 

field_name¡ 
Ñ	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*å"

ClearField7pyspark.sql.connect.proto.types_pb2.DataType.ClearField"
None*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*“ 

field_name¡ 
Ñ	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˜

WhichOneof7pyspark.sql.connect.proto.types_pb2.DataType.WhichOneof"Ç
õUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.types_pb2.DataType.DESCRIPTOR
Anyrq
NULL_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.NULL_FIELD_NUMBER
builtins.int"builtins.intru
BINARY_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.BINARY_FIELD_NUMBER
builtins.int"builtins.intrw
BOOLEAN_FIELD_NUMBERApyspark.sql.connect.proto.types_pb2.DataType.BOOLEAN_FIELD_NUMBER
builtins.int"builtins.intrq
BYTE_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.BYTE_FIELD_NUMBER
builtins.int"builtins.intrs
SHORT_FIELD_NUMBER?pyspark.sql.connect.proto.types_pb2.DataType.SHORT_FIELD_NUMBER
builtins.int"builtins.intrw
INTEGER_FIELD_NUMBERApyspark.sql.connect.proto.types_pb2.DataType.INTEGER_FIELD_NUMBER
builtins.int"builtins.intrq
LONG_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.LONG_FIELD_NUMBER
builtins.int"builtins.intrs
FLOAT_FIELD_NUMBER?pyspark.sql.connect.proto.types_pb2.DataType.FLOAT_FIELD_NUMBER
builtins.int"builtins.intru
DOUBLE_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.DOUBLE_FIELD_NUMBER
builtins.int"builtins.intrw
DECIMAL_FIELD_NUMBERApyspark.sql.connect.proto.types_pb2.DataType.DECIMAL_FIELD_NUMBER
builtins.int"builtins.intru
STRING_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.STRING_FIELD_NUMBER
builtins.int"builtins.intrq
CHAR_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.CHAR_FIELD_NUMBER
builtins.int"builtins.intry
VAR_CHAR_FIELD_NUMBERBpyspark.sql.connect.proto.types_pb2.DataType.VAR_CHAR_FIELD_NUMBER
builtins.int"builtins.intrq
DATE_FIELD_NUMBER>pyspark.sql.connect.proto.types_pb2.DataType.DATE_FIELD_NUMBER
builtins.int"builtins.intr{
TIMESTAMP_FIELD_NUMBERCpyspark.sql.connect.proto.types_pb2.DataType.TIMESTAMP_FIELD_NUMBER
builtins.int"builtins.intrÉ
TIMESTAMP_NTZ_FIELD_NUMBERGpyspark.sql.connect.proto.types_pb2.DataType.TIMESTAMP_NTZ_FIELD_NUMBER
builtins.int"builtins.intrã
CALENDAR_INTERVAL_FIELD_NUMBERKpyspark.sql.connect.proto.types_pb2.DataType.CALENDAR_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrè
 YEAR_MONTH_INTERVAL_FIELD_NUMBERMpyspark.sql.connect.proto.types_pb2.DataType.YEAR_MONTH_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrã
DAY_TIME_INTERVAL_FIELD_NUMBERKpyspark.sql.connect.proto.types_pb2.DataType.DAY_TIME_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrs
ARRAY_FIELD_NUMBER?pyspark.sql.connect.proto.types_pb2.DataType.ARRAY_FIELD_NUMBER
builtins.int"builtins.intru
STRUCT_FIELD_NUMBER@pyspark.sql.connect.proto.types_pb2.DataType.STRUCT_FIELD_NUMBER
builtins.int"builtins.intro
MAP_FIELD_NUMBER=pyspark.sql.connect.proto.types_pb2.DataType.MAP_FIELD_NUMBER
builtins.int"builtins.intro
UDT_FIELD_NUMBER=pyspark.sql.connect.proto.types_pb2.DataType.UDT_FIELD_NUMBER
builtins.int"builtins.intry
UNPARSED_FIELD_NUMBERBpyspark.sql.connect.proto.types_pb2.DataType.UNPARSED_FIELD_NUMBER
builtins.int"builtins.intém
Command.pyspark.sql.connect.proto.commands_pb2.Command"builtins.object*Ë
register_function@pyspark.sql.connect.proto.commands_pb2.Command.register_function"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*ª
write_operation>pyspark.sql.connect.proto.commands_pb2.Command.write_operation"n
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*‡
create_dataframe_viewDpyspark.sql.connect.proto.commands_pb2.Command.create_dataframe_view"Ü
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*≈
write_operation_v2Apyspark.sql.connect.proto.commands_pb2.Command.write_operation_v2"r
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*´
sql_command:pyspark.sql.connect.proto.commands_pb2.Command.sql_command"f
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*Ï
write_stream_operation_startKpyspark.sql.connect.proto.commands_pb2.Command.write_stream_operation_start"Ñ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*Ÿ
streaming_query_commandFpyspark.sql.connect.proto.commands_pb2.Command.streaming_query_command"|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*—
get_resources_commandDpyspark.sql.connect.proto.commands_pb2.Command.get_resources_command"x
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*¯
streaming_query_manager_commandNpyspark.sql.connect.proto.commands_pb2.Command.streaming_query_manager_command"ä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*˙
register_table_functionFpyspark.sql.connect.proto.commands_pb2.Command.register_table_function"ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*»
	extension8pyspark.sql.connect.proto.commands_pb2.Command.extension"
Any*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command0:property`*√
__init__7pyspark.sql.connect.proto.commands_pb2.Command.__init__"
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*ñ
register_function¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *◊
write_operationø
AUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation,None]n
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation
None *Ç
create_dataframe_view‰
MUnion[pyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand,None]Ü
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand
None *‡
write_operation_v2≈
CUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperationV2,None]r
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2
None *«
sql_command≥
=Union[pyspark.sql.connect.proto.commands_pb2.SqlCommand,None]f
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand
None *Ü
write_stream_operation_start·
LUnion[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart,None]Ñ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart
None *Ù
streaming_query_command‘
HUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand,None]|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand
None *Ï
get_resources_commandŒ
FUnion[pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand,None]x
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand
None *í
streaming_query_manager_commandÍ
OUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand,None]ä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand
None *•
register_table_functionÖ
XUnion[pyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction,None]ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction
None *7
	extension&
Union[Any,None]
Any
None *∂
HasField7pyspark.sql.connect.proto.commands_pb2.Command.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*‰

field_name”
ÆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearField9pyspark.sql.connect.proto.commands_pb2.Command.ClearField"
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*‰

field_name”
ÆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙	

WhichOneof9pyspark.sql.connect.proto.commands_pb2.Command.WhichOneof"ˇ
˝Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.commands_pb2.Command".pyspark.sql.connect.proto.commands_pb2.Command*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.commands_pb2.Command.DESCRIPTOR
Anyrç
REGISTER_FUNCTION_FIELD_NUMBERMpyspark.sql.connect.proto.commands_pb2.Command.REGISTER_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrâ
WRITE_OPERATION_FIELD_NUMBERKpyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_FIELD_NUMBER
builtins.int"builtins.intrï
"CREATE_DATAFRAME_VIEW_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.Command.CREATE_DATAFRAME_VIEW_FIELD_NUMBER
builtins.int"builtins.intrè
WRITE_OPERATION_V2_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.Command.WRITE_OPERATION_V2_FIELD_NUMBER
builtins.int"builtins.intrÅ
SQL_COMMAND_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.Command.SQL_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr£
)WRITE_STREAM_OPERATION_START_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.Command.WRITE_STREAM_OPERATION_START_FIELD_NUMBER
builtins.int"builtins.intrô
$STREAMING_QUERY_COMMAND_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.Command.STREAMING_QUERY_COMMAND_FIELD_NUMBER
builtins.int"builtins.intrï
"GET_RESOURCES_COMMAND_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.Command.GET_RESOURCES_COMMAND_FIELD_NUMBER
builtins.int"builtins.intr©
,STREAMING_QUERY_MANAGER_COMMAND_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.Command.STREAMING_QUERY_MANAGER_COMMAND_FIELD_NUMBER
builtins.int"builtins.intrô
$REGISTER_TABLE_FUNCTION_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.Command.REGISTER_TABLE_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr}
EXTENSION_FIELD_NUMBEREpyspark.sql.connect.proto.commands_pb2.Command.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intº

SqlCommand1pyspark.sql.connect.proto.commands_pb2.SqlCommand"builtins.object*«
args6pyspark.sql.connect.proto.commands_pb2.SqlCommand.args"
Any*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand0:property`*œ
pos_args:pyspark.sql.connect.proto.commands_pb2.SqlCommand.pos_args"
Any*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand0:property`*‘
__init__:pyspark.sql.connect.proto.commands_pb2.SqlCommand.__init__"
None*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*'
sql
builtins.str"builtins.str *ä
args˝
eUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]á
Ytyping.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]
builtins.str"builtins.str|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Mapping
None *Ÿ
pos_args»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *◊

ClearField<pyspark.sql.connect.proto.commands_pb2.SqlCommand.ClearField"
None*p
selff
1pyspark.sql.connect.proto.commands_pb2.SqlCommand"1pyspark.sql.connect.proto.commands_pb2.SqlCommand*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.commands_pb2.SqlCommand.DESCRIPTOR
Anyrt
SQL_FIELD_NUMBERBpyspark.sql.connect.proto.commands_pb2.SqlCommand.SQL_FIELD_NUMBER
builtins.int"builtins.intrv
ARGS_FIELD_NUMBERCpyspark.sql.connect.proto.commands_pb2.SqlCommand.ARGS_FIELD_NUMBER
builtins.int"builtins.intr~
POS_ARGS_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.SqlCommand.POS_ARGS_FIELD_NUMBER
builtins.int"builtins.intrZ
sql5pyspark.sql.connect.proto.commands_pb2.SqlCommand.sql
builtins.str"builtins.strâ
CreateDataFrameViewCommandApyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"builtins.object*ÿ
inputGpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand0:property`*ø
__init__Jpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.__init__"
None*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
name
builtins.str"builtins.str */
	is_global
builtins.bool"builtins.bool *-
replace
builtins.bool"builtins.bool *Œ
HasFieldJpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.HasField"
builtins.bool"builtins.bool*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ø

ClearFieldLpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.ClearField"
None*ë
selfÜ
Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand"Apyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrc

DESCRIPTORLpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.DESCRIPTOR
Anyrà
INPUT_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÜ
NAME_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.NAME_FIELD_NUMBER
builtins.int"builtins.intrê
IS_GLOBAL_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.IS_GLOBAL_FIELD_NUMBER
builtins.int"builtins.intrå
REPLACE_FIELD_NUMBERVpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.REPLACE_FIELD_NUMBER
builtins.int"builtins.intrl
nameFpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.name
builtins.str"builtins.strrx
	is_globalKpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.is_global
builtins.bool"builtins.boolrt
replaceIpyspark.sql.connect.proto.commands_pb2.CreateDataFrameViewCommand.replace
builtins.bool"builtins.bool≤W
WriteOperation5pyspark.sql.connect.proto.commands_pb2.WriteOperation"builtins.object*≤
input;pyspark.sql.connect.proto.commands_pb2.WriteOperation.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*—
table;pyspark.sql.connect.proto.commands_pb2.WriteOperation.table"Ç
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*Ì
sort_column_namesGpyspark.sql.connect.proto.commands_pb2.WriteOperation.sort_column_names"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*Û
partitioning_columnsJpyspark.sql.connect.proto.commands_pb2.WriteOperation.partitioning_columns"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*◊
	bucket_by?pyspark.sql.connect.proto.commands_pb2.WriteOperation.bucket_by"Ä
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*Ÿ
options=pyspark.sql.connect.proto.commands_pb2.WriteOperation.options"
Any*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation0:property`*¨
__init__>pyspark.sql.connect.proto.commands_pb2.WriteOperation.__init__"
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *R
sourceD
Union[builtins.str,None]
builtins.str"builtins.str
None *(
path
builtins.str"builtins.str *Ï
tableﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable,None]Ç
?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable"?pyspark.sql.connect.proto.commands_pb2.WriteOperation.SaveTable
None *£
modeñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType *°
sort_column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *§
partitioning_columnsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Ì
	bucket_by€
JUnion[pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy,None]Ä
>pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy">pyspark.sql.connect.proto.commands_pb2.WriteOperation.BucketBy
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *ç
HasField>pyspark.sql.connect.proto.commands_pb2.WriteOperation.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ì

ClearField@pyspark.sql.connect.proto.commands_pb2.WriteOperation.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*æ

field_name≠
ÄUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2º	

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX‹

WhichOneof@pyspark.sql.connect.proto.commands_pb2.WriteOperation.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.commands_pb2.WriteOperation"5pyspark.sql.connect.proto.commands_pb2.WriteOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.commands_pb2.WriteOperation.DESCRIPTOR
Anyr˝
SAVE_MODE_UNSPECIFIEDKpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_UNSPECIFIEDñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperÛ
SAVE_MODE_APPENDFpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_APPENDñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyper˘
SAVE_MODE_OVERWRITEIpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_OVERWRITEñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperÖ
SAVE_MODE_ERROR_IF_EXISTSOpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_ERROR_IF_EXISTSñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyperÛ
SAVE_MODE_IGNOREFpyspark.sql.connect.proto.commands_pb2.WriteOperation.SAVE_MODE_IGNOREñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTyper|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.commands_pb2.WriteOperation.INPUT_FIELD_NUMBER
builtins.int"builtins.intr~
SOURCE_FIELD_NUMBERIpyspark.sql.connect.proto.commands_pb2.WriteOperation.SOURCE_FIELD_NUMBER
builtins.int"builtins.intrz
PATH_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.WriteOperation.PATH_FIELD_NUMBER
builtins.int"builtins.intr|
TABLE_FIELD_NUMBERHpyspark.sql.connect.proto.commands_pb2.WriteOperation.TABLE_FIELD_NUMBER
builtins.int"builtins.intrz
MODE_FIELD_NUMBERGpyspark.sql.connect.proto.commands_pb2.WriteOperation.MODE_FIELD_NUMBER
builtins.int"builtins.intrî
SORT_COLUMN_NAMES_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.WriteOperation.SORT_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intrö
!PARTITIONING_COLUMNS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.WriteOperation.PARTITIONING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÑ
BUCKET_BY_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.WriteOperation.BUCKET_BY_FIELD_NUMBER
builtins.int"builtins.intrÄ
OPTIONS_FIELD_NUMBERJpyspark.sql.connect.proto.commands_pb2.WriteOperation.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrd
source<pyspark.sql.connect.proto.commands_pb2.WriteOperation.source
builtins.str"builtins.strr`
path:pyspark.sql.connect.proto.commands_pb2.WriteOperation.path
builtins.str"builtins.strr€
mode:pyspark.sql.connect.proto.commands_pb2.WriteOperation.modeñ
Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueType"Ipyspark.sql.connect.proto.commands_pb2.WriteOperation._SaveMode.ValueTypeÎK
WriteOperationV27pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"builtins.object*∏
input=pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*˘
partitioning_columnsLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.partitioning_columns"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*ﬂ
options?pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.options"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*Ò
table_propertiesHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_properties"
Any*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*‹
overwrite_conditionKpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.overwrite_condition"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV20:property`*á
__init__@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.__init__"
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *.

table_name
builtins.str"builtins.str *T
providerD
Union[builtins.str,None]
builtins.str"builtins.str
None *≈
partitioning_columns®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *’
table_propertiesº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *ü
modeí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType *ÿ
overwrite_conditionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *°
HasField@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.HasField"
builtins.bool"builtins.bool*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Õ

ClearFieldBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

WhichOneofBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*|
selfr
7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2"7pyspark.sql.connect.proto.commands_pb2.WriteOperationV2*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.DESCRIPTOR
AnyrÒ
MODE_UNSPECIFIEDHpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_UNSPECIFIEDí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÁ
MODE_CREATECpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÌ
MODE_OVERWRITEFpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÉ
MODE_OVERWRITE_PARTITIONSQpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_OVERWRITE_PARTITIONSí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÁ
MODE_APPENDCpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_APPENDí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyperÈ
MODE_REPLACEDpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_REPLACEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper˝
MODE_CREATE_OR_REPLACENpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_CREATE_OR_REPLACEí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTyper~
INPUT_FIELD_NUMBERJpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.INPUT_FIELD_NUMBER
builtins.int"builtins.intrà
TABLE_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrÑ
PROVIDER_FIELD_NUMBERMpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PROVIDER_FIELD_NUMBER
builtins.int"builtins.intrú
!PARTITIONING_COLUMNS_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.PARTITIONING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÇ
OPTIONS_FIELD_NUMBERLpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrî
TABLE_PROPERTIES_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.TABLE_PROPERTIES_FIELD_NUMBER
builtins.int"builtins.intr|
MODE_FIELD_NUMBERIpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.MODE_FIELD_NUMBER
builtins.int"builtins.intrö
 OVERWRITE_CONDITION_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.OVERWRITE_CONDITION_FIELD_NUMBER
builtins.int"builtins.intrn

table_nameBpyspark.sql.connect.proto.commands_pb2.WriteOperationV2.table_name
builtins.str"builtins.strrj
provider@pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.provider
builtins.str"builtins.strrŸ
mode<pyspark.sql.connect.proto.commands_pb2.WriteOperationV2.modeí
Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueType"Gpyspark.sql.connect.proto.commands_pb2.WriteOperationV2._Mode.ValueTypeÿi
WriteStreamOperationStart@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"builtins.object*’
inputFpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*¸
optionsHpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.options"
Any*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*†
partitioning_column_namesZpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.partitioning_column_names"
Any*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*Ü
foreach_writerOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.foreach_writer"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*Ñ
foreach_batchNpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.foreach_batch"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart0:property`*Ê
__init__Ipyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None **
format
builtins.str"builtins.str *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *©
partitioning_column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *<
processing_time_interval
builtins.str"builtins.str *3
available_now
builtins.bool"builtins.bool **
once
builtins.bool"builtins.bool *B
continuous_checkpoint_interval
builtins.str"builtins.str */
output_mode
builtins.str"builtins.str *.

query_name
builtins.str"builtins.str *(
path
builtins.str"builtins.str *.

table_name
builtins.str"builtins.str *ı
foreach_writerﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction
None *Ù
foreach_batchﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction
None *»
HasFieldIpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.HasField"
builtins.bool"builtins.bool*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*æ

field_name≠
ÄUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

ClearFieldKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¸

field_nameÎ
ÊUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2˚

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneofˇ

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXù

WhichOneofKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.WhichOneof"’
cUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart"@pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrb

DESCRIPTORKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.DESCRIPTOR
Anyrá
INPUT_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.INPUT_FIELD_NUMBER
builtins.int"builtins.intrâ
FORMAT_FIELD_NUMBERTpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FORMAT_FIELD_NUMBER
builtins.int"builtins.intrã
OPTIONS_FIELD_NUMBERUpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrØ
&PARTITIONING_COLUMN_NAMES_FIELD_NUMBERgpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PARTITIONING_COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intr≠
%PROCESSING_TIME_INTERVAL_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PROCESSING_TIME_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intró
AVAILABLE_NOW_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.AVAILABLE_NOW_FIELD_NUMBER
builtins.int"builtins.intrÖ
ONCE_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.ONCE_FIELD_NUMBER
builtins.int"builtins.intrπ
+CONTINUOUS_CHECKPOINT_INTERVAL_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.CONTINUOUS_CHECKPOINT_INTERVAL_FIELD_NUMBER
builtins.int"builtins.intrì
OUTPUT_MODE_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.OUTPUT_MODE_FIELD_NUMBER
builtins.int"builtins.intrë
QUERY_NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.QUERY_NAME_FIELD_NUMBER
builtins.int"builtins.intrÖ
PATH_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.PATH_FIELD_NUMBER
builtins.int"builtins.intrë
TABLE_NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrô
FOREACH_WRITER_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FOREACH_WRITER_FIELD_NUMBER
builtins.int"builtins.intró
FOREACH_BATCH_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.FOREACH_BATCH_FIELD_NUMBER
builtins.int"builtins.intro
formatGpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.format
builtins.str"builtins.strrì
processing_time_intervalYpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.processing_time_interval
builtins.str"builtins.strr
available_nowNpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.available_now
builtins.bool"builtins.boolrm
onceEpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.once
builtins.bool"builtins.boolrü
continuous_checkpoint_interval_pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.continuous_checkpoint_interval
builtins.str"builtins.strry
output_modeLpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.output_mode
builtins.str"builtins.strrw

query_nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.query_name
builtins.str"builtins.strrk
pathEpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.path
builtins.str"builtins.strrw

table_nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStart.table_name
builtins.str"builtins.strú 
StreamingForeachFunction?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"builtins.object*Ï
python_functionOpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.python_function"j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction0:property`*Ù
scala_functionNpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.scala_function"t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction0:property`*§
__init__Hpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*—
python_functionπ
?Union[pyspark.sql.connect.proto.expressions_pb2.PythonUDF,None]j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF
None *ﬂ
scala_function»
DUnion[pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF,None]t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF
None *ï
HasFieldHpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearFieldJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Á

WhichOneofJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction"?pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.DESCRIPTOR
Anyrö
PYTHON_FUNCTION_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.PYTHON_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrò
SCALA_FUNCTION_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.StreamingForeachFunction.SCALA_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intÄ
WriteStreamOperationStartResultFpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"builtins.object*å
query_idOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.query_id"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult0:property`*ü
__init__Opyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.__init__"
None*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*Ô
query_idﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *(
name
builtins.str"builtins.str *›
HasFieldOpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.HasField"
builtins.bool"builtins.bool*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ò

ClearFieldQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.ClearField"
None*õ
selfê
Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult"Fpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrh

DESCRIPTORQpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.DESCRIPTOR
Anyrì
QUERY_ID_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intrã
NAME_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.NAME_FIELD_NUMBER
builtins.int"builtins.intrq
nameKpyspark.sql.connect.proto.commands_pb2.WriteStreamOperationStartResult.name
builtins.str"builtins.strŸ
StreamingQueryInstanceId?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"builtins.object*¬
__init__Hpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*&
id
builtins.str"builtins.str **
run_id
builtins.str"builtins.str *‹

ClearFieldJpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.DESCRIPTOR
AnyrÄ
ID_FIELD_NUMBEROpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.ID_FIELD_NUMBER
builtins.int"builtins.intrà
RUN_ID_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.RUN_ID_FIELD_NUMBER
builtins.int"builtins.intrf
idBpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.id
builtins.str"builtins.strrn
run_idFpyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId.run_id
builtins.str"builtins.strúL
StreamingQueryCommand<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"builtins.object*Ì
query_idEpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.query_id"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:property`*É
explainDpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.explain"ö
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:property`*©
await_terminationNpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.await_termination"¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand0:property`*Ÿ

__init__Epyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*Ô
query_idﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *,
status
builtins.bool"builtins.bool *3
last_progress
builtins.bool"builtins.bool *5
recent_progress
builtins.bool"builtins.bool **
stop
builtins.bool"builtins.bool *;
process_all_available
builtins.bool"builtins.bool *í
explainÇ
WUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand,None]ö
Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand"Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ExplainCommand
None */
	exception
builtins.bool"builtins.bool *∑
await_terminationù
`Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand,None]¨
Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand"Tpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AwaitTerminationCommand
None *ï
HasFieldEpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.HasField"
builtins.bool"builtins.bool*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*ò

field_nameá
“Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearFieldGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*ò

field_nameá
“Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∏

WhichOneofGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.WhichOneof"í
ªUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ü
self|
<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand"<pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.DESCRIPTOR
Anyrâ
QUERY_ID_FIELD_NUMBERRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intrÖ
STATUS_FIELD_NUMBERPpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.STATUS_FIELD_NUMBER
builtins.int"builtins.intrì
LAST_PROGRESS_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.LAST_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intró
RECENT_PROGRESS_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.RECENT_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intrÅ
STOP_FIELD_NUMBERNpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.STOP_FIELD_NUMBER
builtins.int"builtins.intr£
"PROCESS_ALL_AVAILABLE_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.PROCESS_ALL_AVAILABLE_FIELD_NUMBER
builtins.int"builtins.intrá
EXPLAIN_FIELD_NUMBERQpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrã
EXCEPTION_FIELD_NUMBERSpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.EXCEPTION_FIELD_NUMBER
builtins.int"builtins.intrõ
AWAIT_TERMINATION_FIELD_NUMBER[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.AWAIT_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intrm
statusCpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.status
builtins.bool"builtins.boolr{
last_progressJpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.last_progress
builtins.bool"builtins.boolr
recent_progressLpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.recent_progress
builtins.bool"builtins.boolri
stopApyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.stop
builtins.bool"builtins.boolrã
process_all_availableRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.process_all_available
builtins.bool"builtins.boolrs
	exceptionFpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommand.exception
builtins.bool"builtins.boolÄJ
StreamingQueryCommandResultBpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"builtins.object*Ä
query_idKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.query_id"Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*ú
statusIpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.status"¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*æ
recent_progressRpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.recent_progress"≤
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*†
explainJpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.explain"§
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*®
	exceptionLpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.exception"®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*∆
await_terminationTpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.await_termination"∂
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult0:property`*„
__init__Kpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.__init__"
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*Ô
query_idﬁ
KUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId,None]Ç
?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId"?pyspark.sql.connect.proto.commands_pb2.StreamingQueryInstanceId
None *ù
statusé
[Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult,None]¢
Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult"Opyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.StatusResult
None *æ
recent_progress¶
cUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult,None]≤
Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult"Wpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RecentProgressResult
None *°
explainë
\Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult,None]§
Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult"Ppyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExplainResult
None *©
	exceptionó
^Union[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult,None]®
Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult"Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ExceptionResult
None *∆
await_termination¨
eUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult,None]∂
Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult"Ypyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AwaitTerminationResult
None *∂
HasFieldKpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.HasField"
builtins.bool"builtins.bool*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearFieldMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.ClearField"
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*›

WhichOneofMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.WhichOneof"§
yUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ì
selfà
Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult"Bpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrd

DESCRIPTORMpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.DESCRIPTOR
Anyrè
QUERY_ID_FIELD_NUMBERXpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.QUERY_ID_FIELD_NUMBER
builtins.int"builtins.intrã
STATUS_FIELD_NUMBERVpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.STATUS_FIELD_NUMBER
builtins.int"builtins.intrù
RECENT_PROGRESS_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.RECENT_PROGRESS_FIELD_NUMBER
builtins.int"builtins.intrç
EXPLAIN_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.EXPLAIN_FIELD_NUMBER
builtins.int"builtins.intrë
EXCEPTION_FIELD_NUMBERYpyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.EXCEPTION_FIELD_NUMBER
builtins.int"builtins.intr°
AWAIT_TERMINATION_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryCommandResult.AWAIT_TERMINATION_FIELD_NUMBER
builtins.int"builtins.int«F
StreamingQueryManagerCommandCpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"builtins.object*€
await_any_terminationYpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.await_any_termination"¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:property`*œ
add_listenerPpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.add_listener"∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:property`*’
remove_listenerSpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.remove_listener"∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand0:property`*‹
__init__Lpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.__init__"
None*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*,
active
builtins.bool"builtins.bool *-
	get_query
builtins.str"builtins.str *Ÿ
await_any_terminationª
jUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand,None]¿
^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand"^pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AwaitAnyTerminationCommand
None *6
reset_terminated
builtins.bool"builtins.bool *Ÿ
add_listenerƒ
mUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand,None]∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand
None *‹
remove_listenerƒ
mUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand,None]∆
apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand"apyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.StreamingQueryListenerCommand
None *4
list_listeners
builtins.bool"builtins.bool *ﬂ
HasFieldLpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.HasField"
builtins.bool"builtins.bool*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Õ

ClearFieldNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ClearField"
None*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ˇ

WhichOneofNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.WhichOneof"√
•Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*ï
selfä
Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand"Cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesre

DESCRIPTORNpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.DESCRIPTOR
Anyrå
ACTIVE_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ACTIVE_FIELD_NUMBER
builtins.int"builtins.intrí
GET_QUERY_FIELD_NUMBERZpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.GET_QUERY_FIELD_NUMBER
builtins.int"builtins.intr™
"AWAIT_ANY_TERMINATION_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.AWAIT_ANY_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intr†
RESET_TERMINATED_FIELD_NUMBERapyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.RESET_TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrò
ADD_LISTENER_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.ADD_LISTENER_FIELD_NUMBER
builtins.int"builtins.intrû
REMOVE_LISTENER_FIELD_NUMBER`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.REMOVE_LISTENER_FIELD_NUMBER
builtins.int"builtins.intrú
LIST_LISTENERS_FIELD_NUMBER_pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.LIST_LISTENERS_FIELD_NUMBER
builtins.int"builtins.intrt
activeJpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.active
builtins.bool"builtins.boolrx
	get_queryMpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.get_query
builtins.str"builtins.strrà
reset_terminatedTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.reset_terminated
builtins.bool"builtins.boolrÑ
list_listenersRpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommand.list_listeners
builtins.bool"builtins.boolòM
"StreamingQueryManagerCommandResultIpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"builtins.object*ø
activePpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.active"∞
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*—
queryOpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.query"ƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*˜
await_any_termination_pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.await_any_termination" 
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*˜
list_listenersXpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.list_listeners"ÿ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult0:property`*ö
__init__Rpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*≤
active£
bUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult,None]∞
Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult"Vpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ActiveResult
None *œ
query¡
lUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance,None]ƒ
`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance"`pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.StreamingQueryInstance
None *Ë
await_any_termination 
oUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult,None] 
cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult"cpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AwaitAnyTerminationResult
None *6
reset_terminated
builtins.bool"builtins.bool *2
add_listener
builtins.bool"builtins.bool *5
remove_listener
builtins.bool"builtins.bool *ˆ
list_listenersﬂ
vUnion[pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult,None]ÿ
jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult"jpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ListStreamingQueryListenerResult
None *Ò
HasFieldRpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.HasField"
builtins.bool"builtins.bool*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ﬂ

ClearFieldTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ClearField"
None*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ë

WhichOneofTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.WhichOneof"√
•Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*°
selfñ
Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult"Ipyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrk

DESCRIPTORTpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.DESCRIPTOR
Anyrí
ACTIVE_FIELD_NUMBER]pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ACTIVE_FIELD_NUMBER
builtins.int"builtins.intrê
QUERY_FIELD_NUMBER\pyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.QUERY_FIELD_NUMBER
builtins.int"builtins.intr∞
"AWAIT_ANY_TERMINATION_FIELD_NUMBERlpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.AWAIT_ANY_TERMINATION_FIELD_NUMBER
builtins.int"builtins.intr¶
RESET_TERMINATED_FIELD_NUMBERgpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.RESET_TERMINATED_FIELD_NUMBER
builtins.int"builtins.intrû
ADD_LISTENER_FIELD_NUMBERcpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.ADD_LISTENER_FIELD_NUMBER
builtins.int"builtins.intr§
REMOVE_LISTENER_FIELD_NUMBERfpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.REMOVE_LISTENER_FIELD_NUMBER
builtins.int"builtins.intr¢
LIST_LISTENERS_FIELD_NUMBERepyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.LIST_LISTENERS_FIELD_NUMBER
builtins.int"builtins.intré
reset_terminatedZpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.reset_terminated
builtins.bool"builtins.boolrÜ
add_listenerVpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.add_listener
builtins.bool"builtins.boolrå
remove_listenerYpyspark.sql.connect.proto.commands_pb2.StreamingQueryManagerCommandResult.remove_listener
builtins.bool"builtins.bool°
GetResourcesCommand:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand"builtins.object*ﬁ
__init__Cpyspark.sql.connect.proto.commands_pb2.GetResourcesCommand.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.commands_pb2.GetResourcesCommand":pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandr\

DESCRIPTOREpyspark.sql.connect.proto.commands_pb2.GetResourcesCommand.DESCRIPTOR
Anyô
GetResourcesCommandResult@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"builtins.object*Ä
	resourcesJpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.resources"
Any*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult0:property`*Û
__init__Ipyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.__init__"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*ˇ
	resourcesÌ
aUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.common_pb2.ResourceInformation],None]˚
Utyping.Mapping[builtins.str,pyspark.sql.connect.proto.common_pb2.ResourceInformation]
builtins.str"builtins.strt
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation"typing.Mapping
None *π

ClearFieldKpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.ClearField"
None*è
selfÑ
@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult"@pyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrb

DESCRIPTORKpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.DESCRIPTOR
Anyrè
RESOURCES_FIELD_NUMBERWpyspark.sql.connect.proto.commands_pb2.GetResourcesCommandResult.RESOURCES_FIELD_NUMBER
builtins.int"builtins.intÚ¶

Expression4pyspark.sql.connect.proto.expressions_pb2.Expression"builtins.object*À
literal<pyspark.sql.connect.proto.expressions_pb2.Expression.literal"|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*˛
unresolved_attributeIpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_attribute"î
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*˙
unresolved_functionHpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_function"í
Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*Ú
expression_stringFpyspark.sql.connect.proto.expressions_pb2.Expression.expression_string"é
Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString"Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*Í
unresolved_starDpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_star"ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*√
alias:pyspark.sql.connect.proto.expressions_pb2.Expression.alias"x
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*ø
cast9pyspark.sql.connect.proto.expressions_pb2.Expression.cast"v
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*Ó
unresolved_regexEpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_regex"å
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*÷

sort_order?pyspark.sql.connect.proto.expressions_pb2.Expression.sort_order"Ä
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*Í
lambda_functionDpyspark.sql.connect.proto.expressions_pb2.Expression.lambda_function"ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*«
window;pyspark.sql.connect.proto.expressions_pb2.Expression.window"z
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*å
unresolved_extract_valueMpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_extract_value"ö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*‚
update_fieldsBpyspark.sql.connect.proto.expressions_pb2.Expression.update_fields"Ü
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*™
 unresolved_named_lambda_variableUpyspark.sql.connect.proto.expressions_pb2.Expression.unresolved_named_lambda_variable"®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*û
#common_inline_user_defined_functionXpyspark.sql.connect.proto.expressions_pb2.Expression.common_inline_user_defined_function"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*À
call_functionBpyspark.sql.connect.proto.expressions_pb2.Expression.call_function"p
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*⁄
	extension>pyspark.sql.connect.proto.expressions_pb2.Expression.extension"
Any*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression0:property`*≥"
__init__=pyspark.sql.connect.proto.expressions_pb2.Expression.__init__"
None*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*‰
literal‘
HUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal,None]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal
None *ñ
unresolved_attribute˘
TUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute,None]î
Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute"Hpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedAttribute
None *í
unresolved_functionˆ
SUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction,None]í
Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction"Gpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedFunction
None *ä
expression_string
QUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString,None]é
Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString"Epyspark.sql.connect.proto.expressions_pb2.Expression.ExpressionString
None *Ç
unresolved_starÍ
OUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar,None]ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar"Cpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedStar
None *‹
aliasŒ
FUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Alias,None]x
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias
None *ÿ
castÀ
EUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Cast,None]v
9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast"9pyspark.sql.connect.proto.expressions_pb2.Expression.Cast
None *Ü
unresolved_regexÌ
PUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex,None]å
Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex"Dpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedRegex
None *Ó

sort_order€
JUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder,None]Ä
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder
None *Ç
lambda_functionÍ
OUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction,None]ä
Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction"Cpyspark.sql.connect.proto.expressions_pb2.Expression.LambdaFunction
None *‡
window—
GUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.Window,None]z
;pyspark.sql.connect.proto.expressions_pb2.Expression.Window";pyspark.sql.connect.proto.expressions_pb2.Expression.Window
None *£
unresolved_extract_valueÇ
WUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue,None]ö
Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue"Kpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedExtractValue
None *˙
update_fields‰
MUnion[pyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields,None]Ü
Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields"Apyspark.sql.connect.proto.expressions_pb2.Expression.UpdateFields
None *¿
 unresolved_named_lambda_variableó
^Union[pyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable,None]®
Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable"Rpyspark.sql.connect.proto.expressions_pb2.Expression.UnresolvedNamedLambdaVariable
None *®
#common_inline_user_defined_function¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *ÿ
call_function¬
BUnion[pyspark.sql.connect.proto.expressions_pb2.CallFunction,None]p
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction
None *7
	extension&
Union[Any,None]
Any
None *¨
HasField=pyspark.sql.connect.proto.expressions_pb2.Expression.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*»

field_name∑
¬Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ö

ClearField?pyspark.sql.connect.proto.expressions_pb2.Expression.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*»

field_name∑
¬Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ê

WhichOneof?pyspark.sql.connect.proto.expressions_pb2.Expression.WhichOneof"Ÿ

ÅUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.expressions_pb2.Expression.DESCRIPTOR
Anyr
LITERAL_FIELD_NUMBERIpyspark.sql.connect.proto.expressions_pb2.Expression.LITERAL_FIELD_NUMBER
builtins.int"builtins.intrô
!UNRESOLVED_ATTRIBUTE_FIELD_NUMBERVpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_ATTRIBUTE_FIELD_NUMBER
builtins.int"builtins.intró
 UNRESOLVED_FUNCTION_FIELD_NUMBERUpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrì
EXPRESSION_STRING_FIELD_NUMBERSpyspark.sql.connect.proto.expressions_pb2.Expression.EXPRESSION_STRING_FIELD_NUMBER
builtins.int"builtins.intrè
UNRESOLVED_STAR_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_STAR_FIELD_NUMBER
builtins.int"builtins.intr{
ALIAS_FIELD_NUMBERGpyspark.sql.connect.proto.expressions_pb2.Expression.ALIAS_FIELD_NUMBER
builtins.int"builtins.intry
CAST_FIELD_NUMBERFpyspark.sql.connect.proto.expressions_pb2.Expression.CAST_FIELD_NUMBER
builtins.int"builtins.intrë
UNRESOLVED_REGEX_FIELD_NUMBERRpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_REGEX_FIELD_NUMBER
builtins.int"builtins.intrÖ
SORT_ORDER_FIELD_NUMBERLpyspark.sql.connect.proto.expressions_pb2.Expression.SORT_ORDER_FIELD_NUMBER
builtins.int"builtins.intrè
LAMBDA_FUNCTION_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.Expression.LAMBDA_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr}
WINDOW_FIELD_NUMBERHpyspark.sql.connect.proto.expressions_pb2.Expression.WINDOW_FIELD_NUMBER
builtins.int"builtins.intr°
%UNRESOLVED_EXTRACT_VALUE_FIELD_NUMBERZpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_EXTRACT_VALUE_FIELD_NUMBER
builtins.int"builtins.intrã
UPDATE_FIELDS_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.UPDATE_FIELDS_FIELD_NUMBER
builtins.int"builtins.intr±
-UNRESOLVED_NAMED_LAMBDA_VARIABLE_FIELD_NUMBERbpyspark.sql.connect.proto.expressions_pb2.Expression.UNRESOLVED_NAMED_LAMBDA_VARIABLE_FIELD_NUMBER
builtins.int"builtins.intr∑
0COMMON_INLINE_USER_DEFINED_FUNCTION_FIELD_NUMBERepyspark.sql.connect.proto.expressions_pb2.Expression.COMMON_INLINE_USER_DEFINED_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrã
CALL_FUNCTION_FIELD_NUMBEROpyspark.sql.connect.proto.expressions_pb2.Expression.CALL_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrÉ
EXTENSION_FIELD_NUMBERKpyspark.sql.connect.proto.expressions_pb2.Expression.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intê:
CommonInlineUserDefinedFunctionIpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"builtins.object*õ
	argumentsSpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.arguments"
Any*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:property`*Ä

python_udfTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.python_udf"j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:property`*ñ
scalar_scala_udfZpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.scalar_scala_udf"t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:property`*¯
java_udfRpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.java_udf"f
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction0:property`*´

__init__Rpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.__init__"
None*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*1
function_name
builtins.str"builtins.str *3
deterministic
builtins.bool"builtins.bool *∫
	arguments®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Ã

python_udfπ
?Union[pyspark.sql.connect.proto.expressions_pb2.PythonUDF,None]j
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF
None *·
scalar_scala_udf»
DUnion[pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF,None]t
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF
None *ƒ
java_udf≥
=Union[pyspark.sql.connect.proto.expressions_pb2.JavaUDF,None]f
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF
None *Ÿ
HasFieldRpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.HasField"
builtins.bool"builtins.bool*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearFieldTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.ClearField"
None*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‘

WhichOneofTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.WhichOneof"Ü
MUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*°
selfñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrk

DESCRIPTORTpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.DESCRIPTOR
Anyr†
FUNCTION_NAME_FIELD_NUMBERdpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr†
DETERMINISTIC_FIELD_NUMBERdpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.DETERMINISTIC_FIELD_NUMBER
builtins.int"builtins.intrò
ARGUMENTS_FIELD_NUMBER`pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intrö
PYTHON_UDF_FIELD_NUMBERapyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.PYTHON_UDF_FIELD_NUMBER
builtins.int"builtins.intr¶
SCALAR_SCALA_UDF_FIELD_NUMBERgpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.SCALAR_SCALA_UDF_FIELD_NUMBER
builtins.int"builtins.intrñ
JAVA_UDF_FIELD_NUMBER_pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.JAVA_UDF_FIELD_NUMBER
builtins.int"builtins.intrÜ
function_nameWpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.function_name
builtins.str"builtins.strrà
deterministicWpyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction.deterministic
builtins.bool"builtins.boolÒ
	PythonUDF3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"builtins.object*∞
output_type?pyspark.sql.connect.proto.expressions_pb2.PythonUDF.output_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF0:property`*ì
__init__<pyspark.sql.connect.proto.expressions_pb2.PythonUDF.__init__"
None*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*∏
output_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *-
	eval_type
builtins.int"builtins.int */
command 
builtins.bytes"builtins.bytes *.

python_ver
builtins.str"builtins.str *¢
HasField<pyspark.sql.connect.proto.expressions_pb2.PythonUDF.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearField>pyspark.sql.connect.proto.expressions_pb2.PythonUDF.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.expressions_pb2.PythonUDF"3pyspark.sql.connect.proto.expressions_pb2.PythonUDF*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.expressions_pb2.PythonUDF.DESCRIPTOR
AnyrÜ
OUTPUT_TYPE_FIELD_NUMBERLpyspark.sql.connect.proto.expressions_pb2.PythonUDF.OUTPUT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÇ
EVAL_TYPE_FIELD_NUMBERJpyspark.sql.connect.proto.expressions_pb2.PythonUDF.EVAL_TYPE_FIELD_NUMBER
builtins.int"builtins.intr~
COMMAND_FIELD_NUMBERHpyspark.sql.connect.proto.expressions_pb2.PythonUDF.COMMAND_FIELD_NUMBER
builtins.int"builtins.intrÑ
PYTHON_VER_FIELD_NUMBERKpyspark.sql.connect.proto.expressions_pb2.PythonUDF.PYTHON_VER_FIELD_NUMBER
builtins.int"builtins.intrh
	eval_type=pyspark.sql.connect.proto.expressions_pb2.PythonUDF.eval_type
builtins.int"builtins.intrh
command;pyspark.sql.connect.proto.expressions_pb2.PythonUDF.command 
builtins.bytes"builtins.bytesrj

python_ver>pyspark.sql.connect.proto.expressions_pb2.PythonUDF.python_ver
builtins.str"builtins.str¬
ScalarScalaUDF8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"builtins.object*Ë

inputTypesCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.inputTypes"
Any*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF0:property`*Ω

outputTypeCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.outputType"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF0:property`*ê
__init__Apyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.__init__"
None*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*/
payload 
builtins.bytes"builtins.bytes *õ

inputTypesà
IUnion[typing.Iterable[pyspark.sql.connect.proto.types_pb2.DataType],None]Æ
=typing.Iterable[pyspark.sql.connect.proto.types_pb2.DataType]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType"typing.Iterable
None *∑

outputType§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *.
nullable
builtins.bool"builtins.bool *±
HasFieldApyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.HasField"
builtins.bool"builtins.bool*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*í

ClearFieldCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.ClearField"
None*~
selft
8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF"8pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.DESCRIPTOR
AnyrÉ
PAYLOAD_FIELD_NUMBERMpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.PAYLOAD_FIELD_NUMBER
builtins.int"builtins.intrâ
INPUTTYPES_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.INPUTTYPES_FIELD_NUMBER
builtins.int"builtins.intrâ
OUTPUTTYPE_FIELD_NUMBERPpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.OUTPUTTYPE_FIELD_NUMBER
builtins.int"builtins.intrÖ
NULLABLE_FIELD_NUMBERNpyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.NULLABLE_FIELD_NUMBER
builtins.int"builtins.intrm
payload@pyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.payload 
builtins.bytes"builtins.bytesrm
nullableApyspark.sql.connect.proto.expressions_pb2.ScalarScalaUDF.nullable
builtins.bool"builtins.bool∆
JavaUDF1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"builtins.object*™
output_type=pyspark.sql.connect.proto.expressions_pb2.JavaUDF.output_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF0:property`*ﬁ
__init__:pyspark.sql.connect.proto.expressions_pb2.JavaUDF.__init__"
None*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*.

class_name
builtins.str"builtins.str *∏
output_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None */
	aggregate
builtins.bool"builtins.bool *¬
HasField:pyspark.sql.connect.proto.expressions_pb2.JavaUDF.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˝

ClearField<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.ClearField"
None*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.expressions_pb2.JavaUDF"1pyspark.sql.connect.proto.expressions_pb2.JavaUDF*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.DESCRIPTOR
AnyrÇ
CLASS_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.expressions_pb2.JavaUDF.CLASS_NAME_FIELD_NUMBER
builtins.int"builtins.intrÑ
OUTPUT_TYPE_FIELD_NUMBERJpyspark.sql.connect.proto.expressions_pb2.JavaUDF.OUTPUT_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÄ
AGGREGATE_FIELD_NUMBERHpyspark.sql.connect.proto.expressions_pb2.JavaUDF.AGGREGATE_FIELD_NUMBER
builtins.int"builtins.intrh

class_name<pyspark.sql.connect.proto.expressions_pb2.JavaUDF.class_name
builtins.str"builtins.strrh
	aggregate;pyspark.sql.connect.proto.expressions_pb2.JavaUDF.aggregate
builtins.bool"builtins.boolß
CallFunction6pyspark.sql.connect.proto.expressions_pb2.CallFunction"builtins.object*‡
	arguments@pyspark.sql.connect.proto.expressions_pb2.CallFunction.arguments"
Any*z
selfp
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction0:property`*¡
__init__?pyspark.sql.connect.proto.expressions_pb2.CallFunction.__init__"
None*z
selfp
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction*1
function_name
builtins.str"builtins.str *∫
	arguments®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ø

ClearFieldApyspark.sql.connect.proto.expressions_pb2.CallFunction.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.expressions_pb2.CallFunction"6pyspark.sql.connect.proto.expressions_pb2.CallFunction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.expressions_pb2.CallFunction.DESCRIPTOR
Anyrç
FUNCTION_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.expressions_pb2.CallFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intrÖ
ARGUMENTS_FIELD_NUMBERMpyspark.sql.connect.proto.expressions_pb2.CallFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intrs
function_nameDpyspark.sql.connect.proto.expressions_pb2.CallFunction.function_name
builtins.str"builtins.str‘∂
Relation0pyspark.sql.connect.proto.relations_pb2.Relation"builtins.object*±
common7pyspark.sql.connect.proto.relations_pb2.Relation.common"p
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ô
read5pyspark.sql.connect.proto.relations_pb2.Relation.read"\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*•
project8pyspark.sql.connect.proto.relations_pb2.Relation.project"b
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*°
filter7pyspark.sql.connect.proto.relations_pb2.Relation.filter"`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ô
join5pyspark.sql.connect.proto.relations_pb2.Relation.join"\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*≠
set_op7pyspark.sql.connect.proto.relations_pb2.Relation.set_op"l
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ô
sort5pyspark.sql.connect.proto.relations_pb2.Relation.sort"\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ù
limit6pyspark.sql.connect.proto.relations_pb2.Relation.limit"^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*≠
	aggregate:pyspark.sql.connect.proto.relations_pb2.Relation.aggregate"f
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ï
sql4pyspark.sql.connect.proto.relations_pb2.Relation.sql"Z
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ø
local_relation?pyspark.sql.connect.proto.relations_pb2.Relation.local_relation"n
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*°
sample7pyspark.sql.connect.proto.relations_pb2.Relation.sample"`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*°
offset7pyspark.sql.connect.proto.relations_pb2.Relation.offset"`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*µ
deduplicate<pyspark.sql.connect.proto.relations_pb2.Relation.deduplicate"j
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ù
range6pyspark.sql.connect.proto.relations_pb2.Relation.range"^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ø
subquery_alias?pyspark.sql.connect.proto.relations_pb2.Relation.subquery_alias"n
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*µ
repartition<pyspark.sql.connect.proto.relations_pb2.Relation.repartition"j
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*õ
to_df6pyspark.sql.connect.proto.relations_pb2.Relation.to_df"\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*’
with_columns_renamedEpyspark.sql.connect.proto.relations_pb2.Relation.with_columns_renamed"x
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*≥
show_string<pyspark.sql.connect.proto.relations_pb2.Relation.show_string"h
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ô
drop5pyspark.sql.connect.proto.relations_pb2.Relation.drop"\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ô
tail5pyspark.sql.connect.proto.relations_pb2.Relation.tail"\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*∑
with_columns=pyspark.sql.connect.proto.relations_pb2.Relation.with_columns"j
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ô
hint5pyspark.sql.connect.proto.relations_pb2.Relation.hint"\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*•
unpivot8pyspark.sql.connect.proto.relations_pb2.Relation.unpivot"b
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*´
	to_schema:pyspark.sql.connect.proto.relations_pb2.Relation.to_schema"d
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*Í
repartition_by_expressionJpyspark.sql.connect.proto.relations_pb2.Relation.repartition_by_expression"Ç
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ø
map_partitions?pyspark.sql.connect.proto.relations_pb2.Relation.map_partitions"n
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*√
collect_metrics@pyspark.sql.connect.proto.relations_pb2.Relation.collect_metrics"p
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ù
parse6pyspark.sql.connect.proto.relations_pb2.Relation.parse"^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*´
	group_map:pyspark.sql.connect.proto.relations_pb2.Relation.group_map"d
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*µ
co_group_map=pyspark.sql.connect.proto.relations_pb2.Relation.co_group_map"h
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ø
with_watermark?pyspark.sql.connect.proto.relations_pb2.Relation.with_watermark"n
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*Í
apply_in_pandas_with_stateKpyspark.sql.connect.proto.relations_pb2.Relation.apply_in_pandas_with_state"Ä
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*≥
html_string<pyspark.sql.connect.proto.relations_pb2.Relation.html_string"h
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*Ÿ
cached_local_relationFpyspark.sql.connect.proto.relations_pb2.Relation.cached_local_relation"z
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*›
cached_remote_relationGpyspark.sql.connect.proto.relations_pb2.Relation.cached_remote_relation"|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*§
)common_inline_user_defined_table_functionZpyspark.sql.connect.proto.relations_pb2.Relation.common_inline_user_defined_table_function"ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*£
fill_na8pyspark.sql.connect.proto.relations_pb2.Relation.fill_na"`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*£
drop_na8pyspark.sql.connect.proto.relations_pb2.Relation.drop_na"`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*©
replace8pyspark.sql.connect.proto.relations_pb2.Relation.replace"f
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*≠
summary8pyspark.sql.connect.proto.relations_pb2.Relation.summary"j
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*±
crosstab9pyspark.sql.connect.proto.relations_pb2.Relation.crosstab"l
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*±
describe9pyspark.sql.connect.proto.relations_pb2.Relation.describe"l
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ù
cov4pyspark.sql.connect.proto.relations_pb2.Relation.cov"b
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*°
corr5pyspark.sql.connect.proto.relations_pb2.Relation.corr"d
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*À
approx_quantile@pyspark.sql.connect.proto.relations_pb2.Relation.approx_quantile"x
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*∑

freq_items;pyspark.sql.connect.proto.relations_pb2.Relation.freq_items"n
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*≥
	sample_by:pyspark.sql.connect.proto.relations_pb2.Relation.sample_by"l
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*°
catalog8pyspark.sql.connect.proto.relations_pb2.Relation.catalog"^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*Œ
	extension:pyspark.sql.connect.proto.relations_pb2.Relation.extension"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*•
unknown8pyspark.sql.connect.proto.relations_pb2.Relation.unknown"b
/pyspark.sql.connect.proto.relations_pb2.Unknown"/pyspark.sql.connect.proto.relations_pb2.Unknown*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation0:property`*ƒS
__init__9pyspark.sql.connect.proto.relations_pb2.Relation.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*—
common¬
BUnion[pyspark.sql.connect.proto.relations_pb2.RelationCommon,None]p
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon
None *±
read§
8Union[pyspark.sql.connect.proto.relations_pb2.Read,None]\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read
None *Ω
project≠
;Union[pyspark.sql.connect.proto.relations_pb2.Project,None]b
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project
None *π
filter™
:Union[pyspark.sql.connect.proto.relations_pb2.Filter,None]`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter
None *±
join§
8Union[pyspark.sql.connect.proto.relations_pb2.Join,None]\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join
None *À
set_opº
@Union[pyspark.sql.connect.proto.relations_pb2.SetOperation,None]l
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation
None *±
sort§
8Union[pyspark.sql.connect.proto.relations_pb2.Sort,None]\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort
None *µ
limitß
9Union[pyspark.sql.connect.proto.relations_pb2.Limit,None]^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit
None *≈
	aggregate≥
=Union[pyspark.sql.connect.proto.relations_pb2.Aggregate,None]f
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate
None *≠
sql°
7Union[pyspark.sql.connect.proto.relations_pb2.SQL,None]Z
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL
None *÷
local_relationø
AUnion[pyspark.sql.connect.proto.relations_pb2.LocalRelation,None]n
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation
None *π
sample™
:Union[pyspark.sql.connect.proto.relations_pb2.Sample,None]`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample
None *π
offset™
:Union[pyspark.sql.connect.proto.relations_pb2.Offset,None]`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset
None *Õ
deduplicateπ
?Union[pyspark.sql.connect.proto.relations_pb2.Deduplicate,None]j
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate
None *µ
rangeß
9Union[pyspark.sql.connect.proto.relations_pb2.Range,None]^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range
None *÷
subquery_aliasø
AUnion[pyspark.sql.connect.proto.relations_pb2.SubqueryAlias,None]n
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias
None *Õ
repartitionπ
?Union[pyspark.sql.connect.proto.relations_pb2.Repartition,None]j
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition
None *≤
to_df§
8Union[pyspark.sql.connect.proto.relations_pb2.ToDF,None]\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF
None *Î
with_columns_renamedŒ
FUnion[pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed,None]x
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed
None * 
show_string∂
>Union[pyspark.sql.connect.proto.relations_pb2.ShowString,None]h
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString
None *±
drop§
8Union[pyspark.sql.connect.proto.relations_pb2.Drop,None]\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop
None *±
tail§
8Union[pyspark.sql.connect.proto.relations_pb2.Tail,None]\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail
None *Œ
with_columnsπ
?Union[pyspark.sql.connect.proto.relations_pb2.WithColumns,None]j
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns
None *±
hint§
8Union[pyspark.sql.connect.proto.relations_pb2.Hint,None]\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint
None *Ω
unpivot≠
;Union[pyspark.sql.connect.proto.relations_pb2.Unpivot,None]b
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot
None *¬
	to_schema∞
<Union[pyspark.sql.connect.proto.relations_pb2.ToSchema,None]d
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema
None *Ä
repartition_by_expressionﬁ
KUnion[pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression,None]Ç
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression
None *÷
map_partitionsø
AUnion[pyspark.sql.connect.proto.relations_pb2.MapPartitions,None]n
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions
None *⁄
collect_metrics¬
BUnion[pyspark.sql.connect.proto.relations_pb2.CollectMetrics,None]p
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics
None *µ
parseß
9Union[pyspark.sql.connect.proto.relations_pb2.Parse,None]^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse
None *¬
	group_map∞
<Union[pyspark.sql.connect.proto.relations_pb2.GroupMap,None]d
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap
None *À
co_group_map∂
>Union[pyspark.sql.connect.proto.relations_pb2.CoGroupMap,None]h
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap
None *÷
with_watermarkø
AUnion[pyspark.sql.connect.proto.relations_pb2.WithWatermark,None]n
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark
None *˛
apply_in_pandas_with_state€
JUnion[pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState,None]Ä
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState
None * 
html_string∂
>Union[pyspark.sql.connect.proto.relations_pb2.HtmlString,None]h
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString
None *Ô
cached_local_relation—
GUnion[pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation,None]z
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation
None *Û
cached_remote_relation‘
HUnion[pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation,None]|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation
None *∑
)common_inline_user_defined_table_functionÖ
XUnion[pyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction,None]ú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction
None *∫
fill_na™
:Union[pyspark.sql.connect.proto.relations_pb2.NAFill,None]`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill
None *∫
drop_na™
:Union[pyspark.sql.connect.proto.relations_pb2.NADrop,None]`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop
None *√
replace≥
=Union[pyspark.sql.connect.proto.relations_pb2.NAReplace,None]f
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace
None *…
summaryπ
?Union[pyspark.sql.connect.proto.relations_pb2.StatSummary,None]j
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary
None *Õ
crosstabº
@Union[pyspark.sql.connect.proto.relations_pb2.StatCrosstab,None]l
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab
None *Õ
describeº
@Union[pyspark.sql.connect.proto.relations_pb2.StatDescribe,None]l
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe
None *π
cov≠
;Union[pyspark.sql.connect.proto.relations_pb2.StatCov,None]b
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov
None *Ω
corr∞
<Union[pyspark.sql.connect.proto.relations_pb2.StatCorr,None]d
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr
None *Ê
approx_quantileŒ
FUnion[pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile,None]x
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile
None *“

freq_itemsø
AUnion[pyspark.sql.connect.proto.relations_pb2.StatFreqItems,None]n
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems
None *Œ
	sample_byº
@Union[pyspark.sql.connect.proto.relations_pb2.StatSampleBy,None]l
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy
None *∑
catalogß
9Union[pyspark.sql.connect.proto.catalog_pb2.Catalog,None]^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog
None *7
	extension&
Union[Any,None]
Any
None *Ω
unknown≠
;Union[pyspark.sql.connect.proto.relations_pb2.Unknown,None]b
/pyspark.sql.connect.proto.relations_pb2.Unknown"/pyspark.sql.connect.proto.relations_pb2.Unknown
None *“F
HasField9pyspark.sql.connect.proto.relations_pb2.Relation.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*˙D

field_nameÈD
åUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¿F

ClearField;pyspark.sql.connect.proto.relations_pb2.Relation.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*˙D

field_nameÈD
åUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ÿ"

WhichOneof;pyspark.sql.connect.proto.relations_pb2.Relation.WhichOneof"◊
ÌUnion[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.Relation.DESCRIPTOR
Anyry
COMMON_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.COMMON_FIELD_NUMBER
builtins.int"builtins.intru
READ_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.READ_FIELD_NUMBER
builtins.int"builtins.intr{
PROJECT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.PROJECT_FIELD_NUMBER
builtins.int"builtins.intry
FILTER_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.FILTER_FIELD_NUMBER
builtins.int"builtins.intru
JOIN_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.JOIN_FIELD_NUMBER
builtins.int"builtins.intry
SET_OP_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.SET_OP_FIELD_NUMBER
builtins.int"builtins.intru
SORT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.SORT_FIELD_NUMBER
builtins.int"builtins.intrw
LIMIT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.LIMIT_FIELD_NUMBER
builtins.int"builtins.intr
AGGREGATE_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.AGGREGATE_FIELD_NUMBER
builtins.int"builtins.intrs
SQL_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Relation.SQL_FIELD_NUMBER
builtins.int"builtins.intrâ
LOCAL_RELATION_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.LOCAL_RELATION_FIELD_NUMBER
builtins.int"builtins.intry
SAMPLE_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.SAMPLE_FIELD_NUMBER
builtins.int"builtins.intry
OFFSET_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Relation.OFFSET_FIELD_NUMBER
builtins.int"builtins.intrÉ
DEDUPLICATE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.DEDUPLICATE_FIELD_NUMBER
builtins.int"builtins.intrw
RANGE_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.RANGE_FIELD_NUMBER
builtins.int"builtins.intrâ
SUBQUERY_ALIAS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.SUBQUERY_ALIAS_FIELD_NUMBER
builtins.int"builtins.intrÉ
REPARTITION_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.REPARTITION_FIELD_NUMBER
builtins.int"builtins.intrw
TO_DF_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.TO_DF_FIELD_NUMBER
builtins.int"builtins.intrï
!WITH_COLUMNS_RENAMED_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.Relation.WITH_COLUMNS_RENAMED_FIELD_NUMBER
builtins.int"builtins.intrÉ
SHOW_STRING_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.SHOW_STRING_FIELD_NUMBER
builtins.int"builtins.intru
DROP_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.DROP_FIELD_NUMBER
builtins.int"builtins.intru
TAIL_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.TAIL_FIELD_NUMBER
builtins.int"builtins.intrÖ
WITH_COLUMNS_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.Relation.WITH_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intru
HINT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.HINT_FIELD_NUMBER
builtins.int"builtins.intr{
UNPIVOT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.UNPIVOT_FIELD_NUMBER
builtins.int"builtins.intr
TO_SCHEMA_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.TO_SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrü
&REPARTITION_BY_EXPRESSION_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.Relation.REPARTITION_BY_EXPRESSION_FIELD_NUMBER
builtins.int"builtins.intrâ
MAP_PARTITIONS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.MAP_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intrã
COLLECT_METRICS_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.Relation.COLLECT_METRICS_FIELD_NUMBER
builtins.int"builtins.intrw
PARSE_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Relation.PARSE_FIELD_NUMBER
builtins.int"builtins.intr
GROUP_MAP_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.GROUP_MAP_FIELD_NUMBER
builtins.int"builtins.intrÖ
CO_GROUP_MAP_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.Relation.CO_GROUP_MAP_FIELD_NUMBER
builtins.int"builtins.intrâ
WITH_WATERMARK_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Relation.WITH_WATERMARK_FIELD_NUMBER
builtins.int"builtins.intr°
'APPLY_IN_PANDAS_WITH_STATE_FIELD_NUMBERXpyspark.sql.connect.proto.relations_pb2.Relation.APPLY_IN_PANDAS_WITH_STATE_FIELD_NUMBER
builtins.int"builtins.intrÉ
HTML_STRING_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Relation.HTML_STRING_FIELD_NUMBER
builtins.int"builtins.intró
"CACHED_LOCAL_RELATION_FIELD_NUMBERSpyspark.sql.connect.proto.relations_pb2.Relation.CACHED_LOCAL_RELATION_FIELD_NUMBER
builtins.int"builtins.intrô
#CACHED_REMOTE_RELATION_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.Relation.CACHED_REMOTE_RELATION_FIELD_NUMBER
builtins.int"builtins.intrø
6COMMON_INLINE_USER_DEFINED_TABLE_FUNCTION_FIELD_NUMBERgpyspark.sql.connect.proto.relations_pb2.Relation.COMMON_INLINE_USER_DEFINED_TABLE_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intr{
FILL_NA_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.FILL_NA_FIELD_NUMBER
builtins.int"builtins.intr{
DROP_NA_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.DROP_NA_FIELD_NUMBER
builtins.int"builtins.intr{
REPLACE_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.REPLACE_FIELD_NUMBER
builtins.int"builtins.intr{
SUMMARY_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.SUMMARY_FIELD_NUMBER
builtins.int"builtins.intr}
CROSSTAB_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Relation.CROSSTAB_FIELD_NUMBER
builtins.int"builtins.intr}
DESCRIBE_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Relation.DESCRIBE_FIELD_NUMBER
builtins.int"builtins.intrs
COV_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Relation.COV_FIELD_NUMBER
builtins.int"builtins.intru
CORR_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Relation.CORR_FIELD_NUMBER
builtins.int"builtins.intrã
APPROX_QUANTILE_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.Relation.APPROX_QUANTILE_FIELD_NUMBER
builtins.int"builtins.intrÅ
FREQ_ITEMS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Relation.FREQ_ITEMS_FIELD_NUMBER
builtins.int"builtins.intr
SAMPLE_BY_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.SAMPLE_BY_FIELD_NUMBER
builtins.int"builtins.intr{
CATALOG_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.CATALOG_FIELD_NUMBER
builtins.int"builtins.intr
EXTENSION_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Relation.EXTENSION_FIELD_NUMBER
builtins.int"builtins.intr{
UNKNOWN_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Relation.UNKNOWN_FIELD_NUMBER
builtins.int"builtins.int›
Unknown/pyspark.sql.connect.proto.relations_pb2.Unknown"builtins.object*º
__init__8pyspark.sql.connect.proto.relations_pb2.Unknown.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unknown"/pyspark.sql.connect.proto.relations_pb2.UnknownrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.Unknown.DESCRIPTOR
Any±
RelationCommon6pyspark.sql.connect.proto.relations_pb2.RelationCommon"builtins.object*◊
__init__?pyspark.sql.connect.proto.relations_pb2.RelationCommon.__init__"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*/
source_info
builtins.str"builtins.str *S
plan_idD
Union[builtins.int,None]
builtins.int"builtins.int
None *—
HasField?pyspark.sql.connect.proto.relations_pb2.RelationCommon.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ê

ClearFieldApyspark.sql.connect.proto.relations_pb2.RelationCommon.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

WhichOneofApyspark.sql.connect.proto.relations_pb2.RelationCommon.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.RelationCommon"6pyspark.sql.connect.proto.relations_pb2.RelationCommon*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.relations_pb2.RelationCommon.DESCRIPTOR
Anyrâ
SOURCE_INFO_FIELD_NUMBEROpyspark.sql.connect.proto.relations_pb2.RelationCommon.SOURCE_INFO_FIELD_NUMBER
builtins.int"builtins.intrÅ
PLAN_ID_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.RelationCommon.PLAN_ID_FIELD_NUMBER
builtins.int"builtins.intro
source_infoBpyspark.sql.connect.proto.relations_pb2.RelationCommon.source_info
builtins.str"builtins.strrg
plan_id>pyspark.sql.connect.proto.relations_pb2.RelationCommon.plan_id
builtins.int"builtins.int”
SQL+pyspark.sql.connect.proto.relations_pb2.SQL"builtins.object*µ
args0pyspark.sql.connect.proto.relations_pb2.SQL.args"
Any*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL0:property`*Ω
pos_args4pyspark.sql.connect.proto.relations_pb2.SQL.pos_args"
Any*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL0:property`*ƒ
__init__4pyspark.sql.connect.proto.relations_pb2.SQL.__init__"
None*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL*)
query
builtins.str"builtins.str *ä
args˝
eUnion[typing.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]á
Ytyping.Mapping[builtins.str,pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]
builtins.str"builtins.str|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Mapping
None *Ÿ
pos_args»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *≈

ClearField6pyspark.sql.connect.proto.relations_pb2.SQL.ClearField"
None*d
selfZ
+pyspark.sql.connect.proto.relations_pb2.SQL"+pyspark.sql.connect.proto.relations_pb2.SQL*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrM

DESCRIPTOR6pyspark.sql.connect.proto.relations_pb2.SQL.DESCRIPTOR
Anyrr
QUERY_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.SQL.QUERY_FIELD_NUMBER
builtins.int"builtins.intrp
ARGS_FIELD_NUMBER=pyspark.sql.connect.proto.relations_pb2.SQL.ARGS_FIELD_NUMBER
builtins.int"builtins.intrx
POS_ARGS_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.SQL.POS_ARGS_FIELD_NUMBER
builtins.int"builtins.intrX
query1pyspark.sql.connect.proto.relations_pb2.SQL.query
builtins.str"builtins.strç 
Read,pyspark.sql.connect.proto.relations_pb2.Read"builtins.object*±
named_table8pyspark.sql.connect.proto.relations_pb2.Read.named_table"r
7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read0:property`*±
data_source8pyspark.sql.connect.proto.relations_pb2.Read.data_source"r
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read0:property`*ü
__init__5pyspark.sql.connect.proto.relations_pb2.Read.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*Ÿ
named_table≈
CUnion[pyspark.sql.connect.proto.relations_pb2.Read.NamedTable,None]r
7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable"7pyspark.sql.connect.proto.relations_pb2.Read.NamedTable
None *Ÿ
data_source≈
CUnion[pyspark.sql.connect.proto.relations_pb2.Read.DataSource,None]r
7pyspark.sql.connect.proto.relations_pb2.Read.DataSource"7pyspark.sql.connect.proto.relations_pb2.Read.DataSource
None *2
is_streaming
builtins.bool"builtins.bool *⁄
HasField5pyspark.sql.connect.proto.relations_pb2.Read.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

ClearField7pyspark.sql.connect.proto.relations_pb2.Read.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

WhichOneof7pyspark.sql.connect.proto.relations_pb2.Read.WhichOneof"∑
7Union[Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Read",pyspark.sql.connect.proto.relations_pb2.Read*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Read.DESCRIPTOR
Anyr
NAMED_TABLE_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Read.NAMED_TABLE_FIELD_NUMBER
builtins.int"builtins.intr
DATA_SOURCE_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Read.DATA_SOURCE_FIELD_NUMBER
builtins.int"builtins.intrÅ
IS_STREAMING_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Read.IS_STREAMING_FIELD_NUMBER
builtins.int"builtins.intri
is_streaming9pyspark.sql.connect.proto.relations_pb2.Read.is_streaming
builtins.bool"builtins.boolï
Project/pyspark.sql.connect.proto.relations_pb2.Project"builtins.object*†
input5pyspark.sql.connect.proto.relations_pb2.Project.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project0:property`*œ
expressions;pyspark.sql.connect.proto.relations_pb2.Project.expressions"
Any*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project0:property`*º
__init__8pyspark.sql.connect.proto.relations_pb2.Project.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *º
expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ñ
HasField8pyspark.sql.connect.proto.relations_pb2.Project.HasField"
builtins.bool"builtins.bool*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*™

ClearField:pyspark.sql.connect.proto.relations_pb2.Project.ClearField"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Project"/pyspark.sql.connect.proto.relations_pb2.Project*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.Project.DESCRIPTOR
Anyrv
INPUT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Project.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÇ
EXPRESSIONS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Project.EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intï
Filter.pyspark.sql.connect.proto.relations_pb2.Filter"builtins.object*ù
input4pyspark.sql.connect.proto.relations_pb2.Filter.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter0:property`*≠
	condition8pyspark.sql.connect.proto.relations_pb2.Filter.condition"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter0:property`*À
__init__7pyspark.sql.connect.proto.relations_pb2.Filter.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *Œ
	conditionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *π
HasField7pyspark.sql.connect.proto.relations_pb2.Filter.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ß

ClearField9pyspark.sql.connect.proto.relations_pb2.Filter.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Filter".pyspark.sql.connect.proto.relations_pb2.Filter*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.Filter.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Filter.INPUT_FIELD_NUMBER
builtins.int"builtins.intr}
CONDITION_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.Filter.CONDITION_FIELD_NUMBER
builtins.int"builtins.intËB
Join,pyspark.sql.connect.proto.relations_pb2.Join"builtins.object*ï
left1pyspark.sql.connect.proto.relations_pb2.Join.left"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:property`*ó
right2pyspark.sql.connect.proto.relations_pb2.Join.right"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:property`*±
join_condition;pyspark.sql.connect.proto.relations_pb2.Join.join_condition"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:property`* 
using_columns:pyspark.sql.connect.proto.relations_pb2.Join.using_columns"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:property`*ª
join_data_type;pyspark.sql.connect.proto.relations_pb2.Join.join_data_type"v
9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType"9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join0:property`*®

__init__5pyspark.sql.connect.proto.relations_pb2.Join.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*Ω
left∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *æ
right∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *”
join_conditionº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *ñ
	join_typeÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType *ù
using_columnsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *‚
join_data_typeÀ
EUnion[pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType,None]v
9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType"9pyspark.sql.connect.proto.relations_pb2.Join.JoinDataType
None *¶
HasField5pyspark.sql.connect.proto.relations_pb2.Join.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‡


ClearField7pyspark.sql.connect.proto.relations_pb2.Join.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‹

WhichOneof7pyspark.sql.connect.proto.relations_pb2.Join.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Join",pyspark.sql.connect.proto.relations_pb2.Join*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Join.DESCRIPTOR
Anyr‚
JOIN_TYPE_UNSPECIFIEDBpyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_UNSPECIFIEDÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper÷
JOIN_TYPE_INNER<pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_INNERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper‡
JOIN_TYPE_FULL_OUTERApyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_FULL_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper‡
JOIN_TYPE_LEFT_OUTERApyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_LEFT_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper‚
JOIN_TYPE_RIGHT_OUTERBpyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_RIGHT_OUTERÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperﬁ
JOIN_TYPE_LEFT_ANTI@pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_LEFT_ANTIÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperﬁ
JOIN_TYPE_LEFT_SEMI@pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_LEFT_SEMIÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyper÷
JOIN_TYPE_CROSS<pyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_CROSSÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTyperq
LEFT_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.Join.LEFT_FIELD_NUMBER
builtins.int"builtins.intrs
RIGHT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Join.RIGHT_FIELD_NUMBER
builtins.int"builtins.intrÖ
JOIN_CONDITION_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Join.JOIN_CONDITION_FIELD_NUMBER
builtins.int"builtins.intr{
JOIN_TYPE_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Join.JOIN_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÉ
USING_COLUMNS_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Join.USING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÖ
JOIN_DATA_TYPE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Join.JOIN_DATA_TYPE_FIELD_NUMBER
builtins.int"builtins.intr 
	join_type6pyspark.sql.connect.proto.relations_pb2.Join.join_typeÑ
@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueType"@pyspark.sql.connect.proto.relations_pb2.Join._JoinType.ValueTypeüH
SetOperation4pyspark.sql.connect.proto.relations_pb2.SetOperation"builtins.object*π

left_input?pyspark.sql.connect.proto.relations_pb2.SetOperation.left_input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation0:property`*ª
right_input@pyspark.sql.connect.proto.relations_pb2.SetOperation.right_input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation0:property`*ö
__init__=pyspark.sql.connect.proto.relations_pb2.SetOperation.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*√

left_input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ƒ
right_input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *™
set_op_typeñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType *U
is_allG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *V
by_nameG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *d
allow_missing_columnsG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *∞
HasField=pyspark.sql.connect.proto.relations_pb2.SetOperation.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ƒ

ClearField?pyspark.sql.connect.proto.relations_pb2.SetOperation.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ò

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneofâ

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXâ

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXâ

WhichOneof?pyspark.sql.connect.proto.relations_pb2.SetOperation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.SetOperation"4pyspark.sql.connect.proto.relations_pb2.SetOperation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.SetOperation.DESCRIPTOR
AnyrÄ
SET_OP_TYPE_UNSPECIFIEDLpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_UNSPECIFIEDñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyper¸
SET_OP_TYPE_INTERSECTJpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_INTERSECTñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperÙ
SET_OP_TYPE_UNIONFpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_UNIONñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperˆ
SET_OP_TYPE_EXCEPTGpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_EXCEPTñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTyperÖ
LEFT_INPUT_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.SetOperation.LEFT_INPUT_FIELD_NUMBER
builtins.int"builtins.intrá
RIGHT_INPUT_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.SetOperation.RIGHT_INPUT_FIELD_NUMBER
builtins.int"builtins.intrá
SET_OP_TYPE_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.SetOperation.SET_OP_TYPE_FIELD_NUMBER
builtins.int"builtins.intr}
IS_ALL_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.SetOperation.IS_ALL_FIELD_NUMBER
builtins.int"builtins.intr
BY_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.SetOperation.BY_NAME_FIELD_NUMBER
builtins.int"builtins.intrõ
"ALLOW_MISSING_COLUMNS_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.SetOperation.ALLOW_MISSING_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrË
set_op_type@pyspark.sql.connect.proto.relations_pb2.SetOperation.set_op_typeñ
Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueType"Ipyspark.sql.connect.proto.relations_pb2.SetOperation._SetOpType.ValueTypere
is_all;pyspark.sql.connect.proto.relations_pb2.SetOperation.is_all
builtins.bool"builtins.boolrg
by_name<pyspark.sql.connect.proto.relations_pb2.SetOperation.by_name
builtins.bool"builtins.boolrÉ
allow_missing_columnsJpyspark.sql.connect.proto.relations_pb2.SetOperation.allow_missing_columns
builtins.bool"builtins.bool‹
Limit-pyspark.sql.connect.proto.relations_pb2.Limit"builtins.object*ö
input3pyspark.sql.connect.proto.relations_pb2.Limit.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit0:property`*¢
__init__6pyspark.sql.connect.proto.relations_pb2.Limit.__init__"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *)
limit
builtins.int"builtins.int *ê
HasField6pyspark.sql.connect.proto.relations_pb2.Limit.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*§

ClearField8pyspark.sql.connect.proto.relations_pb2.Limit.ClearField"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Limit"-pyspark.sql.connect.proto.relations_pb2.Limit*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrO

DESCRIPTOR8pyspark.sql.connect.proto.relations_pb2.Limit.DESCRIPTOR
Anyrt
INPUT_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Limit.INPUT_FIELD_NUMBER
builtins.int"builtins.intrt
LIMIT_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Limit.LIMIT_FIELD_NUMBER
builtins.int"builtins.intrZ
limit3pyspark.sql.connect.proto.relations_pb2.Limit.limit
builtins.int"builtins.intÛ
Offset.pyspark.sql.connect.proto.relations_pb2.Offset"builtins.object*ù
input4pyspark.sql.connect.proto.relations_pb2.Offset.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset0:property`*¶
__init__7pyspark.sql.connect.proto.relations_pb2.Offset.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None **
offset
builtins.int"builtins.int *ì
HasField7pyspark.sql.connect.proto.relations_pb2.Offset.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ß

ClearField9pyspark.sql.connect.proto.relations_pb2.Offset.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Offset".pyspark.sql.connect.proto.relations_pb2.Offset*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.Offset.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Offset.INPUT_FIELD_NUMBER
builtins.int"builtins.intrw
OFFSET_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Offset.OFFSET_FIELD_NUMBER
builtins.int"builtins.intr]
offset5pyspark.sql.connect.proto.relations_pb2.Offset.offset
builtins.int"builtins.int 
Tail,pyspark.sql.connect.proto.relations_pb2.Tail"builtins.object*ó
input2pyspark.sql.connect.proto.relations_pb2.Tail.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail0:property`*ü
__init__5pyspark.sql.connect.proto.relations_pb2.Tail.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *)
limit
builtins.int"builtins.int *ç
HasField5pyspark.sql.connect.proto.relations_pb2.Tail.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*°

ClearField7pyspark.sql.connect.proto.relations_pb2.Tail.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Tail",pyspark.sql.connect.proto.relations_pb2.Tail*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Tail.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Tail.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
LIMIT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Tail.LIMIT_FIELD_NUMBER
builtins.int"builtins.intrY
limit2pyspark.sql.connect.proto.relations_pb2.Tail.limit
builtins.int"builtins.intë2
	Aggregate1pyspark.sql.connect.proto.relations_pb2.Aggregate"builtins.object*¶
input7pyspark.sql.connect.proto.relations_pb2.Aggregate.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:property`*Á
grouping_expressionsFpyspark.sql.connect.proto.relations_pb2.Aggregate.grouping_expressions"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:property`*È
aggregate_expressionsGpyspark.sql.connect.proto.relations_pb2.Aggregate.aggregate_expressions"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:property`*¥
pivot7pyspark.sql.connect.proto.relations_pb2.Aggregate.pivot"r
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate0:property`*ê
__init__:pyspark.sql.connect.proto.relations_pb2.Aggregate.__init__"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *£

group_typeê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType *≈
grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *∆
aggregate_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *”
pivot≈
CUnion[pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot,None]r
7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot"7pyspark.sql.connect.proto.relations_pb2.Aggregate.Pivot
None *¬
HasField:pyspark.sql.connect.proto.relations_pb2.Aggregate.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*£

ClearField<pyspark.sql.connect.proto.relations_pb2.Aggregate.ClearField"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.Aggregate"1pyspark.sql.connect.proto.relations_pb2.Aggregate*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.relations_pb2.Aggregate.DESCRIPTOR
Anyrı
GROUP_TYPE_UNSPECIFIEDHpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_UNSPECIFIEDê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÌ
GROUP_TYPE_GROUPBYDpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_GROUPBYê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÎ
GROUP_TYPE_ROLLUPCpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_ROLLUPê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÁ
GROUP_TYPE_CUBEApyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_CUBEê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperÈ
GROUP_TYPE_PIVOTBpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_PIVOTê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTyperx
INPUT_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Aggregate.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÇ
GROUP_TYPE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUP_TYPE_FIELD_NUMBER
builtins.int"builtins.intrñ
!GROUPING_EXPRESSIONS_FIELD_NUMBERSpyspark.sql.connect.proto.relations_pb2.Aggregate.GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrò
"AGGREGATE_EXPRESSIONS_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.Aggregate.AGGREGATE_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrx
PIVOT_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Aggregate.PIVOT_FIELD_NUMBER
builtins.int"builtins.intr›

group_type<pyspark.sql.connect.proto.relations_pb2.Aggregate.group_typeê
Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueType"Fpyspark.sql.connect.proto.relations_pb2.Aggregate._GroupType.ValueTypeò
Sort,pyspark.sql.connect.proto.relations_pb2.Sort"builtins.object*ó
input2pyspark.sql.connect.proto.relations_pb2.Sort.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort0:property`*∫
order2pyspark.sql.connect.proto.relations_pb2.Sort.order"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort0:property`*∞
__init__5pyspark.sql.connect.proto.relations_pb2.Sort.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ﬂ
order—
[Union[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder],None]Â
Otyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder]Ä
>pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder">pyspark.sql.connect.proto.expressions_pb2.Expression.SortOrder"typing.Iterable
None *X
	is_globalG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *⁄
HasField5pyspark.sql.connect.proto.relations_pb2.Sort.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

ClearField7pyspark.sql.connect.proto.relations_pb2.Sort.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‹

WhichOneof7pyspark.sql.connect.proto.relations_pb2.Sort.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Sort",pyspark.sql.connect.proto.relations_pb2.Sort*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Sort.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Sort.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
ORDER_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Sort.ORDER_FIELD_NUMBER
builtins.int"builtins.intr{
IS_GLOBAL_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Sort.IS_GLOBAL_FIELD_NUMBER
builtins.int"builtins.intrc
	is_global6pyspark.sql.connect.proto.relations_pb2.Sort.is_global
builtins.bool"builtins.boolŸ
Drop,pyspark.sql.connect.proto.relations_pb2.Drop"builtins.object*ó
input2pyspark.sql.connect.proto.relations_pb2.Drop.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop0:property`*æ
columns4pyspark.sql.connect.proto.relations_pb2.Drop.columns"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop0:property`*»
column_names9pyspark.sql.connect.proto.relations_pb2.Drop.column_names"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop0:property`*Œ
__init__5pyspark.sql.connect.proto.relations_pb2.Drop.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *∏
columns®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ú
column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ç
HasField5pyspark.sql.connect.proto.relations_pb2.Drop.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*»

ClearField7pyspark.sql.connect.proto.relations_pb2.Drop.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Drop",pyspark.sql.connect.proto.relations_pb2.Drop*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Drop.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Drop.INPUT_FIELD_NUMBER
builtins.int"builtins.intrw
COLUMNS_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Drop.COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÅ
COLUMN_NAMES_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Drop.COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.int«,
Deduplicate3pyspark.sql.connect.proto.relations_pb2.Deduplicate"builtins.object*¨
input9pyspark.sql.connect.proto.relations_pb2.Deduplicate.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate0:property`*›
column_names@pyspark.sql.connect.proto.relations_pb2.Deduplicate.column_names"
Any*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate0:property`*Ì
__init__<pyspark.sql.connect.proto.relations_pb2.Deduplicate.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ú
column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *b
all_columns_as_keysG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *_
within_watermarkG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *ª
HasField<pyspark.sql.connect.proto.relations_pb2.Deduplicate.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*œ	

ClearField>pyspark.sql.connect.proto.relations_pb2.Deduplicate.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ﬁ

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Deduplicate.WhichOneofÜ

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Deduplicate.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÜ

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Deduplicate.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Deduplicate"3pyspark.sql.connect.proto.relations_pb2.Deduplicate*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.Deduplicate.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Deduplicate.INPUT_FIELD_NUMBER
builtins.int"builtins.intrà
COLUMN_NAMES_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.Deduplicate.COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intrñ
 ALL_COLUMNS_AS_KEYS_FIELD_NUMBERTpyspark.sql.connect.proto.relations_pb2.Deduplicate.ALL_COLUMNS_AS_KEYS_FIELD_NUMBER
builtins.int"builtins.intrê
WITHIN_WATERMARK_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.Deduplicate.WITHIN_WATERMARK_FIELD_NUMBER
builtins.int"builtins.intr~
all_columns_as_keysGpyspark.sql.connect.proto.relations_pb2.Deduplicate.all_columns_as_keys
builtins.bool"builtins.boolrx
within_watermarkDpyspark.sql.connect.proto.relations_pb2.Deduplicate.within_watermark
builtins.bool"builtins.boolé
LocalRelation5pyspark.sql.connect.proto.relations_pb2.LocalRelation"builtins.object*˙
__init__>pyspark.sql.connect.proto.relations_pb2.LocalRelation.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*V
dataJ
Union[builtins.bytes,None] 
builtins.bytes"builtins.bytes
None *R
schemaD
Union[builtins.str,None]
builtins.str"builtins.str
None *õ
HasField>pyspark.sql.connect.proto.relations_pb2.LocalRelation.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*â

ClearField@pyspark.sql.connect.proto.relations_pb2.LocalRelation.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2Ï

WhichOneof@pyspark.sql.connect.proto.relations_pb2.LocalRelation.WhichOneofå

WhichOneof@pyspark.sql.connect.proto.relations_pb2.LocalRelation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXå

WhichOneof@pyspark.sql.connect.proto.relations_pb2.LocalRelation.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.LocalRelation"5pyspark.sql.connect.proto.relations_pb2.LocalRelation*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.LocalRelation.DESCRIPTOR
Anyrz
DATA_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.LocalRelation.DATA_FIELD_NUMBER
builtins.int"builtins.intr~
SCHEMA_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.LocalRelation.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrd
data:pyspark.sql.connect.proto.relations_pb2.LocalRelation.data 
builtins.bytes"builtins.bytesrd
schema<pyspark.sql.connect.proto.relations_pb2.LocalRelation.schema
builtins.str"builtins.strÁ
CachedLocalRelation;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation"builtins.object*ã
__init__Dpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.__init__"
None*Ñ
selfz
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation*(
hash
builtins.str"builtins.str *©

ClearFieldFpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.ClearField"
None*Ñ
selfz
;pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation";pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr]

DESCRIPTORFpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.DESCRIPTOR
AnyrÄ
HASH_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.HASH_FIELD_NUMBER
builtins.int"builtins.intrf
hash@pyspark.sql.connect.proto.relations_pb2.CachedLocalRelation.hash
builtins.str"builtins.strï	
CachedRemoteRelation<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"builtins.object*ï
__init__Epyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.__init__"
None*Ü
self|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation*/
relation_id
builtins.str"builtins.str *¨

ClearFieldGpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.ClearField"
None*Ü
self|
<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation"<pyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr^

DESCRIPTORGpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.DESCRIPTOR
Anyrè
RELATION_ID_FIELD_NUMBERUpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.RELATION_ID_FIELD_NUMBER
builtins.int"builtins.intru
relation_idHpyspark.sql.connect.proto.relations_pb2.CachedRemoteRelation.relation_id
builtins.str"builtins.str«0
Sample.pyspark.sql.connect.proto.relations_pb2.Sample"builtins.object*ù
input4pyspark.sql.connect.proto.relations_pb2.Sample.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample0:property`*“
__init__7pyspark.sql.connect.proto.relations_pb2.Sample.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *3
lower_bound 
builtins.float"builtins.float *3
upper_bound 
builtins.float"builtins.float *_
with_replacementG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *9
deterministic_order
builtins.bool"builtins.bool *¨
HasField7pyspark.sql.connect.proto.relations_pb2.Sample.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*å

ClearField9pyspark.sql.connect.proto.relations_pb2.Sample.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ª

WhichOneof9pyspark.sql.connect.proto.relations_pb2.Sample.WhichOneof˜

WhichOneof9pyspark.sql.connect.proto.relations_pb2.Sample.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˜

WhichOneof9pyspark.sql.connect.proto.relations_pb2.Sample.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.Sample".pyspark.sql.connect.proto.relations_pb2.Sample*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.Sample.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Sample.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÅ
LOWER_BOUND_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Sample.LOWER_BOUND_FIELD_NUMBER
builtins.int"builtins.intrÅ
UPPER_BOUND_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.Sample.UPPER_BOUND_FIELD_NUMBER
builtins.int"builtins.intrã
WITH_REPLACEMENT_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.Sample.WITH_REPLACEMENT_FIELD_NUMBER
builtins.int"builtins.intrs
SEED_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Sample.SEED_FIELD_NUMBER
builtins.int"builtins.intrë
 DETERMINISTIC_ORDER_FIELD_NUMBEROpyspark.sql.connect.proto.relations_pb2.Sample.DETERMINISTIC_ORDER_FIELD_NUMBER
builtins.int"builtins.intrk
lower_bound:pyspark.sql.connect.proto.relations_pb2.Sample.lower_bound 
builtins.float"builtins.floatrk
upper_bound:pyspark.sql.connect.proto.relations_pb2.Sample.upper_bound 
builtins.float"builtins.floatrs
with_replacement?pyspark.sql.connect.proto.relations_pb2.Sample.with_replacement
builtins.bool"builtins.boolrY
seed3pyspark.sql.connect.proto.relations_pb2.Sample.seed
builtins.int"builtins.intry
deterministic_orderBpyspark.sql.connect.proto.relations_pb2.Sample.deterministic_order
builtins.bool"builtins.bool±$
Range-pyspark.sql.connect.proto.relations_pb2.Range"builtins.object*∏
__init__6pyspark.sql.connect.proto.relations_pb2.Range.__init__"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*Q
startD
Union[builtins.int,None]
builtins.int"builtins.int
None *'
end
builtins.int"builtins.int *(
step
builtins.int"builtins.int *Z
num_partitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *É
HasField6pyspark.sql.connect.proto.relations_pb2.Range.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ω	

ClearField8pyspark.sql.connect.proto.relations_pb2.Range.ClearField"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¥

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Range.WhichOneofÙ

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Range.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÙ

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Range.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Range"-pyspark.sql.connect.proto.relations_pb2.Range*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrO

DESCRIPTOR8pyspark.sql.connect.proto.relations_pb2.Range.DESCRIPTOR
Anyrt
START_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Range.START_FIELD_NUMBER
builtins.int"builtins.intrp
END_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.Range.END_FIELD_NUMBER
builtins.int"builtins.intrr
STEP_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Range.STEP_FIELD_NUMBER
builtins.int"builtins.intrÜ
NUM_PARTITIONS_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.Range.NUM_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intrZ
start3pyspark.sql.connect.proto.relations_pb2.Range.start
builtins.int"builtins.intrV
end1pyspark.sql.connect.proto.relations_pb2.Range.end
builtins.int"builtins.intrX
step2pyspark.sql.connect.proto.relations_pb2.Range.step
builtins.int"builtins.intrl
num_partitions<pyspark.sql.connect.proto.relations_pb2.Range.num_partitions
builtins.int"builtins.intñ
SubqueryAlias5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"builtins.object*≤
input;pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias0:property`*›
	qualifier?pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.qualifier"
Any*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias0:property`*÷
__init__>pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *)
alias
builtins.str"builtins.str *ô
	qualifierá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *®
HasField>pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*„

ClearField@pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias"5pyspark.sql.connect.proto.relations_pb2.SubqueryAlias*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.SubqueryAlias.INPUT_FIELD_NUMBER
builtins.int"builtins.intr|
ALIAS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.SubqueryAlias.ALIAS_FIELD_NUMBER
builtins.int"builtins.intrÑ
QUALIFIER_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.SubqueryAlias.QUALIFIER_FIELD_NUMBER
builtins.int"builtins.intrb
alias;pyspark.sql.connect.proto.relations_pb2.SubqueryAlias.alias
builtins.str"builtins.strƒ
Repartition3pyspark.sql.connect.proto.relations_pb2.Repartition"builtins.object*¨
input9pyspark.sql.connect.proto.relations_pb2.Repartition.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition0:property`*ï
__init__<pyspark.sql.connect.proto.relations_pb2.Repartition.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *2
num_partitions
builtins.int"builtins.int *V
shuffleG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *Ô
HasField<pyspark.sql.connect.proto.relations_pb2.Repartition.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearField>pyspark.sql.connect.proto.relations_pb2.Repartition.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ò

WhichOneof>pyspark.sql.connect.proto.relations_pb2.Repartition.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.Repartition"3pyspark.sql.connect.proto.relations_pb2.Repartition*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.Repartition.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.Repartition.INPUT_FIELD_NUMBER
builtins.int"builtins.intrå
NUM_PARTITIONS_FIELD_NUMBEROpyspark.sql.connect.proto.relations_pb2.Repartition.NUM_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intr~
SHUFFLE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.Repartition.SHUFFLE_FIELD_NUMBER
builtins.int"builtins.intrr
num_partitionsBpyspark.sql.connect.proto.relations_pb2.Repartition.num_partitions
builtins.int"builtins.intrf
shuffle;pyspark.sql.connect.proto.relations_pb2.Repartition.shuffle
builtins.bool"builtins.bool¬

ShowString2pyspark.sql.connect.proto.relations_pb2.ShowString"builtins.object*©
input8pyspark.sql.connect.proto.relations_pb2.ShowString.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString0:property`*í
__init__;pyspark.sql.connect.proto.relations_pb2.ShowString.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *,
num_rows
builtins.int"builtins.int *,
truncate
builtins.int"builtins.int *.
vertical
builtins.bool"builtins.bool *ü
HasField;pyspark.sql.connect.proto.relations_pb2.ShowString.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ä

ClearField=pyspark.sql.connect.proto.relations_pb2.ShowString.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.ShowString"2pyspark.sql.connect.proto.relations_pb2.ShowString*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.ShowString.DESCRIPTOR
Anyry
INPUT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.ShowString.INPUT_FIELD_NUMBER
builtins.int"builtins.intr
NUM_ROWS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.ShowString.NUM_ROWS_FIELD_NUMBER
builtins.int"builtins.intr
TRUNCATE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.ShowString.TRUNCATE_FIELD_NUMBER
builtins.int"builtins.intr
VERTICAL_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.ShowString.VERTICAL_FIELD_NUMBER
builtins.int"builtins.intre
num_rows;pyspark.sql.connect.proto.relations_pb2.ShowString.num_rows
builtins.int"builtins.intre
truncate;pyspark.sql.connect.proto.relations_pb2.ShowString.truncate
builtins.int"builtins.intrg
vertical;pyspark.sql.connect.proto.relations_pb2.ShowString.vertical
builtins.bool"builtins.boolÇ

HtmlString2pyspark.sql.connect.proto.relations_pb2.HtmlString"builtins.object*©
input8pyspark.sql.connect.proto.relations_pb2.HtmlString.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString0:property`*‚
__init__;pyspark.sql.connect.proto.relations_pb2.HtmlString.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *,
num_rows
builtins.int"builtins.int *,
truncate
builtins.int"builtins.int *ü
HasField;pyspark.sql.connect.proto.relations_pb2.HtmlString.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*⁄

ClearField=pyspark.sql.connect.proto.relations_pb2.HtmlString.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.HtmlString"2pyspark.sql.connect.proto.relations_pb2.HtmlString*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.HtmlString.DESCRIPTOR
Anyry
INPUT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.HtmlString.INPUT_FIELD_NUMBER
builtins.int"builtins.intr
NUM_ROWS_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.HtmlString.NUM_ROWS_FIELD_NUMBER
builtins.int"builtins.intr
TRUNCATE_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.HtmlString.TRUNCATE_FIELD_NUMBER
builtins.int"builtins.intre
num_rows;pyspark.sql.connect.proto.relations_pb2.HtmlString.num_rows
builtins.int"builtins.intre
truncate;pyspark.sql.connect.proto.relations_pb2.HtmlString.truncate
builtins.int"builtins.intø
StatSummary3pyspark.sql.connect.proto.relations_pb2.StatSummary"builtins.object*¨
input9pyspark.sql.connect.proto.relations_pb2.StatSummary.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary0:property`*Ÿ

statistics>pyspark.sql.connect.proto.relations_pb2.StatSummary.statistics"
Any*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary0:property`*¶
__init__<pyspark.sql.connect.proto.relations_pb2.StatSummary.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ö

statisticsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *¢
HasField<pyspark.sql.connect.proto.relations_pb2.StatSummary.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearField>pyspark.sql.connect.proto.relations_pb2.StatSummary.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.StatSummary"3pyspark.sql.connect.proto.relations_pb2.StatSummary*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.StatSummary.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatSummary.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÑ
STATISTICS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.StatSummary.STATISTICS_FIELD_NUMBER
builtins.int"builtins.int¥
StatDescribe4pyspark.sql.connect.proto.relations_pb2.StatDescribe"builtins.object*Ø
input:pyspark.sql.connect.proto.relations_pb2.StatDescribe.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe0:property`*–
cols9pyspark.sql.connect.proto.relations_pb2.StatDescribe.cols"
Any*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe0:property`*£
__init__=pyspark.sql.connect.proto.relations_pb2.StatDescribe.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *•
HasField=pyspark.sql.connect.proto.relations_pb2.StatDescribe.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*π

ClearField?pyspark.sql.connect.proto.relations_pb2.StatDescribe.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatDescribe"4pyspark.sql.connect.proto.relations_pb2.StatDescribe*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.StatDescribe.DESCRIPTOR
Anyr{
INPUT_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatDescribe.INPUT_FIELD_NUMBER
builtins.int"builtins.intry
COLS_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatDescribe.COLS_FIELD_NUMBER
builtins.int"builtins.intÇ
StatCrosstab4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"builtins.object*Ø
input:pyspark.sql.connect.proto.relations_pb2.StatCrosstab.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab0:property`*‡
__init__=pyspark.sql.connect.proto.relations_pb2.StatCrosstab.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
col1
builtins.str"builtins.str *(
col2
builtins.str"builtins.str *•
HasField=pyspark.sql.connect.proto.relations_pb2.StatCrosstab.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‡

ClearField?pyspark.sql.connect.proto.relations_pb2.StatCrosstab.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatCrosstab"4pyspark.sql.connect.proto.relations_pb2.StatCrosstab*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.StatCrosstab.DESCRIPTOR
Anyr{
INPUT_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatCrosstab.INPUT_FIELD_NUMBER
builtins.int"builtins.intry
COL1_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatCrosstab.COL1_FIELD_NUMBER
builtins.int"builtins.intry
COL2_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatCrosstab.COL2_FIELD_NUMBER
builtins.int"builtins.intr_
col19pyspark.sql.connect.proto.relations_pb2.StatCrosstab.col1
builtins.str"builtins.strr_
col29pyspark.sql.connect.proto.relations_pb2.StatCrosstab.col2
builtins.str"builtins.strû
StatCov/pyspark.sql.connect.proto.relations_pb2.StatCov"builtins.object*†
input5pyspark.sql.connect.proto.relations_pb2.StatCov.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov0:property`*—
__init__8pyspark.sql.connect.proto.relations_pb2.StatCov.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
col1
builtins.str"builtins.str *(
col2
builtins.str"builtins.str *ñ
HasField8pyspark.sql.connect.proto.relations_pb2.StatCov.HasField"
builtins.bool"builtins.bool*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*—

ClearField:pyspark.sql.connect.proto.relations_pb2.StatCov.ClearField"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.StatCov"/pyspark.sql.connect.proto.relations_pb2.StatCov*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.StatCov.DESCRIPTOR
Anyrv
INPUT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.StatCov.INPUT_FIELD_NUMBER
builtins.int"builtins.intrt
COL1_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.StatCov.COL1_FIELD_NUMBER
builtins.int"builtins.intrt
COL2_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.StatCov.COL2_FIELD_NUMBER
builtins.int"builtins.intrZ
col14pyspark.sql.connect.proto.relations_pb2.StatCov.col1
builtins.str"builtins.strrZ
col24pyspark.sql.connect.proto.relations_pb2.StatCov.col2
builtins.str"builtins.strÊ
StatCorr0pyspark.sql.connect.proto.relations_pb2.StatCorr"builtins.object*£
input6pyspark.sql.connect.proto.relations_pb2.StatCorr.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr0:property`*®
__init__9pyspark.sql.connect.proto.relations_pb2.StatCorr.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
col1
builtins.str"builtins.str *(
col2
builtins.str"builtins.str *R
methodD
Union[builtins.str,None]
builtins.str"builtins.str
None *Ê
HasField9pyspark.sql.connect.proto.relations_pb2.StatCorr.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*†

ClearField;pyspark.sql.connect.proto.relations_pb2.StatCorr.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

WhichOneof;pyspark.sql.connect.proto.relations_pb2.StatCorr.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.StatCorr"0pyspark.sql.connect.proto.relations_pb2.StatCorr*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.StatCorr.DESCRIPTOR
Anyrw
INPUT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.StatCorr.INPUT_FIELD_NUMBER
builtins.int"builtins.intru
COL1_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.StatCorr.COL1_FIELD_NUMBER
builtins.int"builtins.intru
COL2_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.StatCorr.COL2_FIELD_NUMBER
builtins.int"builtins.intry
METHOD_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.StatCorr.METHOD_FIELD_NUMBER
builtins.int"builtins.intr[
col15pyspark.sql.connect.proto.relations_pb2.StatCorr.col1
builtins.str"builtins.strr[
col25pyspark.sql.connect.proto.relations_pb2.StatCorr.col2
builtins.str"builtins.strr_
method7pyspark.sql.connect.proto.relations_pb2.StatCorr.method
builtins.str"builtins.strÄ
StatApproxQuantile:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile"builtins.object*¬
input@pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile0:property`*„
cols?pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.cols"
Any*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile0:property`*ı
probabilitiesHpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.probabilities"
Any*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile0:property`*ñ
__init__Cpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *•
probabilitiesè
+Union[typing.Iterable[builtins.float],None]T
typing.Iterable[builtins.float] 
builtins.float"builtins.float"typing.Iterable
None *6
relative_error 
builtins.float"builtins.float *∏
HasFieldCpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ô

ClearFieldEpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile":pyspark.sql.connect.proto.relations_pb2.StatApproxQuantile*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.DESCRIPTOR
AnyrÅ
INPUT_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.INPUT_FIELD_NUMBER
builtins.int"builtins.intr
COLS_FIELD_NUMBERLpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.COLS_FIELD_NUMBER
builtins.int"builtins.intrë
PROBABILITIES_FIELD_NUMBERUpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.PROBABILITIES_FIELD_NUMBER
builtins.int"builtins.intrì
RELATIVE_ERROR_FIELD_NUMBERVpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.RELATIVE_ERROR_FIELD_NUMBER
builtins.int"builtins.intr}
relative_errorIpyspark.sql.connect.proto.relations_pb2.StatApproxQuantile.relative_error 
builtins.float"builtins.float¶
StatFreqItems5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"builtins.object*≤
input;pyspark.sql.connect.proto.relations_pb2.StatFreqItems.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems0:property`*”
cols:pyspark.sql.connect.proto.relations_pb2.StatFreqItems.cols"
Any*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems0:property`*Å
__init__>pyspark.sql.connect.proto.relations_pb2.StatFreqItems.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Y
supportJ
Union[builtins.float,None] 
builtins.float"builtins.float
None *ı
HasField>pyspark.sql.connect.proto.relations_pb2.StatFreqItems.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*â

ClearField@pyspark.sql.connect.proto.relations_pb2.StatFreqItems.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˜

WhichOneof@pyspark.sql.connect.proto.relations_pb2.StatFreqItems.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.StatFreqItems"5pyspark.sql.connect.proto.relations_pb2.StatFreqItems*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.StatFreqItems.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.StatFreqItems.INPUT_FIELD_NUMBER
builtins.int"builtins.intrz
COLS_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatFreqItems.COLS_FIELD_NUMBER
builtins.int"builtins.intrÄ
SUPPORT_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.StatFreqItems.SUPPORT_FIELD_NUMBER
builtins.int"builtins.intrj
support=pyspark.sql.connect.proto.relations_pb2.StatFreqItems.support 
builtins.float"builtins.floatò(
StatSampleBy4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"builtins.object*Ø
input:pyspark.sql.connect.proto.relations_pb2.StatSampleBy.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy0:property`*≥
col8pyspark.sql.connect.proto.relations_pb2.StatSampleBy.col"l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy0:property`*⁄
	fractions>pyspark.sql.connect.proto.relations_pb2.StatSampleBy.fractions"
Any*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy0:property`*ä
__init__=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.__init__"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *»
colº
@Union[pyspark.sql.connect.proto.expressions_pb2.Expression,None]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression
None *ﬁ
	fractionsÃ
ZUnion[typing.Iterable[pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction],None]·
Ntyping.Iterable[pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction]~
=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.Fraction"typing.Iterable
None *P
seedD
Union[builtins.int,None]
builtins.int"builtins.int
None *ò
HasField=pyspark.sql.connect.proto.relations_pb2.StatSampleBy.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¨

ClearField?pyspark.sql.connect.proto.relations_pb2.StatSampleBy.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

WhichOneof?pyspark.sql.connect.proto.relations_pb2.StatSampleBy.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.relations_pb2.StatSampleBy"4pyspark.sql.connect.proto.relations_pb2.StatSampleBy*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.relations_pb2.StatSampleBy.DESCRIPTOR
Anyr{
INPUT_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.StatSampleBy.INPUT_FIELD_NUMBER
builtins.int"builtins.intrw
COL_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.StatSampleBy.COL_FIELD_NUMBER
builtins.int"builtins.intrÉ
FRACTIONS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.StatSampleBy.FRACTIONS_FIELD_NUMBER
builtins.int"builtins.intry
SEED_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.StatSampleBy.SEED_FIELD_NUMBER
builtins.int"builtins.intr_
seed9pyspark.sql.connect.proto.relations_pb2.StatSampleBy.seed
builtins.int"builtins.int˚
NAFill.pyspark.sql.connect.proto.relations_pb2.NAFill"builtins.object*ù
input4pyspark.sql.connect.proto.relations_pb2.NAFill.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill0:property`*æ
cols3pyspark.sql.connect.proto.relations_pb2.NAFill.cols"
Any*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill0:property`*¬
values5pyspark.sql.connect.proto.relations_pb2.NAFill.values"
Any*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill0:property`*Î
__init__7pyspark.sql.connect.proto.relations_pb2.NAFill.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *◊
values»
YUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal],None]ﬁ
Mtyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Literal]|
<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"<pyspark.sql.connect.proto.expressions_pb2.Expression.Literal"typing.Iterable
None *ì
HasField7pyspark.sql.connect.proto.relations_pb2.NAFill.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Œ

ClearField9pyspark.sql.connect.proto.relations_pb2.NAFill.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NAFill".pyspark.sql.connect.proto.relations_pb2.NAFill*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.NAFill.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.NAFill.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
COLS_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.NAFill.COLS_FIELD_NUMBER
builtins.int"builtins.intrw
VALUES_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.NAFill.VALUES_FIELD_NUMBER
builtins.int"builtins.intã
NADrop.pyspark.sql.connect.proto.relations_pb2.NADrop"builtins.object*ù
input4pyspark.sql.connect.proto.relations_pb2.NADrop.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop0:property`*æ
cols3pyspark.sql.connect.proto.relations_pb2.NADrop.cols"
Any*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop0:property`*Ï
__init__7pyspark.sql.connect.proto.relations_pb2.NADrop.__init__"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *Y
min_non_nullsD
Union[builtins.int,None]
builtins.int"builtins.int
None *‡
HasField7pyspark.sql.connect.proto.relations_pb2.NADrop.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

ClearField9pyspark.sql.connect.proto.relations_pb2.NADrop.ClearField"
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‚

WhichOneof9pyspark.sql.connect.proto.relations_pb2.NADrop.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.relations_pb2.NADrop".pyspark.sql.connect.proto.relations_pb2.NADrop*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.relations_pb2.NADrop.DESCRIPTOR
Anyru
INPUT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.NADrop.INPUT_FIELD_NUMBER
builtins.int"builtins.intrs
COLS_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.NADrop.COLS_FIELD_NUMBER
builtins.int"builtins.intrÖ
MIN_NON_NULLS_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.NADrop.MIN_NON_NULLS_FIELD_NUMBER
builtins.int"builtins.intrk
min_non_nulls<pyspark.sql.connect.proto.relations_pb2.NADrop.min_non_nulls
builtins.int"builtins.intÊ
	NAReplace1pyspark.sql.connect.proto.relations_pb2.NAReplace"builtins.object*¶
input7pyspark.sql.connect.proto.relations_pb2.NAReplace.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace0:property`*«
cols6pyspark.sql.connect.proto.relations_pb2.NAReplace.cols"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace0:property`*◊
replacements>pyspark.sql.connect.proto.relations_pb2.NAReplace.replacements"
Any*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace0:property`*˛
__init__:pyspark.sql.connect.proto.relations_pb2.NAReplace.__init__"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *î
colsá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *·
replacementsÃ
ZUnion[typing.Iterable[pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement],None]·
Ntyping.Iterable[pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement]~
=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"=pyspark.sql.connect.proto.relations_pb2.NAReplace.Replacement"typing.Iterable
None *ú
HasField:pyspark.sql.connect.proto.relations_pb2.NAReplace.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.relations_pb2.NAReplace.ClearField"
None*p
selff
1pyspark.sql.connect.proto.relations_pb2.NAReplace"1pyspark.sql.connect.proto.relations_pb2.NAReplace*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.relations_pb2.NAReplace.DESCRIPTOR
Anyrx
INPUT_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.NAReplace.INPUT_FIELD_NUMBER
builtins.int"builtins.intrv
COLS_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.NAReplace.COLS_FIELD_NUMBER
builtins.int"builtins.intrÜ
REPLACEMENTS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.NAReplace.REPLACEMENTS_FIELD_NUMBER
builtins.int"builtins.intΩ
ToDF,pyspark.sql.connect.proto.relations_pb2.ToDF"builtins.object*ó
input2pyspark.sql.connect.proto.relations_pb2.ToDF.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF0:property`*»
column_names9pyspark.sql.connect.proto.relations_pb2.ToDF.column_names"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF0:property`*ì
__init__5pyspark.sql.connect.proto.relations_pb2.ToDF.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *ú
column_namesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *ç
HasField5pyspark.sql.connect.proto.relations_pb2.ToDF.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*°

ClearField7pyspark.sql.connect.proto.relations_pb2.ToDF.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.ToDF",pyspark.sql.connect.proto.relations_pb2.ToDF*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.ToDF.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.ToDF.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÅ
COLUMN_NAMES_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.ToDF.COLUMN_NAMES_FIELD_NUMBER
builtins.int"builtins.intÆ
WithColumnsRenamed:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed"builtins.object*¬
input@pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed0:property`*ˇ
rename_columns_mapMpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.rename_columns_map"
Any*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed0:property`*˘
__init__Cpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.__init__"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *◊
rename_columns_mapº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *∏
HasFieldCpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.HasField"
builtins.bool"builtins.bool*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ã

ClearFieldEpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.ClearField"
None*Ç
selfx
:pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed":pyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr\

DESCRIPTOREpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.DESCRIPTOR
AnyrÅ
INPUT_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.INPUT_FIELD_NUMBER
builtins.int"builtins.intrõ
RENAME_COLUMNS_MAP_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.WithColumnsRenamed.RENAME_COLUMNS_MAP_FIELD_NUMBER
builtins.int"builtins.intË
WithColumns3pyspark.sql.connect.proto.relations_pb2.WithColumns"builtins.object*¨
input9pyspark.sql.connect.proto.relations_pb2.WithColumns.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns0:property`*”
aliases;pyspark.sql.connect.proto.relations_pb2.WithColumns.aliases"
Any*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns0:property`*‹
__init__<pyspark.sql.connect.proto.relations_pb2.WithColumns.__init__"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *–
aliases¿
WUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Alias],None]ÿ
Ktyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression.Alias]x
:pyspark.sql.connect.proto.expressions_pb2.Expression.Alias":pyspark.sql.connect.proto.expressions_pb2.Expression.Alias"typing.Iterable
None *¢
HasField<pyspark.sql.connect.proto.relations_pb2.WithColumns.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearField>pyspark.sql.connect.proto.relations_pb2.WithColumns.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.relations_pb2.WithColumns"3pyspark.sql.connect.proto.relations_pb2.WithColumns*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.relations_pb2.WithColumns.DESCRIPTOR
Anyrz
INPUT_FIELD_NUMBERFpyspark.sql.connect.proto.relations_pb2.WithColumns.INPUT_FIELD_NUMBER
builtins.int"builtins.intr~
ALIASES_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.WithColumns.ALIASES_FIELD_NUMBER
builtins.int"builtins.intÌ
WithWatermark5pyspark.sql.connect.proto.relations_pb2.WithWatermark"builtins.object*≤
input;pyspark.sql.connect.proto.relations_pb2.WithWatermark.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark0:property`*Ù
__init__>pyspark.sql.connect.proto.relations_pb2.WithWatermark.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *.

event_time
builtins.str"builtins.str *3
delay_threshold
builtins.str"builtins.str *®
HasField>pyspark.sql.connect.proto.relations_pb2.WithWatermark.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*„

ClearField@pyspark.sql.connect.proto.relations_pb2.WithWatermark.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.WithWatermark"5pyspark.sql.connect.proto.relations_pb2.WithWatermark*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.WithWatermark.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.WithWatermark.INPUT_FIELD_NUMBER
builtins.int"builtins.intrÜ
EVENT_TIME_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.WithWatermark.EVENT_TIME_FIELD_NUMBER
builtins.int"builtins.intrê
DELAY_THRESHOLD_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.WithWatermark.DELAY_THRESHOLD_FIELD_NUMBER
builtins.int"builtins.intrl

event_time@pyspark.sql.connect.proto.relations_pb2.WithWatermark.event_time
builtins.str"builtins.strrv
delay_thresholdEpyspark.sql.connect.proto.relations_pb2.WithWatermark.delay_threshold
builtins.str"builtins.str
Hint,pyspark.sql.connect.proto.relations_pb2.Hint"builtins.object*ó
input2pyspark.sql.connect.proto.relations_pb2.Hint.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint0:property`*ƒ

parameters7pyspark.sql.connect.proto.relations_pb2.Hint.parameters"
Any*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint0:property`*‹
__init__5pyspark.sql.connect.proto.relations_pb2.Hint.__init__"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
name
builtins.str"builtins.str *ª

parameters®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *ç
HasField5pyspark.sql.connect.proto.relations_pb2.Hint.HasField"
builtins.bool"builtins.bool*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*»

ClearField7pyspark.sql.connect.proto.relations_pb2.Hint.ClearField"
None*f
self\
,pyspark.sql.connect.proto.relations_pb2.Hint",pyspark.sql.connect.proto.relations_pb2.Hint*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrN

DESCRIPTOR7pyspark.sql.connect.proto.relations_pb2.Hint.DESCRIPTOR
Anyrs
INPUT_FIELD_NUMBER?pyspark.sql.connect.proto.relations_pb2.Hint.INPUT_FIELD_NUMBER
builtins.int"builtins.intrq
NAME_FIELD_NUMBER>pyspark.sql.connect.proto.relations_pb2.Hint.NAME_FIELD_NUMBER
builtins.int"builtins.intr}
PARAMETERS_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.Hint.PARAMETERS_FIELD_NUMBER
builtins.int"builtins.intrW
name1pyspark.sql.connect.proto.relations_pb2.Hint.name
builtins.str"builtins.strƒ)
Unpivot/pyspark.sql.connect.proto.relations_pb2.Unpivot"builtins.object*†
input5pyspark.sql.connect.proto.relations_pb2.Unpivot.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot0:property`*ø
ids3pyspark.sql.connect.proto.relations_pb2.Unpivot.ids"
Any*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot0:property`*Æ
values6pyspark.sql.connect.proto.relations_pb2.Unpivot.values"p
6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot0:property`*˘
__init__8pyspark.sql.connect.proto.relations_pb2.Unpivot.__init__"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *¥
ids®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *—
values¬
BUnion[pyspark.sql.connect.proto.relations_pb2.Unpivot.Values,None]p
6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values"6pyspark.sql.connect.proto.relations_pb2.Unpivot.Values
None *8
variable_column_name
builtins.str"builtins.str *5
value_column_name
builtins.str"builtins.str *„
HasField8pyspark.sql.connect.proto.relations_pb2.Unpivot.HasField"
builtins.bool"builtins.bool*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*√	

ClearField:pyspark.sql.connect.proto.relations_pb2.Unpivot.ClearField"
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Â

WhichOneof:pyspark.sql.connect.proto.relations_pb2.Unpivot.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*l
selfb
/pyspark.sql.connect.proto.relations_pb2.Unpivot"/pyspark.sql.connect.proto.relations_pb2.Unpivot*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrQ

DESCRIPTOR:pyspark.sql.connect.proto.relations_pb2.Unpivot.DESCRIPTOR
Anyrv
INPUT_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Unpivot.INPUT_FIELD_NUMBER
builtins.int"builtins.intrr
IDS_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Unpivot.IDS_FIELD_NUMBER
builtins.int"builtins.intrx
VALUES_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.Unpivot.VALUES_FIELD_NUMBER
builtins.int"builtins.intrî
!VARIABLE_COLUMN_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.Unpivot.VARIABLE_COLUMN_NAME_FIELD_NUMBER
builtins.int"builtins.intré
VALUE_COLUMN_NAME_FIELD_NUMBERNpyspark.sql.connect.proto.relations_pb2.Unpivot.VALUE_COLUMN_NAME_FIELD_NUMBER
builtins.int"builtins.intrz
variable_column_nameDpyspark.sql.connect.proto.relations_pb2.Unpivot.variable_column_name
builtins.str"builtins.strrt
value_column_nameApyspark.sql.connect.proto.relations_pb2.Unpivot.value_column_name
builtins.str"builtins.strÜ
ToSchema0pyspark.sql.connect.proto.relations_pb2.ToSchema"builtins.object*£
input6pyspark.sql.connect.proto.relations_pb2.ToSchema.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema0:property`*ù
schema7pyspark.sql.connect.proto.relations_pb2.ToSchema.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema0:property`*∂
__init__9pyspark.sql.connect.proto.relations_pb2.ToSchema.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *ø
HasField9pyspark.sql.connect.proto.relations_pb2.ToSchema.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≠

ClearField;pyspark.sql.connect.proto.relations_pb2.ToSchema.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.ToSchema"0pyspark.sql.connect.proto.relations_pb2.ToSchema*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.ToSchema.DESCRIPTOR
Anyrw
INPUT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.ToSchema.INPUT_FIELD_NUMBER
builtins.int"builtins.intry
SCHEMA_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.ToSchema.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intü#
RepartitionByExpression?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"builtins.object*“
inputEpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression0:property`*â
partition_exprsOpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.partition_exprs"
Any*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression0:property`*Œ
__init__Hpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.__init__"
None*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *¿
partition_exprs®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Z
num_partitionsD
Union[builtins.int,None]
builtins.int"builtins.int
None *ï
HasFieldHpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.HasField"
builtins.bool"builtins.bool*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*©

ClearFieldJpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.ClearField"
None*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ó

WhichOneofJpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ç
selfÇ
?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression"?pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesra

DESCRIPTORJpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.DESCRIPTOR
AnyrÜ
INPUT_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.INPUT_FIELD_NUMBER
builtins.int"builtins.intrö
PARTITION_EXPRS_FIELD_NUMBER\pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.PARTITION_EXPRS_FIELD_NUMBER
builtins.int"builtins.intrò
NUM_PARTITIONS_FIELD_NUMBER[pyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.NUM_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intr~
num_partitionsNpyspark.sql.connect.proto.relations_pb2.RepartitionByExpression.num_partitions
builtins.int"builtins.int€"
MapPartitions5pyspark.sql.connect.proto.relations_pb2.MapPartitions"builtins.object*≤
input;pyspark.sql.connect.proto.relations_pb2.MapPartitions.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions0:property`*„
func:pyspark.sql.connect.proto.relations_pb2.MapPartitions.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions0:property`*ˆ
__init__>pyspark.sql.connect.proto.relations_pb2.MapPartitions.__init__"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *Y

is_barrierG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *õ
HasField>pyspark.sql.connect.proto.relations_pb2.MapPartitions.HasField"
builtins.bool"builtins.bool*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*â

ClearField@pyspark.sql.connect.proto.relations_pb2.MapPartitions.ClearField"
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˜

WhichOneof@pyspark.sql.connect.proto.relations_pb2.MapPartitions.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*x
selfn
5pyspark.sql.connect.proto.relations_pb2.MapPartitions"5pyspark.sql.connect.proto.relations_pb2.MapPartitions*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrW

DESCRIPTOR@pyspark.sql.connect.proto.relations_pb2.MapPartitions.DESCRIPTOR
Anyr|
INPUT_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.MapPartitions.INPUT_FIELD_NUMBER
builtins.int"builtins.intrz
FUNC_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.MapPartitions.FUNC_FIELD_NUMBER
builtins.int"builtins.intrÜ
IS_BARRIER_FIELD_NUMBERMpyspark.sql.connect.proto.relations_pb2.MapPartitions.IS_BARRIER_FIELD_NUMBER
builtins.int"builtins.intrn

is_barrier@pyspark.sql.connect.proto.relations_pb2.MapPartitions.is_barrier
builtins.bool"builtins.booléW
GroupMap0pyspark.sql.connect.proto.relations_pb2.GroupMap"builtins.object*£
input6pyspark.sql.connect.proto.relations_pb2.GroupMap.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:property`*‰
grouping_expressionsEpyspark.sql.connect.proto.relations_pb2.GroupMap.grouping_expressions"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:property`*‘
func5pyspark.sql.connect.proto.relations_pb2.GroupMap.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:property`*‚
sorting_expressionsDpyspark.sql.connect.proto.relations_pb2.GroupMap.sorting_expressions"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:property`*≥
initial_input>pyspark.sql.connect.proto.relations_pb2.GroupMap.initial_input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:property`*Ù
initial_grouping_expressionsMpyspark.sql.connect.proto.relations_pb2.GroupMap.initial_grouping_expressions"
Any*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap0:property`*–
__init__9pyspark.sql.connect.proto.relations_pb2.GroupMap.__init__"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *≈
grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *ƒ
sorting_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *∆
initial_input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *Õ
initial_grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *g
is_map_groups_with_stateG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *W
output_modeD
Union[builtins.str,None]
builtins.str"builtins.str
None *X
timeout_confD
Union[builtins.str,None]
builtins.str"builtins.str
None * 
HasField9pyspark.sql.connect.proto.relations_pb2.GroupMap.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*Ú

field_name·
§Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*™

ClearField;pyspark.sql.connect.proto.relations_pb2.GroupMap.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*‰

field_name”
ÆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2…

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof˝

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.relations_pb2.GroupMap.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.relations_pb2.GroupMap"0pyspark.sql.connect.proto.relations_pb2.GroupMap*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrR

DESCRIPTOR;pyspark.sql.connect.proto.relations_pb2.GroupMap.DESCRIPTOR
Anyrw
INPUT_FIELD_NUMBERCpyspark.sql.connect.proto.relations_pb2.GroupMap.INPUT_FIELD_NUMBER
builtins.int"builtins.intrï
!GROUPING_EXPRESSIONS_FIELD_NUMBERRpyspark.sql.connect.proto.relations_pb2.GroupMap.GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intru
FUNC_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.GroupMap.FUNC_FIELD_NUMBER
builtins.int"builtins.intrì
 SORTING_EXPRESSIONS_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.GroupMap.SORTING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrá
INITIAL_INPUT_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.GroupMap.INITIAL_INPUT_FIELD_NUMBER
builtins.int"builtins.intr•
)INITIAL_GROUPING_EXPRESSIONS_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.GroupMap.INITIAL_GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrù
%IS_MAP_GROUPS_WITH_STATE_FIELD_NUMBERVpyspark.sql.connect.proto.relations_pb2.GroupMap.IS_MAP_GROUPS_WITH_STATE_FIELD_NUMBER
builtins.int"builtins.intrÉ
OUTPUT_MODE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.GroupMap.OUTPUT_MODE_FIELD_NUMBER
builtins.int"builtins.intrÖ
TIMEOUT_CONF_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.GroupMap.TIMEOUT_CONF_FIELD_NUMBER
builtins.int"builtins.intrÖ
is_map_groups_with_stateIpyspark.sql.connect.proto.relations_pb2.GroupMap.is_map_groups_with_state
builtins.bool"builtins.boolri
output_mode<pyspark.sql.connect.proto.relations_pb2.GroupMap.output_mode
builtins.str"builtins.strrk
timeout_conf=pyspark.sql.connect.proto.relations_pb2.GroupMap.timeout_conf
builtins.str"builtins.strØ:

CoGroupMap2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"builtins.object*©
input8pyspark.sql.connect.proto.relations_pb2.CoGroupMap.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:property`*ˆ
input_grouping_expressionsMpyspark.sql.connect.proto.relations_pb2.CoGroupMap.input_grouping_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:property`*©
other8pyspark.sql.connect.proto.relations_pb2.CoGroupMap.other"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:property`*ˆ
other_grouping_expressionsMpyspark.sql.connect.proto.relations_pb2.CoGroupMap.other_grouping_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:property`*⁄
func7pyspark.sql.connect.proto.relations_pb2.CoGroupMap.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:property`*Ù
input_sorting_expressionsLpyspark.sql.connect.proto.relations_pb2.CoGroupMap.input_sorting_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:property`*Ù
other_sorting_expressionsLpyspark.sql.connect.proto.relations_pb2.CoGroupMap.other_sorting_expressions"
Any*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap0:property`*â
__init__;pyspark.sql.connect.proto.relations_pb2.CoGroupMap.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *À
input_grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *æ
other∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *À
other_grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None * 
input_sorting_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None * 
other_sorting_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *Ï
HasField;pyspark.sql.connect.proto.relations_pb2.CoGroupMap.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ú


ClearField=pyspark.sql.connect.proto.relations_pb2.CoGroupMap.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.CoGroupMap"2pyspark.sql.connect.proto.relations_pb2.CoGroupMap*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.CoGroupMap.DESCRIPTOR
Anyry
INPUT_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.CoGroupMap.INPUT_FIELD_NUMBER
builtins.int"builtins.intr£
'INPUT_GROUPING_EXPRESSIONS_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.CoGroupMap.INPUT_GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intry
OTHER_FIELD_NUMBEREpyspark.sql.connect.proto.relations_pb2.CoGroupMap.OTHER_FIELD_NUMBER
builtins.int"builtins.intr£
'OTHER_GROUPING_EXPRESSIONS_FIELD_NUMBERZpyspark.sql.connect.proto.relations_pb2.CoGroupMap.OTHER_GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrw
FUNC_FIELD_NUMBERDpyspark.sql.connect.proto.relations_pb2.CoGroupMap.FUNC_FIELD_NUMBER
builtins.int"builtins.intr°
&INPUT_SORTING_EXPRESSIONS_FIELD_NUMBERYpyspark.sql.connect.proto.relations_pb2.CoGroupMap.INPUT_SORTING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intr°
&OTHER_SORTING_EXPRESSIONS_FIELD_NUMBERYpyspark.sql.connect.proto.relations_pb2.CoGroupMap.OTHER_SORTING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intˇ.
ApplyInPandasWithState>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState"builtins.object*œ
inputDpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState0:property`*ê
grouping_expressionsSpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.grouping_expressions"
Any*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState0:property`*Ä
funcCpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.func"ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState0:property`*»	
__init__Gpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.__init__"
None*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *≈
grouping_expressions®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *â
func¸
UUnion[pyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction,None]ñ
Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction"Ipyspark.sql.connect.proto.expressions_pb2.CommonInlineUserDefinedFunction
None *1
output_schema
builtins.str"builtins.str *0
state_schema
builtins.str"builtins.str */
output_mode
builtins.str"builtins.str *0
timeout_conf
builtins.str"builtins.str *Î
HasFieldGpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.HasField"
builtins.bool"builtins.bool*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ò

ClearFieldIpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.ClearField"
None*ã
selfÄ
>pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState">pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState*¶	

field_nameï	
»Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesr`

DESCRIPTORIpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.DESCRIPTOR
AnyrÖ
INPUT_FIELD_NUMBERQpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.INPUT_FIELD_NUMBER
builtins.int"builtins.intr£
!GROUPING_EXPRESSIONS_FIELD_NUMBER`pyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.GROUPING_EXPRESSIONS_FIELD_NUMBER
builtins.int"builtins.intrÉ
FUNC_FIELD_NUMBERPpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.FUNC_FIELD_NUMBER
builtins.int"builtins.intrï
OUTPUT_SCHEMA_FIELD_NUMBERYpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.OUTPUT_SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrì
STATE_SCHEMA_FIELD_NUMBERXpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.STATE_SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrë
OUTPUT_MODE_FIELD_NUMBERWpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.OUTPUT_MODE_FIELD_NUMBER
builtins.int"builtins.intrì
TIMEOUT_CONF_FIELD_NUMBERXpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.TIMEOUT_CONF_FIELD_NUMBER
builtins.int"builtins.intr{
output_schemaLpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.output_schema
builtins.str"builtins.strry
state_schemaKpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.state_schema
builtins.str"builtins.strrw
output_modeJpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.output_mode
builtins.str"builtins.strry
timeout_confKpyspark.sql.connect.proto.relations_pb2.ApplyInPandasWithState.timeout_conf
builtins.str"builtins.str™(
$CommonInlineUserDefinedTableFunctionLpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"builtins.object*§
	argumentsVpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.arguments"
Any*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction0:property`*â
python_udtfXpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.python_udtf"h
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction0:property`*á
__init__Upyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.__init__"
None*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*1
function_name
builtins.str"builtins.str *3
deterministic
builtins.bool"builtins.bool *∫
	arguments®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None * 
python_udtf∂
>Union[pyspark.sql.connect.proto.relations_pb2.PythonUDTF,None]h
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF
None *ï
HasFieldUpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.HasField"
builtins.bool"builtins.bool*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ˆ

ClearFieldWpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.ClearField"
None*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*æ

WhichOneofWpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*ß
selfú
Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction"Lpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrn

DESCRIPTORWpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.DESCRIPTOR
Anyr£
FUNCTION_NAME_FIELD_NUMBERgpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr£
DETERMINISTIC_FIELD_NUMBERgpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.DETERMINISTIC_FIELD_NUMBER
builtins.int"builtins.intrõ
ARGUMENTS_FIELD_NUMBERcpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.ARGUMENTS_FIELD_NUMBER
builtins.int"builtins.intrü
PYTHON_UDTF_FIELD_NUMBERepyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.PYTHON_UDTF_FIELD_NUMBER
builtins.int"builtins.intrâ
function_nameZpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.function_name
builtins.str"builtins.strrã
deterministicZpyspark.sql.connect.proto.relations_pb2.CommonInlineUserDefinedTableFunction.deterministic
builtins.bool"builtins.boolö

PythonUDTF2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"builtins.object*≠
return_type>pyspark.sql.connect.proto.relations_pb2.PythonUDTF.return_type"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF0:property`*ê
__init__;pyspark.sql.connect.proto.relations_pb2.PythonUDTF.__init__"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*∏
return_type§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *-
	eval_type
builtins.int"builtins.int */
command 
builtins.bytes"builtins.bytes *.

python_ver
builtins.str"builtins.str *≈
HasField;pyspark.sql.connect.proto.relations_pb2.PythonUDTF.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*¶

ClearField=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

WhichOneof=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*r
selfh
2pyspark.sql.connect.proto.relations_pb2.PythonUDTF"2pyspark.sql.connect.proto.relations_pb2.PythonUDTF*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.DESCRIPTOR
AnyrÖ
RETURN_TYPE_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.PythonUDTF.RETURN_TYPE_FIELD_NUMBER
builtins.int"builtins.intrÅ
EVAL_TYPE_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.PythonUDTF.EVAL_TYPE_FIELD_NUMBER
builtins.int"builtins.intr}
COMMAND_FIELD_NUMBERGpyspark.sql.connect.proto.relations_pb2.PythonUDTF.COMMAND_FIELD_NUMBER
builtins.int"builtins.intrÉ
PYTHON_VER_FIELD_NUMBERJpyspark.sql.connect.proto.relations_pb2.PythonUDTF.PYTHON_VER_FIELD_NUMBER
builtins.int"builtins.intrg
	eval_type<pyspark.sql.connect.proto.relations_pb2.PythonUDTF.eval_type
builtins.int"builtins.intrg
command:pyspark.sql.connect.proto.relations_pb2.PythonUDTF.command 
builtins.bytes"builtins.bytesri

python_ver=pyspark.sql.connect.proto.relations_pb2.PythonUDTF.python_ver
builtins.str"builtins.stræ
CollectMetrics6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"builtins.object*µ
input<pyspark.sql.connect.proto.relations_pb2.CollectMetrics.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics0:property`*‹
metrics>pyspark.sql.connect.proto.relations_pb2.CollectMetrics.metrics"
Any*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics0:property`*˜
__init__?pyspark.sql.connect.proto.relations_pb2.CollectMetrics.__init__"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *(
name
builtins.str"builtins.str *∏
metrics®
QUnion[typing.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression],None]∆
Etyping.Iterable[pyspark.sql.connect.proto.expressions_pb2.Expression]l
4pyspark.sql.connect.proto.expressions_pb2.Expression"4pyspark.sql.connect.proto.expressions_pb2.Expression"typing.Iterable
None *´
HasField?pyspark.sql.connect.proto.relations_pb2.CollectMetrics.HasField"
builtins.bool"builtins.bool*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ê

ClearFieldApyspark.sql.connect.proto.relations_pb2.CollectMetrics.ClearField"
None*z
selfp
6pyspark.sql.connect.proto.relations_pb2.CollectMetrics"6pyspark.sql.connect.proto.relations_pb2.CollectMetrics*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrX

DESCRIPTORApyspark.sql.connect.proto.relations_pb2.CollectMetrics.DESCRIPTOR
Anyr}
INPUT_FIELD_NUMBERIpyspark.sql.connect.proto.relations_pb2.CollectMetrics.INPUT_FIELD_NUMBER
builtins.int"builtins.intr{
NAME_FIELD_NUMBERHpyspark.sql.connect.proto.relations_pb2.CollectMetrics.NAME_FIELD_NUMBER
builtins.int"builtins.intrÅ
METRICS_FIELD_NUMBERKpyspark.sql.connect.proto.relations_pb2.CollectMetrics.METRICS_FIELD_NUMBER
builtins.int"builtins.intra
name;pyspark.sql.connect.proto.relations_pb2.CollectMetrics.name
builtins.str"builtins.str˜*
Parse-pyspark.sql.connect.proto.relations_pb2.Parse"builtins.object*ö
input3pyspark.sql.connect.proto.relations_pb2.Parse.input"d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse0:property`*î
schema4pyspark.sql.connect.proto.relations_pb2.Parse.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse0:property`*¡
options5pyspark.sql.connect.proto.relations_pb2.Parse.options"
Any*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse0:property`*ö
__init__6pyspark.sql.connect.proto.relations_pb2.Parse.__init__"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*æ
input∞
<Union[pyspark.sql.connect.proto.relations_pb2.Relation,None]d
0pyspark.sql.connect.proto.relations_pb2.Relation"0pyspark.sql.connect.proto.relations_pb2.Relation
None *õ
formatå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *›
HasField6pyspark.sql.connect.proto.relations_pb2.Parse.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ó

ClearField8pyspark.sql.connect.proto.relations_pb2.Parse.ClearField"
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ﬂ

WhichOneof8pyspark.sql.connect.proto.relations_pb2.Parse.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.relations_pb2.Parse"-pyspark.sql.connect.proto.relations_pb2.Parse*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrO

DESCRIPTOR8pyspark.sql.connect.proto.relations_pb2.Parse.DESCRIPTOR
AnyrÒ
PARSE_FORMAT_UNSPECIFIEDFpyspark.sql.connect.proto.relations_pb2.Parse.PARSE_FORMAT_UNSPECIFIEDå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTyper·
PARSE_FORMAT_CSV>pyspark.sql.connect.proto.relations_pb2.Parse.PARSE_FORMAT_CSVå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTyper„
PARSE_FORMAT_JSON?pyspark.sql.connect.proto.relations_pb2.Parse.PARSE_FORMAT_JSONå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTypert
INPUT_FIELD_NUMBER@pyspark.sql.connect.proto.relations_pb2.Parse.INPUT_FIELD_NUMBER
builtins.int"builtins.intrv
FORMAT_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Parse.FORMAT_FIELD_NUMBER
builtins.int"builtins.intrv
SCHEMA_FIELD_NUMBERApyspark.sql.connect.proto.relations_pb2.Parse.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrx
OPTIONS_FIELD_NUMBERBpyspark.sql.connect.proto.relations_pb2.Parse.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrÕ
format4pyspark.sql.connect.proto.relations_pb2.Parse.formatå
Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueType"Dpyspark.sql.connect.proto.relations_pb2.Parse._ParseFormat.ValueTypeÔ‰
Catalog-pyspark.sql.connect.proto.catalog_pb2.Catalog"builtins.object*∫
current_database>pyspark.sql.connect.proto.catalog_pb2.Catalog.current_database"n
5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*»
set_current_databaseBpyspark.sql.connect.proto.catalog_pb2.Catalog.set_current_database"t
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*≤
list_databases<pyspark.sql.connect.proto.catalog_pb2.Catalog.list_databases"j
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*¶
list_tables9pyspark.sql.connect.proto.catalog_pb2.Catalog.list_tables"d
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*≤
list_functions<pyspark.sql.connect.proto.catalog_pb2.Catalog.list_functions"j
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*™
list_columns:pyspark.sql.connect.proto.catalog_pb2.Catalog.list_columns"f
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*™
get_database:pyspark.sql.connect.proto.catalog_pb2.Catalog.get_database"f
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*û
	get_table7pyspark.sql.connect.proto.catalog_pb2.Catalog.get_table"`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*™
get_function:pyspark.sql.connect.proto.catalog_pb2.Catalog.get_function"f
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*∂
database_exists=pyspark.sql.connect.proto.catalog_pb2.Catalog.database_exists"l
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*™
table_exists:pyspark.sql.connect.proto.catalog_pb2.Catalog.table_exists"f
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*∂
function_exists=pyspark.sql.connect.proto.catalog_pb2.Catalog.function_exists"l
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*Ã
create_external_tableCpyspark.sql.connect.proto.catalog_pb2.Catalog.create_external_table"v
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*™
create_table:pyspark.sql.connect.proto.catalog_pb2.Catalog.create_table"f
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*∞
drop_temp_view<pyspark.sql.connect.proto.catalog_pb2.Catalog.drop_temp_view"h
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`* 
drop_global_temp_viewCpyspark.sql.connect.proto.catalog_pb2.Catalog.drop_global_temp_view"t
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*¬
recover_partitions@pyspark.sql.connect.proto.catalog_pb2.Catalog.recover_partitions"r
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*û
	is_cached7pyspark.sql.connect.proto.catalog_pb2.Catalog.is_cached"`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*¶
cache_table9pyspark.sql.connect.proto.catalog_pb2.Catalog.cache_table"d
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*Æ
uncache_table;pyspark.sql.connect.proto.catalog_pb2.Catalog.uncache_table"h
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*¶
clear_cache9pyspark.sql.connect.proto.catalog_pb2.Catalog.clear_cache"d
0pyspark.sql.connect.proto.catalog_pb2.ClearCache"0pyspark.sql.connect.proto.catalog_pb2.ClearCache*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*Æ
refresh_table;pyspark.sql.connect.proto.catalog_pb2.Catalog.refresh_table"h
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*¥
refresh_by_path=pyspark.sql.connect.proto.catalog_pb2.Catalog.refresh_by_path"j
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*∂
current_catalog=pyspark.sql.connect.proto.catalog_pb2.Catalog.current_catalog"l
4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*ƒ
set_current_catalogApyspark.sql.connect.proto.catalog_pb2.Catalog.set_current_catalog"r
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*Æ
list_catalogs;pyspark.sql.connect.proto.catalog_pb2.Catalog.list_catalogs"h
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog0:property`*õ,
__init__6pyspark.sql.connect.proto.catalog_pb2.Catalog.__init__"
None*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*ÿ
current_databaseø
AUnion[pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase,None]n
5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase
None *Â
set_current_database»
DUnion[pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase,None]t
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase
None *–
list_databasesπ
?Union[pyspark.sql.connect.proto.catalog_pb2.ListDatabases,None]j
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases
None *ƒ
list_tables∞
<Union[pyspark.sql.connect.proto.catalog_pb2.ListTables,None]d
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables
None *–
list_functionsπ
?Union[pyspark.sql.connect.proto.catalog_pb2.ListFunctions,None]j
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions
None *»
list_columns≥
=Union[pyspark.sql.connect.proto.catalog_pb2.ListColumns,None]f
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns
None *»
get_database≥
=Union[pyspark.sql.connect.proto.catalog_pb2.GetDatabase,None]f
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase
None *º
	get_table™
:Union[pyspark.sql.connect.proto.catalog_pb2.GetTable,None]`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable
None *»
get_function≥
=Union[pyspark.sql.connect.proto.catalog_pb2.GetFunction,None]f
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction
None *‘
database_existsº
@Union[pyspark.sql.connect.proto.catalog_pb2.DatabaseExists,None]l
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists
None *»
table_exists≥
=Union[pyspark.sql.connect.proto.catalog_pb2.TableExists,None]f
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists
None *‘
function_existsº
@Union[pyspark.sql.connect.proto.catalog_pb2.FunctionExists,None]l
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists
None *È
create_external_tableÀ
EUnion[pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable,None]v
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable
None *»
create_table≥
=Union[pyspark.sql.connect.proto.catalog_pb2.CreateTable,None]f
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable
None *Õ
drop_temp_view∂
>Union[pyspark.sql.connect.proto.catalog_pb2.DropTempView,None]h
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView
None *Ê
drop_global_temp_view»
DUnion[pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView,None]t
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView
None *‡
recover_partitions≈
CUnion[pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions,None]r
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions
None *º
	is_cached™
:Union[pyspark.sql.connect.proto.catalog_pb2.IsCached,None]`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached
None *ƒ
cache_table∞
<Union[pyspark.sql.connect.proto.catalog_pb2.CacheTable,None]d
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable
None *Ã
uncache_table∂
>Union[pyspark.sql.connect.proto.catalog_pb2.UncacheTable,None]h
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable
None *ƒ
clear_cache∞
<Union[pyspark.sql.connect.proto.catalog_pb2.ClearCache,None]d
0pyspark.sql.connect.proto.catalog_pb2.ClearCache"0pyspark.sql.connect.proto.catalog_pb2.ClearCache
None *Ã
refresh_table∂
>Union[pyspark.sql.connect.proto.catalog_pb2.RefreshTable,None]h
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable
None *—
refresh_by_pathπ
?Union[pyspark.sql.connect.proto.catalog_pb2.RefreshByPath,None]j
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath
None *‘
current_catalogº
@Union[pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog,None]l
4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog
None *·
set_current_catalog≈
CUnion[pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog,None]r
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog
None *Ã
list_catalogs∂
>Union[pyspark.sql.connect.proto.catalog_pb2.ListCatalogs,None]h
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs
None *Ì$
HasField6pyspark.sql.connect.proto.catalog_pb2.Catalog.HasField"
builtins.bool"builtins.bool*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*û#

field_nameç#
‡	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*€$

ClearField8pyspark.sql.connect.proto.catalog_pb2.Catalog.ClearField"
None*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*û#

field_nameç#
‡	Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*ò

WhichOneof8pyspark.sql.connect.proto.catalog_pb2.Catalog.WhichOneof"†
«Union[Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str7
Literal[builtins.str]	
builtins.str"builtins.str
None*h
self^
-pyspark.sql.connect.proto.catalog_pb2.Catalog"-pyspark.sql.connect.proto.catalog_pb2.Catalog*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrO

DESCRIPTOR8pyspark.sql.connect.proto.catalog_pb2.Catalog.DESCRIPTOR
Anyrä
CURRENT_DATABASE_FIELD_NUMBERKpyspark.sql.connect.proto.catalog_pb2.Catalog.CURRENT_DATABASE_FIELD_NUMBER
builtins.int"builtins.intrí
!SET_CURRENT_DATABASE_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.Catalog.SET_CURRENT_DATABASE_FIELD_NUMBER
builtins.int"builtins.intrÜ
LIST_DATABASES_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_DATABASES_FIELD_NUMBER
builtins.int"builtins.intrÄ
LIST_TABLES_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_TABLES_FIELD_NUMBER
builtins.int"builtins.intrÜ
LIST_FUNCTIONS_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_FUNCTIONS_FIELD_NUMBER
builtins.int"builtins.intrÇ
LIST_COLUMNS_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_COLUMNS_FIELD_NUMBER
builtins.int"builtins.intrÇ
GET_DATABASE_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.GET_DATABASE_FIELD_NUMBER
builtins.int"builtins.intr|
GET_TABLE_FIELD_NUMBERDpyspark.sql.connect.proto.catalog_pb2.Catalog.GET_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÇ
GET_FUNCTION_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.GET_FUNCTION_FIELD_NUMBER
builtins.int"builtins.intrà
DATABASE_EXISTS_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.DATABASE_EXISTS_FIELD_NUMBER
builtins.int"builtins.intrÇ
TABLE_EXISTS_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.TABLE_EXISTS_FIELD_NUMBER
builtins.int"builtins.intrà
FUNCTION_EXISTS_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.FUNCTION_EXISTS_FIELD_NUMBER
builtins.int"builtins.intrî
"CREATE_EXTERNAL_TABLE_FIELD_NUMBERPpyspark.sql.connect.proto.catalog_pb2.Catalog.CREATE_EXTERNAL_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÇ
CREATE_TABLE_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.Catalog.CREATE_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÜ
DROP_TEMP_VIEW_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.Catalog.DROP_TEMP_VIEW_FIELD_NUMBER
builtins.int"builtins.intrî
"DROP_GLOBAL_TEMP_VIEW_FIELD_NUMBERPpyspark.sql.connect.proto.catalog_pb2.Catalog.DROP_GLOBAL_TEMP_VIEW_FIELD_NUMBER
builtins.int"builtins.intré
RECOVER_PARTITIONS_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.Catalog.RECOVER_PARTITIONS_FIELD_NUMBER
builtins.int"builtins.intr|
IS_CACHED_FIELD_NUMBERDpyspark.sql.connect.proto.catalog_pb2.Catalog.IS_CACHED_FIELD_NUMBER
builtins.int"builtins.intrÄ
CACHE_TABLE_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.Catalog.CACHE_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÑ
UNCACHE_TABLE_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.Catalog.UNCACHE_TABLE_FIELD_NUMBER
builtins.int"builtins.intrÄ
CLEAR_CACHE_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.Catalog.CLEAR_CACHE_FIELD_NUMBER
builtins.int"builtins.intrÑ
REFRESH_TABLE_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.Catalog.REFRESH_TABLE_FIELD_NUMBER
builtins.int"builtins.intrà
REFRESH_BY_PATH_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.REFRESH_BY_PATH_FIELD_NUMBER
builtins.int"builtins.intrà
CURRENT_CATALOG_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.Catalog.CURRENT_CATALOG_FIELD_NUMBER
builtins.int"builtins.intrê
 SET_CURRENT_CATALOG_FIELD_NUMBERNpyspark.sql.connect.proto.catalog_pb2.Catalog.SET_CURRENT_CATALOG_FIELD_NUMBER
builtins.int"builtins.intrÑ
LIST_CATALOGS_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.Catalog.LIST_CATALOGS_FIELD_NUMBER
builtins.int"builtins.intÉ
CurrentDatabase5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"builtins.object*Œ
__init__>pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase.__init__"
None*x
selfn
5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase"5pyspark.sql.connect.proto.catalog_pb2.CurrentDatabaserW

DESCRIPTOR@pyspark.sql.connect.proto.catalog_pb2.CurrentDatabase.DESCRIPTOR
Any’
SetCurrentDatabase8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"builtins.object*Ñ
__init__Apyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.__init__"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase*+
db_name
builtins.str"builtins.str *ü

ClearFieldCpyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.ClearField"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase"8pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.DESCRIPTOR
AnyrÉ
DB_NAME_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intri
db_name@pyspark.sql.connect.proto.catalog_pb2.SetCurrentDatabase.db_name
builtins.str"builtins.str™
ListDatabases3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"builtins.object*ù
__init__<pyspark.sql.connect.proto.catalog_pb2.ListDatabases.__init__"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *»
HasField<pyspark.sql.connect.proto.catalog_pb2.ListDatabases.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*∂

ClearField>pyspark.sql.connect.proto.catalog_pb2.ListDatabases.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ò

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListDatabases.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListDatabases"3pyspark.sql.connect.proto.catalog_pb2.ListDatabases*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.catalog_pb2.ListDatabases.DESCRIPTOR
Anyr~
PATTERN_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.ListDatabases.PATTERN_FIELD_NUMBER
builtins.int"builtins.intrd
pattern;pyspark.sql.connect.proto.catalog_pb2.ListDatabases.pattern
builtins.str"builtins.strß

ListTables0pyspark.sql.connect.proto.catalog_pb2.ListTables"builtins.object*È
__init__9pyspark.sql.connect.proto.catalog_pb2.ListTables.__init__"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *å
HasField9pyspark.sql.connect.proto.catalog_pb2.ListTables.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*˙

ClearField;pyspark.sql.connect.proto.catalog_pb2.ListTables.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2…

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.ListTables.WhichOneof˝

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.ListTables.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadX˝

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.ListTables.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ListTables"0pyspark.sql.connect.proto.catalog_pb2.ListTables*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrR

DESCRIPTOR;pyspark.sql.connect.proto.catalog_pb2.ListTables.DESCRIPTOR
Anyr{
DB_NAME_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.ListTables.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intr{
PATTERN_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.ListTables.PATTERN_FIELD_NUMBER
builtins.int"builtins.intra
db_name8pyspark.sql.connect.proto.catalog_pb2.ListTables.db_name
builtins.str"builtins.strra
pattern8pyspark.sql.connect.proto.catalog_pb2.ListTables.pattern
builtins.str"builtins.strÏ
ListFunctions3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"builtins.object*Ú
__init__<pyspark.sql.connect.proto.catalog_pb2.ListFunctions.__init__"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *ï
HasField<pyspark.sql.connect.proto.catalog_pb2.ListFunctions.HasField"
builtins.bool"builtins.bool*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*É

ClearField>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¥

field_name£
æUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2ﬁ

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.WhichOneofÜ

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÜ

WhichOneof>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.ListFunctions"3pyspark.sql.connect.proto.catalog_pb2.ListFunctions*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrU

DESCRIPTOR>pyspark.sql.connect.proto.catalog_pb2.ListFunctions.DESCRIPTOR
Anyr~
DB_NAME_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.ListFunctions.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intr~
PATTERN_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.ListFunctions.PATTERN_FIELD_NUMBER
builtins.int"builtins.intrd
db_name;pyspark.sql.connect.proto.catalog_pb2.ListFunctions.db_name
builtins.str"builtins.strrd
pattern;pyspark.sql.connect.proto.catalog_pb2.ListFunctions.pattern
builtins.str"builtins.strŒ
ListColumns1pyspark.sql.connect.proto.catalog_pb2.ListColumns"builtins.object*«
__init__:pyspark.sql.connect.proto.catalog_pb2.ListColumns.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*.

table_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *¬
HasField:pyspark.sql.connect.proto.catalog_pb2.ListColumns.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.catalog_pb2.ListColumns.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.ListColumns.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.ListColumns"1pyspark.sql.connect.proto.catalog_pb2.ListColumns*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.ListColumns.DESCRIPTOR
AnyrÇ
TABLE_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.ListColumns.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.ListColumns.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrh

table_name<pyspark.sql.connect.proto.catalog_pb2.ListColumns.table_name
builtins.str"builtins.strrb
db_name9pyspark.sql.connect.proto.catalog_pb2.ListColumns.db_name
builtins.str"builtins.strá
GetDatabase1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"builtins.object*Ô
__init__:pyspark.sql.connect.proto.catalog_pb2.GetDatabase.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase*+
db_name
builtins.str"builtins.str *ä

ClearField<pyspark.sql.connect.proto.catalog_pb2.GetDatabase.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetDatabase"1pyspark.sql.connect.proto.catalog_pb2.GetDatabase*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.GetDatabase.DESCRIPTOR
Anyr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.GetDatabase.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrb
db_name9pyspark.sql.connect.proto.catalog_pb2.GetDatabase.db_name
builtins.str"builtins.strî
GetTable.pyspark.sql.connect.proto.catalog_pb2.GetTable"builtins.object*æ
__init__7pyspark.sql.connect.proto.catalog_pb2.GetTable.__init__"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*.

table_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *π
HasField7pyspark.sql.connect.proto.catalog_pb2.GetTable.HasField"
builtins.bool"builtins.bool*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Œ

ClearField9pyspark.sql.connect.proto.catalog_pb2.GetTable.ClearField"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‚

WhichOneof9pyspark.sql.connect.proto.catalog_pb2.GetTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.GetTable".pyspark.sql.connect.proto.catalog_pb2.GetTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.catalog_pb2.GetTable.DESCRIPTOR
Anyr
TABLE_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.GetTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intry
DB_NAME_FIELD_NUMBERCpyspark.sql.connect.proto.catalog_pb2.GetTable.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intre

table_name9pyspark.sql.connect.proto.catalog_pb2.GetTable.table_name
builtins.str"builtins.strr_
db_name6pyspark.sql.connect.proto.catalog_pb2.GetTable.db_name
builtins.str"builtins.str›
GetFunction1pyspark.sql.connect.proto.catalog_pb2.GetFunction"builtins.object* 
__init__:pyspark.sql.connect.proto.catalog_pb2.GetFunction.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*1
function_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *¬
HasField:pyspark.sql.connect.proto.catalog_pb2.GetFunction.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.catalog_pb2.GetFunction.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.GetFunction.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.GetFunction"1pyspark.sql.connect.proto.catalog_pb2.GetFunction*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.GetFunction.DESCRIPTOR
Anyrà
FUNCTION_NAME_FIELD_NUMBERLpyspark.sql.connect.proto.catalog_pb2.GetFunction.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.GetFunction.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrn
function_name?pyspark.sql.connect.proto.catalog_pb2.GetFunction.function_name
builtins.str"builtins.strrb
db_name9pyspark.sql.connect.proto.catalog_pb2.GetFunction.db_name
builtins.str"builtins.str®
DatabaseExists4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"builtins.object*¯
__init__=pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.__init__"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists*+
db_name
builtins.str"builtins.str *ì

ClearField?pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists"4pyspark.sql.connect.proto.catalog_pb2.DatabaseExists*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.DESCRIPTOR
Anyr
DB_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.DatabaseExists.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intre
db_name<pyspark.sql.connect.proto.catalog_pb2.DatabaseExists.db_name
builtins.str"builtins.strŒ
TableExists1pyspark.sql.connect.proto.catalog_pb2.TableExists"builtins.object*«
__init__:pyspark.sql.connect.proto.catalog_pb2.TableExists.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*.

table_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *¬
HasField:pyspark.sql.connect.proto.catalog_pb2.TableExists.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*◊

ClearField<pyspark.sql.connect.proto.catalog_pb2.TableExists.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Î

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.TableExists.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.TableExists"1pyspark.sql.connect.proto.catalog_pb2.TableExists*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.TableExists.DESCRIPTOR
AnyrÇ
TABLE_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.TableExists.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr|
DB_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.TableExists.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrh

table_name<pyspark.sql.connect.proto.catalog_pb2.TableExists.table_name
builtins.str"builtins.strrb
db_name9pyspark.sql.connect.proto.catalog_pb2.TableExists.db_name
builtins.str"builtins.strñ
FunctionExists4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"builtins.object*”
__init__=pyspark.sql.connect.proto.catalog_pb2.FunctionExists.__init__"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*1
function_name
builtins.str"builtins.str *S
db_nameD
Union[builtins.str,None]
builtins.str"builtins.str
None *À
HasField=pyspark.sql.connect.proto.catalog_pb2.FunctionExists.HasField"
builtins.bool"builtins.bool*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‡

ClearField?pyspark.sql.connect.proto.catalog_pb2.FunctionExists.ClearField"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ù

WhichOneof?pyspark.sql.connect.proto.catalog_pb2.FunctionExists.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.FunctionExists"4pyspark.sql.connect.proto.catalog_pb2.FunctionExists*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrV

DESCRIPTOR?pyspark.sql.connect.proto.catalog_pb2.FunctionExists.DESCRIPTOR
Anyrã
FUNCTION_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.FunctionExists.FUNCTION_NAME_FIELD_NUMBER
builtins.int"builtins.intr
DB_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.FunctionExists.DB_NAME_FIELD_NUMBER
builtins.int"builtins.intrq
function_nameBpyspark.sql.connect.proto.catalog_pb2.FunctionExists.function_name
builtins.str"builtins.strre
db_name<pyspark.sql.connect.proto.catalog_pb2.FunctionExists.db_name
builtins.str"builtins.strÕ7
CreateExternalTable9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"builtins.object*π
schema@pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable0:property`*Ê
optionsApyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.options"
Any*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable0:property`*∂
__init__Bpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.__init__"
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*.

table_name
builtins.str"builtins.str *P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
sourceD
Union[builtins.str,None]
builtins.str"builtins.str
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *Ù	
HasFieldBpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.HasField"
builtins.bool"builtins.bool*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*Ä

field_nameÔ
öUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Æ

ClearFieldDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.ClearField"
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2¶

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneofô

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXô

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXô

WhichOneofDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*Ä
selfv
9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable"9pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXr[

DESCRIPTORDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.DESCRIPTOR
Anyrä
TABLE_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intr~
PATH_FIELD_NUMBERKpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.PATH_FIELD_NUMBER
builtins.int"builtins.intrÇ
SOURCE_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.SOURCE_FIELD_NUMBER
builtins.int"builtins.intrÇ
SCHEMA_FIELD_NUMBERMpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intrÑ
OPTIONS_FIELD_NUMBERNpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrp

table_nameDpyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.table_name
builtins.str"builtins.strrd
path>pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.path
builtins.str"builtins.strrh
source@pyspark.sql.connect.proto.catalog_pb2.CreateExternalTable.source
builtins.str"builtins.strâA
CreateTable1pyspark.sql.connect.proto.catalog_pb2.CreateTable"builtins.object*†
schema8pyspark.sql.connect.proto.catalog_pb2.CreateTable.schema"\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable0:property`*Õ
options9pyspark.sql.connect.proto.catalog_pb2.CreateTable.options"
Any*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable0:property`*ˆ
__init__:pyspark.sql.connect.proto.catalog_pb2.CreateTable.__init__"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*.

table_name
builtins.str"builtins.str *P
pathD
Union[builtins.str,None]
builtins.str"builtins.str
None *R
sourceD
Union[builtins.str,None]
builtins.str"builtins.str
None *W
descriptionD
Union[builtins.str,None]
builtins.str"builtins.str
None *≥
schema§
8Union[pyspark.sql.connect.proto.types_pb2.DataType,None]\
,pyspark.sql.connect.proto.types_pb2.DataType",pyspark.sql.connect.proto.types_pb2.DataType
None *Ã
optionsº
5Union[typing.Mapping[builtins.str,builtins.str],None]w
)typing.Mapping[builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str"typing.Mapping
None *ß
HasField:pyspark.sql.connect.proto.catalog_pb2.CreateTable.HasField"
builtins.bool"builtins.bool*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*Ã


field_nameª

ˆUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*·

ClearField<pyspark.sql.connect.proto.catalog_pb2.CreateTable.ClearField"
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*ò

field_nameá
“Union[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes2÷

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneofÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXÄ

WhichOneof<pyspark.sql.connect.proto.catalog_pb2.CreateTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*p
selff
1pyspark.sql.connect.proto.catalog_pb2.CreateTable"1pyspark.sql.connect.proto.catalog_pb2.CreateTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes0:typing.overloadXrS

DESCRIPTOR<pyspark.sql.connect.proto.catalog_pb2.CreateTable.DESCRIPTOR
AnyrÇ
TABLE_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.CreateTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrv
PATH_FIELD_NUMBERCpyspark.sql.connect.proto.catalog_pb2.CreateTable.PATH_FIELD_NUMBER
builtins.int"builtins.intrz
SOURCE_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.CreateTable.SOURCE_FIELD_NUMBER
builtins.int"builtins.intrÑ
DESCRIPTION_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.CreateTable.DESCRIPTION_FIELD_NUMBER
builtins.int"builtins.intrz
SCHEMA_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.CreateTable.SCHEMA_FIELD_NUMBER
builtins.int"builtins.intr|
OPTIONS_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.CreateTable.OPTIONS_FIELD_NUMBER
builtins.int"builtins.intrh

table_name<pyspark.sql.connect.proto.catalog_pb2.CreateTable.table_name
builtins.str"builtins.strr\
path6pyspark.sql.connect.proto.catalog_pb2.CreateTable.path
builtins.str"builtins.strr`
source8pyspark.sql.connect.proto.catalog_pb2.CreateTable.source
builtins.str"builtins.strrj
description=pyspark.sql.connect.proto.catalog_pb2.CreateTable.description
builtins.str"builtins.strù
DropTempView2pyspark.sql.connect.proto.catalog_pb2.DropTempView"builtins.object*Ù
__init__;pyspark.sql.connect.proto.catalog_pb2.DropTempView.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView*-
	view_name
builtins.str"builtins.str *ç

ClearField=pyspark.sql.connect.proto.catalog_pb2.DropTempView.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.DropTempView"2pyspark.sql.connect.proto.catalog_pb2.DropTempView*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.DropTempView.DESCRIPTOR
AnyrÅ
VIEW_NAME_FIELD_NUMBERIpyspark.sql.connect.proto.catalog_pb2.DropTempView.VIEW_NAME_FIELD_NUMBER
builtins.int"builtins.intrg
	view_name<pyspark.sql.connect.proto.catalog_pb2.DropTempView.view_name
builtins.str"builtins.strﬂ
DropGlobalTempView8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"builtins.object*Ü
__init__Apyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.__init__"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView*-
	view_name
builtins.str"builtins.str *ü

ClearFieldCpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.ClearField"
None*~
selft
8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView"8pyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.DESCRIPTOR
Anyrá
VIEW_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.VIEW_NAME_FIELD_NUMBER
builtins.int"builtins.intrm
	view_nameBpyspark.sql.connect.proto.catalog_pb2.DropGlobalTempView.view_name
builtins.str"builtins.strŸ
RecoverPartitions7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"builtins.object*Ñ
__init__@pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.__init__"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions*.

table_name
builtins.str"builtins.str *ú

ClearFieldBpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions"7pyspark.sql.connect.proto.catalog_pb2.RecoverPartitions*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.DESCRIPTOR
Anyrà
TABLE_NAME_FIELD_NUMBEROpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrn

table_nameBpyspark.sql.connect.proto.catalog_pb2.RecoverPartitions.table_name
builtins.str"builtins.strı
IsCached.pyspark.sql.connect.proto.catalog_pb2.IsCached"builtins.object*È
__init__7pyspark.sql.connect.proto.catalog_pb2.IsCached.__init__"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached*.

table_name
builtins.str"builtins.str *Å

ClearField9pyspark.sql.connect.proto.catalog_pb2.IsCached.ClearField"
None*j
self`
.pyspark.sql.connect.proto.catalog_pb2.IsCached".pyspark.sql.connect.proto.catalog_pb2.IsCached*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrP

DESCRIPTOR9pyspark.sql.connect.proto.catalog_pb2.IsCached.DESCRIPTOR
Anyr
TABLE_NAME_FIELD_NUMBERFpyspark.sql.connect.proto.catalog_pb2.IsCached.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intre

table_name9pyspark.sql.connect.proto.catalog_pb2.IsCached.table_name
builtins.str"builtins.strî

CacheTable0pyspark.sql.connect.proto.catalog_pb2.CacheTable"builtins.object*µ
storage_level>pyspark.sql.connect.proto.catalog_pb2.CacheTable.storage_level"f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable0:property`*ª
__init__9pyspark.sql.connect.proto.catalog_pb2.CacheTable.__init__"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*.

table_name
builtins.str"builtins.str *…
storage_level≥
=Union[pyspark.sql.connect.proto.common_pb2.StorageLevel,None]f
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel
None *ø
HasField9pyspark.sql.connect.proto.catalog_pb2.CacheTable.HasField"
builtins.bool"builtins.bool*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*‘

ClearField;pyspark.sql.connect.proto.catalog_pb2.CacheTable.ClearField"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*é

field_name˝
êUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ë

WhichOneof;pyspark.sql.connect.proto.catalog_pb2.CacheTable.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.CacheTable"0pyspark.sql.connect.proto.catalog_pb2.CacheTable*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrR

DESCRIPTOR;pyspark.sql.connect.proto.catalog_pb2.CacheTable.DESCRIPTOR
AnyrÅ
TABLE_NAME_FIELD_NUMBERHpyspark.sql.connect.proto.catalog_pb2.CacheTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intrá
STORAGE_LEVEL_FIELD_NUMBERKpyspark.sql.connect.proto.catalog_pb2.CacheTable.STORAGE_LEVEL_FIELD_NUMBER
builtins.int"builtins.intrg

table_name;pyspark.sql.connect.proto.catalog_pb2.CacheTable.table_name
builtins.str"builtins.str¢
UncacheTable2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"builtins.object*ı
__init__;pyspark.sql.connect.proto.catalog_pb2.UncacheTable.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable*.

table_name
builtins.str"builtins.str *ç

ClearField=pyspark.sql.connect.proto.catalog_pb2.UncacheTable.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.UncacheTable"2pyspark.sql.connect.proto.catalog_pb2.UncacheTable*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.UncacheTable.DESCRIPTOR
AnyrÉ
TABLE_NAME_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.UncacheTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intri

table_name=pyspark.sql.connect.proto.catalog_pb2.UncacheTable.table_name
builtins.str"builtins.strÂ

ClearCache0pyspark.sql.connect.proto.catalog_pb2.ClearCache"builtins.object*ø
__init__9pyspark.sql.connect.proto.catalog_pb2.ClearCache.__init__"
None*n
selfd
0pyspark.sql.connect.proto.catalog_pb2.ClearCache"0pyspark.sql.connect.proto.catalog_pb2.ClearCacherR

DESCRIPTOR;pyspark.sql.connect.proto.catalog_pb2.ClearCache.DESCRIPTOR
Any¢
RefreshTable2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"builtins.object*ı
__init__;pyspark.sql.connect.proto.catalog_pb2.RefreshTable.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable*.

table_name
builtins.str"builtins.str *ç

ClearField=pyspark.sql.connect.proto.catalog_pb2.RefreshTable.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.RefreshTable"2pyspark.sql.connect.proto.catalog_pb2.RefreshTable*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.RefreshTable.DESCRIPTOR
AnyrÉ
TABLE_NAME_FIELD_NUMBERJpyspark.sql.connect.proto.catalog_pb2.RefreshTable.TABLE_NAME_FIELD_NUMBER
builtins.int"builtins.intri

table_name=pyspark.sql.connect.proto.catalog_pb2.RefreshTable.table_name
builtins.str"builtins.stré
RefreshByPath3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"builtins.object*Ú
__init__<pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.__init__"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath*(
path
builtins.str"builtins.str *ê

ClearField>pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.ClearField"
None*t
selfj
3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath"3pyspark.sql.connect.proto.catalog_pb2.RefreshByPath*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrU

DESCRIPTOR>pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.DESCRIPTOR
Anyrx
PATH_FIELD_NUMBEREpyspark.sql.connect.proto.catalog_pb2.RefreshByPath.PATH_FIELD_NUMBER
builtins.int"builtins.intr^
path8pyspark.sql.connect.proto.catalog_pb2.RefreshByPath.path
builtins.str"builtins.str˝
CurrentCatalog4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"builtins.object*À
__init__=pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog.__init__"
None*v
selfl
4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog"4pyspark.sql.connect.proto.catalog_pb2.CurrentCatalogrV

DESCRIPTOR?pyspark.sql.connect.proto.catalog_pb2.CurrentCatalog.DESCRIPTOR
Any„
SetCurrentCatalog7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"builtins.object*Ü
__init__@pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.__init__"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog*0
catalog_name
builtins.str"builtins.str *ú

ClearFieldBpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.ClearField"
None*|
selfr
7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog"7pyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog*¡

field_name∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrY

DESCRIPTORBpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.DESCRIPTOR
Anyrå
CATALOG_NAME_FIELD_NUMBERQpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.CATALOG_NAME_FIELD_NUMBER
builtins.int"builtins.intrr
catalog_nameDpyspark.sql.connect.proto.catalog_pb2.SetCurrentCatalog.catalog_name
builtins.str"builtins.strô
ListCatalogs2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"builtins.object*ö
__init__;pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.__init__"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*S
patternD
Union[builtins.str,None]
builtins.str"builtins.str
None *≈
HasField;pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.HasField"
builtins.bool"builtins.bool*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*≥

ClearField=pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.ClearField"
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes*Ó

WhichOneof=pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.WhichOneof"h
!Union[Literal[builtins.str],None]7
Literal[builtins.str]	
builtins.str"builtins.str
None*r
selfh
2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs"2pyspark.sql.connect.proto.catalog_pb2.ListCatalogs*¬
oneof_group∞
4Union[Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrT

DESCRIPTOR=pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.DESCRIPTOR
Anyr}
PATTERN_FIELD_NUMBERGpyspark.sql.connect.proto.catalog_pb2.ListCatalogs.PATTERN_FIELD_NUMBER
builtins.int"builtins.intrc
pattern:pyspark.sql.connect.proto.catalog_pb2.ListCatalogs.pattern
builtins.str"builtins.strÀ
StorageLevel1pyspark.sql.connect.proto.common_pb2.StorageLevel"builtins.object*Ω
__init__:pyspark.sql.connect.proto.common_pb2.StorageLevel.__init__"
None*p
selff
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*.
use_disk
builtins.bool"builtins.bool *0

use_memory
builtins.bool"builtins.bool *2
use_off_heap
builtins.bool"builtins.bool *2
deserialized
builtins.bool"builtins.bool */
replication
builtins.int"builtins.int *£

ClearField<pyspark.sql.connect.proto.common_pb2.StorageLevel.ClearField"
None*p
selff
1pyspark.sql.connect.proto.common_pb2.StorageLevel"1pyspark.sql.connect.proto.common_pb2.StorageLevel*⁄

field_name…
ÏUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrS

DESCRIPTOR<pyspark.sql.connect.proto.common_pb2.StorageLevel.DESCRIPTOR
Anyr~
USE_DISK_FIELD_NUMBERGpyspark.sql.connect.proto.common_pb2.StorageLevel.USE_DISK_FIELD_NUMBER
builtins.int"builtins.intrÇ
USE_MEMORY_FIELD_NUMBERIpyspark.sql.connect.proto.common_pb2.StorageLevel.USE_MEMORY_FIELD_NUMBER
builtins.int"builtins.intrÜ
USE_OFF_HEAP_FIELD_NUMBERKpyspark.sql.connect.proto.common_pb2.StorageLevel.USE_OFF_HEAP_FIELD_NUMBER
builtins.int"builtins.intrÜ
DESERIALIZED_FIELD_NUMBERKpyspark.sql.connect.proto.common_pb2.StorageLevel.DESERIALIZED_FIELD_NUMBER
builtins.int"builtins.intrÑ
REPLICATION_FIELD_NUMBERJpyspark.sql.connect.proto.common_pb2.StorageLevel.REPLICATION_FIELD_NUMBER
builtins.int"builtins.intrf
use_disk:pyspark.sql.connect.proto.common_pb2.StorageLevel.use_disk
builtins.bool"builtins.boolrj

use_memory<pyspark.sql.connect.proto.common_pb2.StorageLevel.use_memory
builtins.bool"builtins.boolrn
use_off_heap>pyspark.sql.connect.proto.common_pb2.StorageLevel.use_off_heap
builtins.bool"builtins.boolrn
deserialized>pyspark.sql.connect.proto.common_pb2.StorageLevel.deserialized
builtins.bool"builtins.boolrj
replication=pyspark.sql.connect.proto.common_pb2.StorageLevel.replication
builtins.int"builtins.int˚
ResourceInformation8pyspark.sql.connect.proto.common_pb2.ResourceInformation"builtins.object*Ê
	addressesBpyspark.sql.connect.proto.common_pb2.ResourceInformation.addresses"
Any*~
selft
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation0:property`*ù
__init__Apyspark.sql.connect.proto.common_pb2.ResourceInformation.__init__"
None*~
selft
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation*(
name
builtins.str"builtins.str *ô
	addressesá
)Union[typing.Iterable[builtins.str],None]N
typing.Iterable[builtins.str]
builtins.str"builtins.str"typing.Iterable
None *≈

ClearFieldCpyspark.sql.connect.proto.common_pb2.ResourceInformation.ClearField"
None*~
selft
8pyspark.sql.connect.proto.common_pb2.ResourceInformation"8pyspark.sql.connect.proto.common_pb2.ResourceInformation*Á

field_name÷
bUnion[Literal[builtins.str],Literal[builtins.bytes],Literal[builtins.str],Literal[builtins.bytes]]7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytes7
Literal[builtins.str]	
builtins.str"builtins.str=
Literal[builtins.bytes]	 
builtins.bytes"builtins.bytesrZ

DESCRIPTORCpyspark.sql.connect.proto.common_pb2.ResourceInformation.DESCRIPTOR
Anyr}
NAME_FIELD_NUMBERJpyspark.sql.connect.proto.common_pb2.ResourceInformation.NAME_FIELD_NUMBER
builtins.int"builtins.intrá
ADDRESSES_FIELD_NUMBEROpyspark.sql.connect.proto.common_pb2.ResourceInformation.ADDRESSES_FIELD_NUMBER
builtins.int"builtins.intrc
name=pyspark.sql.connect.proto.common_pb2.ResourceInformation.name
builtins.str"builtins.strò
)add_SparkConnectServiceServicer_to_serverQpyspark.sql.connect.proto.base_pb2_grpc.add_SparkConnectServiceServicer_to_server*
servicer*

server*z
__path__"pyspark.sql.connect.proto.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*ï
__annotations__)pyspark.sql.connect.proto.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*=
grpc,pyspark.sql.connect.proto.base_pb2_grpc.grpc
Any*G
spark_dot_connect_dot_base__pb2"pyspark.sql.connect.proto.base_pb2 *D

DESCRIPTOR-pyspark.sql.connect.proto.base_pb2.DESCRIPTOR
Any