
torch.distributed._tensor.opsá/
OpSchema-torch.distributed._tensor._op_schema.OpSchema"builtins.object*Ü
	args_spec7torch.distributed._tensor._op_schema.OpSchema.args_spec"«
Ebuiltins.tuple[torch.distributed._tensor.placement_types.DTensorSpec]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec"builtins.tuple*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema0:property`*¸
args_strategy;torch.distributed._tensor._op_schema.OpSchema.args_strategy"µ
?builtins.tuple[torch.distributed._tensor._op_schema.OpStrategy]b
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy"builtins.tuple*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema0:property`*¬
__repr__6torch.distributed._tensor._op_schema.OpSchema.__repr__"
builtins.str"builtins.str*`^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*¿
__str__5torch.distributed._tensor._op_schema.OpSchema.__str__"
builtins.str"builtins.str*`^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*¿
__post_init__;torch.distributed._tensor._op_schema.OpSchema.__post_init__"
None*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*≠
#arg_type_tensor_or_tensor_list_likeQtorch.distributed._tensor._op_schema.OpSchema.arg_type_tensor_or_tensor_list_like"
builtins.bool"builtins.bool*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*)
arg_idx
builtins.int"builtins.int*ˆ
return_type_tuple_tensor_likeKtorch.distributed._tensor._op_schema.OpSchema.return_type_tuple_tensor_like"
builtins.bool"builtins.bool*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*‡
return_type_tensor@torch.distributed._tensor._op_schema.OpSchema.return_type_tensor"
builtins.bool"builtins.bool*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema* 
__hash__6torch.distributed._tensor._op_schema.OpSchema.__hash__"
builtins.int"builtins.int*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*Ê
__eq__4torch.distributed._tensor._op_schema.OpSchema.__eq__"
builtins.bool"builtins.bool*`^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*$"
builtins.object"builtins.object*Ì
gen_fake_args;torch.distributed._tensor._op_schema.OpSchema.gen_fake_args"¥
*TypeAlias[builtins.tuple[builtins.object]]U
builtins.tuple[builtins.object]"
builtins.object"builtins.object"builtins.tuple"-torch.distributed._tensor._op_schema.ArgsType*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*®
gen_fake_kwargs=torch.distributed._tensor._op_schema.OpSchema.gen_fake_kwargs"Î
6TypeAlias[builtins.dict[builtins.str,builtins.object]]~
+builtins.dict[builtins.str,builtins.object]
builtins.str"builtins.str"
builtins.object"builtins.object"builtins.dict"/torch.distributed._tensor._op_schema.KwargsType*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*€
!_inplace_rewrap_schema_suggestionOtorch.distributed._tensor._op_schema.OpSchema._inplace_rewrap_schema_suggestion"
None*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*q
origin_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*í
__init__6torch.distributed._tensor._op_schema.OpSchema.__init__"
None*h
self^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*6
op.
torch._ops.OpOverload"torch._ops.OpOverload*∆
args_schema¥
*TypeAlias[builtins.tuple[builtins.object]]U
builtins.tuple[builtins.object]"
builtins.object"builtins.object"builtins.tuple"-torch.distributed._tensor._op_schema.ArgsType*ˇ
kwargs_schemaÎ
6TypeAlias[builtins.dict[builtins.str,builtins.object]]~
+builtins.dict[builtins.str,builtins.object]
builtins.str"builtins.str"
builtins.object"builtins.object"builtins.dict"/torch.distributed._tensor._op_schema.KwargsType*÷
schema_info¬
BUnion[torch.distributed._tensor._op_schema.RuntimeSchemaInfo,None]p
6torch.distributed._tensor._op_schema.RuntimeSchemaInfo"6torch.distributed._tensor._op_schema.RuntimeSchemaInfo
None 8rf
op0torch.distributed._tensor._op_schema.OpSchema.op.
torch._ops.OpOverload"torch._ops.OpOverloadrˇ
args_schema9torch.distributed._tensor._op_schema.OpSchema.args_schema¥
*TypeAlias[builtins.tuple[builtins.object]]U
builtins.tuple[builtins.object]"
builtins.object"builtins.object"builtins.tuple"-torch.distributed._tensor._op_schema.ArgsTyper∫
kwargs_schema;torch.distributed._tensor._op_schema.OpSchema.kwargs_schemaÎ
6TypeAlias[builtins.dict[builtins.str,builtins.object]]~
+builtins.dict[builtins.str,builtins.object]
builtins.str"builtins.str"
builtins.object"builtins.object"builtins.dict"/torch.distributed._tensor._op_schema.KwargsTyperç
schema_info9torch.distributed._tensor._op_schema.OpSchema.schema_info¬
BUnion[torch.distributed._tensor._op_schema.RuntimeSchemaInfo,None]p
6torch.distributed._tensor._op_schema.RuntimeSchemaInfo"6torch.distributed._tensor._op_schema.RuntimeSchemaInfo
Nonerh
has_symints9torch.distributed._tensor._op_schema.OpSchema.has_symints
builtins.bool"builtins.boolrÙ
__dataclass_fields__Btorch.distributed._tensor._op_schema.OpSchema.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictŸ

OpStrategy/torch.distributed._tensor._op_schema.OpStrategy"1torch.distributed._tensor._op_schema.StrategyType*ò
__init__8torch.distributed._tensor._op_schema.OpStrategy.__init__"
None*l
selfb
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*Ÿ

strategies»
Ebuiltins.list[torch.distributed._tensor._op_schema.PlacementStrategy]p
6torch.distributed._tensor._op_schema.PlacementStrategy"6torch.distributed._tensor._op_schema.PlacementStrategy"builtins.list*∆
__str__7torch.distributed._tensor._op_schema.OpStrategy.__str__"
builtins.str"builtins.str*db
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*‹
max_num_shards>torch.distributed._tensor._op_schema.OpStrategy.max_num_shards"
builtins.int"builtins.int*l
selfb
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*`

mesh_shape:torch.distributed._tensor._op_schema.OpStrategy.mesh_shape*
self0:property`*T
ndim4torch.distributed._tensor._op_schema.OpStrategy.ndim*
self0:property`*V
shape5torch.distributed._tensor._op_schema.OpStrategy.shape*
self0:property`rì

strategies:torch.distributed._tensor._op_schema.OpStrategy.strategies»
Ebuiltins.list[torch.distributed._tensor._op_schema.PlacementStrategy]p
6torch.distributed._tensor._op_schema.PlacementStrategy"6torch.distributed._tensor._op_schema.PlacementStrategy"builtins.listR
StrategyType1torch.distributed._tensor._op_schema.StrategyType"builtins.objectÒ
Partial1torch.distributed._tensor.placement_types.Partial"3torch.distributed._tensor.placement_types.Placement*∂
_reduce_value?torch.distributed._tensor.placement_types.Partial._reduce_value",
torch._tensor.Tensor"torch._tensor.Tensor*p
selff
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*æ
_reduce_shard_valueEtorch.distributed._tensor.placement_types.Partial._reduce_shard_value",
torch._tensor.Tensor"torch._tensor.Tensor*p
selff
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*z

shard_specj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement*º
_partition_valueBtorch.distributed._tensor.placement_types.Partial._partition_value",
torch._tensor.Tensor"torch._tensor.Tensor*p
selff
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*Ú
__eq__8torch.distributed._tensor.placement_types.Partial.__eq__"
builtins.bool"builtins.bool*hf
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*$"
builtins.object"builtins.object*÷
__hash__:torch.distributed._tensor.placement_types.Partial.__hash__"
builtins.int"builtins.int*p
selff
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*Œ
__repr__:torch.distributed._tensor.placement_types.Partial.__repr__"
builtins.str"builtins.str*hf
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*Ã
__str__9torch.distributed._tensor.placement_types.Partial.__str__"
builtins.str"builtins.str*hf
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*Ò
__init__:torch.distributed._tensor.placement_types.Partial.__init__"
None*p
selff
1torch.distributed._tensor.placement_types.Partial"1torch.distributed._tensor.placement_types.Partial*-
	reduce_op
builtins.str"builtins.str 8rf
	reduce_op;torch.distributed._tensor.placement_types.Partial.reduce_op
builtins.str"builtins.strr¯
__dataclass_fields__Ftorch.distributed._tensor.placement_types.Partial.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict—
	Placement3torch.distributed._tensor.placement_types.Placement"builtins.object*Ø
is_shard<torch.distributed._tensor.placement_types.Placement.is_shard"
builtins.bool"builtins.bool*t
selfj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement*O
dimD
Union[builtins.int,None]
builtins.int"builtins.int
None *Ê
is_replicate@torch.distributed._tensor.placement_types.Placement.is_replicate"
builtins.bool"builtins.bool*t
selfj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement*‚

is_partial>torch.distributed._tensor.placement_types.Placement.is_partial"
builtins.bool"builtins.bool*t
selfj
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement¡
	Replicate3torch.distributed._tensor.placement_types.Replicate"3torch.distributed._tensor.placement_types.Placement*¯
__eq__:torch.distributed._tensor.placement_types.Replicate.__eq__"
builtins.bool"builtins.bool*lj
3torch.distributed._tensor.placement_types.Replicate"3torch.distributed._tensor.placement_types.Replicate*$"
builtins.object"builtins.object*‹
__hash__<torch.distributed._tensor.placement_types.Replicate.__hash__"
builtins.int"builtins.int*t
selfj
3torch.distributed._tensor.placement_types.Replicate"3torch.distributed._tensor.placement_types.Replicate*‘
__repr__<torch.distributed._tensor.placement_types.Replicate.__repr__"
builtins.str"builtins.str*lj
3torch.distributed._tensor.placement_types.Replicate"3torch.distributed._tensor.placement_types.Replicate*“
__str__;torch.distributed._tensor.placement_types.Replicate.__str__"
builtins.str"builtins.str*lj
3torch.distributed._tensor.placement_types.Replicate"3torch.distributed._tensor.placement_types.Replicate*ƒ
_replicate_tensorEtorch.distributed._tensor.placement_types.Replicate._replicate_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*t
selfj
3torch.distributed._tensor.placement_types.Replicate"3torch.distributed._tensor.placement_types.Replicate*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int8r˙
__dataclass_fields__Htorch.distributed._tensor.placement_types.Replicate.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictπ(
Shard/torch.distributed._tensor.placement_types.Shard"3torch.distributed._tensor.placement_types.Placement*á
_split_tensor=torch.distributed._tensor.placement_types.Shard._split_tensor"˙
FTuple[builtins.list[torch._tensor.Tensor],builtins.list[builtins.int]]b
#builtins.list[torch._tensor.Tensor],
torch._tensor.Tensor"torch._tensor.Tensor"builtins.listJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*,

num_chunks
builtins.int"builtins.int*2
with_padding
builtins.bool"builtins.bool *0

contiguous
builtins.bool"builtins.bool *í
_local_shard_size_on_dimHtorch.distributed._tensor.placement_types.Shard._local_shard_size_on_dim"`
 Tuple[builtins.int,builtins.int]
builtins.int"builtins.int
builtins.int"builtins.int*-
size_on_dim
builtins.int"builtins.int*,

num_chunks
builtins.int"builtins.int*&
rank
builtins.int"builtins.int*3
return_offset
builtins.bool"builtins.bool 0:staticmethodh*∞
_shard_tensor=torch.distributed._tensor.placement_types.Shard._shard_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*Î
_reduce_shard_tensorDtorch.distributed._tensor.placement_types.Shard._reduce_shard_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*8
tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*+
	reduce_op
builtins.str"builtins.str**
mesh_dim
builtins.int"builtins.int*´
_to_replicate_tensorDtorch.distributed._tensor.placement_types.Shard._to_replicate_tensor",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*>
local_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*e
current_logical_shapeJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*Ò
_replicate_to_shardCtorch.distributed._tensor.placement_types.Shard._replicate_to_shard",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*>
local_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*-
shard_index
builtins.int"builtins.int*÷
_to_new_shard_dimAtorch.distributed._tensor.placement_types.Shard._to_new_shard_dim",
torch._tensor.Tensor"torch._tensor.Tensor*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*>
local_tensor,
torch._tensor.Tensor"torch._tensor.Tensor*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh**
mesh_dim
builtins.int"builtins.int*e
current_logical_shapeJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*/
new_shard_dim
builtins.int"builtins.int*Ï
__eq__6torch.distributed._tensor.placement_types.Shard.__eq__"
builtins.bool"builtins.bool*db
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*$"
builtins.object"builtins.object*–
__hash__8torch.distributed._tensor.placement_types.Shard.__hash__"
builtins.int"builtins.int*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*»
__repr__8torch.distributed._tensor.placement_types.Shard.__repr__"
builtins.str"builtins.str*db
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*∆
__str__7torch.distributed._tensor.placement_types.Shard.__str__"
builtins.str"builtins.str*db
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*„
__init__8torch.distributed._tensor.placement_types.Shard.__init__"
None*l
selfb
/torch.distributed._tensor.placement_types.Shard"/torch.distributed._tensor.placement_types.Shard*%
dim
builtins.int"builtins.int8rX
dim3torch.distributed._tensor.placement_types.Shard.dim
builtins.int"builtins.intrˆ
__dataclass_fields__Dtorch.distributed._tensor.placement_types.Shard.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictÆV

DeviceMesh(torch.distributed.device_mesh.DeviceMesh"builtins.object*Ü
__init__1torch.distributed.device_mesh.DeviceMesh.__init__"
None*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*-
device_type
builtins.str"builtins.str*⁄
meshœ
ËUnion[torch._tensor.Tensor,TypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]]],
torch._tensor.Tensor"torch._tensor.Tensor±
ÃTypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]]∏
¡TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]≈	
∂Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]”
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArrayÇ
znumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]]”
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArray".numpy._typing._nested_sequence._NestedSequenceU
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.object’
Lnumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]U
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.object".numpy._typing._nested_sequence._NestedSequence"(numpy._typing._array_like._DualArrayLike"#numpy._typing._array_like.ArrayLike*õ
mesh_dim_namesÑ
(Union[builtins.tuple[builtins.str],None]L
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple
None *3
_init_backend
builtins.bool"builtins.bool *o
_get_or_create_default_groupEtorch.distributed.device_mesh.DeviceMesh._get_or_create_default_group*
self*_
_init_process_groups=torch.distributed.device_mesh.DeviceMesh._init_process_groups*
self*Ì
	__enter__2torch.distributed.device_mesh.DeviceMesh.__enter__"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*¿
__exit__1torch.distributed.device_mesh.DeviceMesh.__exit__"
None*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*	
Any*	
Any*	
Any*≥
__repr__1torch.distributed.device_mesh.DeviceMesh.__repr__"
builtins.str"builtins.str*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*G
__hash__1torch.distributed.device_mesh.DeviceMesh.__hash__*
self*◊
__eq__/torch.distributed.device_mesh.DeviceMesh.__eq__"
builtins.bool"builtins.bool*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*$"
builtins.object"builtins.object*ó
__getitem__4torch.distributed.device_mesh.DeviceMesh.__getitem__"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*VT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*£†
0Union[builtins.str,builtins.tuple[builtins.str]]
builtins.str"builtins.strL
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple*Ù
	get_group2torch.distributed.device_mesh.DeviceMesh.get_group"R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*
mesh_dimo
%Union[builtins.int,builtins.str,None]
builtins.int"builtins.int
builtins.str"builtins.str
None *«
get_all_groups7torch.distributed.device_mesh.DeviceMesh.get_all_groups"õ
6builtins.list[torch._C._distributed_c10d.ProcessGroup]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup"builtins.list*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*Œ

from_group3torch.distributed.device_mesh.DeviceMesh.from_group"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*Á
group€
eUnion[torch._C._distributed_c10d.ProcessGroup,builtins.list[torch._C._distributed_c10d.ProcessGroup]]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroupõ
6builtins.list[torch._C._distributed_c10d.ProcessGroup]R
'torch._C._distributed_c10d.ProcessGroup"'torch._C._distributed_c10d.ProcessGroup"builtins.list*-
device_type
builtins.str"builtins.str*Î
meshﬁ
ÌUnion[torch._tensor.Tensor,TypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]],None],
torch._tensor.Tensor"torch._tensor.Tensor±
ÃTypeAlias[TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]]∏
¡TypeAlias[Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]]≈	
∂Union[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType],numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]],numpy._typing._array_like._T,numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]]”
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArrayÇ
znumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType]]”
Jnumpy._typing._array_like._SupportsArray[numpy._typing._array_like._DType][
 numpy._typing._array_like._DType(
numpy.dtype[Any]
Any"numpy.dtype"numpy.dtype"(numpy._typing._array_like._SupportsArray".numpy._typing._nested_sequence._NestedSequenceU
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.object’
Lnumpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._T]U
numpy._typing._array_like._T"
builtins.object"builtins.object"builtins.object".numpy._typing._nested_sequence._NestedSequence"(numpy._typing._array_like._DualArrayLike"#numpy._typing._array_like.ArrayLike
None *õ
mesh_dim_namesÑ
(Union[builtins.tuple[builtins.str],None]L
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple
None 0:staticmethodh*â
size-torch.distributed.device_mesh.DeviceMesh.size"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*T
mesh_dimD
Union[builtins.int,None]
builtins.int"builtins.int
None *¡
ndim-torch.distributed.device_mesh.DeviceMesh.ndim"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh0:property`*Û
shape.torch.distributed.device_mesh.DeviceMesh.shape"L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh0:property`*ª
get_rank1torch.distributed.device_mesh.DeviceMesh.get_rank"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*»
get_local_rank7torch.distributed.device_mesh.DeviceMesh.get_local_rank"
builtins.int"builtins.int*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*
mesh_dimo
%Union[builtins.int,builtins.str,None]
builtins.int"builtins.int
builtins.str"builtins.str
None *≠
get_coordinate7torch.distributed.device_mesh.DeviceMesh.get_coordinate"Å
'Union[builtins.list[builtins.int],None]J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
None*^
selfT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshra
device_type4torch.distributed.device_mesh.DeviceMesh.device_type
builtins.str"builtins.strrc
mesh-torch.distributed.device_mesh.DeviceMesh.mesh,
torch._tensor.Tensor"torch._tensor.Tensorr–
mesh_dim_names7torch.distributed.device_mesh.DeviceMesh.mesh_dim_namesÑ
(Union[builtins.tuple[builtins.str],None]L
builtins.tuple[builtins.str]
builtins.str"builtins.str"builtins.tuple
NonerÅ
_flatten_mesh_list;torch.distributed.device_mesh.DeviceMesh._flatten_mesh_list.
builtins.tuple[Any]
Any"builtins.tupler‡
_parent_mesh5torch.distributed.device_mesh.DeviceMesh._parent_meshò
4Union[torch.distributed.device_mesh.DeviceMesh,None]T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh
Noner_

_thread_id3torch.distributed.device_mesh.DeviceMesh._thread_id
builtins.int"builtins.intr’
_coordinate_on_dim;torch.distributed.device_mesh.DeviceMesh._coordinate_on_dimÅ
'Union[builtins.list[builtins.int],None]J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list
NonerV
_dim_group_infos9torch.distributed.device_mesh.DeviceMesh._dim_group_infos
Anyr@
_hash.torch.distributed.device_mesh.DeviceMesh._hash
Any

MaskBuffer6torch.distributed._tensor.ops.embedding_ops.MaskBuffer"builtins.object*o
materialize_maskGtorch.distributed._tensor.ops.embedding_ops.MaskBuffer.materialize_mask*
self*
mask*]
release_maskCtorch.distributed._tensor.ops.embedding_ops.MaskBuffer.release_mask*
self*e

apply_maskAtorch.distributed._tensor.ops.embedding_ops.MaskBuffer.apply_mask*
self*

tensor*ª
__init__?torch.distributed._tensor.ops.embedding_ops.MaskBuffer.__init__"
None*z
selfp
6torch.distributed._tensor.ops.embedding_ops.MaskBuffer"6torch.distributed._tensor.ops.embedding_ops.MaskBuffer*h
data\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None 8r°
data;torch.distributed._tensor.ops.embedding_ops.MaskBuffer.data\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
Noner˝
__dataclass_fields__Ktorch.distributed._tensor.ops.embedding_ops.MaskBuffer.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictâ
PlacementStrategy6torch.distributed._tensor._op_schema.PlacementStrategy"builtins.object*“
output_specBtorch.distributed._tensor._op_schema.PlacementStrategy.output_spec"n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*z
selfp
6torch.distributed._tensor._op_schema.PlacementStrategy"6torch.distributed._tensor._op_schema.PlacementStrategy0:cached_property`*Ê

input_specAtorch.distributed._tensor._op_schema.PlacementStrategy.input_spec"n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*z
selfp
6torch.distributed._tensor._op_schema.PlacementStrategy"6torch.distributed._tensor._op_schema.PlacementStrategy*)
index
builtins.int"builtins.int *€
__str__>torch.distributed._tensor._op_schema.PlacementStrategy.__str__"
builtins.str"builtins.str*rp
6torch.distributed._tensor._op_schema.PlacementStrategy"6torch.distributed._tensor._op_schema.PlacementStrategy* 

__init__?torch.distributed._tensor._op_schema.PlacementStrategy.__init__"
None*z
selfp
6torch.distributed._tensor._op_schema.PlacementStrategy"6torch.distributed._tensor._op_schema.PlacementStrategy*æ
output_specs´
éUnion[torch.distributed._tensor.placement_types.DTensorSpec,builtins.tuple[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]]]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec•
Qbuiltins.tuple[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]]ø
AUnion[torch.distributed._tensor.placement_types.DTensorSpec,None]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec
None"builtins.tuple*¿
input_specs¨
RUnion[typing.Sequence[torch.distributed._tensor.placement_types.DTensorSpec],None]…
Ftyping.Sequence[torch.distributed._tensor.placement_types.DTensorSpec]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec"typing.Sequence
None *Ú
redistribute_costÿ
8Union[builtins.list[builtins.list[builtins.float]],None]è
,builtins.list[builtins.list[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list"builtins.list
None 8rÅ
output_specsCtorch.distributed._tensor._op_schema.PlacementStrategy.output_specs´
éUnion[torch.distributed._tensor.placement_types.DTensorSpec,builtins.tuple[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]]]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec•
Qbuiltins.tuple[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]]ø
AUnion[torch.distributed._tensor.placement_types.DTensorSpec,None]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec
None"builtins.tuplerÄ
input_specsBtorch.distributed._tensor._op_schema.PlacementStrategy.input_specs¨
RUnion[typing.Sequence[torch.distributed._tensor.placement_types.DTensorSpec],None]…
Ftyping.Sequence[torch.distributed._tensor.placement_types.DTensorSpec]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec"typing.Sequence
Noner∏
redistribute_costHtorch.distributed._tensor._op_schema.PlacementStrategy.redistribute_costÿ
8Union[builtins.list[builtins.list[builtins.float]],None]è
,builtins.list[builtins.list[builtins.float]]P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list"builtins.list
Noner˝
__dataclass_fields__Ktorch.distributed._tensor._op_schema.PlacementStrategy.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict˘<
DTensorSpec5torch.distributed._tensor.placement_types.DTensorSpec"builtins.object*^
__post_init__Ctorch.distributed._tensor.placement_types.DTensorSpec.__post_init__*
self*è
__setattr__Atorch.distributed._tensor.placement_types.DTensorSpec.__setattr__"
Any*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*&
attr
builtins.str"builtins.str*
value
Any*Ê

_hash_impl@torch.distributed._tensor.placement_types.DTensorSpec._hash_impl"
builtins.int"builtins.int*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*‚
__hash__>torch.distributed._tensor.placement_types.DTensorSpec.__hash__"
builtins.int"builtins.int*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*˛
__eq__<torch.distributed._tensor.placement_types.DTensorSpec.__eq__"
builtins.bool"builtins.bool*pn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*$"
builtins.object"builtins.object*ÿ
__str__=torch.distributed._tensor.placement_types.DTensorSpec.__str__"
builtins.str"builtins.str*pn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*Ï
shape;torch.distributed._tensor.placement_types.DTensorSpec.shape"
torch._C.Size"torch._C.Size*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec0:property`*ú
stride<torch.distributed._tensor.placement_types.DTensorSpec.stride"L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec0:property`*Ë
ndim:torch.distributed._tensor.placement_types.DTensorSpec.ndim"
builtins.int"builtins.int*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec0:property`*Ù

num_shards@torch.distributed._tensor.placement_types.DTensorSpec.num_shards"
builtins.int"builtins.int*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec0:property`*Æ
device_meshAtorch.distributed._tensor.placement_types.DTensorSpec.device_mesh"T
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec0:property`*ú
dim_map=torch.distributed._tensor.placement_types.DTensorSpec.dim_map"J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec0:property`*ñ
sums:torch.distributed._tensor.placement_types.DTensorSpec.sums"J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec0:property`*ˇ
from_dim_mapBtorch.distributed._tensor.placement_types.DTensorSpec.from_dim_map"n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*ø
clsµ
;Type[torch.distributed._tensor.placement_types.DTensorSpec]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec"type*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*W
dim_mapJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*T
sumsJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*ÿ
tensor_metaƒ
WUnion[TypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]],None]‹
KTypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]]‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype"4torch.distributed._tensor.placement_types.TensorMeta
None 0:classmethodp*^
is_replicatedCtorch.distributed._tensor.placement_types.DTensorSpec.is_replicated*
self*X

is_sharded@torch.distributed._tensor.placement_types.DTensorSpec.is_sharded*
self*∑
shallow_copy_with_tensor_metaStorch.distributed._tensor.placement_types.DTensorSpec.shallow_copy_with_tensor_meta"n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*÷
tensor_metaƒ
WUnion[TypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]],None]‹
KTypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]]‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype"4torch.distributed._tensor.placement_types.TensorMeta
None*ﬁ
__init__>torch.distributed._tensor.placement_types.DTensorSpec.__init__"
None*x
selfn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*“

placements¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*ÿ
tensor_metaƒ
WUnion[TypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]],None]‹
KTypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]]‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype"4torch.distributed._tensor.placement_types.TensorMeta
None 8rò
mesh:torch.distributed._tensor.placement_types.DTensorSpec.meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMeshrí

placements@torch.distributed._tensor.placement_types.DTensorSpec.placements¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tupleró
tensor_metaAtorch.distributed._tensor.placement_types.DTensorSpec.tensor_metaƒ
WUnion[TypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]],None]‹
KTypeAlias[Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]]‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype"4torch.distributed._tensor.placement_types.TensorMeta
Nonerä
_hash;torch.distributed._tensor.placement_types.DTensorSpec._hashD
Union[builtins.int,None]
builtins.int"builtins.int
Noner¸
__dataclass_fields__Jtorch.distributed._tensor.placement_types.DTensorSpec.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictÖ
Enum	enum.Enum"builtins.object*l
nameenum.Enum.name"
builtins.str"builtins.str* 
self
	enum.Enum"	enum.Enum0:_magic_enum_attr`*Y
valueenum.Enum.value"
Any* 
self
	enum.Enum"	enum.Enum0:_magic_enum_attr`*•
	_missing_enum.Enum._missing_"
Any*:
cls1
Type[enum.Enum]
	enum.Enum"	enum.Enum"type*-
value"
builtins.object"builtins.object0:classmethodp*å
_generate_next_value_enum.Enum._generate_next_value_"
Any*&
name
builtins.str"builtins.str*'
start
builtins.int"builtins.int*'
count
builtins.int"builtins.int*=
last_values,
builtins.list[Any]
Any"builtins.list0:staticmethodh*‚
__new__enum.Enum.__new__"5
enum.Enum.Self
	enum.Enum"	enum.Enum"	enum.Enum*^
clsU
Type[enum.Enum.Self]5
enum.Enum.Self
	enum.Enum"	enum.Enum"	enum.Enum"type*-
value"
builtins.object"builtins.object*ä
__dir__enum.Enum.__dir__"J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list* 
self
	enum.Enum"	enum.Enum*ë

__format__enum.Enum.__format__"
builtins.str"builtins.str* 
self
	enum.Enum"	enum.Enum*-
format_spec
builtins.str"builtins.str*©
__reduce_ex__enum.Enum.__reduce_ex__".
builtins.tuple[Any]
Any"builtins.tuple* 
self
	enum.Enum"	enum.Enum*-
proto"
builtins.object"builtins.object@Hbenum.EnumMetar8
_name_enum.Enum._name_
builtins.str"builtins.strr%
_value_enum.Enum._value_
Anyræ
_ignore_enum.Enum._ignore_ù
/Union[builtins.str,builtins.list[builtins.str]]
builtins.str"builtins.strJ
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.listr:
_order_enum.Enum._order_
builtins.str"builtins.strr>
	__order__enum.Enum.__order__
builtins.str"builtins.strµ
Sequencetyping.Sequence"typing.Collection"typing.Reversible*©
indextyping.Sequence.index"
builtins.int"builtins.int*Å
selfw
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence*
value
Any*)
start
builtins.int"builtins.int *(
stop
builtins.int"builtins.int *‘
counttyping.Sequence.count"
builtins.int"builtins.int*Å
selfw
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence*
value
Any*Ì
__contains__typing.Sequence.__contains__"
builtins.bool"builtins.bool*yw
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence*$"
builtins.object"builtins.object*ò
__iter__typing.Sequence.__iter__"w
typing.Iterator[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Iterator*yw
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence*†
__reversed__typing.Sequence.__reversed__"w
typing.Iterator[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Iterator*yw
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence2æ
__getitem__typing.Sequence.__getitem__¨
__getitem__typing.Sequence.__getitem__"E
typing._T_co"
builtins.object"builtins.object"builtins.object*yw
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence*
builtins.int"builtins.int0:overload:abstractmethod@X‚
__getitem__typing.Sequence.__getitem__"w
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence*yw
typing.Sequence[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Sequence*" 
builtins.slice"builtins.slice0:overload:abstractmethod@XPˇ	
RuntimeSchemaInfo6torch.distributed._tensor._op_schema.RuntimeSchemaInfo"builtins.object*‘
__init__?torch.distributed._tensor._op_schema.RuntimeSchemaInfo.__init__"
None*z
selfp
6torch.distributed._tensor._op_schema.RuntimeSchemaInfo"6torch.distributed._tensor._op_schema.RuntimeSchemaInfo*1
static_argnum
builtins.int"builtins.int *ô
static_kwargkeyÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
None *2
needs_pytree
builtins.bool"builtins.bool 8rs
static_argnumDtorch.distributed._tensor._op_schema.RuntimeSchemaInfo.static_argnum
builtins.int"builtins.intr›
static_kwargkeyFtorch.distributed._tensor._op_schema.RuntimeSchemaInfo.static_kwargkeyÅ
'Union[builtins.list[builtins.str],None]J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list
Noners
needs_pytreeCtorch.distributed._tensor._op_schema.RuntimeSchemaInfo.needs_pytree
builtins.bool"builtins.boolr˝
__dataclass_fields__Ktorch.distributed._tensor._op_schema.RuntimeSchemaInfo.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict„
TupleStrategy2torch.distributed._tensor._op_schema.TupleStrategy"1torch.distributed._tensor._op_schema.StrategyType*í
__init__;torch.distributed._tensor._op_schema.TupleStrategy.__init__"
None*r
selfh
2torch.distributed._tensor._op_schema.TupleStrategy"2torch.distributed._tensor._op_schema.TupleStrategy* 
childsΩ
Btyping.Sequence[torch.distributed._tensor._op_schema.StrategyType]f
1torch.distributed._tensor._op_schema.StrategyType"1torch.distributed._tensor._op_schema.StrategyType"typing.Sequence*œ
__str__:torch.distributed._tensor._op_schema.TupleStrategy.__str__"
builtins.str"builtins.str*jh
2torch.distributed._tensor._op_schema.TupleStrategy"2torch.distributed._tensor._op_schema.TupleStrategyrÉ
childs9torch.distributed._tensor._op_schema.TupleStrategy.childsΩ
Btyping.Sequence[torch.distributed._tensor._op_schema.StrategyType]f
1torch.distributed._tensor._op_schema.StrategyType"1torch.distributed._tensor._op_schema.StrategyType"typing.Sequenceﬂ
	Reduction0torch.distributed._tensor.ops.math_ops.Reduction"	enum.EnumHr[
NONE5torch.distributed._tensor.ops.math_ops.Reduction.NONE
builtins.int"builtins.intr[
MEAN5torch.distributed._tensor.ops.math_ops.Reduction.MEAN
builtins.int"builtins.intrY
SUM4torch.distributed._tensor.ops.math_ops.Reduction.SUM
builtins.int"builtins.int™
NormReduction4torch.distributed._tensor.ops.math_ops.NormReduction"builtins.object*Ô
__init__=torch.distributed._tensor.ops.math_ops.NormReduction.__init__"
None*v
selfl
4torch.distributed._tensor.ops.math_ops.NormReduction"4torch.distributed._tensor.ops.math_ops.NormReduction*°
	norm_typeë
/Union[builtins.int,builtins.float,builtins.str]
builtins.int"builtins.int 
builtins.float"builtins.float
builtins.str"builtins.str8rﬂ
	norm_type>torch.distributed._tensor.ops.math_ops.NormReduction.norm_typeë
/Union[builtins.int,builtins.float,builtins.str]
builtins.int"builtins.int 
builtins.float"builtins.float
builtins.str"builtins.strr˚
__dataclass_fields__Itorch.distributed._tensor.ops.math_ops.NormReduction.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictƒ
OutputSharding3torch.distributed._tensor._op_schema.OutputSharding"builtins.object*ˆ	
__init__<torch.distributed._tensor._op_schema.OutputSharding.__init__"
None*t
selfj
3torch.distributed._tensor._op_schema.OutputSharding"3torch.distributed._tensor._op_schema.OutputSharding*´
output_specô
üTypeAlias[Union[torch.distributed._tensor.placement_types.DTensorSpec,typing.Sequence[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]],None]]Ω
îUnion[torch.distributed._tensor.placement_types.DTensorSpec,typing.Sequence[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]],None]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpecß
Rtyping.Sequence[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]]ø
AUnion[torch.distributed._tensor.placement_types.DTensorSpec,None]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec
None"typing.Sequence
None"3torch.distributed._tensor._op_schema.OutputSpecType*√
redistribute_schemaß
9Union[torch.distributed._tensor._op_schema.OpSchema,None]^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema
None *8
needs_redistribute
builtins.bool"builtins.bool 8rÍ
output_spec?torch.distributed._tensor._op_schema.OutputSharding.output_specô
üTypeAlias[Union[torch.distributed._tensor.placement_types.DTensorSpec,typing.Sequence[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]],None]]Ω
îUnion[torch.distributed._tensor.placement_types.DTensorSpec,typing.Sequence[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]],None]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpecß
Rtyping.Sequence[Union[torch.distributed._tensor.placement_types.DTensorSpec,None]]ø
AUnion[torch.distributed._tensor.placement_types.DTensorSpec,None]n
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec
None"typing.Sequence
None"3torch.distributed._tensor._op_schema.OutputSpecTyperà
redistribute_schemaGtorch.distributed._tensor._op_schema.OutputSharding.redistribute_schemaß
9Union[torch.distributed._tensor._op_schema.OpSchema,None]^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema
Noner|
needs_redistributeFtorch.distributed._tensor._op_schema.OutputSharding.needs_redistribute
builtins.bool"builtins.boolr˙
__dataclass_fields__Htorch.distributed._tensor._op_schema.OutputSharding.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict·
Iterabletyping.Iterable"builtins.object*¨
__iter__typing.Iterable.__iter__"w
typing.Iterator[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Iterator*yw
typing.Iterable[typing._T_co]E
typing._T_co"
builtins.object"builtins.object"builtins.object"typing.Iterable0:abstractmethod@8PXù<
Tensortorch._tensor.Tensor"torch._C.TensorBase*E
__deepcopy__!torch._tensor.Tensor.__deepcopy__*
self*
memo*H
__reduce_ex__"torch._tensor.Tensor.__reduce_ex__*
self*	
proto*1
storagetorch._tensor.Tensor.storage*
self*?
_typed_storage#torch._tensor.Tensor._typed_storage*
self*T
_reduce_ex_internal(torch._tensor.Tensor._reduce_ex_internal*
self*	
proto*F
__setstate__!torch._tensor.Tensor.__setstate__*
self*	
state*1
__repr__torch._tensor.Tensor.__repr__* * *y
backwardtorch._tensor.Tensor.backward*
self*
gradient *
retain_graph *
create_graph *
inputs *G
register_hook"torch._tensor.Tensor.register_hook*
self*
hook*q
"register_post_accumulate_grad_hook7torch._tensor.Tensor.register_post_accumulate_grad_hook*
self*
hook*A
	reinforcetorch._tensor.Tensor.reinforce*
self*

reward*5
	is_sharedtorch._tensor.Tensor.is_shared*
self*=
share_memory_"torch._tensor.Tensor.share_memory_*
self*R
module_load torch._tensor.Tensor.module_load*
self*	
other*
assign *3
__reversed__!torch._tensor.Tensor.__reversed__* *§
normtorch._tensor.Tensor.norm"
Any*6
self,
torch._tensor.Tensor"torch._tensor.Tensor*~
pu
'Union[builtins.float,builtins.str,None] 
builtins.float"builtins.float
builtins.str"builtins.str
None *
dim
Any *
keepdim
Any *
dtype
Any *8
solvetorch._tensor.Tensor.solve*
self*	
other*8
lstsqtorch._tensor.Tensor.lstsq*
self*	
other*=
eigtorch._tensor.Tensor.eig*
self*
eigenvectors *C
symeigtorch._tensor.Tensor.symeig*
self*
eigenvectors *E
lutorch._tensor.Tensor.lu*
self*
pivot *
	get_infos *Ì
stfttorch._tensor.Tensor.stft"
Any*6
self,
torch._tensor.Tensor"torch._tensor.Tensor*'
n_fft
builtins.int"builtins.int*V

hop_lengthD
Union[builtins.int,None]
builtins.int"builtins.int
None *V

win_lengthD
Union[builtins.int,None]
builtins.int"builtins.int
None *j
window\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None *,
center
builtins.bool"builtins.bool *,
pad_mode
builtins.str"builtins.str *0

normalized
builtins.bool"builtins.bool *W
onesidedG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *]
return_complexG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *Ï
istfttorch._tensor.Tensor.istft"
Any*6
self,
torch._tensor.Tensor"torch._tensor.Tensor*'
n_fft
builtins.int"builtins.int*V

hop_lengthD
Union[builtins.int,None]
builtins.int"builtins.int
None *V

win_lengthD
Union[builtins.int,None]
builtins.int"builtins.int
None *j
window\
 Union[torch._tensor.Tensor,None],
torch._tensor.Tensor"torch._tensor.Tensor
None *,
center
builtins.bool"builtins.bool *0

normalized
builtins.bool"builtins.bool *W
onesidedG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *R
lengthD
Union[builtins.int,None]
builtins.int"builtins.int
None *4
return_complex
builtins.bool"builtins.bool *:
resizetorch._tensor.Tensor.resize*
self*	
sizes*A
	resize_astorch._tensor.Tensor.resize_as*
self*

tensor*H
splittorch._tensor.Tensor.split*
self*

split_size*	
dim *s
uniquetorch._tensor.Tensor.unique*
self*
sorted *
return_inverse *
return_counts *	
dim *}
unique_consecutive'torch._tensor.Tensor.unique_consecutive*
self*
return_inverse *
return_counts *	
dim *n
__rsub__torch._tensor.Tensor.__rsub__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*n
__rdiv__torch._tensor.Tensor.__rdiv__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*n
__rmod__torch._tensor.Tensor.__rmod__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*H

__format__torch._tensor.Tensor.__format__*
self*
format_spec*n
__rpow__torch._tensor.Tensor.__rpow__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*v
__floordiv__!torch._tensor.Tensor.__floordiv__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*x
__rfloordiv__"torch._tensor.Tensor.__rfloordiv__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*t
__rlshift__ torch._tensor.Tensor.__rlshift__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*t
__rrshift__ torch._tensor.Tensor.__rrshift__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*t
__rmatmul__ torch._tensor.Tensor.__rmatmul__* * 0:=_handle_torch_function_and_wrap_type_error_to_not_implemented*)
__len__torch._tensor.Tensor.__len__* *+
__iter__torch._tensor.Tensor.__iter__* *3
__hash__torch._tensor.Tensor.__hash__*
self*1
__dir__torch._tensor.Tensor.__dir__*
self*B
	__array__torch._tensor.Tensor.__array__*
self*
dtype *J
__array_wrap__#torch._tensor.Tensor.__array_wrap__*
self*	
array*5
__contains__!torch._tensor.Tensor.__contains__* * *a
__cuda_array_interface__-torch._tensor.Tensor.__cuda_array_interface__*
self0:property`*;
storage_type!torch._tensor.Tensor.storage_type*
self*F
refine_names!torch._tensor.Tensor.refine_names*
self*	
names*>
align_totorch._tensor.Tensor.align_to*
self*	
names*I
	unflattentorch._tensor.Tensor.unflatten*
self*
dim*	
sizes*L
rename_torch._tensor.Tensor.rename_*
self*	
names*

rename_map*J
renametorch._tensor.Tensor.rename*
self*	
names*

rename_map*=
to_sparse_coo"torch._tensor.Tensor.to_sparse_coo*
self*5
	dim_ordertorch._tensor.Tensor.dim_order*
self*U
_update_names"torch._tensor.Tensor._update_names*
self*	
names*
inplace*Ü
__torch_function__'torch._tensor.Tensor.__torch_function__*
cls*
func*	
types*

args *
kwargs 0:classmethodp*E

__dlpack__torch._tensor.Tensor.__dlpack__*
self*
stream *’
__dlpack_device__&torch._tensor.Tensor.__dlpack_device__"`
 Tuple[enum.IntEnum,builtins.int]
enum.IntEnum"enum.IntEnum
builtins.int"builtins.int*6
self,
torch._tensor.Tensor"torch._tensor.Tensorrr
detachtorch._tensor.Tensor.detachK
CallableType[builtins.function]&
builtins.function"builtins.functionrt
detach_torch._tensor.Tensor.detach_K
CallableType[builtins.function]&
builtins.function"builtins.functionr:
__rtruediv__!torch._tensor.Tensor.__rtruediv__
Anyr~
__itruediv__!torch._tensor.Tensor.__itruediv__K
CallableType[builtins.function]&
builtins.function"builtins.functionr0
__pow__torch._tensor.Tensor.__pow__
Anyr2
__ipow__torch._tensor.Tensor.__ipow__
Anyrt
__pos__torch._tensor.Tensor.__pos__K
CallableType[builtins.function]&
builtins.function"builtins.functionrt
__neg__torch._tensor.Tensor.__neg__K
CallableType[builtins.function]&
builtins.function"builtins.functionrt
__abs__torch._tensor.Tensor.__abs__K
CallableType[builtins.function]&
builtins.function"builtins.functionr[
__array_priority__'torch._tensor.Tensor.__array_priority__
builtins.int"builtins.inträ
__torch_dispatch__'torch._tensor.Tensor.__torch_dispatch__K
CallableType[builtins.function]&
builtins.function"builtins.functionrK

__module__torch._tensor.Tensor.__module__
builtins.str"builtins.strrä
_post_accumulate_grad_hooks0torch._tensor.Tensor._post_accumulate_grad_hooks9
builtins.dict[Any,Any]
Any
Any"builtins.dict©
DimSpec.torch.distributed._tensor.ops.view_ops.DimSpec"builtins.object*‚
inputs5torch.distributed._tensor.ops.view_ops.DimSpec.inputs"¥
?typing.Iterable[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Iterable*j
self`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec8rı
__dataclass_fields__Ctorch.distributed._tensor.ops.view_ops.DimSpec.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictÈ
	Singleton0torch.distributed._tensor.ops.view_ops.Singleton".torch.distributed._tensor.ops.view_ops.DimSpec8r˜
__dataclass_fields__Etorch.distributed._tensor.ops.view_ops.Singleton.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict∏
InputDim/torch.distributed._tensor.ops.view_ops.InputDim".torch.distributed._tensor.ops.view_ops.DimSpec*È
__init__8torch.distributed._tensor.ops.view_ops.InputDim.__init__"
None*l
selfb
/torch.distributed._tensor.ops.view_ops.InputDim"/torch.distributed._tensor.ops.view_ops.InputDim*+
	input_dim
builtins.int"builtins.int8rd
	input_dim9torch.distributed._tensor.ops.view_ops.InputDim.input_dim
builtins.int"builtins.intrˆ
__dataclass_fields__Dtorch.distributed._tensor.ops.view_ops.InputDim.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict≠
	Broadcast0torch.distributed._tensor.ops.view_ops.Broadcast".torch.distributed._tensor.ops.view_ops.DimSpec*¯
new4torch.distributed._tensor.ops.view_ops.Broadcast.new"`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*∞
cls¶
6Type[torch.distributed._tensor.ops.view_ops.Broadcast]d
0torch.distributed._tensor.ops.view_ops.Broadcast"0torch.distributed._tensor.ops.view_ops.Broadcast"type*i
dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec**
dim_size
builtins.int"builtins.int0:classmethodp*Ë
inputs7torch.distributed._tensor.ops.view_ops.Broadcast.inputs"¥
?typing.Iterable[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Iterable*n
selfd
0torch.distributed._tensor.ops.view_ops.Broadcast"0torch.distributed._tensor.ops.view_ops.Broadcast*÷
__init__9torch.distributed._tensor.ops.view_ops.Broadcast.__init__"
None*n
selfd
0torch.distributed._tensor.ops.view_ops.Broadcast"0torch.distributed._tensor.ops.view_ops.Broadcast*i
dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec**
dim_size
builtins.int"builtins.int8rù
dim4torch.distributed._tensor.ops.view_ops.Broadcast.dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpecrc
dim_size9torch.distributed._tensor.ops.view_ops.Broadcast.dim_size
builtins.int"builtins.intr˜
__dataclass_fields__Etorch.distributed._tensor.ops.view_ops.Broadcast.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictõ
NewDim-torch.distributed._tensor.ops.view_ops.NewDim".torch.distributed._tensor.ops.view_ops.DimSpec*˝
new1torch.distributed._tensor.ops.view_ops.NewDim.new"`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*ß
clsù
3Type[torch.distributed._tensor.ops.view_ops.NewDim]^
-torch.distributed._tensor.ops.view_ops.NewDim"-torch.distributed._tensor.ops.view_ops.NewDim"type*&
size
builtins.int"builtins.int0:classmethodp*ﬁ
__init__6torch.distributed._tensor.ops.view_ops.NewDim.__init__"
None*h
self^
-torch.distributed._tensor.ops.view_ops.NewDim"-torch.distributed._tensor.ops.view_ops.NewDim*&
size
builtins.int"builtins.int8rX
size2torch.distributed._tensor.ops.view_ops.NewDim.size
builtins.int"builtins.intrÙ
__dataclass_fields__Btorch.distributed._tensor.ops.view_ops.NewDim.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictÜ
Repeat-torch.distributed._tensor.ops.view_ops.Repeat".torch.distributed._tensor.ops.view_ops.DimSpec*È
new1torch.distributed._tensor.ops.view_ops.Repeat.new"`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*ß
clsù
3Type[torch.distributed._tensor.ops.view_ops.Repeat]^
-torch.distributed._tensor.ops.view_ops.Repeat"-torch.distributed._tensor.ops.view_ops.Repeat"type*i
dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*'
times
builtins.int"builtins.int0:classmethodp*ﬂ
inputs4torch.distributed._tensor.ops.view_ops.Repeat.inputs"¥
?typing.Iterable[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Iterable*h
self^
-torch.distributed._tensor.ops.view_ops.Repeat"-torch.distributed._tensor.ops.view_ops.Repeat*–
__init__6torch.distributed._tensor.ops.view_ops.Repeat.__init__"
None*h
self^
-torch.distributed._tensor.ops.view_ops.Repeat"-torch.distributed._tensor.ops.view_ops.Repeat*o
	input_dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*'
times
builtins.int"builtins.int8r¶
	input_dim7torch.distributed._tensor.ops.view_ops.Repeat.input_dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpecrZ
times3torch.distributed._tensor.ops.view_ops.Repeat.times
builtins.int"builtins.intrÙ
__dataclass_fields__Btorch.distributed._tensor.ops.view_ops.Repeat.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictÎ
Flatten.torch.distributed._tensor.ops.view_ops.Flatten".torch.distributed._tensor.ops.view_ops.DimSpec*õ
new2torch.distributed._tensor.ops.view_ops.Flatten.new"`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*™
cls†
4Type[torch.distributed._tensor.ops.view_ops.Flatten]`
.torch.distributed._tensor.ops.view_ops.Flatten".torch.distributed._tensor.ops.view_ops.Flatten"type*ø
dims¥
?typing.Sequence[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Sequence0:classmethodp*‚
inputs5torch.distributed._tensor.ops.view_ops.Flatten.inputs"¥
?typing.Iterable[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Iterable*j
self`
.torch.distributed._tensor.ops.view_ops.Flatten".torch.distributed._tensor.ops.view_ops.Flatten*Å
__init__7torch.distributed._tensor.ops.view_ops.Flatten.__init__"
None*j
self`
.torch.distributed._tensor.ops.view_ops.Flatten".torch.distributed._tensor.ops.view_ops.Flatten*≈

input_dims¥
?typing.Sequence[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Sequence8r˛

input_dims9torch.distributed._tensor.ops.view_ops.Flatten.input_dims¥
?typing.Sequence[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Sequencerı
__dataclass_fields__Ctorch.distributed._tensor.ops.view_ops.Flatten.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dictç
Split,torch.distributed._tensor.ops.view_ops.Split".torch.distributed._tensor.ops.view_ops.DimSpec*¬
new0torch.distributed._tensor.ops.view_ops.Split.new"`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*§
clsö
2Type[torch.distributed._tensor.ops.view_ops.Split]\
,torch.distributed._tensor.ops.view_ops.Split",torch.distributed._tensor.ops.view_ops.Split"type*i
dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*]
group_shapeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple*%
idx
builtins.int"builtins.int0:classmethodp*‹
inputs3torch.distributed._tensor.ops.view_ops.Split.inputs"¥
?typing.Iterable[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"typing.Iterable*f
self\
,torch.distributed._tensor.ops.view_ops.Split",torch.distributed._tensor.ops.view_ops.Split*å
__init__5torch.distributed._tensor.ops.view_ops.Split.__init__"
None*f
self\
,torch.distributed._tensor.ops.view_ops.Split",torch.distributed._tensor.ops.view_ops.Split*o
	input_dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec*π
group_shapeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape**
split_id
builtins.int"builtins.int8r•
	input_dim6torch.distributed._tensor.ops.view_ops.Split.input_dim`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpecrÒ
group_shape8torch.distributed._tensor.ops.view_ops.Split.group_shapeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shaper_
split_id5torch.distributed._tensor.ops.view_ops.Split.split_id
builtins.int"builtins.intrÛ
__dataclass_fields__Atorch.distributed._tensor.ops.view_ops.Split.__dataclass_fields__ó
2builtins.dict[builtins.str,dataclasses.Field[Any]]
builtins.str"builtins.str4
dataclasses.Field[Any]
Any"dataclasses.Field"builtins.dict®$

TensorMeta4torch.distributed._tensor.placement_types.TensorMeta"builtins.tuple*π
_replace=torch.distributed._tensor.placement_types.TensorMeta._replace"ì
8torch.distributed._tensor.placement_types.TensorMeta._NT‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype*ü
_selfì
8torch.distributed._tensor.placement_types.TensorMeta._NT‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype*+
shape
torch._C.Size"torch._C.Size *Z
strideL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple *-
dtype 
torch._C.dtype"torch._C.dtype *˚
__new__<torch.distributed._tensor.placement_types.TensorMeta.__new__"ì
8torch.distributed._tensor.placement_types.TensorMeta._NT‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype*È
_clsﬁ
>Type[torch.distributed._tensor.placement_types.TensorMeta._NT]ì
8torch.distributed._tensor.placement_types.TensorMeta._NT‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype"type*)
shape
torch._C.Size"torch._C.Size*X
strideL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple*+
dtype 
torch._C.dtype"torch._C.dtype*¬
_asdict<torch.distributed._tensor.placement_types.TensorMeta._asdict"W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*ü
_selfì
8torch.distributed._tensor.placement_types.TensorMeta._NT‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype*æ
_make:torch.distributed._tensor.placement_types.TensorMeta._make"ì
8torch.distributed._tensor.placement_types.TensorMeta._NT‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype*È
_clsﬁ
>Type[torch.distributed._tensor.placement_types.TensorMeta._NT]ì
8torch.distributed._tensor.placement_types.TensorMeta._NT‘
@Tuple[torch._C.Size,builtins.tuple[builtins.int],torch._C.dtype]
torch._C.Size"torch._C.SizeL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple 
torch._C.dtype"torch._C.dtype"type*>
iterable0
typing.Iterable[Any]
Any"typing.Iterable*
new
Any *
len
Any 0:classmethodprc
shape:torch.distributed._tensor.placement_types.TensorMeta.shape
torch._C.Size"torch._C.Sizerì
stride;torch.distributed._tensor.placement_types.TensorMeta.strideL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuplere
dtype:torch.distributed._tensor.placement_types.TensorMeta.dtype 
torch._C.dtype"torch._C.dtyperc
shape:torch.distributed._tensor.placement_types.TensorMeta.shape
torch._C.Size"torch._C.Sizerì
stride;torch.distributed._tensor.placement_types.TensorMeta.strideL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuplere
dtype:torch.distributed._tensor.placement_types.TensorMeta.dtype 
torch._C.dtype"torch._C.dtyper’
_fields<torch.distributed._tensor.placement_types.TensorMeta._fieldsã
-Tuple[builtins.str,builtins.str,builtins.str]
builtins.str"builtins.str
builtins.str"builtins.str
builtins.str"builtins.strr™
_field_typesAtorch.distributed._tensor.placement_types.TensorMeta._field_typesW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dictr∞
_field_defaultsDtorch.distributed._tensor.placement_types.TensorMeta._field_defaultsW
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dictre
_source<torch.distributed._tensor.placement_types.TensorMeta._source
builtins.str"builtins.strr∞
__annotations__Dtorch.distributed._tensor.placement_types.TensorMeta.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dictƒ
expand_to_full_mesh_op_strategyCtorch.distributed._tensor.ops.utils.expand_to_full_mesh_op_strategy"b
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*m
	op_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*≈
single_mesh_dim_strategies§
Qbuiltins.list[builtins.list[torch.distributed._tensor.placement_types.Placement]]ø
Bbuiltins.list[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.list"builtins.list*/
input_index
builtins.int"builtins.int *0

inplace_op
builtins.bool"builtins.bool k
register_op_strategy8torch.distributed._tensor.ops.utils.register_op_strategy*
op*
schema_info ¸
gen_einsum_strategiesBtorch.distributed._tensor.ops.basic_strategy.gen_einsum_strategies"b
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy**
equation
builtins.str"builtins.str*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*/
	linearity
builtins.bool"builtins.bool §
generate_redistribute_costs?torch.distributed._tensor.ops.utils.generate_redistribute_costs"P
builtins.list[builtins.float] 
builtins.float"builtins.float"builtins.list*t
src_strategyb
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*|
dst_specn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpecá
infer_broadcast_dims_map<torch.distributed._tensor.ops.utils.infer_broadcast_dims_map"J
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*0
common_shape
torch._C.Size"torch._C.Size*/
input_shape
torch._C.Size"torch._C.Size√
is_tensor_shardable7torch.distributed._tensor.ops.utils.is_tensor_shardable"
builtins.bool"builtins.bool*Y
shapeN
typing.Sequence[builtins.int]
builtins.int"builtins.int"typing.Sequence*x
specn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpecå
map_placements_after_broadcastBtorch.distributed._tensor.ops.utils.map_placements_after_broadcast"¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*“

placements¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*)
shape
torch._C.Size"torch._C.Size*b
broadcast_dims_mapJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.listÔ
as_list+torch.distributed._tensor.ops.utils.as_list"˘
`Union[builtins.list[builtins.object],UnboundType[torch.fx.immutable_collections.immutable_list]]S
builtins.list[builtins.object]"
builtins.object"builtins.object"builtins.list>
:UnboundType[torch.fx.immutable_collections.immutable_list]*∫
x≤
5Union[builtins.list[builtins.object],builtins.object]S
builtins.list[builtins.object]"
builtins.object"builtins.object"builtins.list"
builtins.object"builtins.object—
is_tensor_evenly_shardable>torch.distributed._tensor.ops.utils.is_tensor_evenly_shardable"
builtins.bool"builtins.bool*Y
shapeN
typing.Sequence[builtins.int]
builtins.int"builtins.int"typing.Sequence*x
specn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpecØ
normalize_dim1torch.distributed._tensor.ops.utils.normalize_dim"
builtins.int"builtins.int*%
dim
builtins.int"builtins.int*&
ndim
builtins.int"builtins.intÌ
normalize_dims2torch.distributed._tensor.ops.utils.normalize_dims"N
typing.Sequence[builtins.int]
builtins.int"builtins.int"typing.Sequence*Æ
dims£
1Union[builtins.int,typing.Sequence[builtins.int]]
builtins.int"builtins.intN
typing.Sequence[builtins.int]
builtins.int"builtins.int"typing.Sequence*&
ndim
builtins.int"builtins.intâ
normalize_to_torch_size;torch.distributed._tensor.ops.utils.normalize_to_torch_size"
torch._C.Size"torch._C.Size*
size
Any‘
replicate_reduction_dims?torch.distributed._tensor.ops.math_ops.replicate_reduction_dims"¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*“

placements¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*^
reduction_dimsJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.listƒ
map_placements_after_reductionEtorch.distributed._tensor.ops.math_ops.map_placements_after_reduction"¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*“

placements¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*^
reduction_dimsJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*b
reduction_dims_mapJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*˝
reduction_opÍ
STypeAlias[Union[torch.distributed._tensor.ops.math_ops.NormReduction,builtins.str]]ÿ
HUnion[torch.distributed._tensor.ops.math_ops.NormReduction,builtins.str]l
4torch.distributed._tensor.ops.math_ops.NormReduction"4torch.distributed._tensor.ops.math_ops.NormReduction
builtins.str"builtins.str"6torch.distributed._tensor.ops.math_ops.ReductionOpType’
get_placement_from_reduction_opFtorch.distributed._tensor.ops.math_ops.get_placement_from_reduction_op"j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement*˝
reduction_opÍ
STypeAlias[Union[torch.distributed._tensor.ops.math_ops.NormReduction,builtins.str]]ÿ
HUnion[torch.distributed._tensor.ops.math_ops.NormReduction,builtins.str]l
4torch.distributed._tensor.ops.math_ops.NormReduction"4torch.distributed._tensor.ops.math_ops.NormReduction
builtins.str"builtins.str"6torch.distributed._tensor.ops.math_ops.ReductionOpType‡
common_reduction_strategy@torch.distributed._tensor.ops.math_ops.common_reduction_strategy"b
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*v
input_strategyb
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*[
reduce_dimsJ
builtins.list[builtins.int]
builtins.int"builtins.int"builtins.list*.
keep_dim
builtins.bool"builtins.bool *6
reduction_linear
builtins.bool"builtins.bool *ˇ
reduction_opÍ
STypeAlias[Union[torch.distributed._tensor.ops.math_ops.NormReduction,builtins.str]]ÿ
HUnion[torch.distributed._tensor.ops.math_ops.NormReduction,builtins.str]l
4torch.distributed._tensor.ops.math_ops.NormReduction"4torch.distributed._tensor.ops.math_ops.NormReduction
builtins.str"builtins.str"6torch.distributed._tensor.ops.math_ops.ReductionOpType ◊
pointwise_rule9torch.distributed._tensor.ops.common_rules.pointwise_rule"j
3torch.distributed._tensor._op_schema.OutputSharding"3torch.distributed._tensor._op_schema.OutputSharding*m
	op_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*/
	linearity
builtins.bool"builtins.bool ì
is_tensor_dim_sharded9torch.distributed._tensor.ops.utils.is_tensor_dim_sharded"
builtins.bool"builtins.bool*x
specn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpec*%
dim
builtins.int"builtins.int‰
is_tensor_partial5torch.distributed._tensor.ops.utils.is_tensor_partial"
builtins.bool"builtins.bool*x
specn
5torch.distributed._tensor.placement_types.DTensorSpec"5torch.distributed._tensor.placement_types.DTensorSpecg
register_prop_rule6torch.distributed._tensor.ops.utils.register_prop_rule*
op*
schema_info Ñ
default_strategy9torch.distributed._tensor.ops.tensor_ops.default_strategy"f
1torch.distributed._tensor._op_schema.StrategyType"1torch.distributed._tensor._op_schema.StrategyType*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*m
	op_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchemaì
unshard_tensor_dim;torch.distributed._tensor.ops.tensor_ops.unshard_tensor_dim"¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*‘

placements√
Dtyping.Sequence[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"typing.Sequence*%
dim
builtins.int"builtins.intó
replicate_tensor_dim=torch.distributed._tensor.ops.tensor_ops.replicate_tensor_dim"¡
Cbuiltins.tuple[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"builtins.tuple*‘

placements√
Dtyping.Sequence[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"typing.Sequence*%
dim
builtins.int"builtins.int¨
normalize_shard_for_stackBtorch.distributed._tensor.ops.tensor_ops.normalize_shard_for_stack"√
Dtyping.Sequence[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"typing.Sequence*‘

placements√
Dtyping.Sequence[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"typing.Sequence*.

insert_dim
builtins.int"builtins.int ∏
pointwise_strategy>torch.distributed._tensor.ops.pointwise_ops.pointwise_strategy"b
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*m
	op_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*/
	linearity
builtins.bool"builtins.bool ∫
common_pointwise_strategyEtorch.distributed._tensor.ops.pointwise_ops.common_pointwise_strategy"b
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*h
args_schemaW
 typing.Sequence[builtins.object]"
builtins.object"builtins.object"typing.Sequence*y
followed_strategyb
/torch.distributed._tensor._op_schema.OpStrategy"/torch.distributed._tensor._op_schema.OpStrategy*-
	linearity
builtins.bool"builtins.boolô
linear_pointwise_strategyEtorch.distributed._tensor.ops.pointwise_ops.linear_pointwise_strategy"f
1torch.distributed._tensor._op_schema.StrategyType"1torch.distributed._tensor._op_schema.StrategyType*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*m
	op_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema∆
list_pointwise_strategyCtorch.distributed._tensor.ops.pointwise_ops.list_pointwise_strategy"f
1torch.distributed._tensor._op_schema.StrategyType"1torch.distributed._tensor._op_schema.StrategyType*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*m
	op_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema*/
	linearity
builtins.bool"builtins.bool £
list_linear_pointwise_strategyJtorch.distributed._tensor.ops.pointwise_ops.list_linear_pointwise_strategy"f
1torch.distributed._tensor._op_schema.StrategyType"1torch.distributed._tensor._op_schema.StrategyType*^
meshT
(torch.distributed.device_mesh.DeviceMesh"(torch.distributed.device_mesh.DeviceMesh*m
	op_schema^
-torch.distributed._tensor._op_schema.OpSchema"-torch.distributed._tensor._op_schema.OpSchema¶
prod(torch.distributed._tensor.ops.utils.prod"
builtins.int"builtins.int*V
xsN
typing.Iterable[builtins.int]
builtins.int"builtins.int"typing.IterableÀ
dim_pad_left3torch.distributed._tensor.ops.view_ops.dim_pad_left"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int**
min_dims
builtins.int"builtins.int£
dim_atleast_3d5torch.distributed._tensor.ops.view_ops.dim_atleast_3d"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int›
expand-torch.distributed._tensor.ops.view_ops.expand"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*π
input_shapeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape*≥
shapeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.ShapeË
normalize_sizes6torch.distributed._tensor.ops.view_ops.normalize_sizes"ß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape*Ú
sizesÊ
6Union[TypeAlias[builtins.tuple[builtins.int]],Unknown]ß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape œ
dim_flatten2torch.distributed._tensor.ops.view_ops.dim_flatten"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int*
	start_dim
Any *
end_dim
Any á
dim_movedim2torch.distributed._tensor.ops.view_ops.dim_movedim"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int*Ø
input£
1Union[builtins.int,typing.Sequence[builtins.int]]
builtins.int"builtins.intN
typing.Sequence[builtins.int]
builtins.int"builtins.int"typing.Sequence*µ
destination£
1Union[builtins.int,typing.Sequence[builtins.int]]
builtins.int"builtins.intN
typing.Sequence[builtins.int]
builtins.int"builtins.int"typing.Sequence—

dim_repeat1torch.distributed._tensor.ops.view_ops.dim_repeat"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int*≥
sizesß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.ShapeÕ

infer_size1torch.distributed._tensor.ops.view_ops.infer_size"ß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape*,

total_size
builtins.int"builtins.int*≥
sizesß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.ShapeÁ
view_groups2torch.distributed._tensor.ops.view_ops.view_groups"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*∑
	from_sizeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape*µ
to_sizeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.ShapeÔ
dim_tile/torch.distributed._tensor.ops.view_ops.dim_tile"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int*V
dimsL
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tupleÒ
dim_transpose4torch.distributed._tensor.ops.view_ops.dim_transpose"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int*&
dim1
builtins.int"builtins.int*&
dim2
builtins.int"builtins.int¸
dim_squeeze2torch.distributed._tensor.ops.view_ops.dim_squeeze"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*≥
shapeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape*O
dimD
Union[builtins.int,None]
builtins.int"builtins.int
None »
dim_unsqueeze4torch.distributed._tensor.ops.view_ops.dim_unsqueeze"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int*%
dim
builtins.int"builtins.intµ
dim_view_as_real7torch.distributed._tensor.ops.view_ops.dim_view_as_real"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*≥
shapeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shapeï
dim_reduction4torch.distributed._tensor.ops.view_ops.dim_reduction"±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*&
ndim
builtins.int"builtins.int*ƒ
dim_or_dims≤
6Union[builtins.int,typing.Sequence[builtins.int],None]
builtins.int"builtins.intN
typing.Sequence[builtins.int]
builtins.int"builtins.int"typing.Sequence
None*+
keepdim
builtins.bool"builtins.bool°
propagate_shape_and_shardingCtorch.distributed._tensor.ops.view_ops.propagate_shape_and_sharding"°
êTuple[typing.Sequence[torch.distributed._tensor.placement_types.Placement],typing.Sequence[torch.distributed._tensor.placement_types.Placement]]√
Dtyping.Sequence[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"typing.Sequence√
Dtyping.Sequence[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"typing.Sequence*ﬁ
input_src_placements√
Dtyping.Sequence[torch.distributed._tensor.placement_types.Placement]j
3torch.distributed._tensor.placement_types.Placement"3torch.distributed._tensor.placement_types.Placement"typing.Sequence*º
local_in_shapeß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape*º
rule±
ITypeAlias[builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]]≤
>builtins.tuple[torch.distributed._tensor.ops.view_ops.DimSpec]`
.torch.distributed._tensor.ops.view_ops.DimSpec".torch.distributed._tensor.ops.view_ops.DimSpec"builtins.tuple"-torch.distributed._tensor.ops.view_ops.DimMap*∏

mesh_sizesß
'TypeAlias[builtins.tuple[builtins.int]]L
builtins.tuple[builtins.int]
builtins.int"builtins.int"builtins.tuple",torch.distributed._tensor.ops.view_ops.Shape‰
register_op_strategy_map?torch.distributed._tensor.ops.view_ops.register_op_strategy_map"
None*D
aten_op_overload.
torch._ops.OpOverload"torch._ops.OpOverload*^
local_op_nameK
CallableType[builtins.function]&
builtins.function"builtins.function*÷
schema_info¬
BUnion[torch.distributed._tensor._op_schema.RuntimeSchemaInfo,None]p
6torch.distributed._tensor._op_schema.RuntimeSchemaInfo"6torch.distributed._tensor._op_schema.RuntimeSchemaInfo
None "≈
	dataclassdataclasses.dataclassâ
	dataclassdataclasses.dataclass"K
CallableType[builtins.function]&
builtins.function"builtins.function*

None0:overloadXÑ
	dataclassdataclasses.dataclass"g
Type[dataclasses._T]G
dataclasses._T"
builtins.object"builtins.object"builtins.object"type*ig
Type[dataclasses._T]G
dataclasses._T"
builtins.object"builtins.object"builtins.object"type0:overloadXç
	dataclassdataclasses.dataclass"K
CallableType[builtins.function]&
builtins.function"builtins.function**
init
builtins.bool"builtins.bool **
repr
builtins.bool"builtins.bool *(
eq
builtins.bool"builtins.bool *+
order
builtins.bool"builtins.bool *1
unsafe_hash
builtins.bool"builtins.bool *,
frozen
builtins.bool"builtins.bool 0:overloadX"Ç
fielddataclasses.field£
fielddataclasses.field"G
dataclasses._T"
builtins.object"builtins.object"builtins.object*T
defaultG
dataclasses._T"
builtins.object"builtins.object"builtins.object**
init
builtins.bool"builtins.bool **
repr
builtins.bool"builtins.bool *S
hashG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *-
compare
builtins.bool"builtins.bool *~
metadatan
#Union[typing.Mapping[Any,Any],None];
typing.Mapping[Any,Any]
Any
Any"typing.Mapping
None 0:overloadXØ
fielddataclasses.field"G
dataclasses._T"
builtins.object"builtins.object"builtins.object*`
default_factoryK
CallableType[builtins.function]&
builtins.function"builtins.function**
init
builtins.bool"builtins.bool **
repr
builtins.bool"builtins.bool *S
hashG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *-
compare
builtins.bool"builtins.bool *~
metadatan
#Union[typing.Mapping[Any,Any],None];
typing.Mapping[Any,Any]
Any
Any"typing.Mapping
None 0:overloadXç
fielddataclasses.field"
Any**
init
builtins.bool"builtins.bool **
repr
builtins.bool"builtins.bool *S
hashG
Union[builtins.bool,None]
builtins.bool"builtins.bool
None *-
compare
builtins.bool"builtins.bool *~
metadatan
#Union[typing.Mapping[Any,Any],None];
typing.Mapping[Any,Any]
Any
Any"typing.Mapping
None 0:overloadX"≈
casttyping.castﬂ
casttyping.cast"B
	typing._T"
builtins.object"builtins.object"builtins.object*f
typ]
Type[typing._T]B
	typing._T"
builtins.object"builtins.object"builtins.object"type*
val
Any0:overloadXc
casttyping.cast"
Any*%
typ
builtins.str"builtins.str*
val
Any0:overloadXi
casttyping.cast"
Any*+
typ"
builtins.object"builtins.object*
val
Any0:overloadX*~
__path__&torch.distributed._tensor.ops.__path__J
builtins.list[builtins.str]
builtins.str"builtins.str"builtins.list*ô
__annotations__-torch.distributed._tensor.ops.__annotations__W
builtins.dict[builtins.str,Any]
builtins.str"builtins.str
Any"builtins.dict*G
Optionaltyping.Optional*
typing._SpecialForm"typing._SpecialForm*
torchtorch *5
funcol)torch.distributed._functional_collectives *A
aten0torch.distributed._tensor.ops.embedding_ops.aten
Any*
	itertools	itertools *
mathmath *A
Tupletyping.Tuple*
typing._SpecialForm"typing._SpecialForm*A
Uniontyping.Union*
typing._SpecialForm"typing._SpecialForm*≤
LINEAR_REDUCTION_OP_MAP>torch.distributed._tensor.ops.math_ops.LINEAR_REDUCTION_OP_MAPW
builtins.dict[Any,builtins.str]
Any
builtins.str"builtins.str"builtins.dict*Ü
linear_pointwise_ops@torch.distributed._tensor.ops.pointwise_ops.linear_pointwise_ops,
builtins.list[Any]
Any"builtins.list*x
pointwise_ops9torch.distributed._tensor.ops.pointwise_ops.pointwise_ops,
builtins.list[Any]
Any"builtins.list*=
op.torch.distributed._tensor.ops.pointwise_ops.op
Any*v
for_each_ops8torch.distributed._tensor.ops.pointwise_ops.for_each_ops,
builtins.list[Any]
Any"builtins.list*ä
for_each_linearity_opsBtorch.distributed._tensor.ops.pointwise_ops.for_each_linearity_ops,
builtins.list[Any]
Any"builtins.list*p
	fused_ops5torch.distributed._tensor.ops.pointwise_ops.fused_ops,
builtins.list[Any]
Any"builtins.list*G
Callabletyping.Callable*
typing._SpecialForm"typing._SpecialForm*∑
dim_maps/torch.distributed._tensor.ops.view_ops.dim_maps˘
Nbuiltins.dict[CallableType[builtins.function],CallableType[builtins.function]]K
CallableType[builtins.function]&
builtins.function"builtins.functionK
CallableType[builtins.function]&
builtins.function"builtins.function"builtins.dict*
npnumpy 